{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"gpuType":"A100","authorship_tag":"ABX9TyM/+jL7MUmEe92tg4fvTKNY"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"178ca151fb0445c3aedba8030785d0f2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_76dba37fabc44256a9f9dcac0d98b445","IPY_MODEL_c1c8e4c4d3284c439345bf001d251784","IPY_MODEL_cd390bc42cfb497d9c49b3696ed950b1"],"layout":"IPY_MODEL_91d924b385e9469a89f8c1fcfa4240e3"}},"76dba37fabc44256a9f9dcac0d98b445":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4eb47e1bd66346a197ee0b16c5041eb3","placeholder":"​","style":"IPY_MODEL_64efe6168f3f4bcca3ea91975e6fd52d","value":"Optuna 튜닝 진행률:  34%"}},"c1c8e4c4d3284c439345bf001d251784":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_5702c0c83f2f4ba5b7807b5ada01779d","max":50,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a2851b8864ff430db73861660b73b064","value":17}},"cd390bc42cfb497d9c49b3696ed950b1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1423cd799fb84b21965d72584ea0ec38","placeholder":"​","style":"IPY_MODEL_874bcd3dd2174686a4b47dbb75b65e16","value":" 17/50 [04:37&lt;05:25,  9.86s/it]"}},"91d924b385e9469a89f8c1fcfa4240e3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4eb47e1bd66346a197ee0b16c5041eb3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"64efe6168f3f4bcca3ea91975e6fd52d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5702c0c83f2f4ba5b7807b5ada01779d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a2851b8864ff430db73861660b73b064":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1423cd799fb84b21965d72584ea0ec38":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"874bcd3dd2174686a4b47dbb75b65e16":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ae1e84ed6f4041ea896b353f030d0068":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8d833c96df2b49a183b5b0892aabe005","IPY_MODEL_353607436ea84b589bf951260b59840e","IPY_MODEL_432314ea3071498b87d69b0bb443eecb"],"layout":"IPY_MODEL_f98e9801da494a769e4e77e47d67ab93"}},"8d833c96df2b49a183b5b0892aabe005":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b143e74a61c341f197e102e9dda701c5","placeholder":"​","style":"IPY_MODEL_84fbcd9a485946c78929790fdff9adaf","value":"최종 모델 학습: 100%"}},"353607436ea84b589bf951260b59840e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6592ceacd7ab498482bf24848231215d","max":50,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3a698dbedde74f4e88e765ae4439bcca","value":50}},"432314ea3071498b87d69b0bb443eecb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b6a7cb3633604d7c841bd283df26ca3f","placeholder":"​","style":"IPY_MODEL_23c39fb7cd0a485a86c4c1ef7a7754bb","value":" 50/50 [00:55&lt;00:00,  1.10s/it]"}},"f98e9801da494a769e4e77e47d67ab93":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b143e74a61c341f197e102e9dda701c5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"84fbcd9a485946c78929790fdff9adaf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6592ceacd7ab498482bf24848231215d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3a698dbedde74f4e88e765ae4439bcca":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b6a7cb3633604d7c841bd283df26ca3f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"23c39fb7cd0a485a86c4c1ef7a7754bb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"af554182b7d742d491e76b07f2996a18":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f3c2f3f3bf634c1486682f8b83d068e2","IPY_MODEL_abb6acac279943848880d607c5c3dcb6","IPY_MODEL_b281b54710304bd0bf385445418a079c"],"layout":"IPY_MODEL_14b01ec7750942bb9fa00a32fd58edc6"}},"f3c2f3f3bf634c1486682f8b83d068e2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a0586fd8761d4b75a1f9f0f76ea8e0d5","placeholder":"​","style":"IPY_MODEL_7898208f0c3a4313bb612cb2f626ef37","value":"전체 데이터 예측: 100%"}},"abb6acac279943848880d607c5c3dcb6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_48dc1f5f18594bc38f5503d93829835b","max":176,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d69ae9c2f873468b990efcd0cc95e9ce","value":176}},"b281b54710304bd0bf385445418a079c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_950f51d4567542eb8e0f8f1516c04cd5","placeholder":"​","style":"IPY_MODEL_60f45dd70fbb478e8f01a3fd5f8e64b2","value":" 176/176 [00:00&lt;00:00, 360.17it/s]"}},"14b01ec7750942bb9fa00a32fd58edc6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a0586fd8761d4b75a1f9f0f76ea8e0d5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7898208f0c3a4313bb612cb2f626ef37":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"48dc1f5f18594bc38f5503d93829835b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d69ae9c2f873468b990efcd0cc95e9ce":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"950f51d4567542eb8e0f8f1516c04cd5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"60f45dd70fbb478e8f01a3fd5f8e64b2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d46bcb21d80f4233beaec1866499795d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fac142ac3e0641b6bb8c9c8e1a8bbc21","IPY_MODEL_44ee57b445d743f0942ad1c7547c2e61","IPY_MODEL_93a026d4e637403293f2e01cc1d107e7"],"layout":"IPY_MODEL_d7250746be2c4c958be480c976c9ed72"}},"fac142ac3e0641b6bb8c9c8e1a8bbc21":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_704fd8d6e4a4401d946e84a8071ae30c","placeholder":"​","style":"IPY_MODEL_90b1ae063ec34558886db38de621aca8","value":"Optuna 튜닝 진행률:  24%"}},"44ee57b445d743f0942ad1c7547c2e61":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_b40782821c624ed0abc2768f15db2d9b","max":50,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0bc1b5ec1b2648d2899303fa42fba761","value":12}},"93a026d4e637403293f2e01cc1d107e7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3dd355fd3ceb4bcab9f9f1653b8fcde4","placeholder":"​","style":"IPY_MODEL_821b57988e354ff9ab7ad7200960729a","value":" 12/50 [02:06&lt;03:38,  5.74s/it]"}},"d7250746be2c4c958be480c976c9ed72":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"704fd8d6e4a4401d946e84a8071ae30c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"90b1ae063ec34558886db38de621aca8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b40782821c624ed0abc2768f15db2d9b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0bc1b5ec1b2648d2899303fa42fba761":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3dd355fd3ceb4bcab9f9f1653b8fcde4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"821b57988e354ff9ab7ad7200960729a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"df8b8e9922454f9180bf1e143a51f3f3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6debe8fda9914744aa1cf46a64b63458","IPY_MODEL_bbfc02cf0cb94541b90790b7cd0effe9","IPY_MODEL_fccc49d72a5844d8822f921a2767e628"],"layout":"IPY_MODEL_cdaf1c0a33654449af26b060c207544f"}},"6debe8fda9914744aa1cf46a64b63458":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_93e21452933f455d8660a4b3fab8cfd4","placeholder":"​","style":"IPY_MODEL_05a311f6f5884fc59b7139d297418042","value":"최종 모델 학습: 100%"}},"bbfc02cf0cb94541b90790b7cd0effe9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a32abc3c73d8457995f39a6d63044176","max":50,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2b9e7f569f894b51809ac702aa926b81","value":50}},"fccc49d72a5844d8822f921a2767e628":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2c710c74f47f45699bfdbdb738ccf91e","placeholder":"​","style":"IPY_MODEL_4577301fb76c4341be5e44fd9952dd14","value":" 50/50 [00:52&lt;00:00,  1.03s/it]"}},"cdaf1c0a33654449af26b060c207544f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"93e21452933f455d8660a4b3fab8cfd4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"05a311f6f5884fc59b7139d297418042":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a32abc3c73d8457995f39a6d63044176":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2b9e7f569f894b51809ac702aa926b81":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2c710c74f47f45699bfdbdb738ccf91e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4577301fb76c4341be5e44fd9952dd14":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c9fb1713a3d34d37a80fcba3fc06570b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6fb5f2fee5ed42ab855980773368856a","IPY_MODEL_88372c60e3fe420d84d207bd96d7bc18","IPY_MODEL_33e931ed80c34a97b87aa76926d1cda1"],"layout":"IPY_MODEL_1bd07409a8ea43fd8d281d19a43a2a02"}},"6fb5f2fee5ed42ab855980773368856a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_358511fa5ef545a4b8769943f217eb72","placeholder":"​","style":"IPY_MODEL_6e802c7042c241cc8b950ed53a29b09b","value":"전체 데이터 예측: 100%"}},"88372c60e3fe420d84d207bd96d7bc18":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_69276f9420fa488f866b7ca65b3442f5","max":176,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0f0a159ee5474fe18162fed78bffa1d5","value":176}},"33e931ed80c34a97b87aa76926d1cda1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_612e6f96d5cf47c69a792d440cb45b43","placeholder":"​","style":"IPY_MODEL_92319c02721c49ae8f76998b77e65423","value":" 176/176 [00:00&lt;00:00, 280.88it/s]"}},"1bd07409a8ea43fd8d281d19a43a2a02":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"358511fa5ef545a4b8769943f217eb72":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6e802c7042c241cc8b950ed53a29b09b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"69276f9420fa488f866b7ca65b3442f5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0f0a159ee5474fe18162fed78bffa1d5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"612e6f96d5cf47c69a792d440cb45b43":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"92319c02721c49ae8f76998b77e65423":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f250b8f6319b49b89a0ba42d3184a950":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b4b5bb0d83484aec94e982e06721b732","IPY_MODEL_3691c263e2124eecb299869de0bf4b5c","IPY_MODEL_8d8a843daef7459abfadd78c754e4536"],"layout":"IPY_MODEL_288afd8f374749959ad341c36797b267"}},"b4b5bb0d83484aec94e982e06721b732":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cb4e77709855411ab23a84d4413f061f","placeholder":"​","style":"IPY_MODEL_88dd6a4ff28a42538cc123be2398e198","value":"Optuna 튜닝 진행률:  30%"}},"3691c263e2124eecb299869de0bf4b5c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_b96cf5d803f943fea2eec3c9ddab8a0e","max":50,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4a5bc1ece106416ca049c5b2473e4926","value":15}},"8d8a843daef7459abfadd78c754e4536":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c56da89ad0c94a79bb330d06cf1d370b","placeholder":"​","style":"IPY_MODEL_595b7f5ce6504cc9802b23d56c4025cb","value":" 15/50 [03:11&lt;02:53,  4.95s/it]"}},"288afd8f374749959ad341c36797b267":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cb4e77709855411ab23a84d4413f061f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"88dd6a4ff28a42538cc123be2398e198":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b96cf5d803f943fea2eec3c9ddab8a0e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4a5bc1ece106416ca049c5b2473e4926":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c56da89ad0c94a79bb330d06cf1d370b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"595b7f5ce6504cc9802b23d56c4025cb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e0259d8044a24d0598516f2edb170cb0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4ff828602e9040929b2c681d91336a57","IPY_MODEL_38ed25eb689348088a4b1c8403d8461e","IPY_MODEL_486b89ff83144be9a7e9b40f4cca68e7"],"layout":"IPY_MODEL_a23593ff54ca4883a97003a2be85e8ba"}},"4ff828602e9040929b2c681d91336a57":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_99947872dafd428c96c51a47587fadf8","placeholder":"​","style":"IPY_MODEL_0a3b29c172094039b7d3682304cf7849","value":"최종 모델 학습: 100%"}},"38ed25eb689348088a4b1c8403d8461e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d07fdc8006434ba6ab18db3a09f1eb7f","max":50,"min":0,"orientation":"horizontal","style":"IPY_MODEL_41631e0b37cc4a35812a346a0c04d14b","value":50}},"486b89ff83144be9a7e9b40f4cca68e7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ddb05182541c49639fe124d83ba55bfc","placeholder":"​","style":"IPY_MODEL_d4f13db4bfff4f799afd602baa2d3d2d","value":" 50/50 [01:04&lt;00:00,  1.31s/it]"}},"a23593ff54ca4883a97003a2be85e8ba":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"99947872dafd428c96c51a47587fadf8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0a3b29c172094039b7d3682304cf7849":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d07fdc8006434ba6ab18db3a09f1eb7f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"41631e0b37cc4a35812a346a0c04d14b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ddb05182541c49639fe124d83ba55bfc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d4f13db4bfff4f799afd602baa2d3d2d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f295f3c7f292434dbf00a0afaf931aa1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_47064933c1da46ae9b7113102dd6fc08","IPY_MODEL_26593e0303f545bbb8a355a57d26c7a1","IPY_MODEL_bc4f47f8d05947459d9be241281bb135"],"layout":"IPY_MODEL_5c5667153cfa4d1f8c858fa6badd2da7"}},"47064933c1da46ae9b7113102dd6fc08":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_52fc5ab5ae844a56bc8adb25ab8e4477","placeholder":"​","style":"IPY_MODEL_10a1b6c607344dfeba48ef7c1a61ac1b","value":"전체 데이터 예측: 100%"}},"26593e0303f545bbb8a355a57d26c7a1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_856a4b9f71d24f2c89d513241d7f7d1b","max":176,"min":0,"orientation":"horizontal","style":"IPY_MODEL_080b242931384df99113777787b18457","value":176}},"bc4f47f8d05947459d9be241281bb135":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1ad27b50048c4c72ade4a11c4f1f6127","placeholder":"​","style":"IPY_MODEL_b17a2f9b67ae4520bd83be450781b886","value":" 176/176 [00:00&lt;00:00, 350.78it/s]"}},"5c5667153cfa4d1f8c858fa6badd2da7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"52fc5ab5ae844a56bc8adb25ab8e4477":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"10a1b6c607344dfeba48ef7c1a61ac1b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"856a4b9f71d24f2c89d513241d7f7d1b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"080b242931384df99113777787b18457":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1ad27b50048c4c72ade4a11c4f1f6127":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b17a2f9b67ae4520bd83be450781b886":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"35a31440b11146d3a456f753268d7681":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_53f29e278e1c4c85a45d7907528fc162","IPY_MODEL_91ba376bf06e4304b6d1d139eaee19ee","IPY_MODEL_1fc09cccff9946d5b130051f425d4510"],"layout":"IPY_MODEL_97cf484dfce4483596e7ca37b82a5099"}},"53f29e278e1c4c85a45d7907528fc162":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1db5139525054be1b798cae0b232c743","placeholder":"​","style":"IPY_MODEL_f7e536de2aa64ae9872fe8e1dd44d1cb","value":"Optuna 튜닝 진행률:  86%"}},"91ba376bf06e4304b6d1d139eaee19ee":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_d2fe6df672ef42aeaa49201f2bc1cf9d","max":50,"min":0,"orientation":"horizontal","style":"IPY_MODEL_860fd465283f4ff5857b12c5876d0a98","value":43}},"1fc09cccff9946d5b130051f425d4510":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bd13931a4c2f4bd1b55e8a64e473e9d4","placeholder":"​","style":"IPY_MODEL_7ea146a27c894f199cd84178c464e7e5","value":" 43/50 [05:47&lt;00:35,  5.04s/it]"}},"97cf484dfce4483596e7ca37b82a5099":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1db5139525054be1b798cae0b232c743":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f7e536de2aa64ae9872fe8e1dd44d1cb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d2fe6df672ef42aeaa49201f2bc1cf9d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"860fd465283f4ff5857b12c5876d0a98":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bd13931a4c2f4bd1b55e8a64e473e9d4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7ea146a27c894f199cd84178c464e7e5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8e2666f44cd54c80b9f8e091e96348d9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bff771ac856e417782c79d0f936e33c4","IPY_MODEL_dc374eb8e7d941b6a7282a06ee793aa8","IPY_MODEL_57605dc75eaa4a59976696ec78361e0b"],"layout":"IPY_MODEL_2c9a7c140fb0407c827eb49ca11c021d"}},"bff771ac856e417782c79d0f936e33c4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_670394612cb74156a03db00731352866","placeholder":"​","style":"IPY_MODEL_b28eb4438da343de832407ccf476c53b","value":"최종 모델 학습: 100%"}},"dc374eb8e7d941b6a7282a06ee793aa8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b7f12098d894403cba4268728ee1d09e","max":50,"min":0,"orientation":"horizontal","style":"IPY_MODEL_96ca0ceae64944ecbfba167ed6d2a2c7","value":50}},"57605dc75eaa4a59976696ec78361e0b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a3dbce6df5a44ec0a9f106433c12a68f","placeholder":"​","style":"IPY_MODEL_407801e6635043838064b9043b1b4b53","value":" 50/50 [01:05&lt;00:00,  1.28s/it]"}},"2c9a7c140fb0407c827eb49ca11c021d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"670394612cb74156a03db00731352866":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b28eb4438da343de832407ccf476c53b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b7f12098d894403cba4268728ee1d09e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"96ca0ceae64944ecbfba167ed6d2a2c7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a3dbce6df5a44ec0a9f106433c12a68f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"407801e6635043838064b9043b1b4b53":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fda9afdefe304432a98611126f4644e8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4b88ee9b5a394f47a3273152db936c8e","IPY_MODEL_56ad13e75fb14668848fa9fa5aec17f6","IPY_MODEL_9fa285400ff349258e9a35eb66e445f0"],"layout":"IPY_MODEL_c71288f862164110a0d4a2c52c2d1c39"}},"4b88ee9b5a394f47a3273152db936c8e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5bc26e6e192e463bb5dcab1b46612eca","placeholder":"​","style":"IPY_MODEL_ec8011e6c562413ea7a6f7a7daf30388","value":"전체 데이터 예측: 100%"}},"56ad13e75fb14668848fa9fa5aec17f6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a384b4dee61a4bd7b34245de1aeaea00","max":176,"min":0,"orientation":"horizontal","style":"IPY_MODEL_858cc6f2ad7b493f894a1be95e195789","value":176}},"9fa285400ff349258e9a35eb66e445f0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1a7e4fb4483a4e77957b11b3f90ded53","placeholder":"​","style":"IPY_MODEL_21688d19de684edf9baaf81262d15f75","value":" 176/176 [00:00&lt;00:00, 334.51it/s]"}},"c71288f862164110a0d4a2c52c2d1c39":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5bc26e6e192e463bb5dcab1b46612eca":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ec8011e6c562413ea7a6f7a7daf30388":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a384b4dee61a4bd7b34245de1aeaea00":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"858cc6f2ad7b493f894a1be95e195789":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1a7e4fb4483a4e77957b11b3f90ded53":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"21688d19de684edf9baaf81262d15f75":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5c1d1f24b46e44048684ee761463d690":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6207f686781140118b9d7e847dca55e7","IPY_MODEL_6874239040014250be982a08aae73035","IPY_MODEL_cb57c287d486473abff1ac162c1f102a"],"layout":"IPY_MODEL_8bbdf3b574ab435987e54ae369608790"}},"6207f686781140118b9d7e847dca55e7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d33a0c7a32304969b4bf73901767d830","placeholder":"​","style":"IPY_MODEL_c0239bc3d5594cc0b6072671e6aae572","value":"Optuna 튜닝 진행률:  36%"}},"6874239040014250be982a08aae73035":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_dabc91a3eaa540eeab30991adb156621","max":50,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0785448190924403a681b111ba1f6caf","value":18}},"cb57c287d486473abff1ac162c1f102a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_acf9e65e926f44c190cb563d79cace62","placeholder":"​","style":"IPY_MODEL_280696e334c847ba9de5c1bc8c4b39c2","value":" 18/50 [02:18&lt;01:06,  2.09s/it]"}},"8bbdf3b574ab435987e54ae369608790":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d33a0c7a32304969b4bf73901767d830":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c0239bc3d5594cc0b6072671e6aae572":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dabc91a3eaa540eeab30991adb156621":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0785448190924403a681b111ba1f6caf":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"acf9e65e926f44c190cb563d79cace62":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"280696e334c847ba9de5c1bc8c4b39c2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"88642a63770a4bd0b8e73f51a83514ce":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c5338aa3016a4242a0ecf0afb96ff8a2","IPY_MODEL_07317bd7845d4dc89b456b88e1f82ace","IPY_MODEL_605a457a57024b338375078f75f1c5ce"],"layout":"IPY_MODEL_df705b19f2b642be910f417df98869c5"}},"c5338aa3016a4242a0ecf0afb96ff8a2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3f4ec9bd8be148d088771a3d4b47dc55","placeholder":"​","style":"IPY_MODEL_06b75b91e7594df8b8f1fabd28c05f22","value":"최종 모델 학습: 100%"}},"07317bd7845d4dc89b456b88e1f82ace":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1aaf9b1578284fdb90ee5029f63db696","max":50,"min":0,"orientation":"horizontal","style":"IPY_MODEL_983ff5677e7c4c07a145980aa1babf05","value":50}},"605a457a57024b338375078f75f1c5ce":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9b243eb6057e446d967aee76a9305241","placeholder":"​","style":"IPY_MODEL_6d0967c2a0604d72bce44dd232981918","value":" 50/50 [00:57&lt;00:00,  1.16s/it]"}},"df705b19f2b642be910f417df98869c5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3f4ec9bd8be148d088771a3d4b47dc55":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"06b75b91e7594df8b8f1fabd28c05f22":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1aaf9b1578284fdb90ee5029f63db696":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"983ff5677e7c4c07a145980aa1babf05":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9b243eb6057e446d967aee76a9305241":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6d0967c2a0604d72bce44dd232981918":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ff7f6e4be3984c5390086152569b6d1f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_589ebda93160475a9ab56abbfa5aab5d","IPY_MODEL_cec8a1b910c04152ac454236dd70bd78","IPY_MODEL_6cc6ec67e7f045b78f483cb54257b8f8"],"layout":"IPY_MODEL_3f5978ba400f4a109d28fad522f04c72"}},"589ebda93160475a9ab56abbfa5aab5d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5b72d65957214adc8ef61f8a8d2b27e6","placeholder":"​","style":"IPY_MODEL_2454f33e10c040889b17cb1521a34184","value":"전체 데이터 예측: 100%"}},"cec8a1b910c04152ac454236dd70bd78":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6ea8b8d9045f4b14b4c9d11e54d3b5e8","max":176,"min":0,"orientation":"horizontal","style":"IPY_MODEL_059dd67c35b9427faffe174bf4cc7fc3","value":176}},"6cc6ec67e7f045b78f483cb54257b8f8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ba2fd5657e2846658f14ba21fff1acde","placeholder":"​","style":"IPY_MODEL_52c5c97ecca642cc824043ab49bd47e5","value":" 176/176 [00:00&lt;00:00, 349.60it/s]"}},"3f5978ba400f4a109d28fad522f04c72":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5b72d65957214adc8ef61f8a8d2b27e6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2454f33e10c040889b17cb1521a34184":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6ea8b8d9045f4b14b4c9d11e54d3b5e8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"059dd67c35b9427faffe174bf4cc7fc3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ba2fd5657e2846658f14ba21fff1acde":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"52c5c97ecca642cc824043ab49bd47e5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cafe45d8cf1a49058538d0b9b6b85363":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ccd374f05a0944f68147902a6d99f11a","IPY_MODEL_666ca4a30bfb4138b28a6fe7f6b99bc2","IPY_MODEL_4653110a96a04fa08a2db5d6eefbc479"],"layout":"IPY_MODEL_3b12f611f1994dfcb988165cca815456"}},"ccd374f05a0944f68147902a6d99f11a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6fa4526466644abba6ef8870bcf2e03a","placeholder":"​","style":"IPY_MODEL_ddc4231939344ba0822fdfe211e5efbb","value":"Optuna 튜닝 진행률:  22%"}},"666ca4a30bfb4138b28a6fe7f6b99bc2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_1f98c110bf7048a2ba6b9d173eb65aeb","max":50,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0bb692c633aa478db2a9d39ec9a79609","value":11}},"4653110a96a04fa08a2db5d6eefbc479":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_99886c379366453c86f766d0ae6c6758","placeholder":"​","style":"IPY_MODEL_03450645cee0400e89f04ebdd0fa05b4","value":" 11/50 [04:58&lt;07:05, 10.92s/it]"}},"3b12f611f1994dfcb988165cca815456":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6fa4526466644abba6ef8870bcf2e03a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ddc4231939344ba0822fdfe211e5efbb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1f98c110bf7048a2ba6b9d173eb65aeb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0bb692c633aa478db2a9d39ec9a79609":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"99886c379366453c86f766d0ae6c6758":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"03450645cee0400e89f04ebdd0fa05b4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ac85f3e15a1b43d88093fe2ec2fa902a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8a8f1f251c9a46798c5387b3d3ff92c3","IPY_MODEL_0cbb440738ff44c9ad6fddd2e6137331","IPY_MODEL_026e88f3e2a144e0956da76991824cee"],"layout":"IPY_MODEL_c01b800d48c649ddafc1e893cacc44d3"}},"8a8f1f251c9a46798c5387b3d3ff92c3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2a08ba62ecfd40668c177b5077bfff51","placeholder":"​","style":"IPY_MODEL_f714b4a7fca74eab92b5892e728ff2a1","value":"최종 모델 학습: 100%"}},"0cbb440738ff44c9ad6fddd2e6137331":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0ce6fb9445174e2a93ae6be708b81de8","max":50,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4611c2fa021c4ffa8bc6bad568dcddfe","value":50}},"026e88f3e2a144e0956da76991824cee":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f6963c0884064837b551e40f0f5bc51a","placeholder":"​","style":"IPY_MODEL_9165b0f8a2c145f587802f30f1351b85","value":" 50/50 [01:16&lt;00:00,  1.52s/it]"}},"c01b800d48c649ddafc1e893cacc44d3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2a08ba62ecfd40668c177b5077bfff51":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f714b4a7fca74eab92b5892e728ff2a1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0ce6fb9445174e2a93ae6be708b81de8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4611c2fa021c4ffa8bc6bad568dcddfe":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f6963c0884064837b551e40f0f5bc51a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9165b0f8a2c145f587802f30f1351b85":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bfd8739ec7c94f6f83a08f3e2e011a64":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3e548b79af194535a5319027af271b84","IPY_MODEL_6e81f667b9b34af8a08400be17fd89e0","IPY_MODEL_b227a9ef04174ebd96177128ef5fa153"],"layout":"IPY_MODEL_d7926684e5844b02b2828318ddd7b9aa"}},"3e548b79af194535a5319027af271b84":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b9d1b4e4cea943cf85450231e4e6511b","placeholder":"​","style":"IPY_MODEL_7e2a539d28594e07a6f7c52d0f2c2a1b","value":"전체 데이터 예측: 100%"}},"6e81f667b9b34af8a08400be17fd89e0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8e304775ac874c7a90a70e4afbf65d39","max":238,"min":0,"orientation":"horizontal","style":"IPY_MODEL_895c81e2ca004e909c4b09f70dad0298","value":238}},"b227a9ef04174ebd96177128ef5fa153":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4134520cd2b64b6b82637092b7311fe3","placeholder":"​","style":"IPY_MODEL_f5c0638255d34842935c054c99bb9613","value":" 238/238 [00:00&lt;00:00, 354.08it/s]"}},"d7926684e5844b02b2828318ddd7b9aa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b9d1b4e4cea943cf85450231e4e6511b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7e2a539d28594e07a6f7c52d0f2c2a1b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8e304775ac874c7a90a70e4afbf65d39":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"895c81e2ca004e909c4b09f70dad0298":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4134520cd2b64b6b82637092b7311fe3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f5c0638255d34842935c054c99bb9613":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5fb0576f813e4e4fafb94441a0c7be05":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5815ad50a22549f1901f6cd09d9b8c46","IPY_MODEL_a3bd25018c254273af00544cba4d07d2","IPY_MODEL_01404c3d3e184bd2afb266fe863ac596"],"layout":"IPY_MODEL_a9035899b7284cf58c7c8f66707197b0"}},"5815ad50a22549f1901f6cd09d9b8c46":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4725d7c140dc4c4aa6f9de76fcd722fc","placeholder":"​","style":"IPY_MODEL_979e416d7a98467d8a3cb0428c9cc5d2","value":"Optuna 튜닝 진행률:  28%"}},"a3bd25018c254273af00544cba4d07d2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_c0b93d963a1f4fb680666992027fbe3b","max":50,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b57188ac539c4c23b620eda50264aa44","value":14}},"01404c3d3e184bd2afb266fe863ac596":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_16aab10ca4354b8ba1a36d7251ab8a3a","placeholder":"​","style":"IPY_MODEL_4b09f68fa67e4c398ada28977f8d1429","value":" 14/50 [04:19&lt;05:08,  8.56s/it]"}},"a9035899b7284cf58c7c8f66707197b0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4725d7c140dc4c4aa6f9de76fcd722fc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"979e416d7a98467d8a3cb0428c9cc5d2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c0b93d963a1f4fb680666992027fbe3b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b57188ac539c4c23b620eda50264aa44":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"16aab10ca4354b8ba1a36d7251ab8a3a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4b09f68fa67e4c398ada28977f8d1429":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9e64ef66aca8403e9ed78df5ca98806b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bfc2b70ce0604aca8a8b21f39c84721a","IPY_MODEL_cf0e7a46bb6a45368595dda19f16c4a5","IPY_MODEL_914132267a714467bb68b7b57310c0c1"],"layout":"IPY_MODEL_c3ada4738edb4ca3a72e7372d6239d74"}},"bfc2b70ce0604aca8a8b21f39c84721a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_360301f076934e398f4c187073e53550","placeholder":"​","style":"IPY_MODEL_e771639242c7427ebf83744d3a0f0aa2","value":"최종 모델 학습: 100%"}},"cf0e7a46bb6a45368595dda19f16c4a5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c5dbcbf25cc24dc080a23abf19a35e9f","max":50,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b8af31d362d94a94a54931dabf8ceb91","value":50}},"914132267a714467bb68b7b57310c0c1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1c687dcad7374724b37e030d13824648","placeholder":"​","style":"IPY_MODEL_a5256b33644644e082ef57b6062386d3","value":" 50/50 [01:06&lt;00:00,  1.33s/it]"}},"c3ada4738edb4ca3a72e7372d6239d74":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"360301f076934e398f4c187073e53550":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e771639242c7427ebf83744d3a0f0aa2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c5dbcbf25cc24dc080a23abf19a35e9f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b8af31d362d94a94a54931dabf8ceb91":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1c687dcad7374724b37e030d13824648":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a5256b33644644e082ef57b6062386d3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5188b88f7a34423aa4caa47522709274":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_77dfc320e70643f4b0551d45278bcb6d","IPY_MODEL_f91b2d1480ca470cae2fb3429ca35492","IPY_MODEL_ea9a6830450043018cf701c54f06d8b9"],"layout":"IPY_MODEL_bd201089b7a34e3f82dd158191f55183"}},"77dfc320e70643f4b0551d45278bcb6d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6bb009ec1cb9443c837fdc98794fd773","placeholder":"​","style":"IPY_MODEL_65c6f86d017d4818a48cdcafdbf50287","value":"전체 데이터 예측: 100%"}},"f91b2d1480ca470cae2fb3429ca35492":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7192431b893c4558a3c535f7277c2ffc","max":238,"min":0,"orientation":"horizontal","style":"IPY_MODEL_965b7d5c1add44599af8113d85ebf659","value":238}},"ea9a6830450043018cf701c54f06d8b9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7afad501448c4898b38316c426b88f33","placeholder":"​","style":"IPY_MODEL_64a8b4998d9e4fd69e0abc189e9eb3bb","value":" 238/238 [00:00&lt;00:00, 369.15it/s]"}},"bd201089b7a34e3f82dd158191f55183":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6bb009ec1cb9443c837fdc98794fd773":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"65c6f86d017d4818a48cdcafdbf50287":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7192431b893c4558a3c535f7277c2ffc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"965b7d5c1add44599af8113d85ebf659":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7afad501448c4898b38316c426b88f33":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"64a8b4998d9e4fd69e0abc189e9eb3bb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"190da761e04a4d94b6e3554ad1163cb0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2a5a9bc45ea64997bb903f28b4b7099d","IPY_MODEL_a7b084ee04c346619bfa74794fcb221c","IPY_MODEL_d166f4970ad54ab08914b0752cd05f25"],"layout":"IPY_MODEL_12a5a39931274e7abf22b936dc49fdcb"}},"2a5a9bc45ea64997bb903f28b4b7099d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d60a4f9d626043878224d070dc73087f","placeholder":"​","style":"IPY_MODEL_361ab5ef912f45cab1790ffda63a10c3","value":"Optuna 튜닝 진행률:  24%"}},"a7b084ee04c346619bfa74794fcb221c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_ecf1dab11bc64b02bdb1b6e04530e7a2","max":50,"min":0,"orientation":"horizontal","style":"IPY_MODEL_135fe3ef32294d1eba6f5578a4b79d83","value":12}},"d166f4970ad54ab08914b0752cd05f25":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fdb19ba1828e4eef84bf3500a5e04861","placeholder":"​","style":"IPY_MODEL_d49bbe440ddf4cc0a572aa58c33622c1","value":" 12/50 [04:57&lt;07:30, 11.85s/it]"}},"12a5a39931274e7abf22b936dc49fdcb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d60a4f9d626043878224d070dc73087f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"361ab5ef912f45cab1790ffda63a10c3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ecf1dab11bc64b02bdb1b6e04530e7a2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"135fe3ef32294d1eba6f5578a4b79d83":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"fdb19ba1828e4eef84bf3500a5e04861":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d49bbe440ddf4cc0a572aa58c33622c1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"974720afba3a4532b09ca62d055a48b4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8d5b575f085a4b59a09f5405aeb75ba1","IPY_MODEL_341398a352c44c42b193a32fcbb6b695","IPY_MODEL_edfd4091e74840eba2243c3df9c01cfb"],"layout":"IPY_MODEL_dd8054522fac49539d428ef7ff5a1703"}},"8d5b575f085a4b59a09f5405aeb75ba1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b9185f17be2743da986bfcb278f25657","placeholder":"​","style":"IPY_MODEL_5e2fd1ff554c4063927636bc8bfc9aae","value":"최종 모델 학습: 100%"}},"341398a352c44c42b193a32fcbb6b695":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7c4ea73bad194f9aadadc72276fac32b","max":50,"min":0,"orientation":"horizontal","style":"IPY_MODEL_717529ef30de48de812245be4e132db4","value":50}},"edfd4091e74840eba2243c3df9c01cfb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_94a9c8b047294b64ad6a8fa6a733b94b","placeholder":"​","style":"IPY_MODEL_e81150046fcc482f83193f20b802f664","value":" 50/50 [01:13&lt;00:00,  1.47s/it]"}},"dd8054522fac49539d428ef7ff5a1703":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b9185f17be2743da986bfcb278f25657":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5e2fd1ff554c4063927636bc8bfc9aae":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7c4ea73bad194f9aadadc72276fac32b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"717529ef30de48de812245be4e132db4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"94a9c8b047294b64ad6a8fa6a733b94b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e81150046fcc482f83193f20b802f664":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b4b28c7155d24ff0bdb61f1f7c88b83d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_292b47096d214cb9900aeb0972f307dc","IPY_MODEL_698867de19ae4fc0bf79f8e3ed224c39","IPY_MODEL_38401865c4574952ab95889a26f34d08"],"layout":"IPY_MODEL_0a85f88400e14579b5f4290d7c60fc44"}},"292b47096d214cb9900aeb0972f307dc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bc33892c2921439d982862e69e4502c7","placeholder":"​","style":"IPY_MODEL_f13596e6f4114bb4a9fbec83466d5ac0","value":"전체 데이터 예측: 100%"}},"698867de19ae4fc0bf79f8e3ed224c39":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_25cfd3885e9b424aa1c41edad1d015de","max":238,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d314e72013624fceb89ba672fca68624","value":238}},"38401865c4574952ab95889a26f34d08":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a28caba13fd841fabc9d31d8b55af64e","placeholder":"​","style":"IPY_MODEL_73c82e55dac8430b857366b3711f54d7","value":" 238/238 [00:00&lt;00:00, 232.68it/s]"}},"0a85f88400e14579b5f4290d7c60fc44":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bc33892c2921439d982862e69e4502c7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f13596e6f4114bb4a9fbec83466d5ac0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"25cfd3885e9b424aa1c41edad1d015de":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d314e72013624fceb89ba672fca68624":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a28caba13fd841fabc9d31d8b55af64e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"73c82e55dac8430b857366b3711f54d7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bfc028cfc4934baf995f6fbd62d0c524":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b128b8ac604b40b5b80bb00429dfcf82","IPY_MODEL_828ab1b8b00842cdb21c4e068ad2f5a8","IPY_MODEL_1001688d615d461baab7a535fe5a0e78"],"layout":"IPY_MODEL_cdbae2fbffab47de98e18055ec0868e2"}},"b128b8ac604b40b5b80bb00429dfcf82":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_374b5ddea22b4cd59eff1ec405e910d7","placeholder":"​","style":"IPY_MODEL_3fe6e6d9249143549fae6ab11bcb2664","value":"Optuna 튜닝 진행률:  32%"}},"828ab1b8b00842cdb21c4e068ad2f5a8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_8c0adb0b6af940b7bd10eb94801c9bcb","max":50,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6df356e2a9ed46f2bb2c578e5225dc58","value":16}},"1001688d615d461baab7a535fe5a0e78":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_613d1427ffbd4ae1aad946e9b8dc55ec","placeholder":"​","style":"IPY_MODEL_05ff0a15c05344378d0340cd87083282","value":" 16/50 [05:41&lt;03:50,  6.79s/it]"}},"cdbae2fbffab47de98e18055ec0868e2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"374b5ddea22b4cd59eff1ec405e910d7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3fe6e6d9249143549fae6ab11bcb2664":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8c0adb0b6af940b7bd10eb94801c9bcb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6df356e2a9ed46f2bb2c578e5225dc58":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"613d1427ffbd4ae1aad946e9b8dc55ec":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"05ff0a15c05344378d0340cd87083282":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"48b366246c8d4045af5c41656cb9525e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9d079cbba619452a9051a31839425a07","IPY_MODEL_7069e8344f2b4a9cac9f0d1b41380206","IPY_MODEL_31219c9a14c748f1a57a93086fa32981"],"layout":"IPY_MODEL_a9f2e1ee99e746adbedc2568e670f19e"}},"9d079cbba619452a9051a31839425a07":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0026ed64c48b4564bbd9305a3c2e3a5d","placeholder":"​","style":"IPY_MODEL_dadaffa6fef646c8adab7b2a80628a3e","value":"최종 모델 학습: 100%"}},"7069e8344f2b4a9cac9f0d1b41380206":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4f20808b36cc429a80c27f2653a90fc0","max":50,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ec022e9e3b2841768444bd0fde68e3ac","value":50}},"31219c9a14c748f1a57a93086fa32981":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_134a0a0426af45d98201401ec83eba99","placeholder":"​","style":"IPY_MODEL_813bd761aa9a44d4bdae9f6899b90e44","value":" 50/50 [01:22&lt;00:00,  1.64s/it]"}},"a9f2e1ee99e746adbedc2568e670f19e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0026ed64c48b4564bbd9305a3c2e3a5d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dadaffa6fef646c8adab7b2a80628a3e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4f20808b36cc429a80c27f2653a90fc0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ec022e9e3b2841768444bd0fde68e3ac":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"134a0a0426af45d98201401ec83eba99":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"813bd761aa9a44d4bdae9f6899b90e44":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8d277fe0d95840d9991b6778d5adb15e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_700c7ebb1b98436ea78f300df9e0524c","IPY_MODEL_67f23164afab460a9f2d91e1b5bdcfbb","IPY_MODEL_a4552f51c3b2433db08d51fd2bd4a2a2"],"layout":"IPY_MODEL_dd42843070a14719a84301e3119adcc3"}},"700c7ebb1b98436ea78f300df9e0524c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f21b9fa8f8af4fa89f26e1c7843d0ae2","placeholder":"​","style":"IPY_MODEL_ec6dec1b8db34285bc66404906bd28d0","value":"전체 데이터 예측: 100%"}},"67f23164afab460a9f2d91e1b5bdcfbb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_97b9d26f13c84d239924d56ca656d86f","max":238,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3fc6bf0271f34066a8e055ee7d218d06","value":238}},"a4552f51c3b2433db08d51fd2bd4a2a2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_338aeda6d86943c682da6184afe21ecc","placeholder":"​","style":"IPY_MODEL_ce667f57d2184a4da9d373fc1194ff4c","value":" 238/238 [00:00&lt;00:00, 277.28it/s]"}},"dd42843070a14719a84301e3119adcc3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f21b9fa8f8af4fa89f26e1c7843d0ae2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ec6dec1b8db34285bc66404906bd28d0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"97b9d26f13c84d239924d56ca656d86f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3fc6bf0271f34066a8e055ee7d218d06":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"338aeda6d86943c682da6184afe21ecc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ce667f57d2184a4da9d373fc1194ff4c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"035e14987f3348af853e5a015cab2d14":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2666ab30a5bc41e889b99be6a541a5ae","IPY_MODEL_c92b02d3f00c4f5eb56419a86d912c11","IPY_MODEL_03472efb4f6d43a0a1fb7e454bc9c016"],"layout":"IPY_MODEL_95035a0d590a41fb8f1ea64c6b913d8c"}},"2666ab30a5bc41e889b99be6a541a5ae":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e7152c78f8a14e7c8ddfe5402fe673c5","placeholder":"​","style":"IPY_MODEL_0e3f27ceec984210aef315ad88af2546","value":"Optuna 튜닝 진행률:  24%"}},"c92b02d3f00c4f5eb56419a86d912c11":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_4d146d23743c4c23a63f5eaf35a8e35f","max":50,"min":0,"orientation":"horizontal","style":"IPY_MODEL_63bc8e8442d44a4c9b205c7f569c0c69","value":12}},"03472efb4f6d43a0a1fb7e454bc9c016":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d0c691000e3141c59f5334265d47648e","placeholder":"​","style":"IPY_MODEL_661f80ed5d3544b994142d12e95bdd26","value":" 12/50 [03:38&lt;05:38,  8.90s/it]"}},"95035a0d590a41fb8f1ea64c6b913d8c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e7152c78f8a14e7c8ddfe5402fe673c5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0e3f27ceec984210aef315ad88af2546":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4d146d23743c4c23a63f5eaf35a8e35f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"63bc8e8442d44a4c9b205c7f569c0c69":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d0c691000e3141c59f5334265d47648e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"661f80ed5d3544b994142d12e95bdd26":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ec5cf2ca829c4a668ebb456d70056b1a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ca28b2977cc14553a3e115e6c26bb58f","IPY_MODEL_2e491a15a4ae4f4d8371f988390088ff","IPY_MODEL_4d5271ad13e348b18b3ac7bdfd507133"],"layout":"IPY_MODEL_1ba73f4d93184181be9f99b6d36c8e6a"}},"ca28b2977cc14553a3e115e6c26bb58f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5bd0fff205a74729a2dc1c14cdd353a0","placeholder":"​","style":"IPY_MODEL_0ebacff36f364ae280be7d618b3a9cef","value":"최종 모델 학습: 100%"}},"2e491a15a4ae4f4d8371f988390088ff":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_dede7ddc40f8427081b2fbdcd1f1bbe8","max":50,"min":0,"orientation":"horizontal","style":"IPY_MODEL_574b1e7dd63a4a7092d841b117151318","value":50}},"4d5271ad13e348b18b3ac7bdfd507133":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_03cc945e4fe54da89d0bb89f1d11d849","placeholder":"​","style":"IPY_MODEL_3144a849190543288a25f3b5b24e7e53","value":" 50/50 [01:06&lt;00:00,  1.33s/it]"}},"1ba73f4d93184181be9f99b6d36c8e6a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5bd0fff205a74729a2dc1c14cdd353a0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0ebacff36f364ae280be7d618b3a9cef":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dede7ddc40f8427081b2fbdcd1f1bbe8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"574b1e7dd63a4a7092d841b117151318":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"03cc945e4fe54da89d0bb89f1d11d849":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3144a849190543288a25f3b5b24e7e53":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"033cec06d1d94f5cbfd287aa1db08584":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7abfbf22e758461ba5fc434c2565d162","IPY_MODEL_830023fc4baa4e2284f2c4ebf7ce1b11","IPY_MODEL_483a7c9670634de49d2ff01fc796a8f2"],"layout":"IPY_MODEL_079cd52e8f974fab9c3b46b5f0f7b167"}},"7abfbf22e758461ba5fc434c2565d162":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_300dc659dd054118857bb9e9542a2391","placeholder":"​","style":"IPY_MODEL_7d863a9439014ed08422e6363ce90640","value":"전체 데이터 예측: 100%"}},"830023fc4baa4e2284f2c4ebf7ce1b11":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1505cda2b85a4177a10831129df8d4de","max":238,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a7d549f68d65427ba1507ff76ba06914","value":238}},"483a7c9670634de49d2ff01fc796a8f2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c920fe0dc96b43229bdf91bbc2b068a9","placeholder":"​","style":"IPY_MODEL_d0bb2e332f1b47cb9439d093832d62ff","value":" 238/238 [00:00&lt;00:00, 315.12it/s]"}},"079cd52e8f974fab9c3b46b5f0f7b167":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"300dc659dd054118857bb9e9542a2391":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7d863a9439014ed08422e6363ce90640":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1505cda2b85a4177a10831129df8d4de":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a7d549f68d65427ba1507ff76ba06914":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c920fe0dc96b43229bdf91bbc2b068a9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d0bb2e332f1b47cb9439d093832d62ff":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4625899cf4f443b0844e23c838aec583":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_daf26e792ebf423e911124a8d86a0bb1","IPY_MODEL_6777b6689154427c86433dc45a035232","IPY_MODEL_43a8f59bfd4a45db8e8cacd3cd6a71cc"],"layout":"IPY_MODEL_1f885ee528e74498ae269394ba38f602"}},"daf26e792ebf423e911124a8d86a0bb1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7bf4fec7d782402f847ab7b13012f996","placeholder":"​","style":"IPY_MODEL_64ffe98a4e7c4ec9a6cf3e2d638aa895","value":"Optuna 튜닝 진행률:  50%"}},"6777b6689154427c86433dc45a035232":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_7f96681efd454036936a423759e3e44a","max":50,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6228cad18dfb4d2caa7c39665bcf80a3","value":25}},"43a8f59bfd4a45db8e8cacd3cd6a71cc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1404602a56614168b0967768d2bae518","placeholder":"​","style":"IPY_MODEL_19833bd67e5140a1b784f356d27cb7f6","value":" 25/50 [07:22&lt;02:19,  5.57s/it]"}},"1f885ee528e74498ae269394ba38f602":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7bf4fec7d782402f847ab7b13012f996":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"64ffe98a4e7c4ec9a6cf3e2d638aa895":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7f96681efd454036936a423759e3e44a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6228cad18dfb4d2caa7c39665bcf80a3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1404602a56614168b0967768d2bae518":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"19833bd67e5140a1b784f356d27cb7f6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4f9840da7489458c883692d493f0af45":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3fb5fa87d9dc4a7f9ad9f7390e81ada9","IPY_MODEL_dd2aaa369951477c98c20a924391d915","IPY_MODEL_e54914a64589415e92e69893243b0bbc"],"layout":"IPY_MODEL_3992ff06b13540b5930ffa0314632c44"}},"3fb5fa87d9dc4a7f9ad9f7390e81ada9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a17df1a62c644561879a5a563000bc82","placeholder":"​","style":"IPY_MODEL_8eeb4755e5414439b07bec008294a51b","value":"최종 모델 학습: 100%"}},"dd2aaa369951477c98c20a924391d915":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e525323ca2e54d85b31f2e0dabbe138b","max":50,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b3b7c6093d98485d9d004f315356e98d","value":50}},"e54914a64589415e92e69893243b0bbc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_87a9afd9ba1349d5a1af3e761c533016","placeholder":"​","style":"IPY_MODEL_a971f0af142649dab330d0c03c90ab0c","value":" 50/50 [00:55&lt;00:00,  1.13s/it]"}},"3992ff06b13540b5930ffa0314632c44":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a17df1a62c644561879a5a563000bc82":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8eeb4755e5414439b07bec008294a51b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e525323ca2e54d85b31f2e0dabbe138b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b3b7c6093d98485d9d004f315356e98d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"87a9afd9ba1349d5a1af3e761c533016":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a971f0af142649dab330d0c03c90ab0c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3a8474bc999f4f7296b7a2692f105d71":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9327bc49a44d49a2afb22376cdd25e99","IPY_MODEL_df098a0e09624ff2972471ba9d894765","IPY_MODEL_8b5fc486e0d544bea5cbc4a6e063f6d1"],"layout":"IPY_MODEL_90356f5ba8684e4986d4cacfb6e2366b"}},"9327bc49a44d49a2afb22376cdd25e99":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4c591383b32d4a078c39cf4676f84ebd","placeholder":"​","style":"IPY_MODEL_f553b2eedf784f389d40f4c1354cfbdd","value":"전체 데이터 예측: 100%"}},"df098a0e09624ff2972471ba9d894765":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_cfb1ad0370944cac9bb4b851f3a320ab","max":182,"min":0,"orientation":"horizontal","style":"IPY_MODEL_319f92cd148b457ea70dc8b5e200a00c","value":182}},"8b5fc486e0d544bea5cbc4a6e063f6d1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a725cbe4ede44977b3029be731d8180b","placeholder":"​","style":"IPY_MODEL_5719125a26c549eb80fd5bec7e260ed5","value":" 182/182 [00:00&lt;00:00, 355.31it/s]"}},"90356f5ba8684e4986d4cacfb6e2366b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4c591383b32d4a078c39cf4676f84ebd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f553b2eedf784f389d40f4c1354cfbdd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cfb1ad0370944cac9bb4b851f3a320ab":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"319f92cd148b457ea70dc8b5e200a00c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a725cbe4ede44977b3029be731d8180b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5719125a26c549eb80fd5bec7e260ed5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"879c817822604edfa5232c791edaa5a3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_866b7aefda5d44d9b9643c7cb1bc7285","IPY_MODEL_e2632cfc597c4374b5cfbdb3184f90ca","IPY_MODEL_905f4e87eba94a76833d9abb856b4fee"],"layout":"IPY_MODEL_0a483244a54d4901a3b3d38faea787b2"}},"866b7aefda5d44d9b9643c7cb1bc7285":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b3f8511658e24aa58a1c379aa46cebca","placeholder":"​","style":"IPY_MODEL_0a19299a6cdf49a4869924b5af02d45d","value":"Optuna 튜닝 진행률:  26%"}},"e2632cfc597c4374b5cfbdb3184f90ca":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_c1c44bfeb45949ba898372574a6c49ec","max":50,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cc231da84cb54484be6059c8f1446989","value":13}},"905f4e87eba94a76833d9abb856b4fee":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8b6956d42ce644d1ba996e0341a7c808","placeholder":"​","style":"IPY_MODEL_7831e8f062d94b10bf409f38fc374579","value":" 13/50 [04:04&lt;04:00,  6.51s/it]"}},"0a483244a54d4901a3b3d38faea787b2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b3f8511658e24aa58a1c379aa46cebca":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0a19299a6cdf49a4869924b5af02d45d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c1c44bfeb45949ba898372574a6c49ec":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cc231da84cb54484be6059c8f1446989":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8b6956d42ce644d1ba996e0341a7c808":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7831e8f062d94b10bf409f38fc374579":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4d2c558c9e624d909d8bfe6ded5b10e7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8703007ee381400e9b49dc6d918cef52","IPY_MODEL_f48ef9dba6084109bc126a4ed79ce06f","IPY_MODEL_243f256c03014f93af50e2aed8698e50"],"layout":"IPY_MODEL_655729c61bd34a4bab990928e24f6eb6"}},"8703007ee381400e9b49dc6d918cef52":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3fb673bc9ddf4d85b3eecac8c47978b8","placeholder":"​","style":"IPY_MODEL_ddcae09c250d492082fa8c1cc889e621","value":"최종 모델 학습: 100%"}},"f48ef9dba6084109bc126a4ed79ce06f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9c99e33c46ca4020a25e1a375948512e","max":50,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4f4f6fdf77704d75a39aac034a0aec59","value":50}},"243f256c03014f93af50e2aed8698e50":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_acd81dad769947a0b2c8509142e268c7","placeholder":"​","style":"IPY_MODEL_59b19e0e0ba34e978aba52767beec7fb","value":" 50/50 [00:55&lt;00:00,  1.14s/it]"}},"655729c61bd34a4bab990928e24f6eb6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3fb673bc9ddf4d85b3eecac8c47978b8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ddcae09c250d492082fa8c1cc889e621":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9c99e33c46ca4020a25e1a375948512e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4f4f6fdf77704d75a39aac034a0aec59":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"acd81dad769947a0b2c8509142e268c7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"59b19e0e0ba34e978aba52767beec7fb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"10e98966ebdc496d8ac2538f598b6e65":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e7cf5269dba94ede86ba5c0f0997a635","IPY_MODEL_8576985822a0453aadcf0151a00d6953","IPY_MODEL_7295d9d21fdd407497ad4170e9e441b0"],"layout":"IPY_MODEL_4d8f43f4b5e543c0adb76a97855478a9"}},"e7cf5269dba94ede86ba5c0f0997a635":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ff0dbae4438b410996893012ac1e580a","placeholder":"​","style":"IPY_MODEL_f903d38b33024a789e372ab2feeb53b0","value":"전체 데이터 예측: 100%"}},"8576985822a0453aadcf0151a00d6953":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_eb2c7c66613e44219a0f8c37a4f738d0","max":182,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6ff5cdc56057437dac6da49bb5028042","value":182}},"7295d9d21fdd407497ad4170e9e441b0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6e9ddaf98ec14ec08a424e25f1330169","placeholder":"​","style":"IPY_MODEL_68e43cb5d9f94848b6f69225d0e73014","value":" 182/182 [00:00&lt;00:00, 358.21it/s]"}},"4d8f43f4b5e543c0adb76a97855478a9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ff0dbae4438b410996893012ac1e580a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f903d38b33024a789e372ab2feeb53b0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"eb2c7c66613e44219a0f8c37a4f738d0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6ff5cdc56057437dac6da49bb5028042":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6e9ddaf98ec14ec08a424e25f1330169":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"68e43cb5d9f94848b6f69225d0e73014":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3361779c4a6f42c08999bdeb6274451a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_055a4c6e69ab4cbcbbaa93c718bf807c","IPY_MODEL_5e5c65ab15b14ef38d7b0119a89d725b","IPY_MODEL_2841bc4c21374afc9940a006e55b135d"],"layout":"IPY_MODEL_45160580d2174f31af2ec3aba98b1b42"}},"055a4c6e69ab4cbcbbaa93c718bf807c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_97414ddbd2ac444abc8395e0d0d824d3","placeholder":"​","style":"IPY_MODEL_12b92bf2caa5499888a9f3a03e410639","value":"Optuna 튜닝 진행률:  42%"}},"5e5c65ab15b14ef38d7b0119a89d725b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_3064a105dabd401b9fba9c161dd8e0a2","max":50,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6604ecc96b944597a99d4c6cc6ef92e4","value":21}},"2841bc4c21374afc9940a006e55b135d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c746309f96d84f97b8d17b5cc7b39526","placeholder":"​","style":"IPY_MODEL_586c08150d7a4b7e9cd8964850341808","value":" 21/50 [04:23&lt;03:08,  6.49s/it]"}},"45160580d2174f31af2ec3aba98b1b42":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"97414ddbd2ac444abc8395e0d0d824d3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"12b92bf2caa5499888a9f3a03e410639":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3064a105dabd401b9fba9c161dd8e0a2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6604ecc96b944597a99d4c6cc6ef92e4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c746309f96d84f97b8d17b5cc7b39526":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"586c08150d7a4b7e9cd8964850341808":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"134b4e5825f0481fafb314b96434def5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_03d3744ef9e149778da7cc881b4f994d","IPY_MODEL_d8977955e7654d2ca13d0028853e151d","IPY_MODEL_b3f793441cdf4f72ba4db1b172ff4df9"],"layout":"IPY_MODEL_047952de6b2f4284b74cf3eca335f7b1"}},"03d3744ef9e149778da7cc881b4f994d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9de40692da164fe3b6df887d0c89a2cc","placeholder":"​","style":"IPY_MODEL_8d68dedd3bb7423cb8821fe97e484761","value":"최종 모델 학습: 100%"}},"d8977955e7654d2ca13d0028853e151d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_58a6b199129b46f4b8ec8c20bbc3411c","max":50,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1eba94b6626f4473b380e16aacd40ed8","value":50}},"b3f793441cdf4f72ba4db1b172ff4df9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0bf00a7fb67a4e728ddee38e34d6b670","placeholder":"​","style":"IPY_MODEL_123452e5693142c2b1b2e49c9faa26eb","value":" 50/50 [00:52&lt;00:00,  1.06s/it]"}},"047952de6b2f4284b74cf3eca335f7b1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9de40692da164fe3b6df887d0c89a2cc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8d68dedd3bb7423cb8821fe97e484761":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"58a6b199129b46f4b8ec8c20bbc3411c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1eba94b6626f4473b380e16aacd40ed8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0bf00a7fb67a4e728ddee38e34d6b670":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"123452e5693142c2b1b2e49c9faa26eb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"96fc8f01e9f6415a8eaf7d1489f928a7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_191cfdcff8c64c189171784b3ce13d43","IPY_MODEL_dcd0596d2164463386d7cc630214fc4c","IPY_MODEL_37c0ab1f978e45a890d4365610d7273c"],"layout":"IPY_MODEL_52d5f1579dff49988bb80feadaf17b87"}},"191cfdcff8c64c189171784b3ce13d43":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5666a03f60454c9fa769b2d894450b60","placeholder":"​","style":"IPY_MODEL_c3d3f85968d54c269418ab42feb5d7e0","value":"전체 데이터 예측: 100%"}},"dcd0596d2164463386d7cc630214fc4c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_60b16eaf9cc245cfbaba4dcb604930de","max":182,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b2325009d4494a06a82cf2218b6f5594","value":182}},"37c0ab1f978e45a890d4365610d7273c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_267bf87cf3f5447aa211b5e8f56b5f8c","placeholder":"​","style":"IPY_MODEL_e1c1c0c3529a44aba678c01c1bc0961a","value":" 182/182 [00:00&lt;00:00, 365.35it/s]"}},"52d5f1579dff49988bb80feadaf17b87":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5666a03f60454c9fa769b2d894450b60":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c3d3f85968d54c269418ab42feb5d7e0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"60b16eaf9cc245cfbaba4dcb604930de":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b2325009d4494a06a82cf2218b6f5594":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"267bf87cf3f5447aa211b5e8f56b5f8c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e1c1c0c3529a44aba678c01c1bc0961a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dc9013c6bf194d2898383c04ecade3aa":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ee3b88347ed94377b63f5e82358ac19e","IPY_MODEL_4544a0d935224297bbd56fa6862a1e8e","IPY_MODEL_1e6ac94acf654937a8982463d7854ebd"],"layout":"IPY_MODEL_06c095b5441b439c8c57c6224fb429cd"}},"ee3b88347ed94377b63f5e82358ac19e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d2a34fe53fc247fab19bea5bd933386d","placeholder":"​","style":"IPY_MODEL_4ad161787f6e43cc93c32b5194377987","value":"Optuna 튜닝 진행률:  24%"}},"4544a0d935224297bbd56fa6862a1e8e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_4f4bda885a634cae8ecb6a356a1ee623","max":50,"min":0,"orientation":"horizontal","style":"IPY_MODEL_333c0cbb80ea4a2ba2e03c19091b7d9f","value":12}},"1e6ac94acf654937a8982463d7854ebd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6eada2a3ad9048d388a9f32df647eb7b","placeholder":"​","style":"IPY_MODEL_693bb7771eea4b6f823387f7a3961cb6","value":" 12/50 [03:40&lt;06:59, 11.04s/it]"}},"06c095b5441b439c8c57c6224fb429cd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d2a34fe53fc247fab19bea5bd933386d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4ad161787f6e43cc93c32b5194377987":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4f4bda885a634cae8ecb6a356a1ee623":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"333c0cbb80ea4a2ba2e03c19091b7d9f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6eada2a3ad9048d388a9f32df647eb7b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"693bb7771eea4b6f823387f7a3961cb6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3e96d162c3d3441aabc18cb190db7b9b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2d12a40656c14a1c9c3ee4c4ebbea5eb","IPY_MODEL_b3e9e2e5e7254fbcbb3344d2e9a13028","IPY_MODEL_6557f027fe674dfaa55e94d1845c8cd3"],"layout":"IPY_MODEL_961231f972ba426eb8387ef923458304"}},"2d12a40656c14a1c9c3ee4c4ebbea5eb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dd500401af1a4c77b3b8338490821096","placeholder":"​","style":"IPY_MODEL_88ed3a132536428eb825ac892a277b25","value":"최종 모델 학습: 100%"}},"b3e9e2e5e7254fbcbb3344d2e9a13028":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7532473d934f43df92059f1a90ca8ecd","max":50,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2a568776fbd148c295103580ebfdb472","value":50}},"6557f027fe674dfaa55e94d1845c8cd3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4adbbddc998e4c49994896031acbc9dd","placeholder":"​","style":"IPY_MODEL_3062dab1f420436e823fdfe208c19a85","value":" 50/50 [00:59&lt;00:00,  1.19s/it]"}},"961231f972ba426eb8387ef923458304":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dd500401af1a4c77b3b8338490821096":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"88ed3a132536428eb825ac892a277b25":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7532473d934f43df92059f1a90ca8ecd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2a568776fbd148c295103580ebfdb472":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4adbbddc998e4c49994896031acbc9dd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3062dab1f420436e823fdfe208c19a85":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d1251744a38f40269a6bbf3334c6f102":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_603052a6d8ca4e9994776d30a5f889d7","IPY_MODEL_bc1dc29a9b1c45f6aee973a3f9cf8f08","IPY_MODEL_0b00f6110aa94dbbaec24a31ac4fccba"],"layout":"IPY_MODEL_c1fbbb120f8646fe88435290be3c1306"}},"603052a6d8ca4e9994776d30a5f889d7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_afb51f1ddfaa48d9888ab4a1e96a42a0","placeholder":"​","style":"IPY_MODEL_3fd91c2ea3ae40aca8d570ac4b389b60","value":"전체 데이터 예측: 100%"}},"bc1dc29a9b1c45f6aee973a3f9cf8f08":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d36d0071f90d4d4fb2d2a006499f90d8","max":182,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a95fabe00cb246aba4eb1f293914a20b","value":182}},"0b00f6110aa94dbbaec24a31ac4fccba":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1ce2767c0a3949c096feee0faf8fdbd8","placeholder":"​","style":"IPY_MODEL_c6358750ef89400fb50029815c6e9158","value":" 182/182 [00:00&lt;00:00, 350.30it/s]"}},"c1fbbb120f8646fe88435290be3c1306":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"afb51f1ddfaa48d9888ab4a1e96a42a0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3fd91c2ea3ae40aca8d570ac4b389b60":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d36d0071f90d4d4fb2d2a006499f90d8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a95fabe00cb246aba4eb1f293914a20b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1ce2767c0a3949c096feee0faf8fdbd8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c6358750ef89400fb50029815c6e9158":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b05dd6a8218b4214905ae047a66d7569":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_69e2f14075994122bd13fa413e197f62","IPY_MODEL_86e0b05e6d8048d4ac3800ad83c82dc3","IPY_MODEL_7326ff0683794ef994d481e6c20791ae"],"layout":"IPY_MODEL_fae00141112d4728bd317fa63d00f425"}},"69e2f14075994122bd13fa413e197f62":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_85b386b61c194477bec1a9777de481a5","placeholder":"​","style":"IPY_MODEL_461d8e9c495648108854f71872c8fbbb","value":"Optuna 튜닝 진행률:  26%"}},"86e0b05e6d8048d4ac3800ad83c82dc3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_7637a9d9f7b943c184025c78e181ce11","max":50,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2f5e01975281416d95e583edf8c5bfab","value":13}},"7326ff0683794ef994d481e6c20791ae":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8adafd2988dc4fd3880274c260da7327","placeholder":"​","style":"IPY_MODEL_d60df48179f34ae4b36bfa54f5b5189f","value":" 13/50 [01:43&lt;01:23,  2.25s/it]"}},"fae00141112d4728bd317fa63d00f425":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"85b386b61c194477bec1a9777de481a5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"461d8e9c495648108854f71872c8fbbb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7637a9d9f7b943c184025c78e181ce11":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2f5e01975281416d95e583edf8c5bfab":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8adafd2988dc4fd3880274c260da7327":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d60df48179f34ae4b36bfa54f5b5189f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6b391705a5314ed5a1dd55e1c6a54254":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8534e60491ff4b0ba6fbe1d93a829f58","IPY_MODEL_ad72ce2b064d4506b9f1545bb8ff42c1","IPY_MODEL_9e0f5da9cc334d2fa4b4bab5324743e7"],"layout":"IPY_MODEL_1d4fef4d26af40b29063ae8ab9577a46"}},"8534e60491ff4b0ba6fbe1d93a829f58":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c0b3b47d32f14274b60e50e045e81c10","placeholder":"​","style":"IPY_MODEL_f7b46f6d93d342a6943dd130f23450bc","value":"최종 모델 학습: 100%"}},"ad72ce2b064d4506b9f1545bb8ff42c1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_40233cbc790d4c99a55262a3fcc6e5c4","max":50,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c2abbaaa49954e8fbbd00135d418f05d","value":50}},"9e0f5da9cc334d2fa4b4bab5324743e7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7f2b043d41d94da3accb2a5b24b51d08","placeholder":"​","style":"IPY_MODEL_1e04b655aab04e6faea3dec2a9957cc3","value":" 50/50 [01:03&lt;00:00,  1.28s/it]"}},"1d4fef4d26af40b29063ae8ab9577a46":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c0b3b47d32f14274b60e50e045e81c10":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f7b46f6d93d342a6943dd130f23450bc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"40233cbc790d4c99a55262a3fcc6e5c4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c2abbaaa49954e8fbbd00135d418f05d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7f2b043d41d94da3accb2a5b24b51d08":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1e04b655aab04e6faea3dec2a9957cc3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e3198cf46ff0445289c751b5e31f054c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5131dbd30be24cc8a6db1e0f31acd0f3","IPY_MODEL_486ba97899f74a2d88cd3ceeb6fc5da8","IPY_MODEL_5bcb82440d114fa990d230f1685513e9"],"layout":"IPY_MODEL_24dbeab8d7f94a9cb47b01359a6c6dc0"}},"5131dbd30be24cc8a6db1e0f31acd0f3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_64c481014fc744868b0335e0b2a20811","placeholder":"​","style":"IPY_MODEL_ed33283562b344b3a02a85e71b1108c3","value":"전체 데이터 예측: 100%"}},"486ba97899f74a2d88cd3ceeb6fc5da8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f70e28f1441d4848870a17ce6443470d","max":182,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fc4caa7df9164818b84ea26ba64df6af","value":182}},"5bcb82440d114fa990d230f1685513e9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_de16608c49124a99a25c631ea9a2e325","placeholder":"​","style":"IPY_MODEL_e64710ae490848bcb9d4e94ce2f8d0ec","value":" 182/182 [00:00&lt;00:00, 343.98it/s]"}},"24dbeab8d7f94a9cb47b01359a6c6dc0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"64c481014fc744868b0335e0b2a20811":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ed33283562b344b3a02a85e71b1108c3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f70e28f1441d4848870a17ce6443470d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fc4caa7df9164818b84ea26ba64df6af":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"de16608c49124a99a25c631ea9a2e325":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e64710ae490848bcb9d4e94ce2f8d0ec":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5b60be2615e846b9b8a386f11ca04987":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_53be6671e3aa410aa034f5c8fab1c857","IPY_MODEL_ab8f495f35a340c690c1de6826df9398","IPY_MODEL_2096f498ba48488bb3864cc611f4cf12"],"layout":"IPY_MODEL_5a96c559f10947cdb8c688f5ba594839"}},"53be6671e3aa410aa034f5c8fab1c857":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6dd4e0cf275047f1a6b5514cde6982ba","placeholder":"​","style":"IPY_MODEL_68f716ce09724cd89e6ea8ac541772fb","value":"Optuna 튜닝 진행률:  54%"}},"ab8f495f35a340c690c1de6826df9398":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_2b4124e2f98c436d8992ff6ef966ec7e","max":50,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a26ec6b10cdc4e34973a664a3ae38282","value":27}},"2096f498ba48488bb3864cc611f4cf12":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1d067b658c3a4cb5a6fa2d89755c815a","placeholder":"​","style":"IPY_MODEL_9f9ddf22ece649c4ba4bd25535fe26fc","value":" 27/50 [05:39&lt;01:40,  4.35s/it]"}},"5a96c559f10947cdb8c688f5ba594839":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6dd4e0cf275047f1a6b5514cde6982ba":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"68f716ce09724cd89e6ea8ac541772fb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2b4124e2f98c436d8992ff6ef966ec7e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a26ec6b10cdc4e34973a664a3ae38282":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1d067b658c3a4cb5a6fa2d89755c815a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9f9ddf22ece649c4ba4bd25535fe26fc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"06ce44b840dd49aeaf7915166c6482d6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6753b379f69543c9958359a9ddb6d93f","IPY_MODEL_3843e8cd20024e2e9ea33837f4df3f9a","IPY_MODEL_2b2613b3760940e49e58db8bcab9dd09"],"layout":"IPY_MODEL_920e1fcec2a94d2cb702ce96b33c22fa"}},"6753b379f69543c9958359a9ddb6d93f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_08fb6ff3b7014521b6e9e35d8fe0f47c","placeholder":"​","style":"IPY_MODEL_23a034e2c2454be2ba82f6170522bfc2","value":"최종 모델 학습: 100%"}},"3843e8cd20024e2e9ea33837f4df3f9a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a396967e50e546479c77f3223e2e746a","max":50,"min":0,"orientation":"horizontal","style":"IPY_MODEL_37d23728d2814e52a046ca6c3324cf8a","value":50}},"2b2613b3760940e49e58db8bcab9dd09":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f62470bcae6643768ca2cc3be828863c","placeholder":"​","style":"IPY_MODEL_adf6d9cf29b14879a461a101d580e04c","value":" 50/50 [01:01&lt;00:00,  1.22s/it]"}},"920e1fcec2a94d2cb702ce96b33c22fa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"08fb6ff3b7014521b6e9e35d8fe0f47c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"23a034e2c2454be2ba82f6170522bfc2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a396967e50e546479c77f3223e2e746a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"37d23728d2814e52a046ca6c3324cf8a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f62470bcae6643768ca2cc3be828863c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"adf6d9cf29b14879a461a101d580e04c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"aad68fc3c16c4bb2ba2c656004ae3644":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a33ae8534262466ea31bc6621df89dfc","IPY_MODEL_ddf50ff01ccd42ad86d9fd91dd24bed1","IPY_MODEL_9f325aab75db410693695c0c35600c10"],"layout":"IPY_MODEL_e33a9cc013d5487ea7aa32d3dad0bc1e"}},"a33ae8534262466ea31bc6621df89dfc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_811ae03883f544669c93da8af6c0f6b1","placeholder":"​","style":"IPY_MODEL_a0cbd8b977254501828f0df9f7de99d3","value":"전체 데이터 예측: 100%"}},"ddf50ff01ccd42ad86d9fd91dd24bed1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ad4d0fb8abb34fc68fea83b0d756ed15","max":175,"min":0,"orientation":"horizontal","style":"IPY_MODEL_01ce99cbd5e24d30aab3c328d581886c","value":175}},"9f325aab75db410693695c0c35600c10":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_05a9cc6c6d394424962921059365f3f0","placeholder":"​","style":"IPY_MODEL_4dde4d1d5d234c98b3d2dc459113e6c3","value":" 175/175 [00:00&lt;00:00, 343.49it/s]"}},"e33a9cc013d5487ea7aa32d3dad0bc1e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"811ae03883f544669c93da8af6c0f6b1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a0cbd8b977254501828f0df9f7de99d3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ad4d0fb8abb34fc68fea83b0d756ed15":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"01ce99cbd5e24d30aab3c328d581886c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"05a9cc6c6d394424962921059365f3f0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4dde4d1d5d234c98b3d2dc459113e6c3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"68848bb41bc145bb90ddae4524070005":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c7180b450add453a8ac1628838255399","IPY_MODEL_c87c054738274d6c83db40ac4e5eba6d","IPY_MODEL_56beecfabd4b479e94d4fde631639cfc"],"layout":"IPY_MODEL_49924efc0afe48a088606806b32e926a"}},"c7180b450add453a8ac1628838255399":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0d94b167727640b1944c472b609c15de","placeholder":"​","style":"IPY_MODEL_4d3b19a1aebd4b758d15a329b762cb3a","value":"Optuna 튜닝 진행률:  28%"}},"c87c054738274d6c83db40ac4e5eba6d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_f3056bef8dfe4d2f978bb94b8de4bb89","max":50,"min":0,"orientation":"horizontal","style":"IPY_MODEL_20631af4a07f4a228661e4a5929d65e2","value":14}},"56beecfabd4b479e94d4fde631639cfc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_30568d9888ae4854a53cc4b05276f917","placeholder":"​","style":"IPY_MODEL_d317372d3419416ea8a3e04f71fdb52f","value":" 14/50 [01:00&lt;02:11,  3.66s/it]"}},"49924efc0afe48a088606806b32e926a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0d94b167727640b1944c472b609c15de":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4d3b19a1aebd4b758d15a329b762cb3a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f3056bef8dfe4d2f978bb94b8de4bb89":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"20631af4a07f4a228661e4a5929d65e2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"30568d9888ae4854a53cc4b05276f917":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d317372d3419416ea8a3e04f71fdb52f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c1341a768f7a41e3961aee306e90e875":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8bad9f1923864d229c1f3fac53c1b569","IPY_MODEL_1c18f387c6b54010953b7ffa6c96bb49","IPY_MODEL_5f883673852a4defa86f08210fb78060"],"layout":"IPY_MODEL_9cffcde819784cc180119878969dc28e"}},"8bad9f1923864d229c1f3fac53c1b569":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e61beb0485014b559ddbe999a9703d9e","placeholder":"​","style":"IPY_MODEL_a5bfd8b788c24507818a4ca93e132821","value":"최종 모델 학습: 100%"}},"1c18f387c6b54010953b7ffa6c96bb49":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1692e3158d884ba6b865a9cb09de78e9","max":50,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ee59a240575c40238ac9f2963fac5cff","value":50}},"5f883673852a4defa86f08210fb78060":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6636f71c7dd74319b53e53add792c136","placeholder":"​","style":"IPY_MODEL_05216eff3fa649e48b6de7d327a6014e","value":" 50/50 [00:57&lt;00:00,  1.14s/it]"}},"9cffcde819784cc180119878969dc28e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e61beb0485014b559ddbe999a9703d9e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a5bfd8b788c24507818a4ca93e132821":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1692e3158d884ba6b865a9cb09de78e9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ee59a240575c40238ac9f2963fac5cff":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6636f71c7dd74319b53e53add792c136":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"05216eff3fa649e48b6de7d327a6014e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"afe10afcde8b40f49d6028da66efeaa6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c139418e741241d596e87cc839ed433d","IPY_MODEL_86e7100e5ec343aba6e8c4e0c810d9fc","IPY_MODEL_08a0b73d2fd941668fb40c373f182d87"],"layout":"IPY_MODEL_52381221f61541e0a7c74dbdc65f8e5b"}},"c139418e741241d596e87cc839ed433d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d0c70493bb4b487ca33a00d49c25309b","placeholder":"​","style":"IPY_MODEL_0fa39f140f36422db7da74b1824d576c","value":"전체 데이터 예측: 100%"}},"86e7100e5ec343aba6e8c4e0c810d9fc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_80dc71fd3c8f43d3a245d9addef56a5e","max":175,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c3e45240b4754e818a25e88b9187e269","value":175}},"08a0b73d2fd941668fb40c373f182d87":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ac3b09338dca4c9f90cd0e8304b0c4a3","placeholder":"​","style":"IPY_MODEL_55abdca2dfd543febbcf7e24527d33a6","value":" 175/175 [00:00&lt;00:00, 269.33it/s]"}},"52381221f61541e0a7c74dbdc65f8e5b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d0c70493bb4b487ca33a00d49c25309b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0fa39f140f36422db7da74b1824d576c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"80dc71fd3c8f43d3a245d9addef56a5e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c3e45240b4754e818a25e88b9187e269":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ac3b09338dca4c9f90cd0e8304b0c4a3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"55abdca2dfd543febbcf7e24527d33a6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"deb064377633438cbe2ff73cae1ad40a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8595a44783ac497fa775377bab913a98","IPY_MODEL_483b765959f64dd3b007c57ed8481f3f","IPY_MODEL_e553d15fa5694374950c1904ce198b51"],"layout":"IPY_MODEL_364eb6d295c6479380742f5e95468c97"}},"8595a44783ac497fa775377bab913a98":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cd00d0368aa5472a8d163750aa596f50","placeholder":"​","style":"IPY_MODEL_21c604080ad74291b0d40b33079259b1","value":"Optuna 튜닝 진행률:  42%"}},"483b765959f64dd3b007c57ed8481f3f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_85af6d6537e741419eba2c3f9c40ec64","max":50,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1645c78125b84196b578d6e2a8965d74","value":21}},"e553d15fa5694374950c1904ce198b51":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0d4d503d03664fb1a03fee31614b924f","placeholder":"​","style":"IPY_MODEL_2873c6575ee64f2fa2b1ff1e9c9778c8","value":" 21/50 [04:15&lt;02:35,  5.36s/it]"}},"364eb6d295c6479380742f5e95468c97":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cd00d0368aa5472a8d163750aa596f50":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"21c604080ad74291b0d40b33079259b1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"85af6d6537e741419eba2c3f9c40ec64":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1645c78125b84196b578d6e2a8965d74":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0d4d503d03664fb1a03fee31614b924f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2873c6575ee64f2fa2b1ff1e9c9778c8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2d0e1b44be1e400b9ae43920511a9a1d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d08ebb5d271948e4830477b172cedc7d","IPY_MODEL_fa3e6a9d85ff46f2bd289734236889d8","IPY_MODEL_4234263be3cd4fcaa9ecf1906c53b5f1"],"layout":"IPY_MODEL_8dd359c92b0c4b279ae46212da9ca370"}},"d08ebb5d271948e4830477b172cedc7d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2ccf0c250cc7490fbd60834f7c900342","placeholder":"​","style":"IPY_MODEL_e695ac7f755740b78a0bdd5da8283a09","value":"최종 모델 학습: 100%"}},"fa3e6a9d85ff46f2bd289734236889d8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8df3a9c126684d2ca5a67ed9fc5f72d9","max":50,"min":0,"orientation":"horizontal","style":"IPY_MODEL_507482cc093b469c8cdfe0aa75f52120","value":50}},"4234263be3cd4fcaa9ecf1906c53b5f1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8895a3cfe6844065a0358a71e4337b3d","placeholder":"​","style":"IPY_MODEL_a1204a778fdf46b686fed65b7ff865fd","value":" 50/50 [01:01&lt;00:00,  1.25s/it]"}},"8dd359c92b0c4b279ae46212da9ca370":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2ccf0c250cc7490fbd60834f7c900342":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e695ac7f755740b78a0bdd5da8283a09":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8df3a9c126684d2ca5a67ed9fc5f72d9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"507482cc093b469c8cdfe0aa75f52120":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8895a3cfe6844065a0358a71e4337b3d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a1204a778fdf46b686fed65b7ff865fd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"830c61dd0bf245d6b79c758a19cb6ad1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8680eb015f26488fbd6637458a281dd3","IPY_MODEL_27d2ffd197e4458b827f5e2e358a5716","IPY_MODEL_503917cc7b004658aa331311416c83a7"],"layout":"IPY_MODEL_05288c1d5527471bb500a94a0a3bb870"}},"8680eb015f26488fbd6637458a281dd3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cdd6ebe87e1441d2a60bded440d6a948","placeholder":"​","style":"IPY_MODEL_17743ff6591049adb01ddd22d9e57ec2","value":"전체 데이터 예측: 100%"}},"27d2ffd197e4458b827f5e2e358a5716":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_16934732f62c416983b45eb116357d56","max":175,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2074833f0ed8414581890f4e8b88b63f","value":175}},"503917cc7b004658aa331311416c83a7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3ae1fb29935449839264b5386711e44a","placeholder":"​","style":"IPY_MODEL_8811b9cfacc8404e97a1ddb6fdafdfcc","value":" 175/175 [00:00&lt;00:00, 344.86it/s]"}},"05288c1d5527471bb500a94a0a3bb870":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cdd6ebe87e1441d2a60bded440d6a948":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"17743ff6591049adb01ddd22d9e57ec2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"16934732f62c416983b45eb116357d56":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2074833f0ed8414581890f4e8b88b63f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3ae1fb29935449839264b5386711e44a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8811b9cfacc8404e97a1ddb6fdafdfcc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"74ee21b548054a208c9cf65cbe5183b6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c446118c154d461b987d24f2d199009d","IPY_MODEL_f8e7cb29355b41aeae9377f0e13cd54f","IPY_MODEL_5deb20c992c644c4bc4edee8af6ed796"],"layout":"IPY_MODEL_3593fce9219e4ac3a8867f9d4dab4e41"}},"c446118c154d461b987d24f2d199009d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_53311d4060fd4abf9403531214950336","placeholder":"​","style":"IPY_MODEL_e56620c0c6fc4dca9467db9ee5b3bc24","value":"Optuna 튜닝 진행률:  28%"}},"f8e7cb29355b41aeae9377f0e13cd54f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_66da635189424b2ab8948a6ef61b89cd","max":50,"min":0,"orientation":"horizontal","style":"IPY_MODEL_bfc4a527fee049839822e485a116e022","value":14}},"5deb20c992c644c4bc4edee8af6ed796":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5da0796230fa4b46bdc89b165aa00528","placeholder":"​","style":"IPY_MODEL_9455c48cfdc2443d97300181e26b576d","value":" 14/50 [02:23&lt;04:19,  7.21s/it]"}},"3593fce9219e4ac3a8867f9d4dab4e41":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"53311d4060fd4abf9403531214950336":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e56620c0c6fc4dca9467db9ee5b3bc24":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"66da635189424b2ab8948a6ef61b89cd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bfc4a527fee049839822e485a116e022":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5da0796230fa4b46bdc89b165aa00528":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9455c48cfdc2443d97300181e26b576d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"31bec6fc0bf243c487870009482d9ec1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6a181ad378a147268cae3766e9663305","IPY_MODEL_b9b562266c4a4546a957d728241d7039","IPY_MODEL_f1badbb2fd3b4007be2c3101facfe7cc"],"layout":"IPY_MODEL_0377664fcda24e5bb3777adc636cb176"}},"6a181ad378a147268cae3766e9663305":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6849c5bb716249adb00d089165298141","placeholder":"​","style":"IPY_MODEL_469e31243e1541ddac9227486b6c067c","value":"최종 모델 학습: 100%"}},"b9b562266c4a4546a957d728241d7039":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_02e22a2c7a9a406d862a0a33cf712f43","max":50,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e857804bddf4466dabce6cbd9cd32720","value":50}},"f1badbb2fd3b4007be2c3101facfe7cc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_881df015d2dd459bb7a159d5f332f1ea","placeholder":"​","style":"IPY_MODEL_d51fd3cba9284b4e95f2a1814e188717","value":" 50/50 [00:54&lt;00:00,  1.07s/it]"}},"0377664fcda24e5bb3777adc636cb176":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6849c5bb716249adb00d089165298141":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"469e31243e1541ddac9227486b6c067c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"02e22a2c7a9a406d862a0a33cf712f43":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e857804bddf4466dabce6cbd9cd32720":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"881df015d2dd459bb7a159d5f332f1ea":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d51fd3cba9284b4e95f2a1814e188717":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b028de5e99e94ad89c0ce0575f294c57":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_287299b4311a4fd4a3e1f723d445ade2","IPY_MODEL_36a5eb257f6b44a28504d9588f5b486d","IPY_MODEL_cfc831f1ccc142ef95f584766ae573a0"],"layout":"IPY_MODEL_61aa07bd4f5d4ff9a2357de86a0cb66e"}},"287299b4311a4fd4a3e1f723d445ade2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d3c6741ab36f4a7ab548aa67ebd17db2","placeholder":"​","style":"IPY_MODEL_9a78c94b44554e60b2322f8a0d8587a1","value":"전체 데이터 예측: 100%"}},"36a5eb257f6b44a28504d9588f5b486d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2f31da221525436cbd7338dadeac1a88","max":175,"min":0,"orientation":"horizontal","style":"IPY_MODEL_053e17bcd54c447b95a1dc8ce662cc3c","value":175}},"cfc831f1ccc142ef95f584766ae573a0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bb40e5d59f374d40946036219a5b7eb1","placeholder":"​","style":"IPY_MODEL_50dd4e5d3b134f58bce71707e5135577","value":" 175/175 [00:00&lt;00:00, 355.41it/s]"}},"61aa07bd4f5d4ff9a2357de86a0cb66e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d3c6741ab36f4a7ab548aa67ebd17db2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9a78c94b44554e60b2322f8a0d8587a1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2f31da221525436cbd7338dadeac1a88":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"053e17bcd54c447b95a1dc8ce662cc3c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bb40e5d59f374d40946036219a5b7eb1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"50dd4e5d3b134f58bce71707e5135577":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2ee964aeb0c34022ac357b2cbc0a25f2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7d1b61d3ac234b2c9f6c1e8b1171e4dd","IPY_MODEL_e35bbbe8a5d44744810d83f7d4fc8753","IPY_MODEL_ec6ec1b529f54b4da97c6edc9097a970"],"layout":"IPY_MODEL_9b3bedb6a407446b8dec49470a033a2f"}},"7d1b61d3ac234b2c9f6c1e8b1171e4dd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4c912ba697ff41848a5200d3fa5b01ff","placeholder":"​","style":"IPY_MODEL_5e09ee085ea54f35a4503bc6fff9a74c","value":"Optuna 튜닝 진행률:  28%"}},"e35bbbe8a5d44744810d83f7d4fc8753":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_ce1571c7280042089feb8f179eee7214","max":50,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d02148e3908041a3ad80f957b4e851c6","value":14}},"ec6ec1b529f54b4da97c6edc9097a970":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_92cb70ed762c4b57a65c91590fa48c92","placeholder":"​","style":"IPY_MODEL_547a4bc0774441f5b451e9805f518ae6","value":" 14/50 [02:52&lt;03:18,  5.53s/it]"}},"9b3bedb6a407446b8dec49470a033a2f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4c912ba697ff41848a5200d3fa5b01ff":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5e09ee085ea54f35a4503bc6fff9a74c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ce1571c7280042089feb8f179eee7214":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d02148e3908041a3ad80f957b4e851c6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"92cb70ed762c4b57a65c91590fa48c92":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"547a4bc0774441f5b451e9805f518ae6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a10a5c79309d4465a93bfe2e61d4f92e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_472ae2e809f5436d87469bf4a1fa5ab8","IPY_MODEL_78c225f7e221498c9c66a4a559cfac46","IPY_MODEL_007e161d8f8e420593aaf466562fb2ff"],"layout":"IPY_MODEL_9e15ae2d644d48e6a40eef99696a5743"}},"472ae2e809f5436d87469bf4a1fa5ab8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3cfd4f42de0241598ee3b3689ed9ec70","placeholder":"​","style":"IPY_MODEL_27cabce55c704e0f92d71ee2706ee829","value":"최종 모델 학습: 100%"}},"78c225f7e221498c9c66a4a559cfac46":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5fa26702f2da4904b3c2307dec0598a3","max":50,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5607ee686bd24beda014c416e4bacaa7","value":50}},"007e161d8f8e420593aaf466562fb2ff":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_88c573b37e3f4bb0b6e85f6e13d7ca10","placeholder":"​","style":"IPY_MODEL_6db2562681be487fa1f9e603bafdfc90","value":" 50/50 [01:01&lt;00:00,  1.28s/it]"}},"9e15ae2d644d48e6a40eef99696a5743":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3cfd4f42de0241598ee3b3689ed9ec70":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"27cabce55c704e0f92d71ee2706ee829":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5fa26702f2da4904b3c2307dec0598a3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5607ee686bd24beda014c416e4bacaa7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"88c573b37e3f4bb0b6e85f6e13d7ca10":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6db2562681be487fa1f9e603bafdfc90":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b718599dc8d342b8b7fe13cb712385b4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2d53b4f5788340a1bef62e5322b914fa","IPY_MODEL_e0f00c05cee04778b258b1997b39f86b","IPY_MODEL_37026e1fa2c647059f04e11619039a2e"],"layout":"IPY_MODEL_ab573e7e2801467dbf2ca6a62da3c094"}},"2d53b4f5788340a1bef62e5322b914fa":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8ab5b18dda8e47b3ba16475079eede11","placeholder":"​","style":"IPY_MODEL_582f3280693848e78165c32b3f2c9572","value":"전체 데이터 예측: 100%"}},"e0f00c05cee04778b258b1997b39f86b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7b29f235ee0f486587d84ac10af1327b","max":175,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4ce24e94b82e4bcbb1031efd0e0512e9","value":175}},"37026e1fa2c647059f04e11619039a2e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_49e2f9ac1ffc4d61aaadd5b1c5fa6c7b","placeholder":"​","style":"IPY_MODEL_c968a48ccff84484856740bc423d4ab3","value":" 175/175 [00:00&lt;00:00, 337.51it/s]"}},"ab573e7e2801467dbf2ca6a62da3c094":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8ab5b18dda8e47b3ba16475079eede11":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"582f3280693848e78165c32b3f2c9572":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7b29f235ee0f486587d84ac10af1327b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4ce24e94b82e4bcbb1031efd0e0512e9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"49e2f9ac1ffc4d61aaadd5b1c5fa6c7b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c968a48ccff84484856740bc423d4ab3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["# Hyperparameter Tuning\n","\n","모델 깊이: 1 ~ 5, 모델 너비: 32 ~ 512, dropuout: 0.1 ~ 0.5, learning_rate: 1e-5 ~ 1e-2"],"metadata":{"id":"tOgyr_ov3Uhr"}},{"cell_type":"code","source":["! pip install optuna"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oBIuMBK-S4pz","executionInfo":{"status":"ok","timestamp":1760277819639,"user_tz":-540,"elapsed":7153,"user":{"displayName":"KW-data-analytics","userId":"09651493752354345908"}},"outputId":"8d947c37-e270-4eda-fdea-3a31634f009a"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting optuna\n","  Downloading optuna-4.5.0-py3-none-any.whl.metadata (17 kB)\n","Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (1.16.5)\n","Collecting colorlog (from optuna)\n","  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (25.0)\n","Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.43)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from optuna) (4.67.1)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from optuna) (6.0.3)\n","Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (1.3.10)\n","Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (4.15.0)\n","Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.4)\n","Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.12/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.3)\n","Downloading optuna-4.5.0-py3-none-any.whl (400 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m400.9/400.9 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n","Installing collected packages: colorlog, optuna\n","Successfully installed colorlog-6.9.0 optuna-4.5.0\n"]}]},{"cell_type":"code","source":["# --- 데이터 로드 및 전처리 ---\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YH8TDSl6u64G","executionInfo":{"status":"ok","timestamp":1760277834736,"user_tz":-540,"elapsed":13936,"user":{"displayName":"KW-data-analytics","userId":"09651493752354345908"}},"outputId":"19ef3790-23eb-4f8d-a367-72ac6fc5b0b3"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":3,"metadata":{"id":"aZ6d7uB7SKi8","executionInfo":{"status":"ok","timestamp":1760277842490,"user_tz":-540,"elapsed":5345,"user":{"displayName":"KW-data-analytics","userId":"09651493752354345908"}}},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import TensorDataset, DataLoader\n","import optuna\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import average_precision_score, roc_auc_score, f1_score\n","from tqdm.notebook import tqdm\n","import gc"]},{"cell_type":"code","source":["# === 1. PyTorch 장치 설정 ===\n","print(\"🌟 Step 0: PyTorch 장치 설정\")\n","DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"✅ 사용 가능한 장치: {DEVICE}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AHbhfNrsTCYf","executionInfo":{"status":"ok","timestamp":1760277842512,"user_tz":-540,"elapsed":5,"user":{"displayName":"KW-data-analytics","userId":"09651493752354345908"}},"outputId":"24931fe7-c579-44b4-f48f-b33333aeb68a"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["🌟 Step 0: PyTorch 장치 설정\n","✅ 사용 가능한 장치: cuda\n"]}]},{"cell_type":"markdown","source":["# Amazon"],"metadata":{"id":"J4pr3cEc3sQA"}},{"cell_type":"markdown","source":["## T5"],"metadata":{"id":"dJplXeJz3tYq"}},{"cell_type":"code","source":["# === 2. 환경설정 클래스 ===\n","class Config:\n","    \"\"\"실행에 필요한 모든 설정값을 중앙에서 관리합니다.\"\"\"\n","    # 🌟 1. 파일 경로 설정\n","    CSV_FILE_PATH = \"/content/drive/MyDrive/review_helpfulness/PADA/data/amazon/amazon.csv\"\n","    EMBEDDING_PATH = \"/content/drive/MyDrive/review_helpfulness/PADA/embedding/amazon_T5.npy\"\n","\n","    # 🌟 2. 최종 결과 CSV 파일 저장 경로 설정\n","    OUTPUT_CSV_PATH = \"/content/drive/MyDrive/review_helpfulness/PADA/results/s2/amazon/MLP/MLP_amazon_with_T5_predictions.csv\"\n","\n","    # --- 데이터 정보 ---\n","    TARGET_COLUMN = 'binary_helpfulness'\n","\n","    # --- 데이터 분할 ---\n","    TEST_SPLIT_RATIO = 0.2\n","    RANDOM_STATE = 42\n","\n","    # --- PyTorch 모델 및 학습 설정 ---\n","    EPOCHS = 50\n","    BATCH_SIZE = 256\n","    VALIDATION_EARLY_STOPPING_PATIENCE = 5 # 개별 Trial 내 검증 성능 기반 조기 종료\n","\n","    # --- Optuna 튜닝 설정 ---\n","    N_TRIALS = 50\n","    TUNING_METRIC = 'pr_auc'\n","    STUDY_EARLY_STOPPING_ROUNDS = 10 # 전체 Study 조기 종료\n","\n","# === 3. MLP 모델 클래스 (PyTorch) ===\n","class MLP(nn.Module):\n","    def __init__(self, input_dim, trial):\n","        super(MLP, self).__init__()\n","        layers = []\n","\n","        # ✅ 은닉층 탐색 범위를 1~5개로 확장\n","        n_layers = trial.suggest_int('n_layers', 1, 5)\n","\n","        in_features = input_dim\n","        for i in range(n_layers):\n","            out_features = trial.suggest_int(f'n_units_l{i}', 32, 512, log=True)\n","            layers.append(nn.Linear(in_features, out_features))\n","            layers.append(nn.ReLU())\n","            p = trial.suggest_float(f'dropout_l{i}', 0.1, 0.5)\n","            layers.append(nn.Dropout(p))\n","            in_features = out_features\n","\n","        layers.append(nn.Linear(in_features, 1))\n","        self.layers = nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        return torch.sigmoid(self.layers(x).squeeze(-1))\n","\n","# === 4. 학습 및 평가 함수 ===\n","def train_model(model, loader, optimizer, criterion):\n","    model.train()\n","    for inputs, labels in loader:\n","        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n","        optimizer.zero_grad()\n","        outputs = model(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","def evaluate_model(model, loader):\n","    model.eval()\n","    all_preds = []\n","    all_labels = []\n","    with torch.no_grad():\n","        for inputs, labels in loader:\n","            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n","            outputs = model(inputs)\n","            all_preds.extend(outputs.cpu().numpy())\n","            all_labels.extend(labels.cpu().numpy())\n","    return np.array(all_preds), np.array(all_labels)\n","\n","# === 5. Optuna Objective 함수 (PyTorch용) ===\n","def objective(trial, X, y):\n","    X_train, X_val, y_train, y_val = train_test_split(\n","        X, y, test_size=0.25, random_state=Config.RANDOM_STATE, stratify=y)\n","\n","    train_dataset = TensorDataset(torch.FloatTensor(X_train), torch.FloatTensor(y_train))\n","    val_dataset = TensorDataset(torch.FloatTensor(X_val), torch.FloatTensor(y_val))\n","    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)\n","    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE)\n","\n","    input_dim = X_train.shape[1]\n","    model = MLP(input_dim, trial).to(DEVICE)\n","    lr = trial.suggest_float('learning_rate', 1e-5, 1e-2, log=True)\n","    optimizer = optim.Adam(model.parameters(), lr=lr)\n","    criterion = nn.BCELoss()\n","\n","    best_score = -1\n","    patience_counter = 0\n","\n","    for epoch in range(Config.EPOCHS):\n","        train_model(model, train_loader, optimizer, criterion)\n","        y_pred_proba, y_true = evaluate_model(model, val_loader)\n","        score = average_precision_score(y_true, y_pred_proba)\n","\n","        trial.report(score, epoch)\n","        if trial.should_prune():\n","            raise optuna.exceptions.TrialPruned()\n","\n","        if score > best_score:\n","            best_score = score\n","            patience_counter = 0\n","        else:\n","            patience_counter += 1\n","\n","        if patience_counter >= Config.VALIDATION_EARLY_STOPPING_PATIENCE:\n","            break\n","\n","    return best_score\n","\n","# === 6. Optuna 조기 종료 콜백 ===\n","class EarlyStoppingCallback:\n","    def __init__(self, early_stopping_rounds: int):\n","        self._early_stopping_rounds = early_stopping_rounds\n","        self._best_value = -float(\"inf\")\n","        self._counter = 0\n","\n","    def __call__(self, study: optuna.study.Study, trial: optuna.trial.Trial):\n","        current_best_value = study.best_value\n","        if current_best_value is not None and current_best_value > self._best_value:\n","            self._best_value = current_best_value\n","            self._counter = 0\n","        else:\n","            self._counter += 1\n","\n","        if self._counter >= self._early_stopping_rounds:\n","            print(f\"\\n[Optuna 조기 종료] {self._early_stopping_rounds}번의 trial 동안 최고 점수가 갱신되지 않아 튜닝을 중단합니다.\")\n","            study.stop()\n","\n","\n","# === 7. 메인 실행 블록 ===\n","if __name__ == '__main__':\n","    config = Config()\n","\n","    # --- Step 1: 데이터 로드 및 분할 ---\n","    print(\"\\n\" + \"=\"*50)\n","    print(\"📊 Step 1: 데이터 로드 및 분할\")\n","    try:\n","        df = pd.read_csv(config.CSV_FILE_PATH)\n","        labels = df[config.TARGET_COLUMN].values\n","        embeddings = np.load(config.EMBEDDING_PATH)\n","    except Exception as e:\n","        print(f\"🔥 파일 로드 실패: {e}\"); exit()\n","\n","    indices = np.arange(len(df))\n","    train_indices, test_indices = train_test_split(\n","        indices, test_size=config.TEST_SPLIT_RATIO, random_state=config.RANDOM_STATE, stratify=labels)\n","    X_train, X_test = embeddings[train_indices], embeddings[test_indices]\n","    y_train, y_test = labels[train_indices], labels[test_indices]\n","    print(f\"✅ 완료 (학습용: {len(y_train)}건, 테스트용: {len(y_test)}건)\")\n","\n","    # --- Step 2: Optuna 튜닝 수행 ---\n","    print(\"\\n\" + \"=\"*50)\n","    print(f\"🔬 Step 2: Optuna 하이퍼파라미터 튜닝 시작 (PyTorch)\")\n","    print(f\"(최대 {config.N_TRIALS}번 시도, {config.STUDY_EARLY_STOPPING_ROUNDS}번 개선 없으면 스터디 조기 종료)\")\n","    print(\"=\"*50)\n","\n","    study = optuna.create_study(direction='maximize', pruner=optuna.pruners.MedianPruner())\n","    pbar = tqdm(total=config.N_TRIALS, desc=\"Optuna 튜닝 진행률\")\n","\n","    try:\n","        study.optimize(lambda trial: objective(trial, X_train, y_train),\n","                       n_trials=config.N_TRIALS,\n","                       callbacks=[lambda s, t: pbar.update(1), EarlyStoppingCallback(config.STUDY_EARLY_STOPPING_ROUNDS)])\n","    except optuna.exceptions.OptunaError:\n","        pass # 조기 종료 시 예외 처리\n","    pbar.close()\n","\n","    # --- Step 3: 최적 모델 학습 및 평가 ---\n","    print(f\"\\n✅ 튜닝 완료!\")\n","    print(\"\\n\" + \"=\"*50)\n","    print(\"🔬 최적 하이퍼파라미터\")\n","    print(\"=\"*50)\n","    best_params = study.best_params\n","    for key, value in best_params.items():\n","        print(f\"{key:>20s}: {value}\")\n","    print(\"=\"*50)\n","\n","    print(f\"\\n🔬 Step 3: 튜닝된 최종 PyTorch 모델 학습 및 평가...\")\n","    train_dataset = TensorDataset(torch.FloatTensor(X_train), torch.FloatTensor(y_train))\n","    train_loader = DataLoader(train_dataset, batch_size=config.BATCH_SIZE, shuffle=True)\n","    test_dataset = TensorDataset(torch.FloatTensor(X_test), torch.FloatTensor(y_test))\n","    test_loader = DataLoader(test_dataset, batch_size=config.BATCH_SIZE)\n","\n","    # Optuna study 객체를 모의 trial로 사용하여 최종 모델 생성\n","    final_model = MLP(X_train.shape[1], study.best_trial).to(DEVICE)\n","    optimizer = optim.Adam(final_model.parameters(), lr=best_params['learning_rate'])\n","    criterion = nn.BCELoss()\n","\n","    # 최종 모델은 전체 학습 데이터로 학습\n","    for epoch in tqdm(range(config.EPOCHS), desc=\"최종 모델 학습\"):\n","        train_model(final_model, train_loader, optimizer, criterion)\n","\n","    y_pred_proba_tuned, y_true_test = evaluate_model(final_model, test_loader)\n","    y_pred_class_tuned = (y_pred_proba_tuned > 0.5).astype(int)\n","\n","    results = {\n","        \"PR AUC\": average_precision_score(y_true_test, y_pred_proba_tuned),\n","        \"ROC AUC\": roc_auc_score(y_true_test, y_pred_proba_tuned),\n","        \"F1-Score\": f1_score(y_true_test, y_pred_class_tuned),\n","    }\n","    print(\"✅ 튜닝된 PyTorch 모델 평가 완료.\")\n","    print(pd.DataFrame(results, index=['Optuna_Tuned_PyTorch']).round(4))\n","\n","    # --- Step 4: 결과 저장 ---\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"💾 Step 4: 최종 모델 예측 결과를 원본 CSV에 추가하여 저장\")\n","    print(\"=\"*60)\n","\n","    all_dataset = TensorDataset(torch.FloatTensor(embeddings))\n","    all_loader = DataLoader(all_dataset, batch_size=config.BATCH_SIZE * 2) # 예측 시에는 더 큰 배치 사용 가능\n","\n","    final_model.eval()\n","    all_predictions = []\n","    with torch.no_grad():\n","        for (inputs,) in tqdm(all_loader, desc=\"전체 데이터 예측\"):\n","            inputs = inputs.to(DEVICE)\n","            outputs = final_model(inputs)\n","            all_predictions.extend(outputs.cpu().numpy())\n","\n","    df['s2_pred_proba'] = all_predictions\n","    df['s2_pred_class'] = (df['s2_pred_proba'] > 0.5).astype(int)\n","\n","    df.to_csv(config.OUTPUT_CSV_PATH, index=False, encoding='utf-8-sig')\n","    print(f\"✅ 모든 데이터의 예측 결과가 '{config.OUTPUT_CSV_PATH}' 파일에 성공적으로 저장되었습니다.\")\n","\n","    # --- Step 5: 메모리 정리 ---\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"🧹 Step 5: 메모리 정리\")\n","    print(\"=\"*60)\n","    del df, labels, embeddings, X_train, X_test, y_train, y_test, final_model, study\n","    gc.collect()\n","    if torch.cuda.is_available():\n","        torch.cuda.empty_cache()\n","    print(\"✅ 메모리 정리가 완료되었습니다.\")\n","\n","    print(\"\\n🎉 모든 과정이 완료되었습니다!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["178ca151fb0445c3aedba8030785d0f2","76dba37fabc44256a9f9dcac0d98b445","c1c8e4c4d3284c439345bf001d251784","cd390bc42cfb497d9c49b3696ed950b1","91d924b385e9469a89f8c1fcfa4240e3","4eb47e1bd66346a197ee0b16c5041eb3","64efe6168f3f4bcca3ea91975e6fd52d","5702c0c83f2f4ba5b7807b5ada01779d","a2851b8864ff430db73861660b73b064","1423cd799fb84b21965d72584ea0ec38","874bcd3dd2174686a4b47dbb75b65e16","ae1e84ed6f4041ea896b353f030d0068","8d833c96df2b49a183b5b0892aabe005","353607436ea84b589bf951260b59840e","432314ea3071498b87d69b0bb443eecb","f98e9801da494a769e4e77e47d67ab93","b143e74a61c341f197e102e9dda701c5","84fbcd9a485946c78929790fdff9adaf","6592ceacd7ab498482bf24848231215d","3a698dbedde74f4e88e765ae4439bcca","b6a7cb3633604d7c841bd283df26ca3f","23c39fb7cd0a485a86c4c1ef7a7754bb","af554182b7d742d491e76b07f2996a18","f3c2f3f3bf634c1486682f8b83d068e2","abb6acac279943848880d607c5c3dcb6","b281b54710304bd0bf385445418a079c","14b01ec7750942bb9fa00a32fd58edc6","a0586fd8761d4b75a1f9f0f76ea8e0d5","7898208f0c3a4313bb612cb2f626ef37","48dc1f5f18594bc38f5503d93829835b","d69ae9c2f873468b990efcd0cc95e9ce","950f51d4567542eb8e0f8f1516c04cd5","60f45dd70fbb478e8f01a3fd5f8e64b2"]},"id":"2-dK3HQITCjh","executionInfo":{"status":"ok","timestamp":1760279778058,"user_tz":-540,"elapsed":343533,"user":{"displayName":"KW-data-analytics","userId":"09651493752354345908"}},"outputId":"739438b7-a9af-4c9e-c82e-45914d178831"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================================================\n","📊 Step 1: 데이터 로드 및 분할\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-10-12 14:30:41,478] A new study created in memory with name: no-name-63f12785-111f-4863-9bc5-1cb4c89701a3\n"]},{"output_type":"stream","name":"stdout","text":["✅ 완료 (학습용: 71941건, 테스트용: 17986건)\n","\n","==================================================\n","🔬 Step 2: Optuna 하이퍼파라미터 튜닝 시작 (PyTorch)\n","(최대 50번 시도, 10번 개선 없으면 스터디 조기 종료)\n","==================================================\n"]},{"output_type":"display_data","data":{"text/plain":["Optuna 튜닝 진행률:   0%|          | 0/50 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"178ca151fb0445c3aedba8030785d0f2"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2025-10-12 14:31:35,473] Trial 0 finished with value: 0.2981652789399747 and parameters: {'n_layers': 2, 'n_units_l0': 186, 'dropout_l0': 0.15892758484028113, 'n_units_l1': 257, 'dropout_l1': 0.47172771757275556, 'learning_rate': 3.647789321560909e-05}. Best is trial 0 with value: 0.2981652789399747.\n","[I 2025-10-12 14:32:20,304] Trial 1 finished with value: 0.29751379988279913 and parameters: {'n_layers': 1, 'n_units_l0': 114, 'dropout_l0': 0.3671092966933941, 'learning_rate': 9.825332102664499e-05}. Best is trial 0 with value: 0.2981652789399747.\n","[I 2025-10-12 14:32:59,988] Trial 2 finished with value: 0.3010748943694691 and parameters: {'n_layers': 2, 'n_units_l0': 206, 'dropout_l0': 0.13969848886970945, 'n_units_l1': 372, 'dropout_l1': 0.1794383679356839, 'learning_rate': 0.00013127777816374458}. Best is trial 2 with value: 0.3010748943694691.\n","[I 2025-10-12 14:33:17,468] Trial 3 finished with value: 0.29871010172570645 and parameters: {'n_layers': 4, 'n_units_l0': 78, 'dropout_l0': 0.2345474584376015, 'n_units_l1': 497, 'dropout_l1': 0.10816509331061366, 'n_units_l2': 425, 'dropout_l2': 0.16969795619266997, 'n_units_l3': 34, 'dropout_l3': 0.4460177569458099, 'learning_rate': 0.001995691732627533}. Best is trial 2 with value: 0.3010748943694691.\n","[I 2025-10-12 14:33:37,537] Trial 4 finished with value: 0.2998671017106066 and parameters: {'n_layers': 1, 'n_units_l0': 154, 'dropout_l0': 0.4145132551960098, 'learning_rate': 0.0007362738294433063}. Best is trial 2 with value: 0.3010748943694691.\n","[I 2025-10-12 14:33:38,517] Trial 5 pruned. \n","[I 2025-10-12 14:33:54,816] Trial 6 finished with value: 0.3055916363191656 and parameters: {'n_layers': 3, 'n_units_l0': 266, 'dropout_l0': 0.43258733866962806, 'n_units_l1': 291, 'dropout_l1': 0.2865953307130984, 'n_units_l2': 56, 'dropout_l2': 0.2233978579549068, 'learning_rate': 0.000930542552997091}. Best is trial 6 with value: 0.3055916363191656.\n","[I 2025-10-12 14:33:55,916] Trial 7 pruned. \n","[I 2025-10-12 14:33:57,121] Trial 8 pruned. \n","[I 2025-10-12 14:34:14,196] Trial 9 finished with value: 0.3008304340431386 and parameters: {'n_layers': 5, 'n_units_l0': 454, 'dropout_l0': 0.37738960732744664, 'n_units_l1': 60, 'dropout_l1': 0.15977340428658496, 'n_units_l2': 141, 'dropout_l2': 0.3216448349379578, 'n_units_l3': 154, 'dropout_l3': 0.1750737536323401, 'n_units_l4': 160, 'dropout_l4': 0.21677749553283565, 'learning_rate': 0.003011334099590743}. Best is trial 6 with value: 0.3055916363191656.\n","[I 2025-10-12 14:34:18,668] Trial 10 pruned. \n","[I 2025-10-12 14:34:33,007] Trial 11 finished with value: 0.3007762936020244 and parameters: {'n_layers': 3, 'n_units_l0': 274, 'dropout_l0': 0.13373351716043652, 'n_units_l1': 183, 'dropout_l1': 0.21690403715901477, 'n_units_l2': 41, 'dropout_l2': 0.11709323756309734, 'learning_rate': 0.0005103278082718641}. Best is trial 6 with value: 0.3055916363191656.\n","[I 2025-10-12 14:34:34,138] Trial 12 pruned. \n","[I 2025-10-12 14:34:51,511] Trial 13 finished with value: 0.3034090685756511 and parameters: {'n_layers': 2, 'n_units_l0': 273, 'dropout_l0': 0.18548511364768883, 'n_units_l1': 324, 'dropout_l1': 0.40266557025407484, 'learning_rate': 0.0009864680499872898}. Best is trial 6 with value: 0.3055916363191656.\n","[I 2025-10-12 14:35:04,537] Trial 14 finished with value: 0.2997004774962481 and parameters: {'n_layers': 4, 'n_units_l0': 309, 'dropout_l0': 0.22409628450165894, 'n_units_l1': 181, 'dropout_l1': 0.37655889066311904, 'n_units_l2': 74, 'dropout_l2': 0.40993722607919236, 'n_units_l3': 33, 'dropout_l3': 0.4781226287986246, 'learning_rate': 0.0010599475858705765}. Best is trial 6 with value: 0.3055916363191656.\n","[I 2025-10-12 14:35:05,597] Trial 15 pruned. \n","[I 2025-10-12 14:35:18,994] Trial 16 finished with value: 0.30244972254873825 and parameters: {'n_layers': 3, 'n_units_l0': 110, 'dropout_l0': 0.18103760095109092, 'n_units_l1': 299, 'dropout_l1': 0.38786541036186406, 'n_units_l2': 75, 'dropout_l2': 0.19167481698510108, 'learning_rate': 0.001621736637964848}. Best is trial 6 with value: 0.3055916363191656.\n"]},{"output_type":"stream","name":"stdout","text":["\n","[Optuna 조기 종료] 10번의 trial 동안 최고 점수가 갱신되지 않아 튜닝을 중단합니다.\n","\n","✅ 튜닝 완료!\n","\n","==================================================\n","🔬 최적 하이퍼파라미터\n","==================================================\n","            n_layers: 3\n","          n_units_l0: 266\n","          dropout_l0: 0.43258733866962806\n","          n_units_l1: 291\n","          dropout_l1: 0.2865953307130984\n","          n_units_l2: 56\n","          dropout_l2: 0.2233978579549068\n","       learning_rate: 0.000930542552997091\n","==================================================\n","\n","🔬 Step 3: 튜닝된 최종 PyTorch 모델 학습 및 평가...\n"]},{"output_type":"display_data","data":{"text/plain":["최종 모델 학습:   0%|          | 0/50 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ae1e84ed6f4041ea896b353f030d0068"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["✅ 튜닝된 PyTorch 모델 평가 완료.\n","                      PR AUC  ROC AUC  F1-Score\n","Optuna_Tuned_PyTorch  0.3353   0.7806    0.1173\n","\n","============================================================\n","💾 Step 4: 최종 모델 예측 결과를 원본 CSV에 추가하여 저장\n","============================================================\n"]},{"output_type":"display_data","data":{"text/plain":["전체 데이터 예측:   0%|          | 0/176 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"af554182b7d742d491e76b07f2996a18"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["✅ 모든 데이터의 예측 결과가 '/content/drive/MyDrive/review_helpfulness/PADA/results/s2/amazon/MLP/MLP_amazon_with_T5_predictions.csv' 파일에 성공적으로 저장되었습니다.\n","\n","============================================================\n","🧹 Step 5: 메모리 정리\n","============================================================\n","✅ 메모리 정리가 완료되었습니다.\n","\n","🎉 모든 과정이 완료되었습니다!\n"]}]},{"cell_type":"markdown","source":["## BERT"],"metadata":{"id":"GTLxvTYf4weL"}},{"cell_type":"code","source":["# === 2. 환경설정 클래스 ===\n","class Config:\n","    \"\"\"실행에 필요한 모든 설정값을 중앙에서 관리합니다.\"\"\"\n","    # 🌟 1. 파일 경로 설정\n","    CSV_FILE_PATH = \"/content/drive/MyDrive/review_helpfulness/PADA/data/amazon/amazon.csv\"\n","    EMBEDDING_PATH = \"/content/drive/MyDrive/review_helpfulness/PADA/embedding/amazon_BERT.npy\"\n","\n","    # 🌟 2. 최종 결과 CSV 파일 저장 경로 설정\n","    OUTPUT_CSV_PATH = \"/content/drive/MyDrive/review_helpfulness/PADA/results/s2/amazon/MLP/MLP_amazon_with_BERT_predictions.csv\"\n","\n","    # --- 데이터 정보 ---\n","    TARGET_COLUMN = 'binary_helpfulness'\n","\n","    # --- 데이터 분할 ---\n","    TEST_SPLIT_RATIO = 0.2\n","    RANDOM_STATE = 42\n","\n","    # --- PyTorch 모델 및 학습 설정 ---\n","    EPOCHS = 50\n","    BATCH_SIZE = 256\n","    VALIDATION_EARLY_STOPPING_PATIENCE = 5 # 개별 Trial 내 검증 성능 기반 조기 종료\n","\n","    # --- Optuna 튜닝 설정 ---\n","    N_TRIALS = 50\n","    TUNING_METRIC = 'pr_auc'\n","    STUDY_EARLY_STOPPING_ROUNDS = 10 # 전체 Study 조기 종료\n","\n","# === 3. MLP 모델 클래스 (PyTorch) ===\n","class MLP(nn.Module):\n","    def __init__(self, input_dim, trial):\n","        super(MLP, self).__init__()\n","        layers = []\n","\n","        # ✅ 은닉층 탐색 범위를 1~5개로 확장\n","        n_layers = trial.suggest_int('n_layers', 1, 5)\n","\n","        in_features = input_dim\n","        for i in range(n_layers):\n","            out_features = trial.suggest_int(f'n_units_l{i}', 32, 512, log=True)\n","            layers.append(nn.Linear(in_features, out_features))\n","            layers.append(nn.ReLU())\n","            p = trial.suggest_float(f'dropout_l{i}', 0.1, 0.5)\n","            layers.append(nn.Dropout(p))\n","            in_features = out_features\n","\n","        layers.append(nn.Linear(in_features, 1))\n","        self.layers = nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        return torch.sigmoid(self.layers(x).squeeze(-1))\n","\n","# === 4. 학습 및 평가 함수 ===\n","def train_model(model, loader, optimizer, criterion):\n","    model.train()\n","    for inputs, labels in loader:\n","        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n","        optimizer.zero_grad()\n","        outputs = model(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","def evaluate_model(model, loader):\n","    model.eval()\n","    all_preds = []\n","    all_labels = []\n","    with torch.no_grad():\n","        for inputs, labels in loader:\n","            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n","            outputs = model(inputs)\n","            all_preds.extend(outputs.cpu().numpy())\n","            all_labels.extend(labels.cpu().numpy())\n","    return np.array(all_preds), np.array(all_labels)\n","\n","# === 5. Optuna Objective 함수 (PyTorch용) ===\n","def objective(trial, X, y):\n","    X_train, X_val, y_train, y_val = train_test_split(\n","        X, y, test_size=0.25, random_state=Config.RANDOM_STATE, stratify=y)\n","\n","    train_dataset = TensorDataset(torch.FloatTensor(X_train), torch.FloatTensor(y_train))\n","    val_dataset = TensorDataset(torch.FloatTensor(X_val), torch.FloatTensor(y_val))\n","    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)\n","    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE)\n","\n","    input_dim = X_train.shape[1]\n","    model = MLP(input_dim, trial).to(DEVICE)\n","    lr = trial.suggest_float('learning_rate', 1e-5, 1e-2, log=True)\n","    optimizer = optim.Adam(model.parameters(), lr=lr)\n","    criterion = nn.BCELoss()\n","\n","    best_score = -1\n","    patience_counter = 0\n","\n","    for epoch in range(Config.EPOCHS):\n","        train_model(model, train_loader, optimizer, criterion)\n","        y_pred_proba, y_true = evaluate_model(model, val_loader)\n","        score = average_precision_score(y_true, y_pred_proba)\n","\n","        trial.report(score, epoch)\n","        if trial.should_prune():\n","            raise optuna.exceptions.TrialPruned()\n","\n","        if score > best_score:\n","            best_score = score\n","            patience_counter = 0\n","        else:\n","            patience_counter += 1\n","\n","        if patience_counter >= Config.VALIDATION_EARLY_STOPPING_PATIENCE:\n","            break\n","\n","    return best_score\n","\n","# === 6. Optuna 조기 종료 콜백 ===\n","class EarlyStoppingCallback:\n","    def __init__(self, early_stopping_rounds: int):\n","        self._early_stopping_rounds = early_stopping_rounds\n","        self._best_value = -float(\"inf\")\n","        self._counter = 0\n","\n","    def __call__(self, study: optuna.study.Study, trial: optuna.trial.Trial):\n","        current_best_value = study.best_value\n","        if current_best_value is not None and current_best_value > self._best_value:\n","            self._best_value = current_best_value\n","            self._counter = 0\n","        else:\n","            self._counter += 1\n","\n","        if self._counter >= self._early_stopping_rounds:\n","            print(f\"\\n[Optuna 조기 종료] {self._early_stopping_rounds}번의 trial 동안 최고 점수가 갱신되지 않아 튜닝을 중단합니다.\")\n","            study.stop()\n","\n","\n","# === 7. 메인 실행 블록 ===\n","if __name__ == '__main__':\n","    config = Config()\n","\n","    # --- Step 1: 데이터 로드 및 분할 ---\n","    print(\"\\n\" + \"=\"*50)\n","    print(\"📊 Step 1: 데이터 로드 및 분할\")\n","    try:\n","        df = pd.read_csv(config.CSV_FILE_PATH)\n","        labels = df[config.TARGET_COLUMN].values\n","        embeddings = np.load(config.EMBEDDING_PATH)\n","    except Exception as e:\n","        print(f\"🔥 파일 로드 실패: {e}\"); exit()\n","\n","    indices = np.arange(len(df))\n","    train_indices, test_indices = train_test_split(\n","        indices, test_size=config.TEST_SPLIT_RATIO, random_state=config.RANDOM_STATE, stratify=labels)\n","    X_train, X_test = embeddings[train_indices], embeddings[test_indices]\n","    y_train, y_test = labels[train_indices], labels[test_indices]\n","    print(f\"✅ 완료 (학습용: {len(y_train)}건, 테스트용: {len(y_test)}건)\")\n","\n","    # --- Step 2: Optuna 튜닝 수행 ---\n","    print(\"\\n\" + \"=\"*50)\n","    print(f\"🔬 Step 2: Optuna 하이퍼파라미터 튜닝 시작 (PyTorch)\")\n","    print(f\"(최대 {config.N_TRIALS}번 시도, {config.STUDY_EARLY_STOPPING_ROUNDS}번 개선 없으면 스터디 조기 종료)\")\n","    print(\"=\"*50)\n","\n","    study = optuna.create_study(direction='maximize', pruner=optuna.pruners.MedianPruner())\n","    pbar = tqdm(total=config.N_TRIALS, desc=\"Optuna 튜닝 진행률\")\n","\n","    try:\n","        study.optimize(lambda trial: objective(trial, X_train, y_train),\n","                       n_trials=config.N_TRIALS,\n","                       callbacks=[lambda s, t: pbar.update(1), EarlyStoppingCallback(config.STUDY_EARLY_STOPPING_ROUNDS)])\n","    except optuna.exceptions.OptunaError:\n","        pass # 조기 종료 시 예외 처리\n","    pbar.close()\n","\n","    # --- Step 3: 최적 모델 학습 및 평가 ---\n","    print(f\"\\n✅ 튜닝 완료!\")\n","    print(\"\\n\" + \"=\"*50)\n","    print(\"🔬 최적 하이퍼파라미터\")\n","    print(\"=\"*50)\n","    best_params = study.best_params\n","    for key, value in best_params.items():\n","        print(f\"{key:>20s}: {value}\")\n","    print(\"=\"*50)\n","\n","    print(f\"\\n🔬 Step 3: 튜닝된 최종 PyTorch 모델 학습 및 평가...\")\n","    train_dataset = TensorDataset(torch.FloatTensor(X_train), torch.FloatTensor(y_train))\n","    train_loader = DataLoader(train_dataset, batch_size=config.BATCH_SIZE, shuffle=True)\n","    test_dataset = TensorDataset(torch.FloatTensor(X_test), torch.FloatTensor(y_test))\n","    test_loader = DataLoader(test_dataset, batch_size=config.BATCH_SIZE)\n","\n","    # Optuna study 객체를 모의 trial로 사용하여 최종 모델 생성\n","    final_model = MLP(X_train.shape[1], study.best_trial).to(DEVICE)\n","    optimizer = optim.Adam(final_model.parameters(), lr=best_params['learning_rate'])\n","    criterion = nn.BCELoss()\n","\n","    # 최종 모델은 전체 학습 데이터로 학습\n","    for epoch in tqdm(range(config.EPOCHS), desc=\"최종 모델 학습\"):\n","        train_model(final_model, train_loader, optimizer, criterion)\n","\n","    y_pred_proba_tuned, y_true_test = evaluate_model(final_model, test_loader)\n","    y_pred_class_tuned = (y_pred_proba_tuned > 0.5).astype(int)\n","\n","    results = {\n","        \"PR AUC\": average_precision_score(y_true_test, y_pred_proba_tuned),\n","        \"ROC AUC\": roc_auc_score(y_true_test, y_pred_proba_tuned),\n","        \"F1-Score\": f1_score(y_true_test, y_pred_class_tuned),\n","    }\n","    print(\"✅ 튜닝된 PyTorch 모델 평가 완료.\")\n","    print(pd.DataFrame(results, index=['Optuna_Tuned_PyTorch']).round(4))\n","\n","    # --- Step 4: 결과 저장 ---\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"💾 Step 4: 최종 모델 예측 결과를 원본 CSV에 추가하여 저장\")\n","    print(\"=\"*60)\n","\n","    all_dataset = TensorDataset(torch.FloatTensor(embeddings))\n","    all_loader = DataLoader(all_dataset, batch_size=config.BATCH_SIZE * 2) # 예측 시에는 더 큰 배치 사용 가능\n","\n","    final_model.eval()\n","    all_predictions = []\n","    with torch.no_grad():\n","        for (inputs,) in tqdm(all_loader, desc=\"전체 데이터 예측\"):\n","            inputs = inputs.to(DEVICE)\n","            outputs = final_model(inputs)\n","            all_predictions.extend(outputs.cpu().numpy())\n","\n","    df['s2_pred_proba'] = all_predictions\n","    df['s2_pred_class'] = (df['s2_pred_proba'] > 0.5).astype(int)\n","\n","    df.to_csv(config.OUTPUT_CSV_PATH, index=False, encoding='utf-8-sig')\n","    print(f\"✅ 모든 데이터의 예측 결과가 '{config.OUTPUT_CSV_PATH}' 파일에 성공적으로 저장되었습니다.\")\n","\n","    # --- Step 5: 메모리 정리 ---\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"🧹 Step 5: 메모리 정리\")\n","    print(\"=\"*60)\n","    del df, labels, embeddings, X_train, X_test, y_train, y_test, final_model, study\n","    gc.collect()\n","    if torch.cuda.is_available():\n","        torch.cuda.empty_cache()\n","    print(\"✅ 메모리 정리가 완료되었습니다.\")\n","\n","    print(\"\\n🎉 모든 과정이 완료되었습니다!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["d46bcb21d80f4233beaec1866499795d","fac142ac3e0641b6bb8c9c8e1a8bbc21","44ee57b445d743f0942ad1c7547c2e61","93a026d4e637403293f2e01cc1d107e7","d7250746be2c4c958be480c976c9ed72","704fd8d6e4a4401d946e84a8071ae30c","90b1ae063ec34558886db38de621aca8","b40782821c624ed0abc2768f15db2d9b","0bc1b5ec1b2648d2899303fa42fba761","3dd355fd3ceb4bcab9f9f1653b8fcde4","821b57988e354ff9ab7ad7200960729a","df8b8e9922454f9180bf1e143a51f3f3","6debe8fda9914744aa1cf46a64b63458","bbfc02cf0cb94541b90790b7cd0effe9","fccc49d72a5844d8822f921a2767e628","cdaf1c0a33654449af26b060c207544f","93e21452933f455d8660a4b3fab8cfd4","05a311f6f5884fc59b7139d297418042","a32abc3c73d8457995f39a6d63044176","2b9e7f569f894b51809ac702aa926b81","2c710c74f47f45699bfdbdb738ccf91e","4577301fb76c4341be5e44fd9952dd14","c9fb1713a3d34d37a80fcba3fc06570b","6fb5f2fee5ed42ab855980773368856a","88372c60e3fe420d84d207bd96d7bc18","33e931ed80c34a97b87aa76926d1cda1","1bd07409a8ea43fd8d281d19a43a2a02","358511fa5ef545a4b8769943f217eb72","6e802c7042c241cc8b950ed53a29b09b","69276f9420fa488f866b7ca65b3442f5","0f0a159ee5474fe18162fed78bffa1d5","612e6f96d5cf47c69a792d440cb45b43","92319c02721c49ae8f76998b77e65423"]},"id":"JGICH2KI5rME","executionInfo":{"status":"ok","timestamp":1760280825942,"user_tz":-540,"elapsed":187753,"user":{"displayName":"KW-data-analytics","userId":"09651493752354345908"}},"outputId":"b6356776-4c4c-4b19-fe3b-84f8b668ba0f"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================================================\n","📊 Step 1: 데이터 로드 및 분할\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-10-12 14:50:42,389] A new study created in memory with name: no-name-6c59bb5f-f03a-495e-9f13-1ef2a577b709\n"]},{"output_type":"stream","name":"stdout","text":["✅ 완료 (학습용: 71941건, 테스트용: 17986건)\n","\n","==================================================\n","🔬 Step 2: Optuna 하이퍼파라미터 튜닝 시작 (PyTorch)\n","(최대 50번 시도, 10번 개선 없으면 스터디 조기 종료)\n","==================================================\n"]},{"output_type":"display_data","data":{"text/plain":["Optuna 튜닝 진행률:   0%|          | 0/50 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d46bcb21d80f4233beaec1866499795d"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2025-10-12 14:50:59,631] Trial 0 finished with value: 0.3005325573125909 and parameters: {'n_layers': 4, 'n_units_l0': 418, 'dropout_l0': 0.22598653784351652, 'n_units_l1': 101, 'dropout_l1': 0.13485756597182183, 'n_units_l2': 43, 'dropout_l2': 0.1362852945645745, 'n_units_l3': 71, 'dropout_l3': 0.36775696596434626, 'learning_rate': 0.00015896499047781174}. Best is trial 0 with value: 0.3005325573125909.\n","[I 2025-10-12 14:51:48,276] Trial 1 finished with value: 0.30147466741629514 and parameters: {'n_layers': 2, 'n_units_l0': 231, 'dropout_l0': 0.17875369314235817, 'n_units_l1': 160, 'dropout_l1': 0.4631193760591561, 'learning_rate': 2.6718819670902943e-05}. Best is trial 1 with value: 0.30147466741629514.\n","[I 2025-10-12 14:51:56,142] Trial 2 finished with value: 0.29194708797669544 and parameters: {'n_layers': 2, 'n_units_l0': 52, 'dropout_l0': 0.45503153496806636, 'n_units_l1': 151, 'dropout_l1': 0.3543790415166663, 'learning_rate': 0.0034637209524146593}. Best is trial 1 with value: 0.30147466741629514.\n","[I 2025-10-12 14:52:06,269] Trial 3 finished with value: 0.29823348614835116 and parameters: {'n_layers': 1, 'n_units_l0': 256, 'dropout_l0': 0.3229391878519672, 'learning_rate': 0.0037532491942245624}. Best is trial 1 with value: 0.30147466741629514.\n","[I 2025-10-12 14:52:19,825] Trial 4 finished with value: 0.2974200115990501 and parameters: {'n_layers': 3, 'n_units_l0': 238, 'dropout_l0': 0.2731789108145982, 'n_units_l1': 42, 'dropout_l1': 0.37794026906807043, 'n_units_l2': 377, 'dropout_l2': 0.4053967434342194, 'learning_rate': 0.005980437294795915}. Best is trial 1 with value: 0.30147466741629514.\n","[I 2025-10-12 14:52:32,052] Trial 5 finished with value: 0.3010777711906496 and parameters: {'n_layers': 4, 'n_units_l0': 277, 'dropout_l0': 0.18324786245076108, 'n_units_l1': 152, 'dropout_l1': 0.4116340215244032, 'n_units_l2': 270, 'dropout_l2': 0.17835306445054006, 'n_units_l3': 503, 'dropout_l3': 0.2705769511525957, 'learning_rate': 0.0008762673615519447}. Best is trial 1 with value: 0.30147466741629514.\n","[I 2025-10-12 14:52:33,164] Trial 6 pruned. \n","[I 2025-10-12 14:52:34,389] Trial 7 pruned. \n","[I 2025-10-12 14:52:35,560] Trial 8 pruned. \n","[I 2025-10-12 14:52:36,791] Trial 9 pruned. \n","[I 2025-10-12 14:52:37,772] Trial 10 pruned. \n","[I 2025-10-12 14:52:49,299] Trial 11 finished with value: 0.30012149867810745 and parameters: {'n_layers': 5, 'n_units_l0': 130, 'dropout_l0': 0.18953591497362668, 'n_units_l1': 458, 'dropout_l1': 0.4996717918650707, 'n_units_l2': 167, 'dropout_l2': 0.2291157588482371, 'n_units_l3': 33, 'dropout_l3': 0.13155938237308504, 'n_units_l4': 500, 'dropout_l4': 0.1080255583260133, 'learning_rate': 0.000900173093967664}. Best is trial 1 with value: 0.30147466741629514.\n"]},{"output_type":"stream","name":"stdout","text":["\n","[Optuna 조기 종료] 10번의 trial 동안 최고 점수가 갱신되지 않아 튜닝을 중단합니다.\n","\n","✅ 튜닝 완료!\n","\n","==================================================\n","🔬 최적 하이퍼파라미터\n","==================================================\n","            n_layers: 2\n","          n_units_l0: 231\n","          dropout_l0: 0.17875369314235817\n","          n_units_l1: 160\n","          dropout_l1: 0.4631193760591561\n","       learning_rate: 2.6718819670902943e-05\n","==================================================\n","\n","🔬 Step 3: 튜닝된 최종 PyTorch 모델 학습 및 평가...\n"]},{"output_type":"display_data","data":{"text/plain":["최종 모델 학습:   0%|          | 0/50 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"df8b8e9922454f9180bf1e143a51f3f3"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["✅ 튜닝된 PyTorch 모델 평가 완료.\n","                      PR AUC  ROC AUC  F1-Score\n","Optuna_Tuned_PyTorch   0.336   0.7833    0.1616\n","\n","============================================================\n","💾 Step 4: 최종 모델 예측 결과를 원본 CSV에 추가하여 저장\n","============================================================\n"]},{"output_type":"display_data","data":{"text/plain":["전체 데이터 예측:   0%|          | 0/176 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c9fb1713a3d34d37a80fcba3fc06570b"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["✅ 모든 데이터의 예측 결과가 '/content/drive/MyDrive/review_helpfulness/PADA/results/s2/amazon/MLP/MLP_amazon_with_BERT_predictions.csv' 파일에 성공적으로 저장되었습니다.\n","\n","============================================================\n","🧹 Step 5: 메모리 정리\n","============================================================\n","✅ 메모리 정리가 완료되었습니다.\n","\n","🎉 모든 과정이 완료되었습니다!\n"]}]},{"cell_type":"markdown","source":["## SentenceBERT"],"metadata":{"id":"M1_htNEK40C8"}},{"cell_type":"code","source":["# === 2. 환경설정 클래스 ===\n","class Config:\n","    \"\"\"실행에 필요한 모든 설정값을 중앙에서 관리합니다.\"\"\"\n","    # 🌟 1. 파일 경로 설정\n","    CSV_FILE_PATH = \"/content/drive/MyDrive/review_helpfulness/PADA/data/amazon/amazon.csv\"\n","    EMBEDDING_PATH = \"/content/drive/MyDrive/review_helpfulness/PADA/embedding/amazon_SentenceBERT.npy\"\n","\n","    # 🌟 2. 최종 결과 CSV 파일 저장 경로 설정\n","    OUTPUT_CSV_PATH = \"/content/drive/MyDrive/review_helpfulness/PADA/results/s2/amazon/MLP/MLP_amazon_with_SentenceBERT_predictions.csv\"\n","\n","    # --- 데이터 정보 ---\n","    TARGET_COLUMN = 'binary_helpfulness'\n","\n","    # --- 데이터 분할 ---\n","    TEST_SPLIT_RATIO = 0.2\n","    RANDOM_STATE = 42\n","\n","    # --- PyTorch 모델 및 학습 설정 ---\n","    EPOCHS = 50\n","    BATCH_SIZE = 256\n","    VALIDATION_EARLY_STOPPING_PATIENCE = 5 # 개별 Trial 내 검증 성능 기반 조기 종료\n","\n","    # --- Optuna 튜닝 설정 ---\n","    N_TRIALS = 50\n","    TUNING_METRIC = 'pr_auc'\n","    STUDY_EARLY_STOPPING_ROUNDS = 10 # 전체 Study 조기 종료\n","\n","# === 3. MLP 모델 클래스 (PyTorch) ===\n","class MLP(nn.Module):\n","    def __init__(self, input_dim, trial):\n","        super(MLP, self).__init__()\n","        layers = []\n","\n","        # ✅ 은닉층 탐색 범위를 1~5개로 확장\n","        n_layers = trial.suggest_int('n_layers', 1, 5)\n","\n","        in_features = input_dim\n","        for i in range(n_layers):\n","            out_features = trial.suggest_int(f'n_units_l{i}', 32, 512, log=True)\n","            layers.append(nn.Linear(in_features, out_features))\n","            layers.append(nn.ReLU())\n","            p = trial.suggest_float(f'dropout_l{i}', 0.1, 0.5)\n","            layers.append(nn.Dropout(p))\n","            in_features = out_features\n","\n","        layers.append(nn.Linear(in_features, 1))\n","        self.layers = nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        return torch.sigmoid(self.layers(x).squeeze(-1))\n","\n","# === 4. 학습 및 평가 함수 ===\n","def train_model(model, loader, optimizer, criterion):\n","    model.train()\n","    for inputs, labels in loader:\n","        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n","        optimizer.zero_grad()\n","        outputs = model(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","def evaluate_model(model, loader):\n","    model.eval()\n","    all_preds = []\n","    all_labels = []\n","    with torch.no_grad():\n","        for inputs, labels in loader:\n","            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n","            outputs = model(inputs)\n","            all_preds.extend(outputs.cpu().numpy())\n","            all_labels.extend(labels.cpu().numpy())\n","    return np.array(all_preds), np.array(all_labels)\n","\n","# === 5. Optuna Objective 함수 (PyTorch용) ===\n","def objective(trial, X, y):\n","    X_train, X_val, y_train, y_val = train_test_split(\n","        X, y, test_size=0.25, random_state=Config.RANDOM_STATE, stratify=y)\n","\n","    train_dataset = TensorDataset(torch.FloatTensor(X_train), torch.FloatTensor(y_train))\n","    val_dataset = TensorDataset(torch.FloatTensor(X_val), torch.FloatTensor(y_val))\n","    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)\n","    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE)\n","\n","    input_dim = X_train.shape[1]\n","    model = MLP(input_dim, trial).to(DEVICE)\n","    lr = trial.suggest_float('learning_rate', 1e-5, 1e-2, log=True)\n","    optimizer = optim.Adam(model.parameters(), lr=lr)\n","    criterion = nn.BCELoss()\n","\n","    best_score = -1\n","    patience_counter = 0\n","\n","    for epoch in range(Config.EPOCHS):\n","        train_model(model, train_loader, optimizer, criterion)\n","        y_pred_proba, y_true = evaluate_model(model, val_loader)\n","        score = average_precision_score(y_true, y_pred_proba)\n","\n","        trial.report(score, epoch)\n","        if trial.should_prune():\n","            raise optuna.exceptions.TrialPruned()\n","\n","        if score > best_score:\n","            best_score = score\n","            patience_counter = 0\n","        else:\n","            patience_counter += 1\n","\n","        if patience_counter >= Config.VALIDATION_EARLY_STOPPING_PATIENCE:\n","            break\n","\n","    return best_score\n","\n","# === 6. Optuna 조기 종료 콜백 ===\n","class EarlyStoppingCallback:\n","    def __init__(self, early_stopping_rounds: int):\n","        self._early_stopping_rounds = early_stopping_rounds\n","        self._best_value = -float(\"inf\")\n","        self._counter = 0\n","\n","    def __call__(self, study: optuna.study.Study, trial: optuna.trial.Trial):\n","        current_best_value = study.best_value\n","        if current_best_value is not None and current_best_value > self._best_value:\n","            self._best_value = current_best_value\n","            self._counter = 0\n","        else:\n","            self._counter += 1\n","\n","        if self._counter >= self._early_stopping_rounds:\n","            print(f\"\\n[Optuna 조기 종료] {self._early_stopping_rounds}번의 trial 동안 최고 점수가 갱신되지 않아 튜닝을 중단합니다.\")\n","            study.stop()\n","\n","\n","# === 7. 메인 실행 블록 ===\n","if __name__ == '__main__':\n","    config = Config()\n","\n","    # --- Step 1: 데이터 로드 및 분할 ---\n","    print(\"\\n\" + \"=\"*50)\n","    print(\"📊 Step 1: 데이터 로드 및 분할\")\n","    try:\n","        df = pd.read_csv(config.CSV_FILE_PATH)\n","        labels = df[config.TARGET_COLUMN].values\n","        embeddings = np.load(config.EMBEDDING_PATH)\n","    except Exception as e:\n","        print(f\"🔥 파일 로드 실패: {e}\"); exit()\n","\n","    indices = np.arange(len(df))\n","    train_indices, test_indices = train_test_split(\n","        indices, test_size=config.TEST_SPLIT_RATIO, random_state=config.RANDOM_STATE, stratify=labels)\n","    X_train, X_test = embeddings[train_indices], embeddings[test_indices]\n","    y_train, y_test = labels[train_indices], labels[test_indices]\n","    print(f\"✅ 완료 (학습용: {len(y_train)}건, 테스트용: {len(y_test)}건)\")\n","\n","    # --- Step 2: Optuna 튜닝 수행 ---\n","    print(\"\\n\" + \"=\"*50)\n","    print(f\"🔬 Step 2: Optuna 하이퍼파라미터 튜닝 시작 (PyTorch)\")\n","    print(f\"(최대 {config.N_TRIALS}번 시도, {config.STUDY_EARLY_STOPPING_ROUNDS}번 개선 없으면 스터디 조기 종료)\")\n","    print(\"=\"*50)\n","\n","    study = optuna.create_study(direction='maximize', pruner=optuna.pruners.MedianPruner())\n","    pbar = tqdm(total=config.N_TRIALS, desc=\"Optuna 튜닝 진행률\")\n","\n","    try:\n","        study.optimize(lambda trial: objective(trial, X_train, y_train),\n","                       n_trials=config.N_TRIALS,\n","                       callbacks=[lambda s, t: pbar.update(1), EarlyStoppingCallback(config.STUDY_EARLY_STOPPING_ROUNDS)])\n","    except optuna.exceptions.OptunaError:\n","        pass # 조기 종료 시 예외 처리\n","    pbar.close()\n","\n","    # --- Step 3: 최적 모델 학습 및 평가 ---\n","    print(f\"\\n✅ 튜닝 완료!\")\n","    print(\"\\n\" + \"=\"*50)\n","    print(\"🔬 최적 하이퍼파라미터\")\n","    print(\"=\"*50)\n","    best_params = study.best_params\n","    for key, value in best_params.items():\n","        print(f\"{key:>20s}: {value}\")\n","    print(\"=\"*50)\n","\n","    print(f\"\\n🔬 Step 3: 튜닝된 최종 PyTorch 모델 학습 및 평가...\")\n","    train_dataset = TensorDataset(torch.FloatTensor(X_train), torch.FloatTensor(y_train))\n","    train_loader = DataLoader(train_dataset, batch_size=config.BATCH_SIZE, shuffle=True)\n","    test_dataset = TensorDataset(torch.FloatTensor(X_test), torch.FloatTensor(y_test))\n","    test_loader = DataLoader(test_dataset, batch_size=config.BATCH_SIZE)\n","\n","    # Optuna study 객체를 모의 trial로 사용하여 최종 모델 생성\n","    final_model = MLP(X_train.shape[1], study.best_trial).to(DEVICE)\n","    optimizer = optim.Adam(final_model.parameters(), lr=best_params['learning_rate'])\n","    criterion = nn.BCELoss()\n","\n","    # 최종 모델은 전체 학습 데이터로 학습\n","    for epoch in tqdm(range(config.EPOCHS), desc=\"최종 모델 학습\"):\n","        train_model(final_model, train_loader, optimizer, criterion)\n","\n","    y_pred_proba_tuned, y_true_test = evaluate_model(final_model, test_loader)\n","    y_pred_class_tuned = (y_pred_proba_tuned > 0.5).astype(int)\n","\n","    results = {\n","        \"PR AUC\": average_precision_score(y_true_test, y_pred_proba_tuned),\n","        \"ROC AUC\": roc_auc_score(y_true_test, y_pred_proba_tuned),\n","        \"F1-Score\": f1_score(y_true_test, y_pred_class_tuned),\n","    }\n","    print(\"✅ 튜닝된 PyTorch 모델 평가 완료.\")\n","    print(pd.DataFrame(results, index=['Optuna_Tuned_PyTorch']).round(4))\n","\n","    # --- Step 4: 결과 저장 ---\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"💾 Step 4: 최종 모델 예측 결과를 원본 CSV에 추가하여 저장\")\n","    print(\"=\"*60)\n","\n","    all_dataset = TensorDataset(torch.FloatTensor(embeddings))\n","    all_loader = DataLoader(all_dataset, batch_size=config.BATCH_SIZE * 2) # 예측 시에는 더 큰 배치 사용 가능\n","\n","    final_model.eval()\n","    all_predictions = []\n","    with torch.no_grad():\n","        for (inputs,) in tqdm(all_loader, desc=\"전체 데이터 예측\"):\n","            inputs = inputs.to(DEVICE)\n","            outputs = final_model(inputs)\n","            all_predictions.extend(outputs.cpu().numpy())\n","\n","    df['s2_pred_proba'] = all_predictions\n","    df['s2_pred_class'] = (df['s2_pred_proba'] > 0.5).astype(int)\n","\n","    df.to_csv(config.OUTPUT_CSV_PATH, index=False, encoding='utf-8-sig')\n","    print(f\"✅ 모든 데이터의 예측 결과가 '{config.OUTPUT_CSV_PATH}' 파일에 성공적으로 저장되었습니다.\")\n","\n","    # --- Step 5: 메모리 정리 ---\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"🧹 Step 5: 메모리 정리\")\n","    print(\"=\"*60)\n","    del df, labels, embeddings, X_train, X_test, y_train, y_test, final_model, study\n","    gc.collect()\n","    if torch.cuda.is_available():\n","        torch.cuda.empty_cache()\n","    print(\"✅ 메모리 정리가 완료되었습니다.\")\n","\n","    print(\"\\n🎉 모든 과정이 완료되었습니다!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["f250b8f6319b49b89a0ba42d3184a950","b4b5bb0d83484aec94e982e06721b732","3691c263e2124eecb299869de0bf4b5c","8d8a843daef7459abfadd78c754e4536","288afd8f374749959ad341c36797b267","cb4e77709855411ab23a84d4413f061f","88dd6a4ff28a42538cc123be2398e198","b96cf5d803f943fea2eec3c9ddab8a0e","4a5bc1ece106416ca049c5b2473e4926","c56da89ad0c94a79bb330d06cf1d370b","595b7f5ce6504cc9802b23d56c4025cb","e0259d8044a24d0598516f2edb170cb0","4ff828602e9040929b2c681d91336a57","38ed25eb689348088a4b1c8403d8461e","486b89ff83144be9a7e9b40f4cca68e7","a23593ff54ca4883a97003a2be85e8ba","99947872dafd428c96c51a47587fadf8","0a3b29c172094039b7d3682304cf7849","d07fdc8006434ba6ab18db3a09f1eb7f","41631e0b37cc4a35812a346a0c04d14b","ddb05182541c49639fe124d83ba55bfc","d4f13db4bfff4f799afd602baa2d3d2d","f295f3c7f292434dbf00a0afaf931aa1","47064933c1da46ae9b7113102dd6fc08","26593e0303f545bbb8a355a57d26c7a1","bc4f47f8d05947459d9be241281bb135","5c5667153cfa4d1f8c858fa6badd2da7","52fc5ab5ae844a56bc8adb25ab8e4477","10a1b6c607344dfeba48ef7c1a61ac1b","856a4b9f71d24f2c89d513241d7f7d1b","080b242931384df99113777787b18457","1ad27b50048c4c72ade4a11c4f1f6127","b17a2f9b67ae4520bd83be450781b886"]},"id":"p9ssIf9B5wmB","executionInfo":{"status":"ok","timestamp":1760281092554,"user_tz":-540,"elapsed":266600,"user":{"displayName":"KW-data-analytics","userId":"09651493752354345908"}},"outputId":"e650802b-9dab-4773-a248-eb2d66c93b42"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================================================\n","📊 Step 1: 데이터 로드 및 분할\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-10-12 14:53:52,339] A new study created in memory with name: no-name-7019b99f-3683-4051-87ab-7bae22379829\n"]},{"output_type":"stream","name":"stdout","text":["✅ 완료 (학습용: 71941건, 테스트용: 17986건)\n","\n","==================================================\n","🔬 Step 2: Optuna 하이퍼파라미터 튜닝 시작 (PyTorch)\n","(최대 50번 시도, 10번 개선 없으면 스터디 조기 종료)\n","==================================================\n"]},{"output_type":"display_data","data":{"text/plain":["Optuna 튜닝 진행률:   0%|          | 0/50 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f250b8f6319b49b89a0ba42d3184a950"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2025-10-12 14:54:47,119] Trial 0 finished with value: 0.28384230773173325 and parameters: {'n_layers': 4, 'n_units_l0': 40, 'dropout_l0': 0.1998555534075801, 'n_units_l1': 33, 'dropout_l1': 0.44396616215079554, 'n_units_l2': 425, 'dropout_l2': 0.24455731711932327, 'n_units_l3': 66, 'dropout_l3': 0.22478133080450058, 'learning_rate': 4.1909688791150176e-05}. Best is trial 0 with value: 0.28384230773173325.\n","[I 2025-10-12 14:55:21,332] Trial 1 finished with value: 0.2893542310575601 and parameters: {'n_layers': 4, 'n_units_l0': 159, 'dropout_l0': 0.1581513004836418, 'n_units_l1': 353, 'dropout_l1': 0.23417547648060721, 'n_units_l2': 334, 'dropout_l2': 0.1724096880815517, 'n_units_l3': 228, 'dropout_l3': 0.4809148527093007, 'learning_rate': 3.550282259913115e-05}. Best is trial 1 with value: 0.2893542310575601.\n","[I 2025-10-12 14:55:29,913] Trial 2 finished with value: 0.2832942709380887 and parameters: {'n_layers': 5, 'n_units_l0': 102, 'dropout_l0': 0.12556208649505712, 'n_units_l1': 44, 'dropout_l1': 0.16794696676137044, 'n_units_l2': 405, 'dropout_l2': 0.13538975167227707, 'n_units_l3': 90, 'dropout_l3': 0.32487407605159624, 'n_units_l4': 478, 'dropout_l4': 0.4408345695516799, 'learning_rate': 0.00250268724369868}. Best is trial 1 with value: 0.2893542310575601.\n","[I 2025-10-12 14:55:41,094] Trial 3 finished with value: 0.2817935588262392 and parameters: {'n_layers': 4, 'n_units_l0': 73, 'dropout_l0': 0.29979993894972934, 'n_units_l1': 492, 'dropout_l1': 0.4288899930599811, 'n_units_l2': 35, 'dropout_l2': 0.4146546098509186, 'n_units_l3': 49, 'dropout_l3': 0.3394677093699925, 'learning_rate': 0.002865385757401082}. Best is trial 1 with value: 0.2893542310575601.\n","[I 2025-10-12 14:56:07,956] Trial 4 finished with value: 0.28987485186874395 and parameters: {'n_layers': 5, 'n_units_l0': 112, 'dropout_l0': 0.33357835414759074, 'n_units_l1': 130, 'dropout_l1': 0.2992151001226745, 'n_units_l2': 45, 'dropout_l2': 0.14063689901594803, 'n_units_l3': 203, 'dropout_l3': 0.26896689207005764, 'n_units_l4': 63, 'dropout_l4': 0.4789025864453683, 'learning_rate': 0.00011663153685783594}. Best is trial 4 with value: 0.28987485186874395.\n","[I 2025-10-12 14:56:09,130] Trial 5 pruned. \n","[I 2025-10-12 14:56:10,247] Trial 6 pruned. \n","[I 2025-10-12 14:56:29,438] Trial 7 finished with value: 0.2885182522287648 and parameters: {'n_layers': 2, 'n_units_l0': 147, 'dropout_l0': 0.23283218059750382, 'n_units_l1': 381, 'dropout_l1': 0.4858597447584925, 'learning_rate': 0.00017878253893159702}. Best is trial 4 with value: 0.28987485186874395.\n","[I 2025-10-12 14:56:33,219] Trial 8 pruned. \n","[I 2025-10-12 14:56:34,379] Trial 9 pruned. \n","[I 2025-10-12 14:56:46,130] Trial 10 finished with value: 0.2887040065750597 and parameters: {'n_layers': 3, 'n_units_l0': 308, 'dropout_l0': 0.40539980740184417, 'n_units_l1': 131, 'dropout_l1': 0.351309834765718, 'n_units_l2': 47, 'dropout_l2': 0.10195283771504896, 'learning_rate': 0.0007417286648973917}. Best is trial 4 with value: 0.28987485186874395.\n","[I 2025-10-12 14:56:47,416] Trial 11 pruned. \n","[I 2025-10-12 14:57:01,457] Trial 12 pruned. \n","[I 2025-10-12 14:57:02,768] Trial 13 pruned. \n","[I 2025-10-12 14:57:03,996] Trial 14 pruned. \n"]},{"output_type":"stream","name":"stdout","text":["\n","[Optuna 조기 종료] 10번의 trial 동안 최고 점수가 갱신되지 않아 튜닝을 중단합니다.\n","\n","✅ 튜닝 완료!\n","\n","==================================================\n","🔬 최적 하이퍼파라미터\n","==================================================\n","            n_layers: 5\n","          n_units_l0: 112\n","          dropout_l0: 0.33357835414759074\n","          n_units_l1: 130\n","          dropout_l1: 0.2992151001226745\n","          n_units_l2: 45\n","          dropout_l2: 0.14063689901594803\n","          n_units_l3: 203\n","          dropout_l3: 0.26896689207005764\n","          n_units_l4: 63\n","          dropout_l4: 0.4789025864453683\n","       learning_rate: 0.00011663153685783594\n","==================================================\n","\n","🔬 Step 3: 튜닝된 최종 PyTorch 모델 학습 및 평가...\n"]},{"output_type":"display_data","data":{"text/plain":["최종 모델 학습:   0%|          | 0/50 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e0259d8044a24d0598516f2edb170cb0"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["✅ 튜닝된 PyTorch 모델 평가 완료.\n","                      PR AUC  ROC AUC  F1-Score\n","Optuna_Tuned_PyTorch  0.2848   0.7509    0.2001\n","\n","============================================================\n","💾 Step 4: 최종 모델 예측 결과를 원본 CSV에 추가하여 저장\n","============================================================\n"]},{"output_type":"display_data","data":{"text/plain":["전체 데이터 예측:   0%|          | 0/176 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f295f3c7f292434dbf00a0afaf931aa1"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["✅ 모든 데이터의 예측 결과가 '/content/drive/MyDrive/review_helpfulness/PADA/results/s2/amazon/MLP/MLP_amazon_with_SentenceBERT_predictions.csv' 파일에 성공적으로 저장되었습니다.\n","\n","============================================================\n","🧹 Step 5: 메모리 정리\n","============================================================\n","✅ 메모리 정리가 완료되었습니다.\n","\n","🎉 모든 과정이 완료되었습니다!\n"]}]},{"cell_type":"markdown","source":["## RoBERTa"],"metadata":{"id":"3kk1723040VD"}},{"cell_type":"code","source":["# === 2. 환경설정 클래스 ===\n","class Config:\n","    \"\"\"실행에 필요한 모든 설정값을 중앙에서 관리합니다.\"\"\"\n","    # 🌟 1. 파일 경로 설정\n","    CSV_FILE_PATH = \"/content/drive/MyDrive/review_helpfulness/PADA/data/amazon/amazon.csv\"\n","    EMBEDDING_PATH = \"/content/drive/MyDrive/review_helpfulness/PADA/embedding/amazon_RoBERTa.npy\"\n","\n","    # 🌟 2. 최종 결과 CSV 파일 저장 경로 설정\n","    OUTPUT_CSV_PATH = \"/content/drive/MyDrive/review_helpfulness/PADA/results/s2/amazon/MLP/MLP_amazon_with_RoBERTa_predictions.csv\"\n","\n","    # --- 데이터 정보 ---\n","    TARGET_COLUMN = 'binary_helpfulness'\n","\n","    # --- 데이터 분할 ---\n","    TEST_SPLIT_RATIO = 0.2\n","    RANDOM_STATE = 42\n","\n","    # --- PyTorch 모델 및 학습 설정 ---\n","    EPOCHS = 50\n","    BATCH_SIZE = 256\n","    VALIDATION_EARLY_STOPPING_PATIENCE = 5 # 개별 Trial 내 검증 성능 기반 조기 종료\n","\n","    # --- Optuna 튜닝 설정 ---\n","    N_TRIALS = 50\n","    TUNING_METRIC = 'pr_auc'\n","    STUDY_EARLY_STOPPING_ROUNDS = 10 # 전체 Study 조기 종료\n","\n","# === 3. MLP 모델 클래스 (PyTorch) ===\n","class MLP(nn.Module):\n","    def __init__(self, input_dim, trial):\n","        super(MLP, self).__init__()\n","        layers = []\n","\n","        # ✅ 은닉층 탐색 범위를 1~5개로 확장\n","        n_layers = trial.suggest_int('n_layers', 1, 5)\n","\n","        in_features = input_dim\n","        for i in range(n_layers):\n","            out_features = trial.suggest_int(f'n_units_l{i}', 32, 512, log=True)\n","            layers.append(nn.Linear(in_features, out_features))\n","            layers.append(nn.ReLU())\n","            p = trial.suggest_float(f'dropout_l{i}', 0.1, 0.5)\n","            layers.append(nn.Dropout(p))\n","            in_features = out_features\n","\n","        layers.append(nn.Linear(in_features, 1))\n","        self.layers = nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        return torch.sigmoid(self.layers(x).squeeze(-1))\n","\n","# === 4. 학습 및 평가 함수 ===\n","def train_model(model, loader, optimizer, criterion):\n","    model.train()\n","    for inputs, labels in loader:\n","        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n","        optimizer.zero_grad()\n","        outputs = model(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","def evaluate_model(model, loader):\n","    model.eval()\n","    all_preds = []\n","    all_labels = []\n","    with torch.no_grad():\n","        for inputs, labels in loader:\n","            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n","            outputs = model(inputs)\n","            all_preds.extend(outputs.cpu().numpy())\n","            all_labels.extend(labels.cpu().numpy())\n","    return np.array(all_preds), np.array(all_labels)\n","\n","# === 5. Optuna Objective 함수 (PyTorch용) ===\n","def objective(trial, X, y):\n","    X_train, X_val, y_train, y_val = train_test_split(\n","        X, y, test_size=0.25, random_state=Config.RANDOM_STATE, stratify=y)\n","\n","    train_dataset = TensorDataset(torch.FloatTensor(X_train), torch.FloatTensor(y_train))\n","    val_dataset = TensorDataset(torch.FloatTensor(X_val), torch.FloatTensor(y_val))\n","    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)\n","    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE)\n","\n","    input_dim = X_train.shape[1]\n","    model = MLP(input_dim, trial).to(DEVICE)\n","    lr = trial.suggest_float('learning_rate', 1e-5, 1e-2, log=True)\n","    optimizer = optim.Adam(model.parameters(), lr=lr)\n","    criterion = nn.BCELoss()\n","\n","    best_score = -1\n","    patience_counter = 0\n","\n","    for epoch in range(Config.EPOCHS):\n","        train_model(model, train_loader, optimizer, criterion)\n","        y_pred_proba, y_true = evaluate_model(model, val_loader)\n","        score = average_precision_score(y_true, y_pred_proba)\n","\n","        trial.report(score, epoch)\n","        if trial.should_prune():\n","            raise optuna.exceptions.TrialPruned()\n","\n","        if score > best_score:\n","            best_score = score\n","            patience_counter = 0\n","        else:\n","            patience_counter += 1\n","\n","        if patience_counter >= Config.VALIDATION_EARLY_STOPPING_PATIENCE:\n","            break\n","\n","    return best_score\n","\n","# === 6. Optuna 조기 종료 콜백 ===\n","class EarlyStoppingCallback:\n","    def __init__(self, early_stopping_rounds: int):\n","        self._early_stopping_rounds = early_stopping_rounds\n","        self._best_value = -float(\"inf\")\n","        self._counter = 0\n","\n","    def __call__(self, study: optuna.study.Study, trial: optuna.trial.Trial):\n","        current_best_value = study.best_value\n","        if current_best_value is not None and current_best_value > self._best_value:\n","            self._best_value = current_best_value\n","            self._counter = 0\n","        else:\n","            self._counter += 1\n","\n","        if self._counter >= self._early_stopping_rounds:\n","            print(f\"\\n[Optuna 조기 종료] {self._early_stopping_rounds}번의 trial 동안 최고 점수가 갱신되지 않아 튜닝을 중단합니다.\")\n","            study.stop()\n","\n","\n","# === 7. 메인 실행 블록 ===\n","if __name__ == '__main__':\n","    config = Config()\n","\n","    # --- Step 1: 데이터 로드 및 분할 ---\n","    print(\"\\n\" + \"=\"*50)\n","    print(\"📊 Step 1: 데이터 로드 및 분할\")\n","    try:\n","        df = pd.read_csv(config.CSV_FILE_PATH)\n","        labels = df[config.TARGET_COLUMN].values\n","        embeddings = np.load(config.EMBEDDING_PATH)\n","    except Exception as e:\n","        print(f\"🔥 파일 로드 실패: {e}\"); exit()\n","\n","    indices = np.arange(len(df))\n","    train_indices, test_indices = train_test_split(\n","        indices, test_size=config.TEST_SPLIT_RATIO, random_state=config.RANDOM_STATE, stratify=labels)\n","    X_train, X_test = embeddings[train_indices], embeddings[test_indices]\n","    y_train, y_test = labels[train_indices], labels[test_indices]\n","    print(f\"✅ 완료 (학습용: {len(y_train)}건, 테스트용: {len(y_test)}건)\")\n","\n","    # --- Step 2: Optuna 튜닝 수행 ---\n","    print(\"\\n\" + \"=\"*50)\n","    print(f\"🔬 Step 2: Optuna 하이퍼파라미터 튜닝 시작 (PyTorch)\")\n","    print(f\"(최대 {config.N_TRIALS}번 시도, {config.STUDY_EARLY_STOPPING_ROUNDS}번 개선 없으면 스터디 조기 종료)\")\n","    print(\"=\"*50)\n","\n","    study = optuna.create_study(direction='maximize', pruner=optuna.pruners.MedianPruner())\n","    pbar = tqdm(total=config.N_TRIALS, desc=\"Optuna 튜닝 진행률\")\n","\n","    try:\n","        study.optimize(lambda trial: objective(trial, X_train, y_train),\n","                       n_trials=config.N_TRIALS,\n","                       callbacks=[lambda s, t: pbar.update(1), EarlyStoppingCallback(config.STUDY_EARLY_STOPPING_ROUNDS)])\n","    except optuna.exceptions.OptunaError:\n","        pass # 조기 종료 시 예외 처리\n","    pbar.close()\n","\n","    # --- Step 3: 최적 모델 학습 및 평가 ---\n","    print(f\"\\n✅ 튜닝 완료!\")\n","    print(\"\\n\" + \"=\"*50)\n","    print(\"🔬 최적 하이퍼파라미터\")\n","    print(\"=\"*50)\n","    best_params = study.best_params\n","    for key, value in best_params.items():\n","        print(f\"{key:>20s}: {value}\")\n","    print(\"=\"*50)\n","\n","    print(f\"\\n🔬 Step 3: 튜닝된 최종 PyTorch 모델 학습 및 평가...\")\n","    train_dataset = TensorDataset(torch.FloatTensor(X_train), torch.FloatTensor(y_train))\n","    train_loader = DataLoader(train_dataset, batch_size=config.BATCH_SIZE, shuffle=True)\n","    test_dataset = TensorDataset(torch.FloatTensor(X_test), torch.FloatTensor(y_test))\n","    test_loader = DataLoader(test_dataset, batch_size=config.BATCH_SIZE)\n","\n","    # Optuna study 객체를 모의 trial로 사용하여 최종 모델 생성\n","    final_model = MLP(X_train.shape[1], study.best_trial).to(DEVICE)\n","    optimizer = optim.Adam(final_model.parameters(), lr=best_params['learning_rate'])\n","    criterion = nn.BCELoss()\n","\n","    # 최종 모델은 전체 학습 데이터로 학습\n","    for epoch in tqdm(range(config.EPOCHS), desc=\"최종 모델 학습\"):\n","        train_model(final_model, train_loader, optimizer, criterion)\n","\n","    y_pred_proba_tuned, y_true_test = evaluate_model(final_model, test_loader)\n","    y_pred_class_tuned = (y_pred_proba_tuned > 0.5).astype(int)\n","\n","    results = {\n","        \"PR AUC\": average_precision_score(y_true_test, y_pred_proba_tuned),\n","        \"ROC AUC\": roc_auc_score(y_true_test, y_pred_proba_tuned),\n","        \"F1-Score\": f1_score(y_true_test, y_pred_class_tuned),\n","    }\n","    print(\"✅ 튜닝된 PyTorch 모델 평가 완료.\")\n","    print(pd.DataFrame(results, index=['Optuna_Tuned_PyTorch']).round(4))\n","\n","    # --- Step 4: 결과 저장 ---\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"💾 Step 4: 최종 모델 예측 결과를 원본 CSV에 추가하여 저장\")\n","    print(\"=\"*60)\n","\n","    all_dataset = TensorDataset(torch.FloatTensor(embeddings))\n","    all_loader = DataLoader(all_dataset, batch_size=config.BATCH_SIZE * 2) # 예측 시에는 더 큰 배치 사용 가능\n","\n","    final_model.eval()\n","    all_predictions = []\n","    with torch.no_grad():\n","        for (inputs,) in tqdm(all_loader, desc=\"전체 데이터 예측\"):\n","            inputs = inputs.to(DEVICE)\n","            outputs = final_model(inputs)\n","            all_predictions.extend(outputs.cpu().numpy())\n","\n","    df['s2_pred_proba'] = all_predictions\n","    df['s2_pred_class'] = (df['s2_pred_proba'] > 0.5).astype(int)\n","\n","    df.to_csv(config.OUTPUT_CSV_PATH, index=False, encoding='utf-8-sig')\n","    print(f\"✅ 모든 데이터의 예측 결과가 '{config.OUTPUT_CSV_PATH}' 파일에 성공적으로 저장되었습니다.\")\n","\n","    # --- Step 5: 메모리 정리 ---\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"🧹 Step 5: 메모리 정리\")\n","    print(\"=\"*60)\n","    del df, labels, embeddings, X_train, X_test, y_train, y_test, final_model, study\n","    gc.collect()\n","    if torch.cuda.is_available():\n","        torch.cuda.empty_cache()\n","    print(\"✅ 메모리 정리가 완료되었습니다.\")\n","\n","    print(\"\\n🎉 모든 과정이 완료되었습니다!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["35a31440b11146d3a456f753268d7681","53f29e278e1c4c85a45d7907528fc162","91ba376bf06e4304b6d1d139eaee19ee","1fc09cccff9946d5b130051f425d4510","97cf484dfce4483596e7ca37b82a5099","1db5139525054be1b798cae0b232c743","f7e536de2aa64ae9872fe8e1dd44d1cb","d2fe6df672ef42aeaa49201f2bc1cf9d","860fd465283f4ff5857b12c5876d0a98","bd13931a4c2f4bd1b55e8a64e473e9d4","7ea146a27c894f199cd84178c464e7e5","8e2666f44cd54c80b9f8e091e96348d9","bff771ac856e417782c79d0f936e33c4","dc374eb8e7d941b6a7282a06ee793aa8","57605dc75eaa4a59976696ec78361e0b","2c9a7c140fb0407c827eb49ca11c021d","670394612cb74156a03db00731352866","b28eb4438da343de832407ccf476c53b","b7f12098d894403cba4268728ee1d09e","96ca0ceae64944ecbfba167ed6d2a2c7","a3dbce6df5a44ec0a9f106433c12a68f","407801e6635043838064b9043b1b4b53","fda9afdefe304432a98611126f4644e8","4b88ee9b5a394f47a3273152db936c8e","56ad13e75fb14668848fa9fa5aec17f6","9fa285400ff349258e9a35eb66e445f0","c71288f862164110a0d4a2c52c2d1c39","5bc26e6e192e463bb5dcab1b46612eca","ec8011e6c562413ea7a6f7a7daf30388","a384b4dee61a4bd7b34245de1aeaea00","858cc6f2ad7b493f894a1be95e195789","1a7e4fb4483a4e77957b11b3f90ded53","21688d19de684edf9baaf81262d15f75"]},"id":"rtwx6H0o51du","executionInfo":{"status":"ok","timestamp":1760281513656,"user_tz":-540,"elapsed":421079,"user":{"displayName":"KW-data-analytics","userId":"09651493752354345908"}},"outputId":"810888d3-5b66-4b87-c04f-6af394b6f4e7"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================================================\n","📊 Step 1: 데이터 로드 및 분할\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-10-12 14:58:16,843] A new study created in memory with name: no-name-12b08e26-38bb-439a-86e4-02e163e79668\n"]},{"output_type":"stream","name":"stdout","text":["✅ 완료 (학습용: 71941건, 테스트용: 17986건)\n","\n","==================================================\n","🔬 Step 2: Optuna 하이퍼파라미터 튜닝 시작 (PyTorch)\n","(최대 50번 시도, 10번 개선 없으면 스터디 조기 종료)\n","==================================================\n"]},{"output_type":"display_data","data":{"text/plain":["Optuna 튜닝 진행률:   0%|          | 0/50 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"35a31440b11146d3a456f753268d7681"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2025-10-12 14:58:40,411] Trial 0 finished with value: 0.29353196431320183 and parameters: {'n_layers': 2, 'n_units_l0': 90, 'dropout_l0': 0.25233379653788296, 'n_units_l1': 99, 'dropout_l1': 0.4513697007175935, 'learning_rate': 8.591778394097837e-05}. Best is trial 0 with value: 0.29353196431320183.\n","[I 2025-10-12 14:59:19,395] Trial 1 finished with value: 0.29109673192298186 and parameters: {'n_layers': 1, 'n_units_l0': 50, 'dropout_l0': 0.39323749953951725, 'learning_rate': 5.4289641319051e-05}. Best is trial 0 with value: 0.29353196431320183.\n","[I 2025-10-12 14:59:34,539] Trial 2 finished with value: 0.2983929872204086 and parameters: {'n_layers': 5, 'n_units_l0': 151, 'dropout_l0': 0.33541419535763534, 'n_units_l1': 368, 'dropout_l1': 0.3463654117939637, 'n_units_l2': 449, 'dropout_l2': 0.42893551897915216, 'n_units_l3': 263, 'dropout_l3': 0.34434303569521374, 'n_units_l4': 377, 'dropout_l4': 0.40517616228682607, 'learning_rate': 0.0008194663683445672}. Best is trial 2 with value: 0.2983929872204086.\n","[I 2025-10-12 14:59:43,302] Trial 3 finished with value: 0.280340742761762 and parameters: {'n_layers': 2, 'n_units_l0': 47, 'dropout_l0': 0.2645295439371319, 'n_units_l1': 258, 'dropout_l1': 0.4333508521873337, 'learning_rate': 0.006717442850408007}. Best is trial 2 with value: 0.2983929872204086.\n","[I 2025-10-12 14:59:59,692] Trial 4 finished with value: 0.29634278757610066 and parameters: {'n_layers': 4, 'n_units_l0': 95, 'dropout_l0': 0.4324372248414158, 'n_units_l1': 89, 'dropout_l1': 0.2448200491163146, 'n_units_l2': 338, 'dropout_l2': 0.2286626961351276, 'n_units_l3': 124, 'dropout_l3': 0.20537787092071313, 'learning_rate': 0.006564036302284657}. Best is trial 2 with value: 0.2983929872204086.\n","[I 2025-10-12 15:00:13,316] Trial 5 finished with value: 0.296792768324575 and parameters: {'n_layers': 5, 'n_units_l0': 273, 'dropout_l0': 0.26500052981464517, 'n_units_l1': 102, 'dropout_l1': 0.19762490957070047, 'n_units_l2': 338, 'dropout_l2': 0.11737183633707714, 'n_units_l3': 400, 'dropout_l3': 0.3664313908960932, 'n_units_l4': 49, 'dropout_l4': 0.4258064157431988, 'learning_rate': 0.0002878451658598692}. Best is trial 2 with value: 0.2983929872204086.\n","[I 2025-10-12 15:00:14,456] Trial 6 pruned. \n","[I 2025-10-12 15:00:19,120] Trial 7 pruned. \n","[I 2025-10-12 15:00:20,087] Trial 8 pruned. \n","[I 2025-10-12 15:00:21,253] Trial 9 pruned. \n","[I 2025-10-12 15:00:31,833] Trial 10 pruned. \n","[I 2025-10-12 15:00:48,478] Trial 11 finished with value: 0.297377551878482 and parameters: {'n_layers': 5, 'n_units_l0': 215, 'dropout_l0': 0.33077392632929153, 'n_units_l1': 38, 'dropout_l1': 0.12672576131845287, 'n_units_l2': 222, 'dropout_l2': 0.11280586605986807, 'n_units_l3': 450, 'dropout_l3': 0.3583578399983751, 'n_units_l4': 40, 'dropout_l4': 0.45173131905229563, 'learning_rate': 0.0006782130153853412}. Best is trial 2 with value: 0.2983929872204086.\n","[I 2025-10-12 15:01:04,793] Trial 12 finished with value: 0.29861543978377225 and parameters: {'n_layers': 5, 'n_units_l0': 170, 'dropout_l0': 0.10025785438671869, 'n_units_l1': 45, 'dropout_l1': 0.11140484984930539, 'n_units_l2': 177, 'dropout_l2': 0.37554165709406717, 'n_units_l3': 445, 'dropout_l3': 0.4906739502922576, 'n_units_l4': 484, 'dropout_l4': 0.4624041758428753, 'learning_rate': 0.0011674752754261015}. Best is trial 12 with value: 0.29861543978377225.\n","[I 2025-10-12 15:01:08,276] Trial 13 pruned. \n","[I 2025-10-12 15:01:09,608] Trial 14 pruned. \n","[I 2025-10-12 15:01:19,963] Trial 15 finished with value: 0.2980845408513424 and parameters: {'n_layers': 3, 'n_units_l0': 150, 'dropout_l0': 0.12340723961952424, 'n_units_l1': 309, 'dropout_l1': 0.3399873856654786, 'n_units_l2': 71, 'dropout_l2': 0.36626394848721366, 'learning_rate': 0.001861549709154403}. Best is trial 12 with value: 0.29861543978377225.\n","[I 2025-10-12 15:01:24,348] Trial 16 pruned. \n","[I 2025-10-12 15:01:39,621] Trial 17 finished with value: 0.2980276125253876 and parameters: {'n_layers': 5, 'n_units_l0': 211, 'dropout_l0': 0.3510994094413398, 'n_units_l1': 64, 'dropout_l1': 0.29574172180293545, 'n_units_l2': 487, 'dropout_l2': 0.3287594018312263, 'n_units_l3': 245, 'dropout_l3': 0.4821792069309931, 'n_units_l4': 483, 'dropout_l4': 0.3158381391512868, 'learning_rate': 0.0005479755289818036}. Best is trial 12 with value: 0.29861543978377225.\n","[I 2025-10-12 15:01:40,816] Trial 18 pruned. \n","[I 2025-10-12 15:01:42,079] Trial 19 pruned. \n","[I 2025-10-12 15:01:55,022] Trial 20 finished with value: 0.2973707182279141 and parameters: {'n_layers': 2, 'n_units_l0': 76, 'dropout_l0': 0.3651557062599979, 'n_units_l1': 47, 'dropout_l1': 0.3079663109716031, 'learning_rate': 0.0010592276480065632}. Best is trial 12 with value: 0.29861543978377225.\n","[I 2025-10-12 15:01:56,155] Trial 21 pruned. \n","[I 2025-10-12 15:02:09,798] Trial 22 finished with value: 0.2988627014451981 and parameters: {'n_layers': 4, 'n_units_l0': 163, 'dropout_l0': 0.10376884866402192, 'n_units_l1': 366, 'dropout_l1': 0.32968528802922265, 'n_units_l2': 52, 'dropout_l2': 0.3169667083094564, 'n_units_l3': 328, 'dropout_l3': 0.2787273374316255, 'learning_rate': 0.0006256818214259579}. Best is trial 22 with value: 0.2988627014451981.\n","[I 2025-10-12 15:02:11,007] Trial 23 pruned. \n","[I 2025-10-12 15:02:25,189] Trial 24 finished with value: 0.2990997316079787 and parameters: {'n_layers': 5, 'n_units_l0': 273, 'dropout_l0': 0.10380801773728156, 'n_units_l1': 417, 'dropout_l1': 0.38982165404192826, 'n_units_l2': 100, 'dropout_l2': 0.18938532332106334, 'n_units_l3': 302, 'dropout_l3': 0.23566193242532002, 'n_units_l4': 284, 'dropout_l4': 0.3859613355960161, 'learning_rate': 0.000654527719449153}. Best is trial 24 with value: 0.2990997316079787.\n","[I 2025-10-12 15:02:27,684] Trial 25 pruned. \n","[I 2025-10-12 15:02:29,045] Trial 26 pruned. \n","[I 2025-10-12 15:02:43,449] Trial 27 finished with value: 0.29796457224950335 and parameters: {'n_layers': 4, 'n_units_l0': 369, 'dropout_l0': 0.21122718201657947, 'n_units_l1': 73, 'dropout_l1': 0.2688301394882046, 'n_units_l2': 165, 'dropout_l2': 0.2771607392758682, 'n_units_l3': 337, 'dropout_l3': 0.2990570023349554, 'learning_rate': 0.003354990986761023}. Best is trial 24 with value: 0.2990997316079787.\n","[I 2025-10-12 15:02:48,255] Trial 28 pruned. \n","[I 2025-10-12 15:02:49,473] Trial 29 pruned. \n","[I 2025-10-12 15:02:50,748] Trial 30 pruned. \n","[I 2025-10-12 15:02:58,942] Trial 31 pruned. \n","[I 2025-10-12 15:03:17,259] Trial 32 finished with value: 0.30045202552584593 and parameters: {'n_layers': 5, 'n_units_l0': 116, 'dropout_l0': 0.2885002245900376, 'n_units_l1': 352, 'dropout_l1': 0.36109284010178866, 'n_units_l2': 336, 'dropout_l2': 0.3949540459693273, 'n_units_l3': 303, 'dropout_l3': 0.2827995283642472, 'n_units_l4': 156, 'dropout_l4': 0.4961550340547851, 'learning_rate': 0.0007766702220744428}. Best is trial 32 with value: 0.30045202552584593.\n","[I 2025-10-12 15:03:27,818] Trial 33 finished with value: 0.2973760718654044 and parameters: {'n_layers': 5, 'n_units_l0': 110, 'dropout_l0': 0.1579833434208596, 'n_units_l1': 255, 'dropout_l1': 0.3773110054385718, 'n_units_l2': 257, 'dropout_l2': 0.39922681551107375, 'n_units_l3': 313, 'dropout_l3': 0.27334717763065525, 'n_units_l4': 141, 'dropout_l4': 0.49806087736162563, 'learning_rate': 0.0013901835645423826}. Best is trial 32 with value: 0.30045202552584593.\n","[I 2025-10-12 15:03:29,052] Trial 34 pruned. \n","[I 2025-10-12 15:03:35,597] Trial 35 pruned. \n","[I 2025-10-12 15:03:37,977] Trial 36 pruned. \n","[I 2025-10-12 15:03:43,971] Trial 37 pruned. \n","[I 2025-10-12 15:03:45,174] Trial 38 pruned. \n","[I 2025-10-12 15:03:46,630] Trial 39 pruned. \n","[I 2025-10-12 15:03:47,843] Trial 40 pruned. \n","[I 2025-10-12 15:04:01,931] Trial 41 finished with value: 0.29740761896513346 and parameters: {'n_layers': 5, 'n_units_l0': 179, 'dropout_l0': 0.3074310897982069, 'n_units_l1': 506, 'dropout_l1': 0.3675726531362354, 'n_units_l2': 412, 'dropout_l2': 0.4690951471934683, 'n_units_l3': 282, 'dropout_l3': 0.17179699930094586, 'n_units_l4': 377, 'dropout_l4': 0.3961590841656644, 'learning_rate': 0.000692612065603906}. Best is trial 32 with value: 0.30045202552584593.\n","[I 2025-10-12 15:04:04,295] Trial 42 pruned. \n"]},{"output_type":"stream","name":"stdout","text":["\n","[Optuna 조기 종료] 10번의 trial 동안 최고 점수가 갱신되지 않아 튜닝을 중단합니다.\n","\n","✅ 튜닝 완료!\n","\n","==================================================\n","🔬 최적 하이퍼파라미터\n","==================================================\n","            n_layers: 5\n","          n_units_l0: 116\n","          dropout_l0: 0.2885002245900376\n","          n_units_l1: 352\n","          dropout_l1: 0.36109284010178866\n","          n_units_l2: 336\n","          dropout_l2: 0.3949540459693273\n","          n_units_l3: 303\n","          dropout_l3: 0.2827995283642472\n","          n_units_l4: 156\n","          dropout_l4: 0.4961550340547851\n","       learning_rate: 0.0007766702220744428\n","==================================================\n","\n","🔬 Step 3: 튜닝된 최종 PyTorch 모델 학습 및 평가...\n"]},{"output_type":"display_data","data":{"text/plain":["최종 모델 학습:   0%|          | 0/50 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8e2666f44cd54c80b9f8e091e96348d9"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["✅ 튜닝된 PyTorch 모델 평가 완료.\n","                      PR AUC  ROC AUC  F1-Score\n","Optuna_Tuned_PyTorch  0.3212   0.7558    0.1194\n","\n","============================================================\n","💾 Step 4: 최종 모델 예측 결과를 원본 CSV에 추가하여 저장\n","============================================================\n"]},{"output_type":"display_data","data":{"text/plain":["전체 데이터 예측:   0%|          | 0/176 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fda9afdefe304432a98611126f4644e8"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["✅ 모든 데이터의 예측 결과가 '/content/drive/MyDrive/review_helpfulness/PADA/results/s2/amazon/MLP/MLP_amazon_with_RoBERTa_predictions.csv' 파일에 성공적으로 저장되었습니다.\n","\n","============================================================\n","🧹 Step 5: 메모리 정리\n","============================================================\n","✅ 메모리 정리가 완료되었습니다.\n","\n","🎉 모든 과정이 완료되었습니다!\n"]}]},{"cell_type":"markdown","source":["## DistilBERT"],"metadata":{"id":"tpxsdh5F40qh"}},{"cell_type":"code","source":["# === 2. 환경설정 클래스 ===\n","class Config:\n","    \"\"\"실행에 필요한 모든 설정값을 중앙에서 관리합니다.\"\"\"\n","    # 🌟 1. 파일 경로 설정\n","    CSV_FILE_PATH = \"/content/drive/MyDrive/review_helpfulness/PADA/data/amazon/amazon.csv\"\n","    EMBEDDING_PATH = \"/content/drive/MyDrive/review_helpfulness/PADA/embedding/amazon_DistilBERT.npy\"\n","\n","    # 🌟 2. 최종 결과 CSV 파일 저장 경로 설정\n","    OUTPUT_CSV_PATH = \"/content/drive/MyDrive/review_helpfulness/PADA/results/s2/amazon/MLP/MLP_amazon_with_DistilBERT_predictions.csv\"\n","\n","    # --- 데이터 정보 ---\n","    TARGET_COLUMN = 'binary_helpfulness'\n","\n","    # --- 데이터 분할 ---\n","    TEST_SPLIT_RATIO = 0.2\n","    RANDOM_STATE = 42\n","\n","    # --- PyTorch 모델 및 학습 설정 ---\n","    EPOCHS = 50\n","    BATCH_SIZE = 256\n","    VALIDATION_EARLY_STOPPING_PATIENCE = 5 # 개별 Trial 내 검증 성능 기반 조기 종료\n","\n","    # --- Optuna 튜닝 설정 ---\n","    N_TRIALS = 50\n","    TUNING_METRIC = 'pr_auc'\n","    STUDY_EARLY_STOPPING_ROUNDS = 10 # 전체 Study 조기 종료\n","\n","# === 3. MLP 모델 클래스 (PyTorch) ===\n","class MLP(nn.Module):\n","    def __init__(self, input_dim, trial):\n","        super(MLP, self).__init__()\n","        layers = []\n","\n","        # ✅ 은닉층 탐색 범위를 1~5개로 확장\n","        n_layers = trial.suggest_int('n_layers', 1, 5)\n","\n","        in_features = input_dim\n","        for i in range(n_layers):\n","            out_features = trial.suggest_int(f'n_units_l{i}', 32, 512, log=True)\n","            layers.append(nn.Linear(in_features, out_features))\n","            layers.append(nn.ReLU())\n","            p = trial.suggest_float(f'dropout_l{i}', 0.1, 0.5)\n","            layers.append(nn.Dropout(p))\n","            in_features = out_features\n","\n","        layers.append(nn.Linear(in_features, 1))\n","        self.layers = nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        return torch.sigmoid(self.layers(x).squeeze(-1))\n","\n","# === 4. 학습 및 평가 함수 ===\n","def train_model(model, loader, optimizer, criterion):\n","    model.train()\n","    for inputs, labels in loader:\n","        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n","        optimizer.zero_grad()\n","        outputs = model(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","def evaluate_model(model, loader):\n","    model.eval()\n","    all_preds = []\n","    all_labels = []\n","    with torch.no_grad():\n","        for inputs, labels in loader:\n","            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n","            outputs = model(inputs)\n","            all_preds.extend(outputs.cpu().numpy())\n","            all_labels.extend(labels.cpu().numpy())\n","    return np.array(all_preds), np.array(all_labels)\n","\n","# === 5. Optuna Objective 함수 (PyTorch용) ===\n","def objective(trial, X, y):\n","    X_train, X_val, y_train, y_val = train_test_split(\n","        X, y, test_size=0.25, random_state=Config.RANDOM_STATE, stratify=y)\n","\n","    train_dataset = TensorDataset(torch.FloatTensor(X_train), torch.FloatTensor(y_train))\n","    val_dataset = TensorDataset(torch.FloatTensor(X_val), torch.FloatTensor(y_val))\n","    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)\n","    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE)\n","\n","    input_dim = X_train.shape[1]\n","    model = MLP(input_dim, trial).to(DEVICE)\n","    lr = trial.suggest_float('learning_rate', 1e-5, 1e-2, log=True)\n","    optimizer = optim.Adam(model.parameters(), lr=lr)\n","    criterion = nn.BCELoss()\n","\n","    best_score = -1\n","    patience_counter = 0\n","\n","    for epoch in range(Config.EPOCHS):\n","        train_model(model, train_loader, optimizer, criterion)\n","        y_pred_proba, y_true = evaluate_model(model, val_loader)\n","        score = average_precision_score(y_true, y_pred_proba)\n","\n","        trial.report(score, epoch)\n","        if trial.should_prune():\n","            raise optuna.exceptions.TrialPruned()\n","\n","        if score > best_score:\n","            best_score = score\n","            patience_counter = 0\n","        else:\n","            patience_counter += 1\n","\n","        if patience_counter >= Config.VALIDATION_EARLY_STOPPING_PATIENCE:\n","            break\n","\n","    return best_score\n","\n","# === 6. Optuna 조기 종료 콜백 ===\n","class EarlyStoppingCallback:\n","    def __init__(self, early_stopping_rounds: int):\n","        self._early_stopping_rounds = early_stopping_rounds\n","        self._best_value = -float(\"inf\")\n","        self._counter = 0\n","\n","    def __call__(self, study: optuna.study.Study, trial: optuna.trial.Trial):\n","        current_best_value = study.best_value\n","        if current_best_value is not None and current_best_value > self._best_value:\n","            self._best_value = current_best_value\n","            self._counter = 0\n","        else:\n","            self._counter += 1\n","\n","        if self._counter >= self._early_stopping_rounds:\n","            print(f\"\\n[Optuna 조기 종료] {self._early_stopping_rounds}번의 trial 동안 최고 점수가 갱신되지 않아 튜닝을 중단합니다.\")\n","            study.stop()\n","\n","\n","# === 7. 메인 실행 블록 ===\n","if __name__ == '__main__':\n","    config = Config()\n","\n","    # --- Step 1: 데이터 로드 및 분할 ---\n","    print(\"\\n\" + \"=\"*50)\n","    print(\"📊 Step 1: 데이터 로드 및 분할\")\n","    try:\n","        df = pd.read_csv(config.CSV_FILE_PATH)\n","        labels = df[config.TARGET_COLUMN].values\n","        embeddings = np.load(config.EMBEDDING_PATH)\n","    except Exception as e:\n","        print(f\"🔥 파일 로드 실패: {e}\"); exit()\n","\n","    indices = np.arange(len(df))\n","    train_indices, test_indices = train_test_split(\n","        indices, test_size=config.TEST_SPLIT_RATIO, random_state=config.RANDOM_STATE, stratify=labels)\n","    X_train, X_test = embeddings[train_indices], embeddings[test_indices]\n","    y_train, y_test = labels[train_indices], labels[test_indices]\n","    print(f\"✅ 완료 (학습용: {len(y_train)}건, 테스트용: {len(y_test)}건)\")\n","\n","    # --- Step 2: Optuna 튜닝 수행 ---\n","    print(\"\\n\" + \"=\"*50)\n","    print(f\"🔬 Step 2: Optuna 하이퍼파라미터 튜닝 시작 (PyTorch)\")\n","    print(f\"(최대 {config.N_TRIALS}번 시도, {config.STUDY_EARLY_STOPPING_ROUNDS}번 개선 없으면 스터디 조기 종료)\")\n","    print(\"=\"*50)\n","\n","    study = optuna.create_study(direction='maximize', pruner=optuna.pruners.MedianPruner())\n","    pbar = tqdm(total=config.N_TRIALS, desc=\"Optuna 튜닝 진행률\")\n","\n","    try:\n","        study.optimize(lambda trial: objective(trial, X_train, y_train),\n","                       n_trials=config.N_TRIALS,\n","                       callbacks=[lambda s, t: pbar.update(1), EarlyStoppingCallback(config.STUDY_EARLY_STOPPING_ROUNDS)])\n","    except optuna.exceptions.OptunaError:\n","        pass # 조기 종료 시 예외 처리\n","    pbar.close()\n","\n","    # --- Step 3: 최적 모델 학습 및 평가 ---\n","    print(f\"\\n✅ 튜닝 완료!\")\n","    print(\"\\n\" + \"=\"*50)\n","    print(\"🔬 최적 하이퍼파라미터\")\n","    print(\"=\"*50)\n","    best_params = study.best_params\n","    for key, value in best_params.items():\n","        print(f\"{key:>20s}: {value}\")\n","    print(\"=\"*50)\n","\n","    print(f\"\\n🔬 Step 3: 튜닝된 최종 PyTorch 모델 학습 및 평가...\")\n","    train_dataset = TensorDataset(torch.FloatTensor(X_train), torch.FloatTensor(y_train))\n","    train_loader = DataLoader(train_dataset, batch_size=config.BATCH_SIZE, shuffle=True)\n","    test_dataset = TensorDataset(torch.FloatTensor(X_test), torch.FloatTensor(y_test))\n","    test_loader = DataLoader(test_dataset, batch_size=config.BATCH_SIZE)\n","\n","    # Optuna study 객체를 모의 trial로 사용하여 최종 모델 생성\n","    final_model = MLP(X_train.shape[1], study.best_trial).to(DEVICE)\n","    optimizer = optim.Adam(final_model.parameters(), lr=best_params['learning_rate'])\n","    criterion = nn.BCELoss()\n","\n","    # 최종 모델은 전체 학습 데이터로 학습\n","    for epoch in tqdm(range(config.EPOCHS), desc=\"최종 모델 학습\"):\n","        train_model(final_model, train_loader, optimizer, criterion)\n","\n","    y_pred_proba_tuned, y_true_test = evaluate_model(final_model, test_loader)\n","    y_pred_class_tuned = (y_pred_proba_tuned > 0.5).astype(int)\n","\n","    results = {\n","        \"PR AUC\": average_precision_score(y_true_test, y_pred_proba_tuned),\n","        \"ROC AUC\": roc_auc_score(y_true_test, y_pred_proba_tuned),\n","        \"F1-Score\": f1_score(y_true_test, y_pred_class_tuned),\n","    }\n","    print(\"✅ 튜닝된 PyTorch 모델 평가 완료.\")\n","    print(pd.DataFrame(results, index=['Optuna_Tuned_PyTorch']).round(4))\n","\n","    # --- Step 4: 결과 저장 ---\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"💾 Step 4: 최종 모델 예측 결과를 원본 CSV에 추가하여 저장\")\n","    print(\"=\"*60)\n","\n","    all_dataset = TensorDataset(torch.FloatTensor(embeddings))\n","    all_loader = DataLoader(all_dataset, batch_size=config.BATCH_SIZE * 2) # 예측 시에는 더 큰 배치 사용 가능\n","\n","    final_model.eval()\n","    all_predictions = []\n","    with torch.no_grad():\n","        for (inputs,) in tqdm(all_loader, desc=\"전체 데이터 예측\"):\n","            inputs = inputs.to(DEVICE)\n","            outputs = final_model(inputs)\n","            all_predictions.extend(outputs.cpu().numpy())\n","\n","    df['s2_pred_proba'] = all_predictions\n","    df['s2_pred_class'] = (df['s2_pred_proba'] > 0.5).astype(int)\n","\n","    df.to_csv(config.OUTPUT_CSV_PATH, index=False, encoding='utf-8-sig')\n","    print(f\"✅ 모든 데이터의 예측 결과가 '{config.OUTPUT_CSV_PATH}' 파일에 성공적으로 저장되었습니다.\")\n","\n","    # --- Step 5: 메모리 정리 ---\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"🧹 Step 5: 메모리 정리\")\n","    print(\"=\"*60)\n","    del df, labels, embeddings, X_train, X_test, y_train, y_test, final_model, study\n","    gc.collect()\n","    if torch.cuda.is_available():\n","        torch.cuda.empty_cache()\n","    print(\"✅ 메모리 정리가 완료되었습니다.\")\n","\n","    print(\"\\n🎉 모든 과정이 완료되었습니다!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["5c1d1f24b46e44048684ee761463d690","6207f686781140118b9d7e847dca55e7","6874239040014250be982a08aae73035","cb57c287d486473abff1ac162c1f102a","8bbdf3b574ab435987e54ae369608790","d33a0c7a32304969b4bf73901767d830","c0239bc3d5594cc0b6072671e6aae572","dabc91a3eaa540eeab30991adb156621","0785448190924403a681b111ba1f6caf","acf9e65e926f44c190cb563d79cace62","280696e334c847ba9de5c1bc8c4b39c2","88642a63770a4bd0b8e73f51a83514ce","c5338aa3016a4242a0ecf0afb96ff8a2","07317bd7845d4dc89b456b88e1f82ace","605a457a57024b338375078f75f1c5ce","df705b19f2b642be910f417df98869c5","3f4ec9bd8be148d088771a3d4b47dc55","06b75b91e7594df8b8f1fabd28c05f22","1aaf9b1578284fdb90ee5029f63db696","983ff5677e7c4c07a145980aa1babf05","9b243eb6057e446d967aee76a9305241","6d0967c2a0604d72bce44dd232981918","ff7f6e4be3984c5390086152569b6d1f","589ebda93160475a9ab56abbfa5aab5d","cec8a1b910c04152ac454236dd70bd78","6cc6ec67e7f045b78f483cb54257b8f8","3f5978ba400f4a109d28fad522f04c72","5b72d65957214adc8ef61f8a8d2b27e6","2454f33e10c040889b17cb1521a34184","6ea8b8d9045f4b14b4c9d11e54d3b5e8","059dd67c35b9427faffe174bf4cc7fc3","ba2fd5657e2846658f14ba21fff1acde","52c5c97ecca642cc824043ab49bd47e5"]},"id":"RQ1_0iAE5-xo","executionInfo":{"status":"ok","timestamp":1760281718484,"user_tz":-540,"elapsed":204807,"user":{"displayName":"KW-data-analytics","userId":"09651493752354345908"}},"outputId":"c4c5b022-bdec-40f9-ed27-38a79ba878f4"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================================================\n","📊 Step 1: 데이터 로드 및 분할\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-10-12 15:05:18,415] A new study created in memory with name: no-name-3f50cccf-8847-4b46-bba4-f86381f0f51c\n"]},{"output_type":"stream","name":"stdout","text":["✅ 완료 (학습용: 71941건, 테스트용: 17986건)\n","\n","==================================================\n","🔬 Step 2: Optuna 하이퍼파라미터 튜닝 시작 (PyTorch)\n","(최대 50번 시도, 10번 개선 없으면 스터디 조기 종료)\n","==================================================\n"]},{"output_type":"display_data","data":{"text/plain":["Optuna 튜닝 진행률:   0%|          | 0/50 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5c1d1f24b46e44048684ee761463d690"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2025-10-12 15:05:31,505] Trial 0 finished with value: 0.2985317619185047 and parameters: {'n_layers': 5, 'n_units_l0': 221, 'dropout_l0': 0.25802259904852454, 'n_units_l1': 199, 'dropout_l1': 0.42851237140329723, 'n_units_l2': 254, 'dropout_l2': 0.3017183766637207, 'n_units_l3': 64, 'dropout_l3': 0.32758550554287097, 'n_units_l4': 243, 'dropout_l4': 0.1776006257134057, 'learning_rate': 0.0008298681273709458}. Best is trial 0 with value: 0.2985317619185047.\n","[I 2025-10-12 15:06:02,575] Trial 1 finished with value: 0.29909116710192185 and parameters: {'n_layers': 4, 'n_units_l0': 37, 'dropout_l0': 0.19544813302795672, 'n_units_l1': 221, 'dropout_l1': 0.43281807462347877, 'n_units_l2': 289, 'dropout_l2': 0.24524047806936944, 'n_units_l3': 252, 'dropout_l3': 0.22434050578492182, 'learning_rate': 6.724060977499696e-05}. Best is trial 1 with value: 0.29909116710192185.\n","[I 2025-10-12 15:06:18,402] Trial 2 finished with value: 0.29776294929409663 and parameters: {'n_layers': 2, 'n_units_l0': 253, 'dropout_l0': 0.11963369631304502, 'n_units_l1': 38, 'dropout_l1': 0.32179676231315485, 'learning_rate': 0.00897272678173969}. Best is trial 1 with value: 0.29909116710192185.\n","[I 2025-10-12 15:06:35,792] Trial 3 finished with value: 0.3002501733458891 and parameters: {'n_layers': 1, 'n_units_l0': 63, 'dropout_l0': 0.3976903496202696, 'learning_rate': 0.0003422459210001904}. Best is trial 3 with value: 0.3002501733458891.\n","[I 2025-10-12 15:06:48,722] Trial 4 finished with value: 0.3005054774712896 and parameters: {'n_layers': 1, 'n_units_l0': 426, 'dropout_l0': 0.3388905760527674, 'learning_rate': 0.0008362047793278085}. Best is trial 4 with value: 0.3005054774712896.\n","[I 2025-10-12 15:06:50,121] Trial 5 pruned. \n","[I 2025-10-12 15:07:01,517] Trial 6 pruned. \n","[I 2025-10-12 15:07:16,353] Trial 7 finished with value: 0.301034966353696 and parameters: {'n_layers': 3, 'n_units_l0': 182, 'dropout_l0': 0.21928302736213126, 'n_units_l1': 272, 'dropout_l1': 0.31986279742139023, 'n_units_l2': 297, 'dropout_l2': 0.31941296712554257, 'learning_rate': 0.0009392363424652996}. Best is trial 7 with value: 0.301034966353696.\n","[I 2025-10-12 15:07:18,595] Trial 8 pruned. \n","[I 2025-10-12 15:07:19,656] Trial 9 pruned. \n","[I 2025-10-12 15:07:20,792] Trial 10 pruned. \n","[I 2025-10-12 15:07:28,119] Trial 11 finished with value: 0.2997155062675695 and parameters: {'n_layers': 1, 'n_units_l0': 487, 'dropout_l0': 0.16689381772948175, 'learning_rate': 0.002162875508875033}. Best is trial 7 with value: 0.301034966353696.\n","[I 2025-10-12 15:07:29,362] Trial 12 pruned. \n","[I 2025-10-12 15:07:30,496] Trial 13 pruned. \n","[I 2025-10-12 15:07:31,503] Trial 14 pruned. \n","[I 2025-10-12 15:07:33,769] Trial 15 pruned. \n","[I 2025-10-12 15:07:34,839] Trial 16 pruned. \n","[I 2025-10-12 15:07:36,891] Trial 17 pruned. \n"]},{"output_type":"stream","name":"stdout","text":["\n","[Optuna 조기 종료] 10번의 trial 동안 최고 점수가 갱신되지 않아 튜닝을 중단합니다.\n","\n","✅ 튜닝 완료!\n","\n","==================================================\n","🔬 최적 하이퍼파라미터\n","==================================================\n","            n_layers: 3\n","          n_units_l0: 182\n","          dropout_l0: 0.21928302736213126\n","          n_units_l1: 272\n","          dropout_l1: 0.31986279742139023\n","          n_units_l2: 297\n","          dropout_l2: 0.31941296712554257\n","       learning_rate: 0.0009392363424652996\n","==================================================\n","\n","🔬 Step 3: 튜닝된 최종 PyTorch 모델 학습 및 평가...\n"]},{"output_type":"display_data","data":{"text/plain":["최종 모델 학습:   0%|          | 0/50 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"88642a63770a4bd0b8e73f51a83514ce"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["✅ 튜닝된 PyTorch 모델 평가 완료.\n","                      PR AUC  ROC AUC  F1-Score\n","Optuna_Tuned_PyTorch  0.2476   0.7408    0.1151\n","\n","============================================================\n","💾 Step 4: 최종 모델 예측 결과를 원본 CSV에 추가하여 저장\n","============================================================\n"]},{"output_type":"display_data","data":{"text/plain":["전체 데이터 예측:   0%|          | 0/176 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ff7f6e4be3984c5390086152569b6d1f"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["✅ 모든 데이터의 예측 결과가 '/content/drive/MyDrive/review_helpfulness/PADA/results/s2/amazon/MLP/MLP_amazon_with_DistilBERT_predictions.csv' 파일에 성공적으로 저장되었습니다.\n","\n","============================================================\n","🧹 Step 5: 메모리 정리\n","============================================================\n","✅ 메모리 정리가 완료되었습니다.\n","\n","🎉 모든 과정이 완료되었습니다!\n"]}]},{"cell_type":"markdown","source":["# Coursera"],"metadata":{"id":"YOwru_C54_TY"}},{"cell_type":"markdown","source":["## T5"],"metadata":{"id":"XnY3fbxo5Beo"}},{"cell_type":"code","source":["# === 2. 환경설정 클래스 ===\n","class Config:\n","    \"\"\"실행에 필요한 모든 설정값을 중앙에서 관리합니다.\"\"\"\n","    # 🌟 1. 파일 경로 설정\n","    CSV_FILE_PATH = \"/content/drive/MyDrive/review_helpfulness/PADA/data/coursera/coursera.csv\"\n","    EMBEDDING_PATH = \"/content/drive/MyDrive/review_helpfulness/PADA/embedding/coursera_T5.npy\"\n","\n","    # 🌟 2. 최종 결과 CSV 파일 저장 경로 설정\n","    OUTPUT_CSV_PATH = \"/content/drive/MyDrive/review_helpfulness/PADA/results/s2/coursera/MLP/MLP_coursera_with_T5_predictions.csv\"\n","\n","    # --- 데이터 정보 ---\n","    TARGET_COLUMN = 'binary_helpfulness'\n","\n","    # --- 데이터 분할 ---\n","    TEST_SPLIT_RATIO = 0.2\n","    RANDOM_STATE = 42\n","\n","    # --- PyTorch 모델 및 학습 설정 ---\n","    EPOCHS = 50\n","    BATCH_SIZE = 256\n","    VALIDATION_EARLY_STOPPING_PATIENCE = 5 # 개별 Trial 내 검증 성능 기반 조기 종료\n","\n","    # --- Optuna 튜닝 설정 ---\n","    N_TRIALS = 50\n","    TUNING_METRIC = 'pr_auc'\n","    STUDY_EARLY_STOPPING_ROUNDS = 10 # 전체 Study 조기 종료\n","\n","# === 3. MLP 모델 클래스 (PyTorch) ===\n","class MLP(nn.Module):\n","    def __init__(self, input_dim, trial):\n","        super(MLP, self).__init__()\n","        layers = []\n","\n","        # ✅ 은닉층 탐색 범위를 1~5개로 확장\n","        n_layers = trial.suggest_int('n_layers', 1, 5)\n","\n","        in_features = input_dim\n","        for i in range(n_layers):\n","            out_features = trial.suggest_int(f'n_units_l{i}', 32, 512, log=True)\n","            layers.append(nn.Linear(in_features, out_features))\n","            layers.append(nn.ReLU())\n","            p = trial.suggest_float(f'dropout_l{i}', 0.1, 0.5)\n","            layers.append(nn.Dropout(p))\n","            in_features = out_features\n","\n","        layers.append(nn.Linear(in_features, 1))\n","        self.layers = nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        return torch.sigmoid(self.layers(x).squeeze(-1))\n","\n","# === 4. 학습 및 평가 함수 ===\n","def train_model(model, loader, optimizer, criterion):\n","    model.train()\n","    for inputs, labels in loader:\n","        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n","        optimizer.zero_grad()\n","        outputs = model(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","def evaluate_model(model, loader):\n","    model.eval()\n","    all_preds = []\n","    all_labels = []\n","    with torch.no_grad():\n","        for inputs, labels in loader:\n","            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n","            outputs = model(inputs)\n","            all_preds.extend(outputs.cpu().numpy())\n","            all_labels.extend(labels.cpu().numpy())\n","    return np.array(all_preds), np.array(all_labels)\n","\n","# === 5. Optuna Objective 함수 (PyTorch용) ===\n","def objective(trial, X, y):\n","    X_train, X_val, y_train, y_val = train_test_split(\n","        X, y, test_size=0.25, random_state=Config.RANDOM_STATE, stratify=y)\n","\n","    train_dataset = TensorDataset(torch.FloatTensor(X_train), torch.FloatTensor(y_train))\n","    val_dataset = TensorDataset(torch.FloatTensor(X_val), torch.FloatTensor(y_val))\n","    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)\n","    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE)\n","\n","    input_dim = X_train.shape[1]\n","    model = MLP(input_dim, trial).to(DEVICE)\n","    lr = trial.suggest_float('learning_rate', 1e-5, 1e-2, log=True)\n","    optimizer = optim.Adam(model.parameters(), lr=lr)\n","    criterion = nn.BCELoss()\n","\n","    best_score = -1\n","    patience_counter = 0\n","\n","    for epoch in range(Config.EPOCHS):\n","        train_model(model, train_loader, optimizer, criterion)\n","        y_pred_proba, y_true = evaluate_model(model, val_loader)\n","        score = average_precision_score(y_true, y_pred_proba)\n","\n","        trial.report(score, epoch)\n","        if trial.should_prune():\n","            raise optuna.exceptions.TrialPruned()\n","\n","        if score > best_score:\n","            best_score = score\n","            patience_counter = 0\n","        else:\n","            patience_counter += 1\n","\n","        if patience_counter >= Config.VALIDATION_EARLY_STOPPING_PATIENCE:\n","            break\n","\n","    return best_score\n","\n","# === 6. Optuna 조기 종료 콜백 ===\n","class EarlyStoppingCallback:\n","    def __init__(self, early_stopping_rounds: int):\n","        self._early_stopping_rounds = early_stopping_rounds\n","        self._best_value = -float(\"inf\")\n","        self._counter = 0\n","\n","    def __call__(self, study: optuna.study.Study, trial: optuna.trial.Trial):\n","        current_best_value = study.best_value\n","        if current_best_value is not None and current_best_value > self._best_value:\n","            self._best_value = current_best_value\n","            self._counter = 0\n","        else:\n","            self._counter += 1\n","\n","        if self._counter >= self._early_stopping_rounds:\n","            print(f\"\\n[Optuna 조기 종료] {self._early_stopping_rounds}번의 trial 동안 최고 점수가 갱신되지 않아 튜닝을 중단합니다.\")\n","            study.stop()\n","\n","\n","# === 7. 메인 실행 블록 ===\n","if __name__ == '__main__':\n","    config = Config()\n","\n","    # --- Step 1: 데이터 로드 및 분할 ---\n","    print(\"\\n\" + \"=\"*50)\n","    print(\"📊 Step 1: 데이터 로드 및 분할\")\n","    try:\n","        df = pd.read_csv(config.CSV_FILE_PATH)\n","        labels = df[config.TARGET_COLUMN].values\n","        embeddings = np.load(config.EMBEDDING_PATH)\n","    except Exception as e:\n","        print(f\"🔥 파일 로드 실패: {e}\"); exit()\n","\n","    indices = np.arange(len(df))\n","    train_indices, test_indices = train_test_split(\n","        indices, test_size=config.TEST_SPLIT_RATIO, random_state=config.RANDOM_STATE, stratify=labels)\n","    X_train, X_test = embeddings[train_indices], embeddings[test_indices]\n","    y_train, y_test = labels[train_indices], labels[test_indices]\n","    print(f\"✅ 완료 (학습용: {len(y_train)}건, 테스트용: {len(y_test)}건)\")\n","\n","    # --- Step 2: Optuna 튜닝 수행 ---\n","    print(\"\\n\" + \"=\"*50)\n","    print(f\"🔬 Step 2: Optuna 하이퍼파라미터 튜닝 시작 (PyTorch)\")\n","    print(f\"(최대 {config.N_TRIALS}번 시도, {config.STUDY_EARLY_STOPPING_ROUNDS}번 개선 없으면 스터디 조기 종료)\")\n","    print(\"=\"*50)\n","\n","    study = optuna.create_study(direction='maximize', pruner=optuna.pruners.MedianPruner())\n","    pbar = tqdm(total=config.N_TRIALS, desc=\"Optuna 튜닝 진행률\")\n","\n","    try:\n","        study.optimize(lambda trial: objective(trial, X_train, y_train),\n","                       n_trials=config.N_TRIALS,\n","                       callbacks=[lambda s, t: pbar.update(1), EarlyStoppingCallback(config.STUDY_EARLY_STOPPING_ROUNDS)])\n","    except optuna.exceptions.OptunaError:\n","        pass # 조기 종료 시 예외 처리\n","    pbar.close()\n","\n","    # --- Step 3: 최적 모델 학습 및 평가 ---\n","    print(f\"\\n✅ 튜닝 완료!\")\n","    print(\"\\n\" + \"=\"*50)\n","    print(\"🔬 최적 하이퍼파라미터\")\n","    print(\"=\"*50)\n","    best_params = study.best_params\n","    for key, value in best_params.items():\n","        print(f\"{key:>20s}: {value}\")\n","    print(\"=\"*50)\n","\n","    print(f\"\\n🔬 Step 3: 튜닝된 최종 PyTorch 모델 학습 및 평가...\")\n","    train_dataset = TensorDataset(torch.FloatTensor(X_train), torch.FloatTensor(y_train))\n","    train_loader = DataLoader(train_dataset, batch_size=config.BATCH_SIZE, shuffle=True)\n","    test_dataset = TensorDataset(torch.FloatTensor(X_test), torch.FloatTensor(y_test))\n","    test_loader = DataLoader(test_dataset, batch_size=config.BATCH_SIZE)\n","\n","    # Optuna study 객체를 모의 trial로 사용하여 최종 모델 생성\n","    final_model = MLP(X_train.shape[1], study.best_trial).to(DEVICE)\n","    optimizer = optim.Adam(final_model.parameters(), lr=best_params['learning_rate'])\n","    criterion = nn.BCELoss()\n","\n","    # 최종 모델은 전체 학습 데이터로 학습\n","    for epoch in tqdm(range(config.EPOCHS), desc=\"최종 모델 학습\"):\n","        train_model(final_model, train_loader, optimizer, criterion)\n","\n","    y_pred_proba_tuned, y_true_test = evaluate_model(final_model, test_loader)\n","    y_pred_class_tuned = (y_pred_proba_tuned > 0.5).astype(int)\n","\n","    results = {\n","        \"PR AUC\": average_precision_score(y_true_test, y_pred_proba_tuned),\n","        \"ROC AUC\": roc_auc_score(y_true_test, y_pred_proba_tuned),\n","        \"F1-Score\": f1_score(y_true_test, y_pred_class_tuned),\n","    }\n","    print(\"✅ 튜닝된 PyTorch 모델 평가 완료.\")\n","    print(pd.DataFrame(results, index=['Optuna_Tuned_PyTorch']).round(4))\n","\n","    # --- Step 4: 결과 저장 ---\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"💾 Step 4: 최종 모델 예측 결과를 원본 CSV에 추가하여 저장\")\n","    print(\"=\"*60)\n","\n","    all_dataset = TensorDataset(torch.FloatTensor(embeddings))\n","    all_loader = DataLoader(all_dataset, batch_size=config.BATCH_SIZE * 2) # 예측 시에는 더 큰 배치 사용 가능\n","\n","    final_model.eval()\n","    all_predictions = []\n","    with torch.no_grad():\n","        for (inputs,) in tqdm(all_loader, desc=\"전체 데이터 예측\"):\n","            inputs = inputs.to(DEVICE)\n","            outputs = final_model(inputs)\n","            all_predictions.extend(outputs.cpu().numpy())\n","\n","    df['s2_pred_proba'] = all_predictions\n","    df['s2_pred_class'] = (df['s2_pred_proba'] > 0.5).astype(int)\n","\n","    df.to_csv(config.OUTPUT_CSV_PATH, index=False, encoding='utf-8-sig')\n","    print(f\"✅ 모든 데이터의 예측 결과가 '{config.OUTPUT_CSV_PATH}' 파일에 성공적으로 저장되었습니다.\")\n","\n","    # --- Step 5: 메모리 정리 ---\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"🧹 Step 5: 메모리 정리\")\n","    print(\"=\"*60)\n","    del df, labels, embeddings, X_train, X_test, y_train, y_test, final_model, study\n","    gc.collect()\n","    if torch.cuda.is_available():\n","        torch.cuda.empty_cache()\n","    print(\"✅ 메모리 정리가 완료되었습니다.\")\n","\n","    print(\"\\n🎉 모든 과정이 완료되었습니다!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["cafe45d8cf1a49058538d0b9b6b85363","ccd374f05a0944f68147902a6d99f11a","666ca4a30bfb4138b28a6fe7f6b99bc2","4653110a96a04fa08a2db5d6eefbc479","3b12f611f1994dfcb988165cca815456","6fa4526466644abba6ef8870bcf2e03a","ddc4231939344ba0822fdfe211e5efbb","1f98c110bf7048a2ba6b9d173eb65aeb","0bb692c633aa478db2a9d39ec9a79609","99886c379366453c86f766d0ae6c6758","03450645cee0400e89f04ebdd0fa05b4","ac85f3e15a1b43d88093fe2ec2fa902a","8a8f1f251c9a46798c5387b3d3ff92c3","0cbb440738ff44c9ad6fddd2e6137331","026e88f3e2a144e0956da76991824cee","c01b800d48c649ddafc1e893cacc44d3","2a08ba62ecfd40668c177b5077bfff51","f714b4a7fca74eab92b5892e728ff2a1","0ce6fb9445174e2a93ae6be708b81de8","4611c2fa021c4ffa8bc6bad568dcddfe","f6963c0884064837b551e40f0f5bc51a","9165b0f8a2c145f587802f30f1351b85","bfd8739ec7c94f6f83a08f3e2e011a64","3e548b79af194535a5319027af271b84","6e81f667b9b34af8a08400be17fd89e0","b227a9ef04174ebd96177128ef5fa153","d7926684e5844b02b2828318ddd7b9aa","b9d1b4e4cea943cf85450231e4e6511b","7e2a539d28594e07a6f7c52d0f2c2a1b","8e304775ac874c7a90a70e4afbf65d39","895c81e2ca004e909c4b09f70dad0298","4134520cd2b64b6b82637092b7311fe3","f5c0638255d34842935c054c99bb9613"]},"id":"VIl0BR9I6Grz","executionInfo":{"status":"ok","timestamp":1760282103485,"user_tz":-540,"elapsed":384966,"user":{"displayName":"KW-data-analytics","userId":"09651493752354345908"}},"outputId":"4bc12ca0-60b4-41a3-da8c-28881dee71d9"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================================================\n","📊 Step 1: 데이터 로드 및 분할\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-10-12 15:08:44,061] A new study created in memory with name: no-name-3939b791-0d4b-4240-b66e-6e01111cad50\n"]},{"output_type":"stream","name":"stdout","text":["✅ 완료 (학습용: 97108건, 테스트용: 24278건)\n","\n","==================================================\n","🔬 Step 2: Optuna 하이퍼파라미터 튜닝 시작 (PyTorch)\n","(최대 50번 시도, 10번 개선 없으면 스터디 조기 종료)\n","==================================================\n"]},{"output_type":"display_data","data":{"text/plain":["Optuna 튜닝 진행률:   0%|          | 0/50 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cafe45d8cf1a49058538d0b9b6b85363"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2025-10-12 15:09:09,054] Trial 0 finished with value: 0.2223024103973823 and parameters: {'n_layers': 3, 'n_units_l0': 110, 'dropout_l0': 0.2652667823566912, 'n_units_l1': 417, 'dropout_l1': 0.21959280501933698, 'n_units_l2': 378, 'dropout_l2': 0.3935111133916508, 'learning_rate': 0.0017610272144902785}. Best is trial 0 with value: 0.2223024103973823.\n","[I 2025-10-12 15:09:28,765] Trial 1 finished with value: 0.2165700348558064 and parameters: {'n_layers': 3, 'n_units_l0': 35, 'dropout_l0': 0.37246362152018997, 'n_units_l1': 215, 'dropout_l1': 0.4866734467770705, 'n_units_l2': 200, 'dropout_l2': 0.4271909418748937, 'learning_rate': 0.0029372749657421947}. Best is trial 0 with value: 0.2223024103973823.\n","[I 2025-10-12 15:10:30,389] Trial 2 finished with value: 0.20929307689319668 and parameters: {'n_layers': 1, 'n_units_l0': 41, 'dropout_l0': 0.30509547556566474, 'learning_rate': 8.607634092007127e-05}. Best is trial 0 with value: 0.2223024103973823.\n","[I 2025-10-12 15:11:43,657] Trial 3 finished with value: 0.20707866826472432 and parameters: {'n_layers': 4, 'n_units_l0': 166, 'dropout_l0': 0.3875648131206786, 'n_units_l1': 109, 'dropout_l1': 0.20316816504469348, 'n_units_l2': 55, 'dropout_l2': 0.3932536668178638, 'n_units_l3': 49, 'dropout_l3': 0.44802790333417264, 'learning_rate': 1.5205759620765643e-05}. Best is trial 0 with value: 0.2223024103973823.\n","[I 2025-10-12 15:12:57,203] Trial 4 finished with value: 0.20932864507004134 and parameters: {'n_layers': 4, 'n_units_l0': 225, 'dropout_l0': 0.2486047930567275, 'n_units_l1': 73, 'dropout_l1': 0.4579269094454034, 'n_units_l2': 324, 'dropout_l2': 0.2042974343021279, 'n_units_l3': 203, 'dropout_l3': 0.25899944518574225, 'learning_rate': 1.185495365447855e-05}. Best is trial 0 with value: 0.2223024103973823.\n","[I 2025-10-12 15:13:18,071] Trial 5 finished with value: 0.2195712322565209 and parameters: {'n_layers': 3, 'n_units_l0': 374, 'dropout_l0': 0.3839938073304652, 'n_units_l1': 371, 'dropout_l1': 0.2274927790733938, 'n_units_l2': 109, 'dropout_l2': 0.3866982267279314, 'learning_rate': 0.0030882580820373443}. Best is trial 0 with value: 0.2223024103973823.\n","[I 2025-10-12 15:13:19,720] Trial 6 pruned. \n","[I 2025-10-12 15:13:33,908] Trial 7 finished with value: 0.20930871348132954 and parameters: {'n_layers': 5, 'n_units_l0': 54, 'dropout_l0': 0.2670201918401828, 'n_units_l1': 80, 'dropout_l1': 0.3062953967654716, 'n_units_l2': 277, 'dropout_l2': 0.35621152442086035, 'n_units_l3': 53, 'dropout_l3': 0.245944083867047, 'n_units_l4': 387, 'dropout_l4': 0.4675336567862437, 'learning_rate': 0.0031989862381824902}. Best is trial 0 with value: 0.2223024103973823.\n","[I 2025-10-12 15:13:35,222] Trial 8 pruned. \n","[I 2025-10-12 15:13:36,860] Trial 9 pruned. \n","[I 2025-10-12 15:13:42,241] Trial 10 pruned. \n"]},{"output_type":"stream","name":"stdout","text":["\n","[Optuna 조기 종료] 10번의 trial 동안 최고 점수가 갱신되지 않아 튜닝을 중단합니다.\n","\n","✅ 튜닝 완료!\n","\n","==================================================\n","🔬 최적 하이퍼파라미터\n","==================================================\n","            n_layers: 3\n","          n_units_l0: 110\n","          dropout_l0: 0.2652667823566912\n","          n_units_l1: 417\n","          dropout_l1: 0.21959280501933698\n","          n_units_l2: 378\n","          dropout_l2: 0.3935111133916508\n","       learning_rate: 0.0017610272144902785\n","==================================================\n","\n","🔬 Step 3: 튜닝된 최종 PyTorch 모델 학습 및 평가...\n"]},{"output_type":"display_data","data":{"text/plain":["최종 모델 학습:   0%|          | 0/50 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ac85f3e15a1b43d88093fe2ec2fa902a"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["✅ 튜닝된 PyTorch 모델 평가 완료.\n","                      PR AUC  ROC AUC  F1-Score\n","Optuna_Tuned_PyTorch   0.211   0.7748    0.1305\n","\n","============================================================\n","💾 Step 4: 최종 모델 예측 결과를 원본 CSV에 추가하여 저장\n","============================================================\n"]},{"output_type":"display_data","data":{"text/plain":["전체 데이터 예측:   0%|          | 0/238 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bfd8739ec7c94f6f83a08f3e2e011a64"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["✅ 모든 데이터의 예측 결과가 '/content/drive/MyDrive/review_helpfulness/PADA/results/s2/coursera/MLP/MLP_coursera_with_T5_predictions.csv' 파일에 성공적으로 저장되었습니다.\n","\n","============================================================\n","🧹 Step 5: 메모리 정리\n","============================================================\n","✅ 메모리 정리가 완료되었습니다.\n","\n","🎉 모든 과정이 완료되었습니다!\n"]}]},{"cell_type":"markdown","source":["## BERT"],"metadata":{"id":"pRAtnzF05Bvj"}},{"cell_type":"code","source":["# === 2. 환경설정 클래스 ===\n","class Config:\n","    \"\"\"실행에 필요한 모든 설정값을 중앙에서 관리합니다.\"\"\"\n","    # 🌟 1. 파일 경로 설정\n","    CSV_FILE_PATH = \"/content/drive/MyDrive/review_helpfulness/PADA/data/coursera/coursera.csv\"\n","    EMBEDDING_PATH = \"/content/drive/MyDrive/review_helpfulness/PADA/embedding/coursera_BERT.npy\"\n","\n","    # 🌟 2. 최종 결과 CSV 파일 저장 경로 설정\n","    OUTPUT_CSV_PATH = \"/content/drive/MyDrive/review_helpfulness/PADA/results/s2/coursera/MLP/MLP_coursera_with_BERT_predictions.csv\"\n","\n","    # --- 데이터 정보 ---\n","    TARGET_COLUMN = 'binary_helpfulness'\n","\n","    # --- 데이터 분할 ---\n","    TEST_SPLIT_RATIO = 0.2\n","    RANDOM_STATE = 42\n","\n","    # --- PyTorch 모델 및 학습 설정 ---\n","    EPOCHS = 50\n","    BATCH_SIZE = 256\n","    VALIDATION_EARLY_STOPPING_PATIENCE = 5 # 개별 Trial 내 검증 성능 기반 조기 종료\n","\n","    # --- Optuna 튜닝 설정 ---\n","    N_TRIALS = 50\n","    TUNING_METRIC = 'pr_auc'\n","    STUDY_EARLY_STOPPING_ROUNDS = 10 # 전체 Study 조기 종료\n","\n","# === 3. MLP 모델 클래스 (PyTorch) ===\n","class MLP(nn.Module):\n","    def __init__(self, input_dim, trial):\n","        super(MLP, self).__init__()\n","        layers = []\n","\n","        # ✅ 은닉층 탐색 범위를 1~5개로 확장\n","        n_layers = trial.suggest_int('n_layers', 1, 5)\n","\n","        in_features = input_dim\n","        for i in range(n_layers):\n","            out_features = trial.suggest_int(f'n_units_l{i}', 32, 512, log=True)\n","            layers.append(nn.Linear(in_features, out_features))\n","            layers.append(nn.ReLU())\n","            p = trial.suggest_float(f'dropout_l{i}', 0.1, 0.5)\n","            layers.append(nn.Dropout(p))\n","            in_features = out_features\n","\n","        layers.append(nn.Linear(in_features, 1))\n","        self.layers = nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        return torch.sigmoid(self.layers(x).squeeze(-1))\n","\n","# === 4. 학습 및 평가 함수 ===\n","def train_model(model, loader, optimizer, criterion):\n","    model.train()\n","    for inputs, labels in loader:\n","        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n","        optimizer.zero_grad()\n","        outputs = model(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","def evaluate_model(model, loader):\n","    model.eval()\n","    all_preds = []\n","    all_labels = []\n","    with torch.no_grad():\n","        for inputs, labels in loader:\n","            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n","            outputs = model(inputs)\n","            all_preds.extend(outputs.cpu().numpy())\n","            all_labels.extend(labels.cpu().numpy())\n","    return np.array(all_preds), np.array(all_labels)\n","\n","# === 5. Optuna Objective 함수 (PyTorch용) ===\n","def objective(trial, X, y):\n","    X_train, X_val, y_train, y_val = train_test_split(\n","        X, y, test_size=0.25, random_state=Config.RANDOM_STATE, stratify=y)\n","\n","    train_dataset = TensorDataset(torch.FloatTensor(X_train), torch.FloatTensor(y_train))\n","    val_dataset = TensorDataset(torch.FloatTensor(X_val), torch.FloatTensor(y_val))\n","    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)\n","    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE)\n","\n","    input_dim = X_train.shape[1]\n","    model = MLP(input_dim, trial).to(DEVICE)\n","    lr = trial.suggest_float('learning_rate', 1e-5, 1e-2, log=True)\n","    optimizer = optim.Adam(model.parameters(), lr=lr)\n","    criterion = nn.BCELoss()\n","\n","    best_score = -1\n","    patience_counter = 0\n","\n","    for epoch in range(Config.EPOCHS):\n","        train_model(model, train_loader, optimizer, criterion)\n","        y_pred_proba, y_true = evaluate_model(model, val_loader)\n","        score = average_precision_score(y_true, y_pred_proba)\n","\n","        trial.report(score, epoch)\n","        if trial.should_prune():\n","            raise optuna.exceptions.TrialPruned()\n","\n","        if score > best_score:\n","            best_score = score\n","            patience_counter = 0\n","        else:\n","            patience_counter += 1\n","\n","        if patience_counter >= Config.VALIDATION_EARLY_STOPPING_PATIENCE:\n","            break\n","\n","    return best_score\n","\n","# === 6. Optuna 조기 종료 콜백 ===\n","class EarlyStoppingCallback:\n","    def __init__(self, early_stopping_rounds: int):\n","        self._early_stopping_rounds = early_stopping_rounds\n","        self._best_value = -float(\"inf\")\n","        self._counter = 0\n","\n","    def __call__(self, study: optuna.study.Study, trial: optuna.trial.Trial):\n","        current_best_value = study.best_value\n","        if current_best_value is not None and current_best_value > self._best_value:\n","            self._best_value = current_best_value\n","            self._counter = 0\n","        else:\n","            self._counter += 1\n","\n","        if self._counter >= self._early_stopping_rounds:\n","            print(f\"\\n[Optuna 조기 종료] {self._early_stopping_rounds}번의 trial 동안 최고 점수가 갱신되지 않아 튜닝을 중단합니다.\")\n","            study.stop()\n","\n","\n","# === 7. 메인 실행 블록 ===\n","if __name__ == '__main__':\n","    config = Config()\n","\n","    # --- Step 1: 데이터 로드 및 분할 ---\n","    print(\"\\n\" + \"=\"*50)\n","    print(\"📊 Step 1: 데이터 로드 및 분할\")\n","    try:\n","        df = pd.read_csv(config.CSV_FILE_PATH)\n","        labels = df[config.TARGET_COLUMN].values\n","        embeddings = np.load(config.EMBEDDING_PATH)\n","    except Exception as e:\n","        print(f\"🔥 파일 로드 실패: {e}\"); exit()\n","\n","    indices = np.arange(len(df))\n","    train_indices, test_indices = train_test_split(\n","        indices, test_size=config.TEST_SPLIT_RATIO, random_state=config.RANDOM_STATE, stratify=labels)\n","    X_train, X_test = embeddings[train_indices], embeddings[test_indices]\n","    y_train, y_test = labels[train_indices], labels[test_indices]\n","    print(f\"✅ 완료 (학습용: {len(y_train)}건, 테스트용: {len(y_test)}건)\")\n","\n","    # --- Step 2: Optuna 튜닝 수행 ---\n","    print(\"\\n\" + \"=\"*50)\n","    print(f\"🔬 Step 2: Optuna 하이퍼파라미터 튜닝 시작 (PyTorch)\")\n","    print(f\"(최대 {config.N_TRIALS}번 시도, {config.STUDY_EARLY_STOPPING_ROUNDS}번 개선 없으면 스터디 조기 종료)\")\n","    print(\"=\"*50)\n","\n","    study = optuna.create_study(direction='maximize', pruner=optuna.pruners.MedianPruner())\n","    pbar = tqdm(total=config.N_TRIALS, desc=\"Optuna 튜닝 진행률\")\n","\n","    try:\n","        study.optimize(lambda trial: objective(trial, X_train, y_train),\n","                       n_trials=config.N_TRIALS,\n","                       callbacks=[lambda s, t: pbar.update(1), EarlyStoppingCallback(config.STUDY_EARLY_STOPPING_ROUNDS)])\n","    except optuna.exceptions.OptunaError:\n","        pass # 조기 종료 시 예외 처리\n","    pbar.close()\n","\n","    # --- Step 3: 최적 모델 학습 및 평가 ---\n","    print(f\"\\n✅ 튜닝 완료!\")\n","    print(\"\\n\" + \"=\"*50)\n","    print(\"🔬 최적 하이퍼파라미터\")\n","    print(\"=\"*50)\n","    best_params = study.best_params\n","    for key, value in best_params.items():\n","        print(f\"{key:>20s}: {value}\")\n","    print(\"=\"*50)\n","\n","    print(f\"\\n🔬 Step 3: 튜닝된 최종 PyTorch 모델 학습 및 평가...\")\n","    train_dataset = TensorDataset(torch.FloatTensor(X_train), torch.FloatTensor(y_train))\n","    train_loader = DataLoader(train_dataset, batch_size=config.BATCH_SIZE, shuffle=True)\n","    test_dataset = TensorDataset(torch.FloatTensor(X_test), torch.FloatTensor(y_test))\n","    test_loader = DataLoader(test_dataset, batch_size=config.BATCH_SIZE)\n","\n","    # Optuna study 객체를 모의 trial로 사용하여 최종 모델 생성\n","    final_model = MLP(X_train.shape[1], study.best_trial).to(DEVICE)\n","    optimizer = optim.Adam(final_model.parameters(), lr=best_params['learning_rate'])\n","    criterion = nn.BCELoss()\n","\n","    # 최종 모델은 전체 학습 데이터로 학습\n","    for epoch in tqdm(range(config.EPOCHS), desc=\"최종 모델 학습\"):\n","        train_model(final_model, train_loader, optimizer, criterion)\n","\n","    y_pred_proba_tuned, y_true_test = evaluate_model(final_model, test_loader)\n","    y_pred_class_tuned = (y_pred_proba_tuned > 0.5).astype(int)\n","\n","    results = {\n","        \"PR AUC\": average_precision_score(y_true_test, y_pred_proba_tuned),\n","        \"ROC AUC\": roc_auc_score(y_true_test, y_pred_proba_tuned),\n","        \"F1-Score\": f1_score(y_true_test, y_pred_class_tuned),\n","    }\n","    print(\"✅ 튜닝된 PyTorch 모델 평가 완료.\")\n","    print(pd.DataFrame(results, index=['Optuna_Tuned_PyTorch']).round(4))\n","\n","    # --- Step 4: 결과 저장 ---\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"💾 Step 4: 최종 모델 예측 결과를 원본 CSV에 추가하여 저장\")\n","    print(\"=\"*60)\n","\n","    all_dataset = TensorDataset(torch.FloatTensor(embeddings))\n","    all_loader = DataLoader(all_dataset, batch_size=config.BATCH_SIZE * 2) # 예측 시에는 더 큰 배치 사용 가능\n","\n","    final_model.eval()\n","    all_predictions = []\n","    with torch.no_grad():\n","        for (inputs,) in tqdm(all_loader, desc=\"전체 데이터 예측\"):\n","            inputs = inputs.to(DEVICE)\n","            outputs = final_model(inputs)\n","            all_predictions.extend(outputs.cpu().numpy())\n","\n","    df['s2_pred_proba'] = all_predictions\n","    df['s2_pred_class'] = (df['s2_pred_proba'] > 0.5).astype(int)\n","\n","    df.to_csv(config.OUTPUT_CSV_PATH, index=False, encoding='utf-8-sig')\n","    print(f\"✅ 모든 데이터의 예측 결과가 '{config.OUTPUT_CSV_PATH}' 파일에 성공적으로 저장되었습니다.\")\n","\n","    # --- Step 5: 메모리 정리 ---\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"🧹 Step 5: 메모리 정리\")\n","    print(\"=\"*60)\n","    del df, labels, embeddings, X_train, X_test, y_train, y_test, final_model, study\n","    gc.collect()\n","    if torch.cuda.is_available():\n","        torch.cuda.empty_cache()\n","    print(\"✅ 메모리 정리가 완료되었습니다.\")\n","\n","    print(\"\\n🎉 모든 과정이 완료되었습니다!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["5fb0576f813e4e4fafb94441a0c7be05","5815ad50a22549f1901f6cd09d9b8c46","a3bd25018c254273af00544cba4d07d2","01404c3d3e184bd2afb266fe863ac596","a9035899b7284cf58c7c8f66707197b0","4725d7c140dc4c4aa6f9de76fcd722fc","979e416d7a98467d8a3cb0428c9cc5d2","c0b93d963a1f4fb680666992027fbe3b","b57188ac539c4c23b620eda50264aa44","16aab10ca4354b8ba1a36d7251ab8a3a","4b09f68fa67e4c398ada28977f8d1429","9e64ef66aca8403e9ed78df5ca98806b","bfc2b70ce0604aca8a8b21f39c84721a","cf0e7a46bb6a45368595dda19f16c4a5","914132267a714467bb68b7b57310c0c1","c3ada4738edb4ca3a72e7372d6239d74","360301f076934e398f4c187073e53550","e771639242c7427ebf83744d3a0f0aa2","c5dbcbf25cc24dc080a23abf19a35e9f","b8af31d362d94a94a54931dabf8ceb91","1c687dcad7374724b37e030d13824648","a5256b33644644e082ef57b6062386d3","5188b88f7a34423aa4caa47522709274","77dfc320e70643f4b0551d45278bcb6d","f91b2d1480ca470cae2fb3429ca35492","ea9a6830450043018cf701c54f06d8b9","bd201089b7a34e3f82dd158191f55183","6bb009ec1cb9443c837fdc98794fd773","65c6f86d017d4818a48cdcafdbf50287","7192431b893c4558a3c535f7277c2ffc","965b7d5c1add44599af8113d85ebf659","7afad501448c4898b38316c426b88f33","64a8b4998d9e4fd69e0abc189e9eb3bb"]},"id":"6fZuUFcV61cy","executionInfo":{"status":"ok","timestamp":1760282439498,"user_tz":-540,"elapsed":336012,"user":{"displayName":"KW-data-analytics","userId":"09651493752354345908"}},"outputId":"db8674f5-f13e-4d35-9614-1f03eeed46f6"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================================================\n","📊 Step 1: 데이터 로드 및 분할\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-10-12 15:15:08,540] A new study created in memory with name: no-name-cf4a3565-96f3-4d0e-a98d-91b3a3a59cde\n"]},{"output_type":"stream","name":"stdout","text":["✅ 완료 (학습용: 97108건, 테스트용: 24278건)\n","\n","==================================================\n","🔬 Step 2: Optuna 하이퍼파라미터 튜닝 시작 (PyTorch)\n","(최대 50번 시도, 10번 개선 없으면 스터디 조기 종료)\n","==================================================\n"]},{"output_type":"display_data","data":{"text/plain":["Optuna 튜닝 진행률:   0%|          | 0/50 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5fb0576f813e4e4fafb94441a0c7be05"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2025-10-12 15:15:45,376] Trial 0 finished with value: 0.20532492844763076 and parameters: {'n_layers': 4, 'n_units_l0': 131, 'dropout_l0': 0.12482202061334227, 'n_units_l1': 75, 'dropout_l1': 0.12868744111960156, 'n_units_l2': 217, 'dropout_l2': 0.48004912675220746, 'n_units_l3': 49, 'dropout_l3': 0.35750445309977996, 'learning_rate': 4.269764556598191e-05}. Best is trial 0 with value: 0.20532492844763076.\n","[I 2025-10-12 15:16:17,983] Trial 1 finished with value: 0.20757549195513514 and parameters: {'n_layers': 5, 'n_units_l0': 494, 'dropout_l0': 0.16666537867677733, 'n_units_l1': 55, 'dropout_l1': 0.3681928583838223, 'n_units_l2': 278, 'dropout_l2': 0.4262919237467758, 'n_units_l3': 162, 'dropout_l3': 0.324821149297923, 'n_units_l4': 205, 'dropout_l4': 0.4925078822514204, 'learning_rate': 4.726569318383233e-05}. Best is trial 1 with value: 0.20757549195513514.\n","[I 2025-10-12 15:16:29,943] Trial 2 finished with value: 0.2049826451557517 and parameters: {'n_layers': 2, 'n_units_l0': 58, 'dropout_l0': 0.36330706763683496, 'n_units_l1': 59, 'dropout_l1': 0.4753772021022309, 'learning_rate': 0.0008959072970344543}. Best is trial 1 with value: 0.20757549195513514.\n","[I 2025-10-12 15:17:24,840] Trial 3 finished with value: 0.21004439464697353 and parameters: {'n_layers': 1, 'n_units_l0': 140, 'dropout_l0': 0.3386993188683119, 'learning_rate': 8.622367446973934e-05}. Best is trial 3 with value: 0.21004439464697353.\n","[I 2025-10-12 15:18:04,684] Trial 4 finished with value: 0.20689300053548118 and parameters: {'n_layers': 4, 'n_units_l0': 231, 'dropout_l0': 0.3428074754037195, 'n_units_l1': 80, 'dropout_l1': 0.16250905603384297, 'n_units_l2': 53, 'dropout_l2': 0.4059304319062055, 'n_units_l3': 33, 'dropout_l3': 0.1398169317031399, 'learning_rate': 5.446224902789318e-05}. Best is trial 3 with value: 0.21004439464697353.\n","[I 2025-10-12 15:18:16,654] Trial 5 finished with value: 0.20331254185045272 and parameters: {'n_layers': 2, 'n_units_l0': 205, 'dropout_l0': 0.24807617860050862, 'n_units_l1': 199, 'dropout_l1': 0.25809797218686215, 'learning_rate': 0.0023647033530892923}. Best is trial 3 with value: 0.21004439464697353.\n","[I 2025-10-12 15:18:29,512] Trial 6 finished with value: 0.20609362790871158 and parameters: {'n_layers': 3, 'n_units_l0': 97, 'dropout_l0': 0.2092586223034828, 'n_units_l1': 49, 'dropout_l1': 0.12425831946249098, 'n_units_l2': 121, 'dropout_l2': 0.22538475970066224, 'learning_rate': 0.0028928934276671214}. Best is trial 3 with value: 0.21004439464697353.\n","[I 2025-10-12 15:18:47,641] Trial 7 finished with value: 0.20862063608200956 and parameters: {'n_layers': 4, 'n_units_l0': 419, 'dropout_l0': 0.16875911314196634, 'n_units_l1': 40, 'dropout_l1': 0.23446010023751185, 'n_units_l2': 49, 'dropout_l2': 0.3012460891383211, 'n_units_l3': 47, 'dropout_l3': 0.22660419213731697, 'learning_rate': 0.0009713178868709828}. Best is trial 3 with value: 0.21004439464697353.\n","[I 2025-10-12 15:18:49,077] Trial 8 pruned. \n","[I 2025-10-12 15:19:04,806] Trial 9 finished with value: 0.20719500717249037 and parameters: {'n_layers': 5, 'n_units_l0': 301, 'dropout_l0': 0.2699102740540804, 'n_units_l1': 211, 'dropout_l1': 0.14181188889115479, 'n_units_l2': 246, 'dropout_l2': 0.23746575468393433, 'n_units_l3': 214, 'dropout_l3': 0.3739247658794925, 'n_units_l4': 302, 'dropout_l4': 0.30370482166483814, 'learning_rate': 0.0016718279230774696}. Best is trial 3 with value: 0.21004439464697353.\n","[I 2025-10-12 15:19:06,150] Trial 10 pruned. \n","[I 2025-10-12 15:19:07,498] Trial 11 pruned. \n","[I 2025-10-12 15:19:26,921] Trial 12 finished with value: 0.20806603615362862 and parameters: {'n_layers': 4, 'n_units_l0': 150, 'dropout_l0': 0.3128970113477985, 'n_units_l1': 416, 'dropout_l1': 0.3173908687903926, 'n_units_l2': 32, 'dropout_l2': 0.3327665928243745, 'n_units_l3': 74, 'dropout_l3': 0.15825518470700803, 'learning_rate': 0.0005324681846478901}. Best is trial 3 with value: 0.21004439464697353.\n","[I 2025-10-12 15:19:28,432] Trial 13 pruned. \n"]},{"output_type":"stream","name":"stdout","text":["\n","[Optuna 조기 종료] 10번의 trial 동안 최고 점수가 갱신되지 않아 튜닝을 중단합니다.\n","\n","✅ 튜닝 완료!\n","\n","==================================================\n","🔬 최적 하이퍼파라미터\n","==================================================\n","            n_layers: 1\n","          n_units_l0: 140\n","          dropout_l0: 0.3386993188683119\n","       learning_rate: 8.622367446973934e-05\n","==================================================\n","\n","🔬 Step 3: 튜닝된 최종 PyTorch 모델 학습 및 평가...\n"]},{"output_type":"display_data","data":{"text/plain":["최종 모델 학습:   0%|          | 0/50 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9e64ef66aca8403e9ed78df5ca98806b"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["✅ 튜닝된 PyTorch 모델 평가 완료.\n","                      PR AUC  ROC AUC  F1-Score\n","Optuna_Tuned_PyTorch   0.223   0.7879    0.0887\n","\n","============================================================\n","💾 Step 4: 최종 모델 예측 결과를 원본 CSV에 추가하여 저장\n","============================================================\n"]},{"output_type":"display_data","data":{"text/plain":["전체 데이터 예측:   0%|          | 0/238 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5188b88f7a34423aa4caa47522709274"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["✅ 모든 데이터의 예측 결과가 '/content/drive/MyDrive/review_helpfulness/PADA/results/s2/coursera/MLP/MLP_coursera_with_BERT_predictions.csv' 파일에 성공적으로 저장되었습니다.\n","\n","============================================================\n","🧹 Step 5: 메모리 정리\n","============================================================\n","✅ 메모리 정리가 완료되었습니다.\n","\n","🎉 모든 과정이 완료되었습니다!\n"]}]},{"cell_type":"markdown","source":["## SentenceBERT"],"metadata":{"id":"bMDELprD5CSc"}},{"cell_type":"code","source":["# === 2. 환경설정 클래스 ===\n","class Config:\n","    \"\"\"실행에 필요한 모든 설정값을 중앙에서 관리합니다.\"\"\"\n","    # 🌟 1. 파일 경로 설정\n","    CSV_FILE_PATH = \"/content/drive/MyDrive/review_helpfulness/PADA/data/coursera/coursera.csv\"\n","    EMBEDDING_PATH = \"/content/drive/MyDrive/review_helpfulness/PADA/embedding/coursera_SentenceBERT.npy\"\n","\n","    # 🌟 2. 최종 결과 CSV 파일 저장 경로 설정\n","    OUTPUT_CSV_PATH = \"/content/drive/MyDrive/review_helpfulness/PADA/results/s2/coursera/MLP/MLP_coursera_with_SentenceBERT_predictions.csv\"\n","\n","    # --- 데이터 정보 ---\n","    TARGET_COLUMN = 'binary_helpfulness'\n","\n","    # --- 데이터 분할 ---\n","    TEST_SPLIT_RATIO = 0.2\n","    RANDOM_STATE = 42\n","\n","    # --- PyTorch 모델 및 학습 설정 ---\n","    EPOCHS = 50\n","    BATCH_SIZE = 256\n","    VALIDATION_EARLY_STOPPING_PATIENCE = 5 # 개별 Trial 내 검증 성능 기반 조기 종료\n","\n","    # --- Optuna 튜닝 설정 ---\n","    N_TRIALS = 50\n","    TUNING_METRIC = 'pr_auc'\n","    STUDY_EARLY_STOPPING_ROUNDS = 10 # 전체 Study 조기 종료\n","\n","# === 3. MLP 모델 클래스 (PyTorch) ===\n","class MLP(nn.Module):\n","    def __init__(self, input_dim, trial):\n","        super(MLP, self).__init__()\n","        layers = []\n","\n","        # ✅ 은닉층 탐색 범위를 1~5개로 확장\n","        n_layers = trial.suggest_int('n_layers', 1, 5)\n","\n","        in_features = input_dim\n","        for i in range(n_layers):\n","            out_features = trial.suggest_int(f'n_units_l{i}', 32, 512, log=True)\n","            layers.append(nn.Linear(in_features, out_features))\n","            layers.append(nn.ReLU())\n","            p = trial.suggest_float(f'dropout_l{i}', 0.1, 0.5)\n","            layers.append(nn.Dropout(p))\n","            in_features = out_features\n","\n","        layers.append(nn.Linear(in_features, 1))\n","        self.layers = nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        return torch.sigmoid(self.layers(x).squeeze(-1))\n","\n","# === 4. 학습 및 평가 함수 ===\n","def train_model(model, loader, optimizer, criterion):\n","    model.train()\n","    for inputs, labels in loader:\n","        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n","        optimizer.zero_grad()\n","        outputs = model(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","def evaluate_model(model, loader):\n","    model.eval()\n","    all_preds = []\n","    all_labels = []\n","    with torch.no_grad():\n","        for inputs, labels in loader:\n","            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n","            outputs = model(inputs)\n","            all_preds.extend(outputs.cpu().numpy())\n","            all_labels.extend(labels.cpu().numpy())\n","    return np.array(all_preds), np.array(all_labels)\n","\n","# === 5. Optuna Objective 함수 (PyTorch용) ===\n","def objective(trial, X, y):\n","    X_train, X_val, y_train, y_val = train_test_split(\n","        X, y, test_size=0.25, random_state=Config.RANDOM_STATE, stratify=y)\n","\n","    train_dataset = TensorDataset(torch.FloatTensor(X_train), torch.FloatTensor(y_train))\n","    val_dataset = TensorDataset(torch.FloatTensor(X_val), torch.FloatTensor(y_val))\n","    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)\n","    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE)\n","\n","    input_dim = X_train.shape[1]\n","    model = MLP(input_dim, trial).to(DEVICE)\n","    lr = trial.suggest_float('learning_rate', 1e-5, 1e-2, log=True)\n","    optimizer = optim.Adam(model.parameters(), lr=lr)\n","    criterion = nn.BCELoss()\n","\n","    best_score = -1\n","    patience_counter = 0\n","\n","    for epoch in range(Config.EPOCHS):\n","        train_model(model, train_loader, optimizer, criterion)\n","        y_pred_proba, y_true = evaluate_model(model, val_loader)\n","        score = average_precision_score(y_true, y_pred_proba)\n","\n","        trial.report(score, epoch)\n","        if trial.should_prune():\n","            raise optuna.exceptions.TrialPruned()\n","\n","        if score > best_score:\n","            best_score = score\n","            patience_counter = 0\n","        else:\n","            patience_counter += 1\n","\n","        if patience_counter >= Config.VALIDATION_EARLY_STOPPING_PATIENCE:\n","            break\n","\n","    return best_score\n","\n","# === 6. Optuna 조기 종료 콜백 ===\n","class EarlyStoppingCallback:\n","    def __init__(self, early_stopping_rounds: int):\n","        self._early_stopping_rounds = early_stopping_rounds\n","        self._best_value = -float(\"inf\")\n","        self._counter = 0\n","\n","    def __call__(self, study: optuna.study.Study, trial: optuna.trial.Trial):\n","        current_best_value = study.best_value\n","        if current_best_value is not None and current_best_value > self._best_value:\n","            self._best_value = current_best_value\n","            self._counter = 0\n","        else:\n","            self._counter += 1\n","\n","        if self._counter >= self._early_stopping_rounds:\n","            print(f\"\\n[Optuna 조기 종료] {self._early_stopping_rounds}번의 trial 동안 최고 점수가 갱신되지 않아 튜닝을 중단합니다.\")\n","            study.stop()\n","\n","\n","# === 7. 메인 실행 블록 ===\n","if __name__ == '__main__':\n","    config = Config()\n","\n","    # --- Step 1: 데이터 로드 및 분할 ---\n","    print(\"\\n\" + \"=\"*50)\n","    print(\"📊 Step 1: 데이터 로드 및 분할\")\n","    try:\n","        df = pd.read_csv(config.CSV_FILE_PATH)\n","        labels = df[config.TARGET_COLUMN].values\n","        embeddings = np.load(config.EMBEDDING_PATH)\n","    except Exception as e:\n","        print(f\"🔥 파일 로드 실패: {e}\"); exit()\n","\n","    indices = np.arange(len(df))\n","    train_indices, test_indices = train_test_split(\n","        indices, test_size=config.TEST_SPLIT_RATIO, random_state=config.RANDOM_STATE, stratify=labels)\n","    X_train, X_test = embeddings[train_indices], embeddings[test_indices]\n","    y_train, y_test = labels[train_indices], labels[test_indices]\n","    print(f\"✅ 완료 (학습용: {len(y_train)}건, 테스트용: {len(y_test)}건)\")\n","\n","    # --- Step 2: Optuna 튜닝 수행 ---\n","    print(\"\\n\" + \"=\"*50)\n","    print(f\"🔬 Step 2: Optuna 하이퍼파라미터 튜닝 시작 (PyTorch)\")\n","    print(f\"(최대 {config.N_TRIALS}번 시도, {config.STUDY_EARLY_STOPPING_ROUNDS}번 개선 없으면 스터디 조기 종료)\")\n","    print(\"=\"*50)\n","\n","    study = optuna.create_study(direction='maximize', pruner=optuna.pruners.MedianPruner())\n","    pbar = tqdm(total=config.N_TRIALS, desc=\"Optuna 튜닝 진행률\")\n","\n","    try:\n","        study.optimize(lambda trial: objective(trial, X_train, y_train),\n","                       n_trials=config.N_TRIALS,\n","                       callbacks=[lambda s, t: pbar.update(1), EarlyStoppingCallback(config.STUDY_EARLY_STOPPING_ROUNDS)])\n","    except optuna.exceptions.OptunaError:\n","        pass # 조기 종료 시 예외 처리\n","    pbar.close()\n","\n","    # --- Step 3: 최적 모델 학습 및 평가 ---\n","    print(f\"\\n✅ 튜닝 완료!\")\n","    print(\"\\n\" + \"=\"*50)\n","    print(\"🔬 최적 하이퍼파라미터\")\n","    print(\"=\"*50)\n","    best_params = study.best_params\n","    for key, value in best_params.items():\n","        print(f\"{key:>20s}: {value}\")\n","    print(\"=\"*50)\n","\n","    print(f\"\\n🔬 Step 3: 튜닝된 최종 PyTorch 모델 학습 및 평가...\")\n","    train_dataset = TensorDataset(torch.FloatTensor(X_train), torch.FloatTensor(y_train))\n","    train_loader = DataLoader(train_dataset, batch_size=config.BATCH_SIZE, shuffle=True)\n","    test_dataset = TensorDataset(torch.FloatTensor(X_test), torch.FloatTensor(y_test))\n","    test_loader = DataLoader(test_dataset, batch_size=config.BATCH_SIZE)\n","\n","    # Optuna study 객체를 모의 trial로 사용하여 최종 모델 생성\n","    final_model = MLP(X_train.shape[1], study.best_trial).to(DEVICE)\n","    optimizer = optim.Adam(final_model.parameters(), lr=best_params['learning_rate'])\n","    criterion = nn.BCELoss()\n","\n","    # 최종 모델은 전체 학습 데이터로 학습\n","    for epoch in tqdm(range(config.EPOCHS), desc=\"최종 모델 학습\"):\n","        train_model(final_model, train_loader, optimizer, criterion)\n","\n","    y_pred_proba_tuned, y_true_test = evaluate_model(final_model, test_loader)\n","    y_pred_class_tuned = (y_pred_proba_tuned > 0.5).astype(int)\n","\n","    results = {\n","        \"PR AUC\": average_precision_score(y_true_test, y_pred_proba_tuned),\n","        \"ROC AUC\": roc_auc_score(y_true_test, y_pred_proba_tuned),\n","        \"F1-Score\": f1_score(y_true_test, y_pred_class_tuned),\n","    }\n","    print(\"✅ 튜닝된 PyTorch 모델 평가 완료.\")\n","    print(pd.DataFrame(results, index=['Optuna_Tuned_PyTorch']).round(4))\n","\n","    # --- Step 4: 결과 저장 ---\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"💾 Step 4: 최종 모델 예측 결과를 원본 CSV에 추가하여 저장\")\n","    print(\"=\"*60)\n","\n","    all_dataset = TensorDataset(torch.FloatTensor(embeddings))\n","    all_loader = DataLoader(all_dataset, batch_size=config.BATCH_SIZE * 2) # 예측 시에는 더 큰 배치 사용 가능\n","\n","    final_model.eval()\n","    all_predictions = []\n","    with torch.no_grad():\n","        for (inputs,) in tqdm(all_loader, desc=\"전체 데이터 예측\"):\n","            inputs = inputs.to(DEVICE)\n","            outputs = final_model(inputs)\n","            all_predictions.extend(outputs.cpu().numpy())\n","\n","    df['s2_pred_proba'] = all_predictions\n","    df['s2_pred_class'] = (df['s2_pred_proba'] > 0.5).astype(int)\n","\n","    df.to_csv(config.OUTPUT_CSV_PATH, index=False, encoding='utf-8-sig')\n","    print(f\"✅ 모든 데이터의 예측 결과가 '{config.OUTPUT_CSV_PATH}' 파일에 성공적으로 저장되었습니다.\")\n","\n","    # --- Step 5: 메모리 정리 ---\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"🧹 Step 5: 메모리 정리\")\n","    print(\"=\"*60)\n","    del df, labels, embeddings, X_train, X_test, y_train, y_test, final_model, study\n","    gc.collect()\n","    if torch.cuda.is_available():\n","        torch.cuda.empty_cache()\n","    print(\"✅ 메모리 정리가 완료되었습니다.\")\n","\n","    print(\"\\n🎉 모든 과정이 완료되었습니다!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["190da761e04a4d94b6e3554ad1163cb0","2a5a9bc45ea64997bb903f28b4b7099d","a7b084ee04c346619bfa74794fcb221c","d166f4970ad54ab08914b0752cd05f25","12a5a39931274e7abf22b936dc49fdcb","d60a4f9d626043878224d070dc73087f","361ab5ef912f45cab1790ffda63a10c3","ecf1dab11bc64b02bdb1b6e04530e7a2","135fe3ef32294d1eba6f5578a4b79d83","fdb19ba1828e4eef84bf3500a5e04861","d49bbe440ddf4cc0a572aa58c33622c1","974720afba3a4532b09ca62d055a48b4","8d5b575f085a4b59a09f5405aeb75ba1","341398a352c44c42b193a32fcbb6b695","edfd4091e74840eba2243c3df9c01cfb","dd8054522fac49539d428ef7ff5a1703","b9185f17be2743da986bfcb278f25657","5e2fd1ff554c4063927636bc8bfc9aae","7c4ea73bad194f9aadadc72276fac32b","717529ef30de48de812245be4e132db4","94a9c8b047294b64ad6a8fa6a733b94b","e81150046fcc482f83193f20b802f664","b4b28c7155d24ff0bdb61f1f7c88b83d","292b47096d214cb9900aeb0972f307dc","698867de19ae4fc0bf79f8e3ed224c39","38401865c4574952ab95889a26f34d08","0a85f88400e14579b5f4290d7c60fc44","bc33892c2921439d982862e69e4502c7","f13596e6f4114bb4a9fbec83466d5ac0","25cfd3885e9b424aa1c41edad1d015de","d314e72013624fceb89ba672fca68624","a28caba13fd841fabc9d31d8b55af64e","73c82e55dac8430b857366b3711f54d7"]},"id":"6fo1HHzZ7DKR","executionInfo":{"status":"ok","timestamp":1760282821509,"user_tz":-540,"elapsed":381975,"user":{"displayName":"KW-data-analytics","userId":"09651493752354345908"}},"outputId":"ab0b4ec8-a0be-4821-f8fa-30845e22bd7a"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================================================\n","📊 Step 1: 데이터 로드 및 분할\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-10-12 15:20:46,065] A new study created in memory with name: no-name-e41359b1-5274-47af-a9ed-d204c5c4f1af\n"]},{"output_type":"stream","name":"stdout","text":["✅ 완료 (학습용: 97108건, 테스트용: 24278건)\n","\n","==================================================\n","🔬 Step 2: Optuna 하이퍼파라미터 튜닝 시작 (PyTorch)\n","(최대 50번 시도, 10번 개선 없으면 스터디 조기 종료)\n","==================================================\n"]},{"output_type":"display_data","data":{"text/plain":["Optuna 튜닝 진행률:   0%|          | 0/50 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"190da761e04a4d94b6e3554ad1163cb0"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2025-10-12 15:22:01,006] Trial 0 finished with value: 0.18267204495701522 and parameters: {'n_layers': 4, 'n_units_l0': 512, 'dropout_l0': 0.1377973729229478, 'n_units_l1': 114, 'dropout_l1': 0.1529118149701358, 'n_units_l2': 50, 'dropout_l2': 0.31009664530941905, 'n_units_l3': 134, 'dropout_l3': 0.12083983890278925, 'learning_rate': 1.1699308115936522e-05}. Best is trial 0 with value: 0.18267204495701522.\n","[I 2025-10-12 15:22:13,261] Trial 1 finished with value: 0.19170557484759362 and parameters: {'n_layers': 2, 'n_units_l0': 39, 'dropout_l0': 0.21543783989588491, 'n_units_l1': 56, 'dropout_l1': 0.43765742076895686, 'learning_rate': 0.0031399831590192503}. Best is trial 1 with value: 0.19170557484759362.\n","[I 2025-10-12 15:22:28,652] Trial 2 finished with value: 0.18973976049919655 and parameters: {'n_layers': 1, 'n_units_l0': 132, 'dropout_l0': 0.4874060650939248, 'learning_rate': 0.0036575664418538505}. Best is trial 1 with value: 0.19170557484759362.\n","[I 2025-10-12 15:23:20,468] Trial 3 finished with value: 0.186666819374827 and parameters: {'n_layers': 5, 'n_units_l0': 70, 'dropout_l0': 0.11286169321493103, 'n_units_l1': 139, 'dropout_l1': 0.2697153189256972, 'n_units_l2': 67, 'dropout_l2': 0.3640040484722963, 'n_units_l3': 505, 'dropout_l3': 0.4005561226583143, 'n_units_l4': 40, 'dropout_l4': 0.48720089425122814, 'learning_rate': 5.5743897506380763e-05}. Best is trial 1 with value: 0.19170557484759362.\n","[I 2025-10-12 15:24:34,889] Trial 4 finished with value: 0.18172628163130117 and parameters: {'n_layers': 4, 'n_units_l0': 463, 'dropout_l0': 0.12492181400055098, 'n_units_l1': 293, 'dropout_l1': 0.49648133472831635, 'n_units_l2': 38, 'dropout_l2': 0.36228937359249225, 'n_units_l3': 102, 'dropout_l3': 0.25123964323622683, 'learning_rate': 1.0924425503048017e-05}. Best is trial 1 with value: 0.19170557484759362.\n","[I 2025-10-12 15:24:51,684] Trial 5 finished with value: 0.18633691343403375 and parameters: {'n_layers': 4, 'n_units_l0': 37, 'dropout_l0': 0.35422331593274614, 'n_units_l1': 174, 'dropout_l1': 0.20112985361518004, 'n_units_l2': 34, 'dropout_l2': 0.4258566463323349, 'n_units_l3': 150, 'dropout_l3': 0.18460176930738506, 'learning_rate': 0.0008720568334095592}. Best is trial 1 with value: 0.19170557484759362.\n","[I 2025-10-12 15:25:00,666] Trial 6 finished with value: 0.18819325262755657 and parameters: {'n_layers': 1, 'n_units_l0': 114, 'dropout_l0': 0.20578240209123316, 'learning_rate': 0.006525033922755547}. Best is trial 1 with value: 0.19170557484759362.\n","[I 2025-10-12 15:25:13,820] Trial 7 finished with value: 0.186076706631914 and parameters: {'n_layers': 3, 'n_units_l0': 61, 'dropout_l0': 0.12413002110885155, 'n_units_l1': 427, 'dropout_l1': 0.34338211210715697, 'n_units_l2': 44, 'dropout_l2': 0.25843487294403167, 'learning_rate': 0.0044981214247416254}. Best is trial 1 with value: 0.19170557484759362.\n","[I 2025-10-12 15:25:25,432] Trial 8 finished with value: 0.19077434701085835 and parameters: {'n_layers': 3, 'n_units_l0': 437, 'dropout_l0': 0.10443256809848506, 'n_units_l1': 35, 'dropout_l1': 0.3767364913051091, 'n_units_l2': 489, 'dropout_l2': 0.37018455561272934, 'learning_rate': 0.001716537988449603}. Best is trial 1 with value: 0.19170557484759362.\n","[I 2025-10-12 15:25:26,909] Trial 9 pruned. \n","[I 2025-10-12 15:25:28,493] Trial 10 pruned. \n","[I 2025-10-12 15:25:43,414] Trial 11 finished with value: 0.1911796286495261 and parameters: {'n_layers': 2, 'n_units_l0': 277, 'dropout_l0': 0.20814762401514325, 'n_units_l1': 35, 'dropout_l1': 0.3862788393507653, 'learning_rate': 0.0016218119986245727}. Best is trial 1 with value: 0.19170557484759362.\n"]},{"output_type":"stream","name":"stdout","text":["\n","[Optuna 조기 종료] 10번의 trial 동안 최고 점수가 갱신되지 않아 튜닝을 중단합니다.\n","\n","✅ 튜닝 완료!\n","\n","==================================================\n","🔬 최적 하이퍼파라미터\n","==================================================\n","            n_layers: 2\n","          n_units_l0: 39\n","          dropout_l0: 0.21543783989588491\n","          n_units_l1: 56\n","          dropout_l1: 0.43765742076895686\n","       learning_rate: 0.0031399831590192503\n","==================================================\n","\n","🔬 Step 3: 튜닝된 최종 PyTorch 모델 학습 및 평가...\n"]},{"output_type":"display_data","data":{"text/plain":["최종 모델 학습:   0%|          | 0/50 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"974720afba3a4532b09ca62d055a48b4"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["✅ 튜닝된 PyTorch 모델 평가 완료.\n","                      PR AUC  ROC AUC  F1-Score\n","Optuna_Tuned_PyTorch  0.1561   0.6913    0.1385\n","\n","============================================================\n","💾 Step 4: 최종 모델 예측 결과를 원본 CSV에 추가하여 저장\n","============================================================\n"]},{"output_type":"display_data","data":{"text/plain":["전체 데이터 예측:   0%|          | 0/238 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b4b28c7155d24ff0bdb61f1f7c88b83d"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["✅ 모든 데이터의 예측 결과가 '/content/drive/MyDrive/review_helpfulness/PADA/results/s2/coursera/MLP/MLP_coursera_with_SentenceBERT_predictions.csv' 파일에 성공적으로 저장되었습니다.\n","\n","============================================================\n","🧹 Step 5: 메모리 정리\n","============================================================\n","✅ 메모리 정리가 완료되었습니다.\n","\n","🎉 모든 과정이 완료되었습니다!\n"]}]},{"cell_type":"markdown","source":["## RoBERTa"],"metadata":{"id":"bi4o3-ti5DFI"}},{"cell_type":"code","source":["# === 2. 환경설정 클래스 ===\n","class Config:\n","    \"\"\"실행에 필요한 모든 설정값을 중앙에서 관리합니다.\"\"\"\n","    # 🌟 1. 파일 경로 설정\n","    CSV_FILE_PATH = \"/content/drive/MyDrive/review_helpfulness/PADA/data/coursera/coursera.csv\"\n","    EMBEDDING_PATH = \"/content/drive/MyDrive/review_helpfulness/PADA/embedding/coursera_RoBERTa.npy\"\n","\n","    # 🌟 2. 최종 결과 CSV 파일 저장 경로 설정\n","    OUTPUT_CSV_PATH = \"/content/drive/MyDrive/review_helpfulness/PADA/results/s2/coursera/MLP/MLP_coursera_with_RoBERTa_predictions.csv\"\n","\n","    # --- 데이터 정보 ---\n","    TARGET_COLUMN = 'binary_helpfulness'\n","\n","    # --- 데이터 분할 ---\n","    TEST_SPLIT_RATIO = 0.2\n","    RANDOM_STATE = 42\n","\n","    # --- PyTorch 모델 및 학습 설정 ---\n","    EPOCHS = 50\n","    BATCH_SIZE = 256\n","    VALIDATION_EARLY_STOPPING_PATIENCE = 5 # 개별 Trial 내 검증 성능 기반 조기 종료\n","\n","    # --- Optuna 튜닝 설정 ---\n","    N_TRIALS = 50\n","    TUNING_METRIC = 'pr_auc'\n","    STUDY_EARLY_STOPPING_ROUNDS = 10 # 전체 Study 조기 종료\n","\n","# === 3. MLP 모델 클래스 (PyTorch) ===\n","class MLP(nn.Module):\n","    def __init__(self, input_dim, trial):\n","        super(MLP, self).__init__()\n","        layers = []\n","\n","        # ✅ 은닉층 탐색 범위를 1~5개로 확장\n","        n_layers = trial.suggest_int('n_layers', 1, 5)\n","\n","        in_features = input_dim\n","        for i in range(n_layers):\n","            out_features = trial.suggest_int(f'n_units_l{i}', 32, 512, log=True)\n","            layers.append(nn.Linear(in_features, out_features))\n","            layers.append(nn.ReLU())\n","            p = trial.suggest_float(f'dropout_l{i}', 0.1, 0.5)\n","            layers.append(nn.Dropout(p))\n","            in_features = out_features\n","\n","        layers.append(nn.Linear(in_features, 1))\n","        self.layers = nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        return torch.sigmoid(self.layers(x).squeeze(-1))\n","\n","# === 4. 학습 및 평가 함수 ===\n","def train_model(model, loader, optimizer, criterion):\n","    model.train()\n","    for inputs, labels in loader:\n","        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n","        optimizer.zero_grad()\n","        outputs = model(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","def evaluate_model(model, loader):\n","    model.eval()\n","    all_preds = []\n","    all_labels = []\n","    with torch.no_grad():\n","        for inputs, labels in loader:\n","            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n","            outputs = model(inputs)\n","            all_preds.extend(outputs.cpu().numpy())\n","            all_labels.extend(labels.cpu().numpy())\n","    return np.array(all_preds), np.array(all_labels)\n","\n","# === 5. Optuna Objective 함수 (PyTorch용) ===\n","def objective(trial, X, y):\n","    X_train, X_val, y_train, y_val = train_test_split(\n","        X, y, test_size=0.25, random_state=Config.RANDOM_STATE, stratify=y)\n","\n","    train_dataset = TensorDataset(torch.FloatTensor(X_train), torch.FloatTensor(y_train))\n","    val_dataset = TensorDataset(torch.FloatTensor(X_val), torch.FloatTensor(y_val))\n","    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)\n","    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE)\n","\n","    input_dim = X_train.shape[1]\n","    model = MLP(input_dim, trial).to(DEVICE)\n","    lr = trial.suggest_float('learning_rate', 1e-5, 1e-2, log=True)\n","    optimizer = optim.Adam(model.parameters(), lr=lr)\n","    criterion = nn.BCELoss()\n","\n","    best_score = -1\n","    patience_counter = 0\n","\n","    for epoch in range(Config.EPOCHS):\n","        train_model(model, train_loader, optimizer, criterion)\n","        y_pred_proba, y_true = evaluate_model(model, val_loader)\n","        score = average_precision_score(y_true, y_pred_proba)\n","\n","        trial.report(score, epoch)\n","        if trial.should_prune():\n","            raise optuna.exceptions.TrialPruned()\n","\n","        if score > best_score:\n","            best_score = score\n","            patience_counter = 0\n","        else:\n","            patience_counter += 1\n","\n","        if patience_counter >= Config.VALIDATION_EARLY_STOPPING_PATIENCE:\n","            break\n","\n","    return best_score\n","\n","# === 6. Optuna 조기 종료 콜백 ===\n","class EarlyStoppingCallback:\n","    def __init__(self, early_stopping_rounds: int):\n","        self._early_stopping_rounds = early_stopping_rounds\n","        self._best_value = -float(\"inf\")\n","        self._counter = 0\n","\n","    def __call__(self, study: optuna.study.Study, trial: optuna.trial.Trial):\n","        current_best_value = study.best_value\n","        if current_best_value is not None and current_best_value > self._best_value:\n","            self._best_value = current_best_value\n","            self._counter = 0\n","        else:\n","            self._counter += 1\n","\n","        if self._counter >= self._early_stopping_rounds:\n","            print(f\"\\n[Optuna 조기 종료] {self._early_stopping_rounds}번의 trial 동안 최고 점수가 갱신되지 않아 튜닝을 중단합니다.\")\n","            study.stop()\n","\n","\n","# === 7. 메인 실행 블록 ===\n","if __name__ == '__main__':\n","    config = Config()\n","\n","    # --- Step 1: 데이터 로드 및 분할 ---\n","    print(\"\\n\" + \"=\"*50)\n","    print(\"📊 Step 1: 데이터 로드 및 분할\")\n","    try:\n","        df = pd.read_csv(config.CSV_FILE_PATH)\n","        labels = df[config.TARGET_COLUMN].values\n","        embeddings = np.load(config.EMBEDDING_PATH)\n","    except Exception as e:\n","        print(f\"🔥 파일 로드 실패: {e}\"); exit()\n","\n","    indices = np.arange(len(df))\n","    train_indices, test_indices = train_test_split(\n","        indices, test_size=config.TEST_SPLIT_RATIO, random_state=config.RANDOM_STATE, stratify=labels)\n","    X_train, X_test = embeddings[train_indices], embeddings[test_indices]\n","    y_train, y_test = labels[train_indices], labels[test_indices]\n","    print(f\"✅ 완료 (학습용: {len(y_train)}건, 테스트용: {len(y_test)}건)\")\n","\n","    # --- Step 2: Optuna 튜닝 수행 ---\n","    print(\"\\n\" + \"=\"*50)\n","    print(f\"🔬 Step 2: Optuna 하이퍼파라미터 튜닝 시작 (PyTorch)\")\n","    print(f\"(최대 {config.N_TRIALS}번 시도, {config.STUDY_EARLY_STOPPING_ROUNDS}번 개선 없으면 스터디 조기 종료)\")\n","    print(\"=\"*50)\n","\n","    study = optuna.create_study(direction='maximize', pruner=optuna.pruners.MedianPruner())\n","    pbar = tqdm(total=config.N_TRIALS, desc=\"Optuna 튜닝 진행률\")\n","\n","    try:\n","        study.optimize(lambda trial: objective(trial, X_train, y_train),\n","                       n_trials=config.N_TRIALS,\n","                       callbacks=[lambda s, t: pbar.update(1), EarlyStoppingCallback(config.STUDY_EARLY_STOPPING_ROUNDS)])\n","    except optuna.exceptions.OptunaError:\n","        pass # 조기 종료 시 예외 처리\n","    pbar.close()\n","\n","    # --- Step 3: 최적 모델 학습 및 평가 ---\n","    print(f\"\\n✅ 튜닝 완료!\")\n","    print(\"\\n\" + \"=\"*50)\n","    print(\"🔬 최적 하이퍼파라미터\")\n","    print(\"=\"*50)\n","    best_params = study.best_params\n","    for key, value in best_params.items():\n","        print(f\"{key:>20s}: {value}\")\n","    print(\"=\"*50)\n","\n","    print(f\"\\n🔬 Step 3: 튜닝된 최종 PyTorch 모델 학습 및 평가...\")\n","    train_dataset = TensorDataset(torch.FloatTensor(X_train), torch.FloatTensor(y_train))\n","    train_loader = DataLoader(train_dataset, batch_size=config.BATCH_SIZE, shuffle=True)\n","    test_dataset = TensorDataset(torch.FloatTensor(X_test), torch.FloatTensor(y_test))\n","    test_loader = DataLoader(test_dataset, batch_size=config.BATCH_SIZE)\n","\n","    # Optuna study 객체를 모의 trial로 사용하여 최종 모델 생성\n","    final_model = MLP(X_train.shape[1], study.best_trial).to(DEVICE)\n","    optimizer = optim.Adam(final_model.parameters(), lr=best_params['learning_rate'])\n","    criterion = nn.BCELoss()\n","\n","    # 최종 모델은 전체 학습 데이터로 학습\n","    for epoch in tqdm(range(config.EPOCHS), desc=\"최종 모델 학습\"):\n","        train_model(final_model, train_loader, optimizer, criterion)\n","\n","    y_pred_proba_tuned, y_true_test = evaluate_model(final_model, test_loader)\n","    y_pred_class_tuned = (y_pred_proba_tuned > 0.5).astype(int)\n","\n","    results = {\n","        \"PR AUC\": average_precision_score(y_true_test, y_pred_proba_tuned),\n","        \"ROC AUC\": roc_auc_score(y_true_test, y_pred_proba_tuned),\n","        \"F1-Score\": f1_score(y_true_test, y_pred_class_tuned),\n","    }\n","    print(\"✅ 튜닝된 PyTorch 모델 평가 완료.\")\n","    print(pd.DataFrame(results, index=['Optuna_Tuned_PyTorch']).round(4))\n","\n","    # --- Step 4: 결과 저장 ---\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"💾 Step 4: 최종 모델 예측 결과를 원본 CSV에 추가하여 저장\")\n","    print(\"=\"*60)\n","\n","    all_dataset = TensorDataset(torch.FloatTensor(embeddings))\n","    all_loader = DataLoader(all_dataset, batch_size=config.BATCH_SIZE * 2) # 예측 시에는 더 큰 배치 사용 가능\n","\n","    final_model.eval()\n","    all_predictions = []\n","    with torch.no_grad():\n","        for (inputs,) in tqdm(all_loader, desc=\"전체 데이터 예측\"):\n","            inputs = inputs.to(DEVICE)\n","            outputs = final_model(inputs)\n","            all_predictions.extend(outputs.cpu().numpy())\n","\n","    df['s2_pred_proba'] = all_predictions\n","    df['s2_pred_class'] = (df['s2_pred_proba'] > 0.5).astype(int)\n","\n","    df.to_csv(config.OUTPUT_CSV_PATH, index=False, encoding='utf-8-sig')\n","    print(f\"✅ 모든 데이터의 예측 결과가 '{config.OUTPUT_CSV_PATH}' 파일에 성공적으로 저장되었습니다.\")\n","\n","    # --- Step 5: 메모리 정리 ---\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"🧹 Step 5: 메모리 정리\")\n","    print(\"=\"*60)\n","    del df, labels, embeddings, X_train, X_test, y_train, y_test, final_model, study\n","    gc.collect()\n","    if torch.cuda.is_available():\n","        torch.cuda.empty_cache()\n","    print(\"✅ 메모리 정리가 완료되었습니다.\")\n","\n","    print(\"\\n🎉 모든 과정이 완료되었습니다!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["bfc028cfc4934baf995f6fbd62d0c524","b128b8ac604b40b5b80bb00429dfcf82","828ab1b8b00842cdb21c4e068ad2f5a8","1001688d615d461baab7a535fe5a0e78","cdbae2fbffab47de98e18055ec0868e2","374b5ddea22b4cd59eff1ec405e910d7","3fe6e6d9249143549fae6ab11bcb2664","8c0adb0b6af940b7bd10eb94801c9bcb","6df356e2a9ed46f2bb2c578e5225dc58","613d1427ffbd4ae1aad946e9b8dc55ec","05ff0a15c05344378d0340cd87083282","48b366246c8d4045af5c41656cb9525e","9d079cbba619452a9051a31839425a07","7069e8344f2b4a9cac9f0d1b41380206","31219c9a14c748f1a57a93086fa32981","a9f2e1ee99e746adbedc2568e670f19e","0026ed64c48b4564bbd9305a3c2e3a5d","dadaffa6fef646c8adab7b2a80628a3e","4f20808b36cc429a80c27f2653a90fc0","ec022e9e3b2841768444bd0fde68e3ac","134a0a0426af45d98201401ec83eba99","813bd761aa9a44d4bdae9f6899b90e44","8d277fe0d95840d9991b6778d5adb15e","700c7ebb1b98436ea78f300df9e0524c","67f23164afab460a9f2d91e1b5bdcfbb","a4552f51c3b2433db08d51fd2bd4a2a2","dd42843070a14719a84301e3119adcc3","f21b9fa8f8af4fa89f26e1c7843d0ae2","ec6dec1b8db34285bc66404906bd28d0","97b9d26f13c84d239924d56ca656d86f","3fc6bf0271f34066a8e055ee7d218d06","338aeda6d86943c682da6184afe21ecc","ce667f57d2184a4da9d373fc1194ff4c"]},"id":"ZINzm8U17VER","executionInfo":{"status":"ok","timestamp":1760283255167,"user_tz":-540,"elapsed":433652,"user":{"displayName":"KW-data-analytics","userId":"09651493752354345908"}},"outputId":"fb3ed68b-0313-45b1-8409-e4b19dcc4725"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================================================\n","📊 Step 1: 데이터 로드 및 분할\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-10-12 15:27:07,173] A new study created in memory with name: no-name-40dd7485-5e04-4c4e-b919-66877a1b71e7\n"]},{"output_type":"stream","name":"stdout","text":["✅ 완료 (학습용: 97108건, 테스트용: 24278건)\n","\n","==================================================\n","🔬 Step 2: Optuna 하이퍼파라미터 튜닝 시작 (PyTorch)\n","(최대 50번 시도, 10번 개선 없으면 스터디 조기 종료)\n","==================================================\n"]},{"output_type":"display_data","data":{"text/plain":["Optuna 튜닝 진행률:   0%|          | 0/50 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bfc028cfc4934baf995f6fbd62d0c524"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2025-10-12 15:27:22,928] Trial 0 finished with value: 0.20152063545381013 and parameters: {'n_layers': 3, 'n_units_l0': 194, 'dropout_l0': 0.4807034430037874, 'n_units_l1': 140, 'dropout_l1': 0.34867125300516777, 'n_units_l2': 42, 'dropout_l2': 0.2682347826873447, 'learning_rate': 0.0010824089250375361}. Best is trial 0 with value: 0.20152063545381013.\n","[I 2025-10-12 15:28:09,960] Trial 1 finished with value: 0.21239474606165548 and parameters: {'n_layers': 5, 'n_units_l0': 149, 'dropout_l0': 0.4594702681749995, 'n_units_l1': 124, 'dropout_l1': 0.2543661780328996, 'n_units_l2': 59, 'dropout_l2': 0.18705462757355937, 'n_units_l3': 63, 'dropout_l3': 0.38430870990778554, 'n_units_l4': 235, 'dropout_l4': 0.4251338061038049, 'learning_rate': 0.000752448148146284}. Best is trial 1 with value: 0.21239474606165548.\n","[I 2025-10-12 15:29:12,389] Trial 2 finished with value: 0.21053398935116582 and parameters: {'n_layers': 1, 'n_units_l0': 347, 'dropout_l0': 0.48227153062790584, 'learning_rate': 0.00010212324365876193}. Best is trial 1 with value: 0.21239474606165548.\n","[I 2025-10-12 15:29:23,399] Trial 3 finished with value: 0.17106644332700874 and parameters: {'n_layers': 5, 'n_units_l0': 161, 'dropout_l0': 0.1280679382899298, 'n_units_l1': 115, 'dropout_l1': 0.3404102331622126, 'n_units_l2': 132, 'dropout_l2': 0.4448423347706044, 'n_units_l3': 113, 'dropout_l3': 0.3644266318044227, 'n_units_l4': 284, 'dropout_l4': 0.3707065564754627, 'learning_rate': 0.009375185017624552}. Best is trial 1 with value: 0.21239474606165548.\n","[I 2025-10-12 15:30:25,606] Trial 4 finished with value: 0.19523731158935298 and parameters: {'n_layers': 1, 'n_units_l0': 262, 'dropout_l0': 0.31364760988382956, 'learning_rate': 1.9609928105725118e-05}. Best is trial 1 with value: 0.21239474606165548.\n","[I 2025-10-12 15:31:02,717] Trial 5 finished with value: 0.2185808598936849 and parameters: {'n_layers': 4, 'n_units_l0': 133, 'dropout_l0': 0.4717165261437468, 'n_units_l1': 79, 'dropout_l1': 0.10205448275752255, 'n_units_l2': 97, 'dropout_l2': 0.40188795124183274, 'n_units_l3': 153, 'dropout_l3': 0.18391629125407027, 'learning_rate': 0.0001856344822916662}. Best is trial 5 with value: 0.2185808598936849.\n","[I 2025-10-12 15:31:11,262] Trial 6 pruned. \n","[I 2025-10-12 15:31:42,443] Trial 7 finished with value: 0.2175646241319585 and parameters: {'n_layers': 1, 'n_units_l0': 153, 'dropout_l0': 0.36738132544435353, 'learning_rate': 0.0022263351988573293}. Best is trial 5 with value: 0.2185808598936849.\n","[I 2025-10-12 15:31:43,779] Trial 8 pruned. \n","[I 2025-10-12 15:31:45,369] Trial 9 pruned. \n","[I 2025-10-12 15:32:16,822] Trial 10 finished with value: 0.21323131695169828 and parameters: {'n_layers': 4, 'n_units_l0': 84, 'dropout_l0': 0.22357367149808102, 'n_units_l1': 323, 'dropout_l1': 0.104515560596765, 'n_units_l2': 80, 'dropout_l2': 0.48370501862782633, 'n_units_l3': 343, 'dropout_l3': 0.12766765013224884, 'learning_rate': 0.00022646388446747687}. Best is trial 5 with value: 0.2185808598936849.\n","[I 2025-10-12 15:32:30,146] Trial 11 pruned. \n","[I 2025-10-12 15:32:43,686] Trial 12 pruned. \n","[I 2025-10-12 15:32:45,293] Trial 13 pruned. \n","[I 2025-10-12 15:32:46,727] Trial 14 pruned. \n","[I 2025-10-12 15:32:48,484] Trial 15 pruned. \n"]},{"output_type":"stream","name":"stdout","text":["\n","[Optuna 조기 종료] 10번의 trial 동안 최고 점수가 갱신되지 않아 튜닝을 중단합니다.\n","\n","✅ 튜닝 완료!\n","\n","==================================================\n","🔬 최적 하이퍼파라미터\n","==================================================\n","            n_layers: 4\n","          n_units_l0: 133\n","          dropout_l0: 0.4717165261437468\n","          n_units_l1: 79\n","          dropout_l1: 0.10205448275752255\n","          n_units_l2: 97\n","          dropout_l2: 0.40188795124183274\n","          n_units_l3: 153\n","          dropout_l3: 0.18391629125407027\n","       learning_rate: 0.0001856344822916662\n","==================================================\n","\n","🔬 Step 3: 튜닝된 최종 PyTorch 모델 학습 및 평가...\n"]},{"output_type":"display_data","data":{"text/plain":["최종 모델 학습:   0%|          | 0/50 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"48b366246c8d4045af5c41656cb9525e"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["✅ 튜닝된 PyTorch 모델 평가 완료.\n","                      PR AUC  ROC AUC  F1-Score\n","Optuna_Tuned_PyTorch   0.213   0.7646    0.1071\n","\n","============================================================\n","💾 Step 4: 최종 모델 예측 결과를 원본 CSV에 추가하여 저장\n","============================================================\n"]},{"output_type":"display_data","data":{"text/plain":["전체 데이터 예측:   0%|          | 0/238 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8d277fe0d95840d9991b6778d5adb15e"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["✅ 모든 데이터의 예측 결과가 '/content/drive/MyDrive/review_helpfulness/PADA/results/s2/coursera/MLP/MLP_coursera_with_RoBERTa_predictions.csv' 파일에 성공적으로 저장되었습니다.\n","\n","============================================================\n","🧹 Step 5: 메모리 정리\n","============================================================\n","✅ 메모리 정리가 완료되었습니다.\n","\n","🎉 모든 과정이 완료되었습니다!\n"]}]},{"cell_type":"markdown","source":["## DistilBERT"],"metadata":{"id":"LtzCyfq45ENt"}},{"cell_type":"code","source":["# === 2. 환경설정 클래스 ===\n","class Config:\n","    \"\"\"실행에 필요한 모든 설정값을 중앙에서 관리합니다.\"\"\"\n","    # 🌟 1. 파일 경로 설정\n","    CSV_FILE_PATH = \"/content/drive/MyDrive/review_helpfulness/PADA/data/coursera/coursera.csv\"\n","    EMBEDDING_PATH = \"/content/drive/MyDrive/review_helpfulness/PADA/embedding/coursera_DistilBERT.npy\"\n","\n","    # 🌟 2. 최종 결과 CSV 파일 저장 경로 설정\n","    OUTPUT_CSV_PATH = \"/content/drive/MyDrive/review_helpfulness/PADA/results/s2/coursera/MLP/MLP_coursera_with_DistilBERT_predictions.csv\"\n","\n","    # --- 데이터 정보 ---\n","    TARGET_COLUMN = 'binary_helpfulness'\n","\n","    # --- 데이터 분할 ---\n","    TEST_SPLIT_RATIO = 0.2\n","    RANDOM_STATE = 42\n","\n","    # --- PyTorch 모델 및 학습 설정 ---\n","    EPOCHS = 50\n","    BATCH_SIZE = 256\n","    VALIDATION_EARLY_STOPPING_PATIENCE = 5 # 개별 Trial 내 검증 성능 기반 조기 종료\n","\n","    # --- Optuna 튜닝 설정 ---\n","    N_TRIALS = 50\n","    TUNING_METRIC = 'pr_auc'\n","    STUDY_EARLY_STOPPING_ROUNDS = 10 # 전체 Study 조기 종료\n","\n","# === 3. MLP 모델 클래스 (PyTorch) ===\n","class MLP(nn.Module):\n","    def __init__(self, input_dim, trial):\n","        super(MLP, self).__init__()\n","        layers = []\n","\n","        # ✅ 은닉층 탐색 범위를 1~5개로 확장\n","        n_layers = trial.suggest_int('n_layers', 1, 5)\n","\n","        in_features = input_dim\n","        for i in range(n_layers):\n","            out_features = trial.suggest_int(f'n_units_l{i}', 32, 512, log=True)\n","            layers.append(nn.Linear(in_features, out_features))\n","            layers.append(nn.ReLU())\n","            p = trial.suggest_float(f'dropout_l{i}', 0.1, 0.5)\n","            layers.append(nn.Dropout(p))\n","            in_features = out_features\n","\n","        layers.append(nn.Linear(in_features, 1))\n","        self.layers = nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        return torch.sigmoid(self.layers(x).squeeze(-1))\n","\n","# === 4. 학습 및 평가 함수 ===\n","def train_model(model, loader, optimizer, criterion):\n","    model.train()\n","    for inputs, labels in loader:\n","        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n","        optimizer.zero_grad()\n","        outputs = model(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","def evaluate_model(model, loader):\n","    model.eval()\n","    all_preds = []\n","    all_labels = []\n","    with torch.no_grad():\n","        for inputs, labels in loader:\n","            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n","            outputs = model(inputs)\n","            all_preds.extend(outputs.cpu().numpy())\n","            all_labels.extend(labels.cpu().numpy())\n","    return np.array(all_preds), np.array(all_labels)\n","\n","# === 5. Optuna Objective 함수 (PyTorch용) ===\n","def objective(trial, X, y):\n","    X_train, X_val, y_train, y_val = train_test_split(\n","        X, y, test_size=0.25, random_state=Config.RANDOM_STATE, stratify=y)\n","\n","    train_dataset = TensorDataset(torch.FloatTensor(X_train), torch.FloatTensor(y_train))\n","    val_dataset = TensorDataset(torch.FloatTensor(X_val), torch.FloatTensor(y_val))\n","    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)\n","    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE)\n","\n","    input_dim = X_train.shape[1]\n","    model = MLP(input_dim, trial).to(DEVICE)\n","    lr = trial.suggest_float('learning_rate', 1e-5, 1e-2, log=True)\n","    optimizer = optim.Adam(model.parameters(), lr=lr)\n","    criterion = nn.BCELoss()\n","\n","    best_score = -1\n","    patience_counter = 0\n","\n","    for epoch in range(Config.EPOCHS):\n","        train_model(model, train_loader, optimizer, criterion)\n","        y_pred_proba, y_true = evaluate_model(model, val_loader)\n","        score = average_precision_score(y_true, y_pred_proba)\n","\n","        trial.report(score, epoch)\n","        if trial.should_prune():\n","            raise optuna.exceptions.TrialPruned()\n","\n","        if score > best_score:\n","            best_score = score\n","            patience_counter = 0\n","        else:\n","            patience_counter += 1\n","\n","        if patience_counter >= Config.VALIDATION_EARLY_STOPPING_PATIENCE:\n","            break\n","\n","    return best_score\n","\n","# === 6. Optuna 조기 종료 콜백 ===\n","class EarlyStoppingCallback:\n","    def __init__(self, early_stopping_rounds: int):\n","        self._early_stopping_rounds = early_stopping_rounds\n","        self._best_value = -float(\"inf\")\n","        self._counter = 0\n","\n","    def __call__(self, study: optuna.study.Study, trial: optuna.trial.Trial):\n","        current_best_value = study.best_value\n","        if current_best_value is not None and current_best_value > self._best_value:\n","            self._best_value = current_best_value\n","            self._counter = 0\n","        else:\n","            self._counter += 1\n","\n","        if self._counter >= self._early_stopping_rounds:\n","            print(f\"\\n[Optuna 조기 종료] {self._early_stopping_rounds}번의 trial 동안 최고 점수가 갱신되지 않아 튜닝을 중단합니다.\")\n","            study.stop()\n","\n","\n","# === 7. 메인 실행 블록 ===\n","if __name__ == '__main__':\n","    config = Config()\n","\n","    # --- Step 1: 데이터 로드 및 분할 ---\n","    print(\"\\n\" + \"=\"*50)\n","    print(\"📊 Step 1: 데이터 로드 및 분할\")\n","    try:\n","        df = pd.read_csv(config.CSV_FILE_PATH)\n","        labels = df[config.TARGET_COLUMN].values\n","        embeddings = np.load(config.EMBEDDING_PATH)\n","    except Exception as e:\n","        print(f\"🔥 파일 로드 실패: {e}\"); exit()\n","\n","    indices = np.arange(len(df))\n","    train_indices, test_indices = train_test_split(\n","        indices, test_size=config.TEST_SPLIT_RATIO, random_state=config.RANDOM_STATE, stratify=labels)\n","    X_train, X_test = embeddings[train_indices], embeddings[test_indices]\n","    y_train, y_test = labels[train_indices], labels[test_indices]\n","    print(f\"✅ 완료 (학습용: {len(y_train)}건, 테스트용: {len(y_test)}건)\")\n","\n","    # --- Step 2: Optuna 튜닝 수행 ---\n","    print(\"\\n\" + \"=\"*50)\n","    print(f\"🔬 Step 2: Optuna 하이퍼파라미터 튜닝 시작 (PyTorch)\")\n","    print(f\"(최대 {config.N_TRIALS}번 시도, {config.STUDY_EARLY_STOPPING_ROUNDS}번 개선 없으면 스터디 조기 종료)\")\n","    print(\"=\"*50)\n","\n","    study = optuna.create_study(direction='maximize', pruner=optuna.pruners.MedianPruner())\n","    pbar = tqdm(total=config.N_TRIALS, desc=\"Optuna 튜닝 진행률\")\n","\n","    try:\n","        study.optimize(lambda trial: objective(trial, X_train, y_train),\n","                       n_trials=config.N_TRIALS,\n","                       callbacks=[lambda s, t: pbar.update(1), EarlyStoppingCallback(config.STUDY_EARLY_STOPPING_ROUNDS)])\n","    except optuna.exceptions.OptunaError:\n","        pass # 조기 종료 시 예외 처리\n","    pbar.close()\n","\n","    # --- Step 3: 최적 모델 학습 및 평가 ---\n","    print(f\"\\n✅ 튜닝 완료!\")\n","    print(\"\\n\" + \"=\"*50)\n","    print(\"🔬 최적 하이퍼파라미터\")\n","    print(\"=\"*50)\n","    best_params = study.best_params\n","    for key, value in best_params.items():\n","        print(f\"{key:>20s}: {value}\")\n","    print(\"=\"*50)\n","\n","    print(f\"\\n🔬 Step 3: 튜닝된 최종 PyTorch 모델 학습 및 평가...\")\n","    train_dataset = TensorDataset(torch.FloatTensor(X_train), torch.FloatTensor(y_train))\n","    train_loader = DataLoader(train_dataset, batch_size=config.BATCH_SIZE, shuffle=True)\n","    test_dataset = TensorDataset(torch.FloatTensor(X_test), torch.FloatTensor(y_test))\n","    test_loader = DataLoader(test_dataset, batch_size=config.BATCH_SIZE)\n","\n","    # Optuna study 객체를 모의 trial로 사용하여 최종 모델 생성\n","    final_model = MLP(X_train.shape[1], study.best_trial).to(DEVICE)\n","    optimizer = optim.Adam(final_model.parameters(), lr=best_params['learning_rate'])\n","    criterion = nn.BCELoss()\n","\n","    # 최종 모델은 전체 학습 데이터로 학습\n","    for epoch in tqdm(range(config.EPOCHS), desc=\"최종 모델 학습\"):\n","        train_model(final_model, train_loader, optimizer, criterion)\n","\n","    y_pred_proba_tuned, y_true_test = evaluate_model(final_model, test_loader)\n","    y_pred_class_tuned = (y_pred_proba_tuned > 0.5).astype(int)\n","\n","    results = {\n","        \"PR AUC\": average_precision_score(y_true_test, y_pred_proba_tuned),\n","        \"ROC AUC\": roc_auc_score(y_true_test, y_pred_proba_tuned),\n","        \"F1-Score\": f1_score(y_true_test, y_pred_class_tuned),\n","    }\n","    print(\"✅ 튜닝된 PyTorch 모델 평가 완료.\")\n","    print(pd.DataFrame(results, index=['Optuna_Tuned_PyTorch']).round(4))\n","\n","    # --- Step 4: 결과 저장 ---\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"💾 Step 4: 최종 모델 예측 결과를 원본 CSV에 추가하여 저장\")\n","    print(\"=\"*60)\n","\n","    all_dataset = TensorDataset(torch.FloatTensor(embeddings))\n","    all_loader = DataLoader(all_dataset, batch_size=config.BATCH_SIZE * 2) # 예측 시에는 더 큰 배치 사용 가능\n","\n","    final_model.eval()\n","    all_predictions = []\n","    with torch.no_grad():\n","        for (inputs,) in tqdm(all_loader, desc=\"전체 데이터 예측\"):\n","            inputs = inputs.to(DEVICE)\n","            outputs = final_model(inputs)\n","            all_predictions.extend(outputs.cpu().numpy())\n","\n","    df['s2_pred_proba'] = all_predictions\n","    df['s2_pred_class'] = (df['s2_pred_proba'] > 0.5).astype(int)\n","\n","    df.to_csv(config.OUTPUT_CSV_PATH, index=False, encoding='utf-8-sig')\n","    print(f\"✅ 모든 데이터의 예측 결과가 '{config.OUTPUT_CSV_PATH}' 파일에 성공적으로 저장되었습니다.\")\n","\n","    # --- Step 5: 메모리 정리 ---\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"🧹 Step 5: 메모리 정리\")\n","    print(\"=\"*60)\n","    del df, labels, embeddings, X_train, X_test, y_train, y_test, final_model, study\n","    gc.collect()\n","    if torch.cuda.is_available():\n","        torch.cuda.empty_cache()\n","    print(\"✅ 메모리 정리가 완료되었습니다.\")\n","\n","    print(\"\\n🎉 모든 과정이 완료되었습니다!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["035e14987f3348af853e5a015cab2d14","2666ab30a5bc41e889b99be6a541a5ae","c92b02d3f00c4f5eb56419a86d912c11","03472efb4f6d43a0a1fb7e454bc9c016","95035a0d590a41fb8f1ea64c6b913d8c","e7152c78f8a14e7c8ddfe5402fe673c5","0e3f27ceec984210aef315ad88af2546","4d146d23743c4c23a63f5eaf35a8e35f","63bc8e8442d44a4c9b205c7f569c0c69","d0c691000e3141c59f5334265d47648e","661f80ed5d3544b994142d12e95bdd26","ec5cf2ca829c4a668ebb456d70056b1a","ca28b2977cc14553a3e115e6c26bb58f","2e491a15a4ae4f4d8371f988390088ff","4d5271ad13e348b18b3ac7bdfd507133","1ba73f4d93184181be9f99b6d36c8e6a","5bd0fff205a74729a2dc1c14cdd353a0","0ebacff36f364ae280be7d618b3a9cef","dede7ddc40f8427081b2fbdcd1f1bbe8","574b1e7dd63a4a7092d841b117151318","03cc945e4fe54da89d0bb89f1d11d849","3144a849190543288a25f3b5b24e7e53","033cec06d1d94f5cbfd287aa1db08584","7abfbf22e758461ba5fc434c2565d162","830023fc4baa4e2284f2c4ebf7ce1b11","483a7c9670634de49d2ff01fc796a8f2","079cd52e8f974fab9c3b46b5f0f7b167","300dc659dd054118857bb9e9542a2391","7d863a9439014ed08422e6363ce90640","1505cda2b85a4177a10831129df8d4de","a7d549f68d65427ba1507ff76ba06914","c920fe0dc96b43229bdf91bbc2b068a9","d0bb2e332f1b47cb9439d093832d62ff"]},"id":"6TcI8UhH7b5D","executionInfo":{"status":"ok","timestamp":1760283550063,"user_tz":-540,"elapsed":294869,"user":{"displayName":"KW-data-analytics","userId":"09651493752354345908"}},"outputId":"4dd86290-e2b5-4d08-bbb2-bc8a9dab5a13"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================================================\n","📊 Step 1: 데이터 로드 및 분할\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-10-12 15:34:20,544] A new study created in memory with name: no-name-07e7ebb5-a150-437d-8b29-e4c6d7b41149\n"]},{"output_type":"stream","name":"stdout","text":["✅ 완료 (학습용: 97108건, 테스트용: 24278건)\n","\n","==================================================\n","🔬 Step 2: Optuna 하이퍼파라미터 튜닝 시작 (PyTorch)\n","(최대 50번 시도, 10번 개선 없으면 스터디 조기 종료)\n","==================================================\n"]},{"output_type":"display_data","data":{"text/plain":["Optuna 튜닝 진행률:   0%|          | 0/50 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"035e14987f3348af853e5a015cab2d14"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2025-10-12 15:34:37,852] Trial 0 finished with value: 0.19956035701172847 and parameters: {'n_layers': 5, 'n_units_l0': 73, 'dropout_l0': 0.18504176280155585, 'n_units_l1': 279, 'dropout_l1': 0.1944009346027989, 'n_units_l2': 281, 'dropout_l2': 0.15203786829464586, 'n_units_l3': 32, 'dropout_l3': 0.14476559790303756, 'n_units_l4': 52, 'dropout_l4': 0.4673966585341116, 'learning_rate': 0.002391994372585765}. Best is trial 0 with value: 0.19956035701172847.\n","[I 2025-10-12 15:35:03,045] Trial 1 finished with value: 0.21032719026145774 and parameters: {'n_layers': 1, 'n_units_l0': 344, 'dropout_l0': 0.3430771021245596, 'learning_rate': 0.0008476866845825352}. Best is trial 1 with value: 0.21032719026145774.\n","[I 2025-10-12 15:36:05,875] Trial 2 finished with value: 0.20454568568899742 and parameters: {'n_layers': 1, 'n_units_l0': 38, 'dropout_l0': 0.2691742990119146, 'learning_rate': 0.00011572694016555544}. Best is trial 1 with value: 0.21032719026145774.\n","[I 2025-10-12 15:36:37,301] Trial 3 finished with value: 0.2097832474446573 and parameters: {'n_layers': 4, 'n_units_l0': 210, 'dropout_l0': 0.1937591265428374, 'n_units_l1': 224, 'dropout_l1': 0.3081634650218466, 'n_units_l2': 150, 'dropout_l2': 0.12997990813387178, 'n_units_l3': 93, 'dropout_l3': 0.43118461387112206, 'learning_rate': 9.913073471222943e-05}. Best is trial 1 with value: 0.21032719026145774.\n","[I 2025-10-12 15:37:02,984] Trial 4 finished with value: 0.21021738336685714 and parameters: {'n_layers': 4, 'n_units_l0': 470, 'dropout_l0': 0.46538851721519336, 'n_units_l1': 480, 'dropout_l1': 0.11598753124111782, 'n_units_l2': 67, 'dropout_l2': 0.1405322545929416, 'n_units_l3': 216, 'dropout_l3': 0.32581403073884363, 'learning_rate': 0.0001122214321454766}. Best is trial 1 with value: 0.21032719026145774.\n","[I 2025-10-12 15:37:11,107] Trial 5 pruned. \n","[I 2025-10-12 15:37:12,471] Trial 6 pruned. \n","[I 2025-10-12 15:37:21,454] Trial 7 pruned. \n","[I 2025-10-12 15:37:48,414] Trial 8 finished with value: 0.21026313871023114 and parameters: {'n_layers': 4, 'n_units_l0': 410, 'dropout_l0': 0.40629714446383836, 'n_units_l1': 40, 'dropout_l1': 0.1844681510195331, 'n_units_l2': 94, 'dropout_l2': 0.1304548831221197, 'n_units_l3': 177, 'dropout_l3': 0.30874805725846843, 'learning_rate': 0.0012505470030143974}. Best is trial 1 with value: 0.21032719026145774.\n","[I 2025-10-12 15:37:49,984] Trial 9 pruned. \n","[I 2025-10-12 15:37:51,590] Trial 10 pruned. \n","[I 2025-10-12 15:37:58,856] Trial 11 pruned. \n"]},{"output_type":"stream","name":"stdout","text":["\n","[Optuna 조기 종료] 10번의 trial 동안 최고 점수가 갱신되지 않아 튜닝을 중단합니다.\n","\n","✅ 튜닝 완료!\n","\n","==================================================\n","🔬 최적 하이퍼파라미터\n","==================================================\n","            n_layers: 1\n","          n_units_l0: 344\n","          dropout_l0: 0.3430771021245596\n","       learning_rate: 0.0008476866845825352\n","==================================================\n","\n","🔬 Step 3: 튜닝된 최종 PyTorch 모델 학습 및 평가...\n"]},{"output_type":"display_data","data":{"text/plain":["최종 모델 학습:   0%|          | 0/50 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ec5cf2ca829c4a668ebb456d70056b1a"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["✅ 튜닝된 PyTorch 모델 평가 완료.\n","                      PR AUC  ROC AUC  F1-Score\n","Optuna_Tuned_PyTorch  0.2064    0.772    0.1095\n","\n","============================================================\n","💾 Step 4: 최종 모델 예측 결과를 원본 CSV에 추가하여 저장\n","============================================================\n"]},{"output_type":"display_data","data":{"text/plain":["전체 데이터 예측:   0%|          | 0/238 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"033cec06d1d94f5cbfd287aa1db08584"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["✅ 모든 데이터의 예측 결과가 '/content/drive/MyDrive/review_helpfulness/PADA/results/s2/coursera/MLP/MLP_coursera_with_DistilBERT_predictions.csv' 파일에 성공적으로 저장되었습니다.\n","\n","============================================================\n","🧹 Step 5: 메모리 정리\n","============================================================\n","✅ 메모리 정리가 완료되었습니다.\n","\n","🎉 모든 과정이 완료되었습니다!\n"]}]},{"cell_type":"markdown","source":["# Audible"],"metadata":{"id":"lkob2TFO5SMA"}},{"cell_type":"markdown","source":["## T5"],"metadata":{"id":"T1VBdOZ_5T1L"}},{"cell_type":"code","source":["# === 2. 환경설정 클래스 ===\n","class Config:\n","    \"\"\"실행에 필요한 모든 설정값을 중앙에서 관리합니다.\"\"\"\n","    # 🌟 1. 파일 경로 설정\n","    CSV_FILE_PATH = \"/content/drive/MyDrive/review_helpfulness/PADA/data/audible/audible.csv\"\n","    EMBEDDING_PATH = \"/content/drive/MyDrive/review_helpfulness/PADA/embedding/audible_T5.npy\"\n","\n","    # 🌟 2. 최종 결과 CSV 파일 저장 경로 설정\n","    OUTPUT_CSV_PATH = \"/content/drive/MyDrive/review_helpfulness/PADA/results/s2/audible/MLP/MLP_audible_with_T5_predictions.csv\"\n","\n","    # --- 데이터 정보 ---\n","    TARGET_COLUMN = 'binary_helpfulness'\n","\n","    # --- 데이터 분할 ---\n","    TEST_SPLIT_RATIO = 0.2\n","    RANDOM_STATE = 42\n","\n","    # --- PyTorch 모델 및 학습 설정 ---\n","    EPOCHS = 50\n","    BATCH_SIZE = 256\n","    VALIDATION_EARLY_STOPPING_PATIENCE = 5 # 개별 Trial 내 검증 성능 기반 조기 종료\n","\n","    # --- Optuna 튜닝 설정 ---\n","    N_TRIALS = 50\n","    TUNING_METRIC = 'pr_auc'\n","    STUDY_EARLY_STOPPING_ROUNDS = 10 # 전체 Study 조기 종료\n","\n","# === 3. MLP 모델 클래스 (PyTorch) ===\n","class MLP(nn.Module):\n","    def __init__(self, input_dim, trial):\n","        super(MLP, self).__init__()\n","        layers = []\n","\n","        # ✅ 은닉층 탐색 범위를 1~5개로 확장\n","        n_layers = trial.suggest_int('n_layers', 1, 5)\n","\n","        in_features = input_dim\n","        for i in range(n_layers):\n","            out_features = trial.suggest_int(f'n_units_l{i}', 32, 512, log=True)\n","            layers.append(nn.Linear(in_features, out_features))\n","            layers.append(nn.ReLU())\n","            p = trial.suggest_float(f'dropout_l{i}', 0.1, 0.5)\n","            layers.append(nn.Dropout(p))\n","            in_features = out_features\n","\n","        layers.append(nn.Linear(in_features, 1))\n","        self.layers = nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        return torch.sigmoid(self.layers(x).squeeze(-1))\n","\n","# === 4. 학습 및 평가 함수 ===\n","def train_model(model, loader, optimizer, criterion):\n","    model.train()\n","    for inputs, labels in loader:\n","        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n","        optimizer.zero_grad()\n","        outputs = model(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","def evaluate_model(model, loader):\n","    model.eval()\n","    all_preds = []\n","    all_labels = []\n","    with torch.no_grad():\n","        for inputs, labels in loader:\n","            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n","            outputs = model(inputs)\n","            all_preds.extend(outputs.cpu().numpy())\n","            all_labels.extend(labels.cpu().numpy())\n","    return np.array(all_preds), np.array(all_labels)\n","\n","# === 5. Optuna Objective 함수 (PyTorch용) ===\n","def objective(trial, X, y):\n","    X_train, X_val, y_train, y_val = train_test_split(\n","        X, y, test_size=0.25, random_state=Config.RANDOM_STATE, stratify=y)\n","\n","    train_dataset = TensorDataset(torch.FloatTensor(X_train), torch.FloatTensor(y_train))\n","    val_dataset = TensorDataset(torch.FloatTensor(X_val), torch.FloatTensor(y_val))\n","    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)\n","    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE)\n","\n","    input_dim = X_train.shape[1]\n","    model = MLP(input_dim, trial).to(DEVICE)\n","    lr = trial.suggest_float('learning_rate', 1e-5, 1e-2, log=True)\n","    optimizer = optim.Adam(model.parameters(), lr=lr)\n","    criterion = nn.BCELoss()\n","\n","    best_score = -1\n","    patience_counter = 0\n","\n","    for epoch in range(Config.EPOCHS):\n","        train_model(model, train_loader, optimizer, criterion)\n","        y_pred_proba, y_true = evaluate_model(model, val_loader)\n","        score = average_precision_score(y_true, y_pred_proba)\n","\n","        trial.report(score, epoch)\n","        if trial.should_prune():\n","            raise optuna.exceptions.TrialPruned()\n","\n","        if score > best_score:\n","            best_score = score\n","            patience_counter = 0\n","        else:\n","            patience_counter += 1\n","\n","        if patience_counter >= Config.VALIDATION_EARLY_STOPPING_PATIENCE:\n","            break\n","\n","    return best_score\n","\n","# === 6. Optuna 조기 종료 콜백 ===\n","class EarlyStoppingCallback:\n","    def __init__(self, early_stopping_rounds: int):\n","        self._early_stopping_rounds = early_stopping_rounds\n","        self._best_value = -float(\"inf\")\n","        self._counter = 0\n","\n","    def __call__(self, study: optuna.study.Study, trial: optuna.trial.Trial):\n","        current_best_value = study.best_value\n","        if current_best_value is not None and current_best_value > self._best_value:\n","            self._best_value = current_best_value\n","            self._counter = 0\n","        else:\n","            self._counter += 1\n","\n","        if self._counter >= self._early_stopping_rounds:\n","            print(f\"\\n[Optuna 조기 종료] {self._early_stopping_rounds}번의 trial 동안 최고 점수가 갱신되지 않아 튜닝을 중단합니다.\")\n","            study.stop()\n","\n","\n","# === 7. 메인 실행 블록 ===\n","if __name__ == '__main__':\n","    config = Config()\n","\n","    # --- Step 1: 데이터 로드 및 분할 ---\n","    print(\"\\n\" + \"=\"*50)\n","    print(\"📊 Step 1: 데이터 로드 및 분할\")\n","    try:\n","        df = pd.read_csv(config.CSV_FILE_PATH)\n","        labels = df[config.TARGET_COLUMN].values\n","        embeddings = np.load(config.EMBEDDING_PATH)\n","    except Exception as e:\n","        print(f\"🔥 파일 로드 실패: {e}\"); exit()\n","\n","    indices = np.arange(len(df))\n","    train_indices, test_indices = train_test_split(\n","        indices, test_size=config.TEST_SPLIT_RATIO, random_state=config.RANDOM_STATE, stratify=labels)\n","    X_train, X_test = embeddings[train_indices], embeddings[test_indices]\n","    y_train, y_test = labels[train_indices], labels[test_indices]\n","    print(f\"✅ 완료 (학습용: {len(y_train)}건, 테스트용: {len(y_test)}건)\")\n","\n","    # --- Step 2: Optuna 튜닝 수행 ---\n","    print(\"\\n\" + \"=\"*50)\n","    print(f\"🔬 Step 2: Optuna 하이퍼파라미터 튜닝 시작 (PyTorch)\")\n","    print(f\"(최대 {config.N_TRIALS}번 시도, {config.STUDY_EARLY_STOPPING_ROUNDS}번 개선 없으면 스터디 조기 종료)\")\n","    print(\"=\"*50)\n","\n","    study = optuna.create_study(direction='maximize', pruner=optuna.pruners.MedianPruner())\n","    pbar = tqdm(total=config.N_TRIALS, desc=\"Optuna 튜닝 진행률\")\n","\n","    try:\n","        study.optimize(lambda trial: objective(trial, X_train, y_train),\n","                       n_trials=config.N_TRIALS,\n","                       callbacks=[lambda s, t: pbar.update(1), EarlyStoppingCallback(config.STUDY_EARLY_STOPPING_ROUNDS)])\n","    except optuna.exceptions.OptunaError:\n","        pass # 조기 종료 시 예외 처리\n","    pbar.close()\n","\n","    # --- Step 3: 최적 모델 학습 및 평가 ---\n","    print(f\"\\n✅ 튜닝 완료!\")\n","    print(\"\\n\" + \"=\"*50)\n","    print(\"🔬 최적 하이퍼파라미터\")\n","    print(\"=\"*50)\n","    best_params = study.best_params\n","    for key, value in best_params.items():\n","        print(f\"{key:>20s}: {value}\")\n","    print(\"=\"*50)\n","\n","    print(f\"\\n🔬 Step 3: 튜닝된 최종 PyTorch 모델 학습 및 평가...\")\n","    train_dataset = TensorDataset(torch.FloatTensor(X_train), torch.FloatTensor(y_train))\n","    train_loader = DataLoader(train_dataset, batch_size=config.BATCH_SIZE, shuffle=True)\n","    test_dataset = TensorDataset(torch.FloatTensor(X_test), torch.FloatTensor(y_test))\n","    test_loader = DataLoader(test_dataset, batch_size=config.BATCH_SIZE)\n","\n","    # Optuna study 객체를 모의 trial로 사용하여 최종 모델 생성\n","    final_model = MLP(X_train.shape[1], study.best_trial).to(DEVICE)\n","    optimizer = optim.Adam(final_model.parameters(), lr=best_params['learning_rate'])\n","    criterion = nn.BCELoss()\n","\n","    # 최종 모델은 전체 학습 데이터로 학습\n","    for epoch in tqdm(range(config.EPOCHS), desc=\"최종 모델 학습\"):\n","        train_model(final_model, train_loader, optimizer, criterion)\n","\n","    y_pred_proba_tuned, y_true_test = evaluate_model(final_model, test_loader)\n","    y_pred_class_tuned = (y_pred_proba_tuned > 0.5).astype(int)\n","\n","    results = {\n","        \"PR AUC\": average_precision_score(y_true_test, y_pred_proba_tuned),\n","        \"ROC AUC\": roc_auc_score(y_true_test, y_pred_proba_tuned),\n","        \"F1-Score\": f1_score(y_true_test, y_pred_class_tuned),\n","    }\n","    print(\"✅ 튜닝된 PyTorch 모델 평가 완료.\")\n","    print(pd.DataFrame(results, index=['Optuna_Tuned_PyTorch']).round(4))\n","\n","    # --- Step 4: 결과 저장 ---\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"💾 Step 4: 최종 모델 예측 결과를 원본 CSV에 추가하여 저장\")\n","    print(\"=\"*60)\n","\n","    all_dataset = TensorDataset(torch.FloatTensor(embeddings))\n","    all_loader = DataLoader(all_dataset, batch_size=config.BATCH_SIZE * 2) # 예측 시에는 더 큰 배치 사용 가능\n","\n","    final_model.eval()\n","    all_predictions = []\n","    with torch.no_grad():\n","        for (inputs,) in tqdm(all_loader, desc=\"전체 데이터 예측\"):\n","            inputs = inputs.to(DEVICE)\n","            outputs = final_model(inputs)\n","            all_predictions.extend(outputs.cpu().numpy())\n","\n","    df['s2_pred_proba'] = all_predictions\n","    df['s2_pred_class'] = (df['s2_pred_proba'] > 0.5).astype(int)\n","\n","    df.to_csv(config.OUTPUT_CSV_PATH, index=False, encoding='utf-8-sig')\n","    print(f\"✅ 모든 데이터의 예측 결과가 '{config.OUTPUT_CSV_PATH}' 파일에 성공적으로 저장되었습니다.\")\n","\n","    # --- Step 5: 메모리 정리 ---\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"🧹 Step 5: 메모리 정리\")\n","    print(\"=\"*60)\n","    del df, labels, embeddings, X_train, X_test, y_train, y_test, final_model, study\n","    gc.collect()\n","    if torch.cuda.is_available():\n","        torch.cuda.empty_cache()\n","    print(\"✅ 메모리 정리가 완료되었습니다.\")\n","\n","    print(\"\\n🎉 모든 과정이 완료되었습니다!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["4625899cf4f443b0844e23c838aec583","daf26e792ebf423e911124a8d86a0bb1","6777b6689154427c86433dc45a035232","43a8f59bfd4a45db8e8cacd3cd6a71cc","1f885ee528e74498ae269394ba38f602","7bf4fec7d782402f847ab7b13012f996","64ffe98a4e7c4ec9a6cf3e2d638aa895","7f96681efd454036936a423759e3e44a","6228cad18dfb4d2caa7c39665bcf80a3","1404602a56614168b0967768d2bae518","19833bd67e5140a1b784f356d27cb7f6","4f9840da7489458c883692d493f0af45","3fb5fa87d9dc4a7f9ad9f7390e81ada9","dd2aaa369951477c98c20a924391d915","e54914a64589415e92e69893243b0bbc","3992ff06b13540b5930ffa0314632c44","a17df1a62c644561879a5a563000bc82","8eeb4755e5414439b07bec008294a51b","e525323ca2e54d85b31f2e0dabbe138b","b3b7c6093d98485d9d004f315356e98d","87a9afd9ba1349d5a1af3e761c533016","a971f0af142649dab330d0c03c90ab0c","3a8474bc999f4f7296b7a2692f105d71","9327bc49a44d49a2afb22376cdd25e99","df098a0e09624ff2972471ba9d894765","8b5fc486e0d544bea5cbc4a6e063f6d1","90356f5ba8684e4986d4cacfb6e2366b","4c591383b32d4a078c39cf4676f84ebd","f553b2eedf784f389d40f4c1354cfbdd","cfb1ad0370944cac9bb4b851f3a320ab","319f92cd148b457ea70dc8b5e200a00c","a725cbe4ede44977b3029be731d8180b","5719125a26c549eb80fd5bec7e260ed5"]},"id":"W09RfLMS7knQ","executionInfo":{"status":"ok","timestamp":1760284056355,"user_tz":-540,"elapsed":506267,"user":{"displayName":"KW-data-analytics","userId":"09651493752354345908"}},"outputId":"8d720601-75f3-4f98-94ce-6f3e1da3dd1d"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================================================\n","📊 Step 1: 데이터 로드 및 분할\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-10-12 15:39:14,705] A new study created in memory with name: no-name-add98394-d969-49ed-9ea8-b6e5c736077a\n"]},{"output_type":"stream","name":"stdout","text":["✅ 완료 (학습용: 74391건, 테스트용: 18598건)\n","\n","==================================================\n","🔬 Step 2: Optuna 하이퍼파라미터 튜닝 시작 (PyTorch)\n","(최대 50번 시도, 10번 개선 없으면 스터디 조기 종료)\n","==================================================\n"]},{"output_type":"display_data","data":{"text/plain":["Optuna 튜닝 진행률:   0%|          | 0/50 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4625899cf4f443b0844e23c838aec583"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2025-10-12 15:39:38,687] Trial 0 finished with value: 0.15832367005918896 and parameters: {'n_layers': 4, 'n_units_l0': 334, 'dropout_l0': 0.4374513967225664, 'n_units_l1': 287, 'dropout_l1': 0.2441970909381669, 'n_units_l2': 176, 'dropout_l2': 0.2085248071529681, 'n_units_l3': 119, 'dropout_l3': 0.40055546378176543, 'learning_rate': 0.00017562084192594755}. Best is trial 0 with value: 0.15832367005918896.\n","[I 2025-10-12 15:39:51,159] Trial 1 finished with value: 0.15755277964706466 and parameters: {'n_layers': 1, 'n_units_l0': 119, 'dropout_l0': 0.24933531147195281, 'learning_rate': 0.007756214405997634}. Best is trial 0 with value: 0.15832367005918896.\n","[I 2025-10-12 15:40:39,421] Trial 2 finished with value: 0.16160437789424167 and parameters: {'n_layers': 1, 'n_units_l0': 395, 'dropout_l0': 0.10573661005825641, 'learning_rate': 9.033407885502957e-05}. Best is trial 2 with value: 0.16160437789424167.\n","[I 2025-10-12 15:41:25,141] Trial 3 finished with value: 0.1569357274098782 and parameters: {'n_layers': 5, 'n_units_l0': 150, 'dropout_l0': 0.10413625802897993, 'n_units_l1': 57, 'dropout_l1': 0.20022136448535918, 'n_units_l2': 473, 'dropout_l2': 0.44201808385126384, 'n_units_l3': 38, 'dropout_l3': 0.24295651297423904, 'n_units_l4': 365, 'dropout_l4': 0.37831426217297415, 'learning_rate': 3.0333821693626297e-05}. Best is trial 2 with value: 0.16160437789424167.\n","[I 2025-10-12 15:42:01,955] Trial 4 finished with value: 0.15670876893878558 and parameters: {'n_layers': 3, 'n_units_l0': 36, 'dropout_l0': 0.36965098211430125, 'n_units_l1': 64, 'dropout_l1': 0.4448339030475966, 'n_units_l2': 87, 'dropout_l2': 0.46899769720640094, 'learning_rate': 0.0001497426229902746}. Best is trial 2 with value: 0.16160437789424167.\n","[I 2025-10-12 15:42:31,702] Trial 5 finished with value: 0.1599986458334729 and parameters: {'n_layers': 4, 'n_units_l0': 228, 'dropout_l0': 0.403658720751651, 'n_units_l1': 458, 'dropout_l1': 0.30901990693999914, 'n_units_l2': 62, 'dropout_l2': 0.3100449200942965, 'n_units_l3': 117, 'dropout_l3': 0.13511260233067857, 'learning_rate': 0.0008244893100036297}. Best is trial 2 with value: 0.16160437789424167.\n","[I 2025-10-12 15:42:32,756] Trial 6 pruned. \n","[I 2025-10-12 15:43:26,953] Trial 7 finished with value: 0.16420644266604556 and parameters: {'n_layers': 3, 'n_units_l0': 336, 'dropout_l0': 0.3717682958884073, 'n_units_l1': 132, 'dropout_l1': 0.2956484448075372, 'n_units_l2': 100, 'dropout_l2': 0.2825564537121204, 'learning_rate': 0.00015944388246541717}. Best is trial 7 with value: 0.16420644266604556.\n","[I 2025-10-12 15:43:28,005] Trial 8 pruned. \n","[I 2025-10-12 15:43:29,295] Trial 9 pruned. \n","[I 2025-10-12 15:43:43,610] Trial 10 finished with value: 0.1581243590685557 and parameters: {'n_layers': 3, 'n_units_l0': 180, 'dropout_l0': 0.4980570403891772, 'n_units_l1': 156, 'dropout_l1': 0.10370919334467674, 'n_units_l2': 32, 'dropout_l2': 0.128365245770748, 'learning_rate': 0.0007580270081984292}. Best is trial 7 with value: 0.16420644266604556.\n","[I 2025-10-12 15:44:22,501] Trial 11 finished with value: 0.16462936541475193 and parameters: {'n_layers': 2, 'n_units_l0': 487, 'dropout_l0': 0.10622109381713253, 'n_units_l1': 158, 'dropout_l1': 0.49799590101550517, 'learning_rate': 0.0005204619361266416}. Best is trial 11 with value: 0.16462936541475193.\n","[I 2025-10-12 15:44:38,968] Trial 12 pruned. \n","[I 2025-10-12 15:44:56,539] Trial 13 finished with value: 0.15999172828577282 and parameters: {'n_layers': 2, 'n_units_l0': 239, 'dropout_l0': 0.1837041065218647, 'n_units_l1': 213, 'dropout_l1': 0.38134949226162534, 'learning_rate': 0.004152544064833953}. Best is trial 11 with value: 0.16462936541475193.\n","[I 2025-10-12 15:45:29,400] Trial 14 finished with value: 0.165559912658708 and parameters: {'n_layers': 2, 'n_units_l0': 495, 'dropout_l0': 0.33441689932313784, 'n_units_l1': 87, 'dropout_l1': 0.27860212361297026, 'learning_rate': 0.0021077341581684705}. Best is trial 14 with value: 0.165559912658708.\n","[I 2025-10-12 15:45:38,867] Trial 15 finished with value: 0.15706164646733423 and parameters: {'n_layers': 2, 'n_units_l0': 101, 'dropout_l0': 0.3021908458570198, 'n_units_l1': 89, 'dropout_l1': 0.16755785591738384, 'learning_rate': 0.0022135401192109622}. Best is trial 14 with value: 0.165559912658708.\n","[I 2025-10-12 15:45:46,121] Trial 16 pruned. \n","[I 2025-10-12 15:45:47,307] Trial 17 pruned. \n","[I 2025-10-12 15:45:52,600] Trial 18 pruned. \n","[I 2025-10-12 15:45:53,859] Trial 19 pruned. \n","[I 2025-10-12 15:46:22,485] Trial 20 finished with value: 0.16249184154146729 and parameters: {'n_layers': 2, 'n_units_l0': 254, 'dropout_l0': 0.1449219324682553, 'n_units_l1': 202, 'dropout_l1': 0.3522579735009531, 'learning_rate': 0.003122076686448235}. Best is trial 14 with value: 0.165559912658708.\n","[I 2025-10-12 15:46:23,819] Trial 21 pruned. \n","[I 2025-10-12 15:46:34,667] Trial 22 finished with value: 0.15704877302624115 and parameters: {'n_layers': 3, 'n_units_l0': 286, 'dropout_l0': 0.25699570050068926, 'n_units_l1': 152, 'dropout_l1': 0.2924557065833076, 'n_units_l2': 57, 'dropout_l2': 0.1959929626435697, 'learning_rate': 0.0011223568203418772}. Best is trial 14 with value: 0.165559912658708.\n","[I 2025-10-12 15:46:35,848] Trial 23 pruned. \n","[I 2025-10-12 15:46:36,971] Trial 24 pruned. \n"]},{"output_type":"stream","name":"stdout","text":["\n","[Optuna 조기 종료] 10번의 trial 동안 최고 점수가 갱신되지 않아 튜닝을 중단합니다.\n","\n","✅ 튜닝 완료!\n","\n","==================================================\n","🔬 최적 하이퍼파라미터\n","==================================================\n","            n_layers: 2\n","          n_units_l0: 495\n","          dropout_l0: 0.33441689932313784\n","          n_units_l1: 87\n","          dropout_l1: 0.27860212361297026\n","       learning_rate: 0.0021077341581684705\n","==================================================\n","\n","🔬 Step 3: 튜닝된 최종 PyTorch 모델 학습 및 평가...\n"]},{"output_type":"display_data","data":{"text/plain":["최종 모델 학습:   0%|          | 0/50 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4f9840da7489458c883692d493f0af45"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["✅ 튜닝된 PyTorch 모델 평가 완료.\n","                      PR AUC  ROC AUC  F1-Score\n","Optuna_Tuned_PyTorch  0.1695   0.6799    0.0073\n","\n","============================================================\n","💾 Step 4: 최종 모델 예측 결과를 원본 CSV에 추가하여 저장\n","============================================================\n"]},{"output_type":"display_data","data":{"text/plain":["전체 데이터 예측:   0%|          | 0/182 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3a8474bc999f4f7296b7a2692f105d71"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["✅ 모든 데이터의 예측 결과가 '/content/drive/MyDrive/review_helpfulness/PADA/results/s2/audible/MLP/MLP_audible_with_T5_predictions.csv' 파일에 성공적으로 저장되었습니다.\n","\n","============================================================\n","🧹 Step 5: 메모리 정리\n","============================================================\n","✅ 메모리 정리가 완료되었습니다.\n","\n","🎉 모든 과정이 완료되었습니다!\n"]}]},{"cell_type":"markdown","source":["## BERT"],"metadata":{"id":"EcFJh1Fd5UHs"}},{"cell_type":"code","source":["# === 2. 환경설정 클래스 ===\n","class Config:\n","    \"\"\"실행에 필요한 모든 설정값을 중앙에서 관리합니다.\"\"\"\n","    # 🌟 1. 파일 경로 설정\n","    CSV_FILE_PATH = \"/content/drive/MyDrive/review_helpfulness/PADA/data/audible/audible.csv\"\n","    EMBEDDING_PATH = \"/content/drive/MyDrive/review_helpfulness/PADA/embedding/audible_BERT.npy\"\n","\n","    # 🌟 2. 최종 결과 CSV 파일 저장 경로 설정\n","    OUTPUT_CSV_PATH = \"/content/drive/MyDrive/review_helpfulness/PADA/results/s2/audible/MLP/MLP_audible_with_BERT_predictions.csv\"\n","\n","    # --- 데이터 정보 ---\n","    TARGET_COLUMN = 'binary_helpfulness'\n","\n","    # --- 데이터 분할 ---\n","    TEST_SPLIT_RATIO = 0.2\n","    RANDOM_STATE = 42\n","\n","    # --- PyTorch 모델 및 학습 설정 ---\n","    EPOCHS = 50\n","    BATCH_SIZE = 256\n","    VALIDATION_EARLY_STOPPING_PATIENCE = 5 # 개별 Trial 내 검증 성능 기반 조기 종료\n","\n","    # --- Optuna 튜닝 설정 ---\n","    N_TRIALS = 50\n","    TUNING_METRIC = 'pr_auc'\n","    STUDY_EARLY_STOPPING_ROUNDS = 10 # 전체 Study 조기 종료\n","\n","# === 3. MLP 모델 클래스 (PyTorch) ===\n","class MLP(nn.Module):\n","    def __init__(self, input_dim, trial):\n","        super(MLP, self).__init__()\n","        layers = []\n","\n","        # ✅ 은닉층 탐색 범위를 1~5개로 확장\n","        n_layers = trial.suggest_int('n_layers', 1, 5)\n","\n","        in_features = input_dim\n","        for i in range(n_layers):\n","            out_features = trial.suggest_int(f'n_units_l{i}', 32, 512, log=True)\n","            layers.append(nn.Linear(in_features, out_features))\n","            layers.append(nn.ReLU())\n","            p = trial.suggest_float(f'dropout_l{i}', 0.1, 0.5)\n","            layers.append(nn.Dropout(p))\n","            in_features = out_features\n","\n","        layers.append(nn.Linear(in_features, 1))\n","        self.layers = nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        return torch.sigmoid(self.layers(x).squeeze(-1))\n","\n","# === 4. 학습 및 평가 함수 ===\n","def train_model(model, loader, optimizer, criterion):\n","    model.train()\n","    for inputs, labels in loader:\n","        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n","        optimizer.zero_grad()\n","        outputs = model(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","def evaluate_model(model, loader):\n","    model.eval()\n","    all_preds = []\n","    all_labels = []\n","    with torch.no_grad():\n","        for inputs, labels in loader:\n","            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n","            outputs = model(inputs)\n","            all_preds.extend(outputs.cpu().numpy())\n","            all_labels.extend(labels.cpu().numpy())\n","    return np.array(all_preds), np.array(all_labels)\n","\n","# === 5. Optuna Objective 함수 (PyTorch용) ===\n","def objective(trial, X, y):\n","    X_train, X_val, y_train, y_val = train_test_split(\n","        X, y, test_size=0.25, random_state=Config.RANDOM_STATE, stratify=y)\n","\n","    train_dataset = TensorDataset(torch.FloatTensor(X_train), torch.FloatTensor(y_train))\n","    val_dataset = TensorDataset(torch.FloatTensor(X_val), torch.FloatTensor(y_val))\n","    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)\n","    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE)\n","\n","    input_dim = X_train.shape[1]\n","    model = MLP(input_dim, trial).to(DEVICE)\n","    lr = trial.suggest_float('learning_rate', 1e-5, 1e-2, log=True)\n","    optimizer = optim.Adam(model.parameters(), lr=lr)\n","    criterion = nn.BCELoss()\n","\n","    best_score = -1\n","    patience_counter = 0\n","\n","    for epoch in range(Config.EPOCHS):\n","        train_model(model, train_loader, optimizer, criterion)\n","        y_pred_proba, y_true = evaluate_model(model, val_loader)\n","        score = average_precision_score(y_true, y_pred_proba)\n","\n","        trial.report(score, epoch)\n","        if trial.should_prune():\n","            raise optuna.exceptions.TrialPruned()\n","\n","        if score > best_score:\n","            best_score = score\n","            patience_counter = 0\n","        else:\n","            patience_counter += 1\n","\n","        if patience_counter >= Config.VALIDATION_EARLY_STOPPING_PATIENCE:\n","            break\n","\n","    return best_score\n","\n","# === 6. Optuna 조기 종료 콜백 ===\n","class EarlyStoppingCallback:\n","    def __init__(self, early_stopping_rounds: int):\n","        self._early_stopping_rounds = early_stopping_rounds\n","        self._best_value = -float(\"inf\")\n","        self._counter = 0\n","\n","    def __call__(self, study: optuna.study.Study, trial: optuna.trial.Trial):\n","        current_best_value = study.best_value\n","        if current_best_value is not None and current_best_value > self._best_value:\n","            self._best_value = current_best_value\n","            self._counter = 0\n","        else:\n","            self._counter += 1\n","\n","        if self._counter >= self._early_stopping_rounds:\n","            print(f\"\\n[Optuna 조기 종료] {self._early_stopping_rounds}번의 trial 동안 최고 점수가 갱신되지 않아 튜닝을 중단합니다.\")\n","            study.stop()\n","\n","\n","# === 7. 메인 실행 블록 ===\n","if __name__ == '__main__':\n","    config = Config()\n","\n","    # --- Step 1: 데이터 로드 및 분할 ---\n","    print(\"\\n\" + \"=\"*50)\n","    print(\"📊 Step 1: 데이터 로드 및 분할\")\n","    try:\n","        df = pd.read_csv(config.CSV_FILE_PATH)\n","        labels = df[config.TARGET_COLUMN].values\n","        embeddings = np.load(config.EMBEDDING_PATH)\n","    except Exception as e:\n","        print(f\"🔥 파일 로드 실패: {e}\"); exit()\n","\n","    indices = np.arange(len(df))\n","    train_indices, test_indices = train_test_split(\n","        indices, test_size=config.TEST_SPLIT_RATIO, random_state=config.RANDOM_STATE, stratify=labels)\n","    X_train, X_test = embeddings[train_indices], embeddings[test_indices]\n","    y_train, y_test = labels[train_indices], labels[test_indices]\n","    print(f\"✅ 완료 (학습용: {len(y_train)}건, 테스트용: {len(y_test)}건)\")\n","\n","    # --- Step 2: Optuna 튜닝 수행 ---\n","    print(\"\\n\" + \"=\"*50)\n","    print(f\"🔬 Step 2: Optuna 하이퍼파라미터 튜닝 시작 (PyTorch)\")\n","    print(f\"(최대 {config.N_TRIALS}번 시도, {config.STUDY_EARLY_STOPPING_ROUNDS}번 개선 없으면 스터디 조기 종료)\")\n","    print(\"=\"*50)\n","\n","    study = optuna.create_study(direction='maximize', pruner=optuna.pruners.MedianPruner())\n","    pbar = tqdm(total=config.N_TRIALS, desc=\"Optuna 튜닝 진행률\")\n","\n","    try:\n","        study.optimize(lambda trial: objective(trial, X_train, y_train),\n","                       n_trials=config.N_TRIALS,\n","                       callbacks=[lambda s, t: pbar.update(1), EarlyStoppingCallback(config.STUDY_EARLY_STOPPING_ROUNDS)])\n","    except optuna.exceptions.OptunaError:\n","        pass # 조기 종료 시 예외 처리\n","    pbar.close()\n","\n","    # --- Step 3: 최적 모델 학습 및 평가 ---\n","    print(f\"\\n✅ 튜닝 완료!\")\n","    print(\"\\n\" + \"=\"*50)\n","    print(\"🔬 최적 하이퍼파라미터\")\n","    print(\"=\"*50)\n","    best_params = study.best_params\n","    for key, value in best_params.items():\n","        print(f\"{key:>20s}: {value}\")\n","    print(\"=\"*50)\n","\n","    print(f\"\\n🔬 Step 3: 튜닝된 최종 PyTorch 모델 학습 및 평가...\")\n","    train_dataset = TensorDataset(torch.FloatTensor(X_train), torch.FloatTensor(y_train))\n","    train_loader = DataLoader(train_dataset, batch_size=config.BATCH_SIZE, shuffle=True)\n","    test_dataset = TensorDataset(torch.FloatTensor(X_test), torch.FloatTensor(y_test))\n","    test_loader = DataLoader(test_dataset, batch_size=config.BATCH_SIZE)\n","\n","    # Optuna study 객체를 모의 trial로 사용하여 최종 모델 생성\n","    final_model = MLP(X_train.shape[1], study.best_trial).to(DEVICE)\n","    optimizer = optim.Adam(final_model.parameters(), lr=best_params['learning_rate'])\n","    criterion = nn.BCELoss()\n","\n","    # 최종 모델은 전체 학습 데이터로 학습\n","    for epoch in tqdm(range(config.EPOCHS), desc=\"최종 모델 학습\"):\n","        train_model(final_model, train_loader, optimizer, criterion)\n","\n","    y_pred_proba_tuned, y_true_test = evaluate_model(final_model, test_loader)\n","    y_pred_class_tuned = (y_pred_proba_tuned > 0.5).astype(int)\n","\n","    results = {\n","        \"PR AUC\": average_precision_score(y_true_test, y_pred_proba_tuned),\n","        \"ROC AUC\": roc_auc_score(y_true_test, y_pred_proba_tuned),\n","        \"F1-Score\": f1_score(y_true_test, y_pred_class_tuned),\n","    }\n","    print(\"✅ 튜닝된 PyTorch 모델 평가 완료.\")\n","    print(pd.DataFrame(results, index=['Optuna_Tuned_PyTorch']).round(4))\n","\n","    # --- Step 4: 결과 저장 ---\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"💾 Step 4: 최종 모델 예측 결과를 원본 CSV에 추가하여 저장\")\n","    print(\"=\"*60)\n","\n","    all_dataset = TensorDataset(torch.FloatTensor(embeddings))\n","    all_loader = DataLoader(all_dataset, batch_size=config.BATCH_SIZE * 2) # 예측 시에는 더 큰 배치 사용 가능\n","\n","    final_model.eval()\n","    all_predictions = []\n","    with torch.no_grad():\n","        for (inputs,) in tqdm(all_loader, desc=\"전체 데이터 예측\"):\n","            inputs = inputs.to(DEVICE)\n","            outputs = final_model(inputs)\n","            all_predictions.extend(outputs.cpu().numpy())\n","\n","    df['s2_pred_proba'] = all_predictions\n","    df['s2_pred_class'] = (df['s2_pred_proba'] > 0.5).astype(int)\n","\n","    df.to_csv(config.OUTPUT_CSV_PATH, index=False, encoding='utf-8-sig')\n","    print(f\"✅ 모든 데이터의 예측 결과가 '{config.OUTPUT_CSV_PATH}' 파일에 성공적으로 저장되었습니다.\")\n","\n","    # --- Step 5: 메모리 정리 ---\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"🧹 Step 5: 메모리 정리\")\n","    print(\"=\"*60)\n","    del df, labels, embeddings, X_train, X_test, y_train, y_test, final_model, study\n","    gc.collect()\n","    if torch.cuda.is_available():\n","        torch.cuda.empty_cache()\n","    print(\"✅ 메모리 정리가 완료되었습니다.\")\n","\n","    print(\"\\n🎉 모든 과정이 완료되었습니다!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["879c817822604edfa5232c791edaa5a3","866b7aefda5d44d9b9643c7cb1bc7285","e2632cfc597c4374b5cfbdb3184f90ca","905f4e87eba94a76833d9abb856b4fee","0a483244a54d4901a3b3d38faea787b2","b3f8511658e24aa58a1c379aa46cebca","0a19299a6cdf49a4869924b5af02d45d","c1c44bfeb45949ba898372574a6c49ec","cc231da84cb54484be6059c8f1446989","8b6956d42ce644d1ba996e0341a7c808","7831e8f062d94b10bf409f38fc374579","4d2c558c9e624d909d8bfe6ded5b10e7","8703007ee381400e9b49dc6d918cef52","f48ef9dba6084109bc126a4ed79ce06f","243f256c03014f93af50e2aed8698e50","655729c61bd34a4bab990928e24f6eb6","3fb673bc9ddf4d85b3eecac8c47978b8","ddcae09c250d492082fa8c1cc889e621","9c99e33c46ca4020a25e1a375948512e","4f4f6fdf77704d75a39aac034a0aec59","acd81dad769947a0b2c8509142e268c7","59b19e0e0ba34e978aba52767beec7fb","10e98966ebdc496d8ac2538f598b6e65","e7cf5269dba94ede86ba5c0f0997a635","8576985822a0453aadcf0151a00d6953","7295d9d21fdd407497ad4170e9e441b0","4d8f43f4b5e543c0adb76a97855478a9","ff0dbae4438b410996893012ac1e580a","f903d38b33024a789e372ab2feeb53b0","eb2c7c66613e44219a0f8c37a4f738d0","6ff5cdc56057437dac6da49bb5028042","6e9ddaf98ec14ec08a424e25f1330169","68e43cb5d9f94848b6f69225d0e73014"]},"id":"r56PAgCy79e-","executionInfo":{"status":"ok","timestamp":1760284364899,"user_tz":-540,"elapsed":308532,"user":{"displayName":"KW-data-analytics","userId":"09651493752354345908"}},"outputId":"64c90dda-3563-4824-efa1-1bbff28c64bd"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================================================\n","📊 Step 1: 데이터 로드 및 분할\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-10-12 15:47:40,435] A new study created in memory with name: no-name-eb23bf5b-7e83-4892-8938-b6ab68082287\n"]},{"output_type":"stream","name":"stdout","text":["✅ 완료 (학습용: 74391건, 테스트용: 18598건)\n","\n","==================================================\n","🔬 Step 2: Optuna 하이퍼파라미터 튜닝 시작 (PyTorch)\n","(최대 50번 시도, 10번 개선 없으면 스터디 조기 종료)\n","==================================================\n"]},{"output_type":"display_data","data":{"text/plain":["Optuna 튜닝 진행률:   0%|          | 0/50 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"879c817822604edfa5232c791edaa5a3"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2025-10-12 15:48:24,992] Trial 0 finished with value: 0.15192347228003172 and parameters: {'n_layers': 1, 'n_units_l0': 113, 'dropout_l0': 0.4266391290773144, 'learning_rate': 6.737352817892477e-05}. Best is trial 0 with value: 0.15192347228003172.\n","[I 2025-10-12 15:49:13,078] Trial 1 finished with value: 0.1465675852809513 and parameters: {'n_layers': 1, 'n_units_l0': 85, 'dropout_l0': 0.16891559285256597, 'learning_rate': 2.7830442058512113e-05}. Best is trial 0 with value: 0.15192347228003172.\n","[I 2025-10-12 15:50:04,454] Trial 2 finished with value: 0.1541960963431384 and parameters: {'n_layers': 2, 'n_units_l0': 35, 'dropout_l0': 0.3104531674853326, 'n_units_l1': 131, 'dropout_l1': 0.19173763166862623, 'learning_rate': 7.205981056702433e-05}. Best is trial 2 with value: 0.1541960963431384.\n","[I 2025-10-12 15:50:27,270] Trial 3 finished with value: 0.15127802936876047 and parameters: {'n_layers': 3, 'n_units_l0': 219, 'dropout_l0': 0.46224212479192617, 'n_units_l1': 298, 'dropout_l1': 0.11323509215728236, 'n_units_l2': 148, 'dropout_l2': 0.41066721544738494, 'learning_rate': 0.0009035720797733647}. Best is trial 2 with value: 0.1541960963431384.\n","[I 2025-10-12 15:50:38,260] Trial 4 finished with value: 0.13563153945166598 and parameters: {'n_layers': 5, 'n_units_l0': 118, 'dropout_l0': 0.2939063687866661, 'n_units_l1': 89, 'dropout_l1': 0.11408698848441397, 'n_units_l2': 156, 'dropout_l2': 0.45516158258136585, 'n_units_l3': 100, 'dropout_l3': 0.23759562423291802, 'n_units_l4': 66, 'dropout_l4': 0.22878219362148214, 'learning_rate': 0.008164057788330192}. Best is trial 2 with value: 0.1541960963431384.\n","[I 2025-10-12 15:50:39,296] Trial 5 pruned. \n","[I 2025-10-12 15:50:59,795] Trial 6 finished with value: 0.15087243090803232 and parameters: {'n_layers': 2, 'n_units_l0': 140, 'dropout_l0': 0.46926307418868607, 'n_units_l1': 452, 'dropout_l1': 0.26571729281254935, 'learning_rate': 0.0004938504805714287}. Best is trial 2 with value: 0.1541960963431384.\n","[I 2025-10-12 15:51:20,496] Trial 7 finished with value: 0.15278912968680947 and parameters: {'n_layers': 4, 'n_units_l0': 254, 'dropout_l0': 0.10707445822379223, 'n_units_l1': 107, 'dropout_l1': 0.13938343372785356, 'n_units_l2': 303, 'dropout_l2': 0.3539684124062017, 'n_units_l3': 103, 'dropout_l3': 0.4777200323582854, 'learning_rate': 0.0001813625211326569}. Best is trial 2 with value: 0.1541960963431384.\n","[I 2025-10-12 15:51:27,761] Trial 8 finished with value: 0.14374410200316085 and parameters: {'n_layers': 5, 'n_units_l0': 278, 'dropout_l0': 0.18591861705653112, 'n_units_l1': 224, 'dropout_l1': 0.20265085395890703, 'n_units_l2': 37, 'dropout_l2': 0.20190651045762598, 'n_units_l3': 33, 'dropout_l3': 0.27639315666784503, 'n_units_l4': 198, 'dropout_l4': 0.3528382768868391, 'learning_rate': 0.0062749752198738885}. Best is trial 2 with value: 0.1541960963431384.\n","[I 2025-10-12 15:51:29,004] Trial 9 pruned. \n","[I 2025-10-12 15:51:42,375] Trial 10 finished with value: 0.14857203316312406 and parameters: {'n_layers': 2, 'n_units_l0': 34, 'dropout_l0': 0.34739858319850253, 'n_units_l1': 33, 'dropout_l1': 0.41099571716289196, 'learning_rate': 0.001535623530486337}. Best is trial 2 with value: 0.1541960963431384.\n","[I 2025-10-12 15:51:43,735] Trial 11 pruned. \n","[I 2025-10-12 15:51:44,998] Trial 12 pruned. \n"]},{"output_type":"stream","name":"stdout","text":["\n","[Optuna 조기 종료] 10번의 trial 동안 최고 점수가 갱신되지 않아 튜닝을 중단합니다.\n","\n","✅ 튜닝 완료!\n","\n","==================================================\n","🔬 최적 하이퍼파라미터\n","==================================================\n","            n_layers: 2\n","          n_units_l0: 35\n","          dropout_l0: 0.3104531674853326\n","          n_units_l1: 131\n","          dropout_l1: 0.19173763166862623\n","       learning_rate: 7.205981056702433e-05\n","==================================================\n","\n","🔬 Step 3: 튜닝된 최종 PyTorch 모델 학습 및 평가...\n"]},{"output_type":"display_data","data":{"text/plain":["최종 모델 학습:   0%|          | 0/50 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4d2c558c9e624d909d8bfe6ded5b10e7"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["✅ 튜닝된 PyTorch 모델 평가 완료.\n","                      PR AUC  ROC AUC  F1-Score\n","Optuna_Tuned_PyTorch  0.1598   0.6711       0.0\n","\n","============================================================\n","💾 Step 4: 최종 모델 예측 결과를 원본 CSV에 추가하여 저장\n","============================================================\n"]},{"output_type":"display_data","data":{"text/plain":["전체 데이터 예측:   0%|          | 0/182 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"10e98966ebdc496d8ac2538f598b6e65"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["✅ 모든 데이터의 예측 결과가 '/content/drive/MyDrive/review_helpfulness/PADA/results/s2/audible/MLP/MLP_audible_with_BERT_predictions.csv' 파일에 성공적으로 저장되었습니다.\n","\n","============================================================\n","🧹 Step 5: 메모리 정리\n","============================================================\n","✅ 메모리 정리가 완료되었습니다.\n","\n","🎉 모든 과정이 완료되었습니다!\n"]}]},{"cell_type":"markdown","source":["## SentenceBERT"],"metadata":{"id":"bFp5NlZg5Uai"}},{"cell_type":"code","source":["# === 2. 환경설정 클래스 ===\n","class Config:\n","    \"\"\"실행에 필요한 모든 설정값을 중앙에서 관리합니다.\"\"\"\n","    # 🌟 1. 파일 경로 설정\n","    CSV_FILE_PATH = \"/content/drive/MyDrive/review_helpfulness/PADA/data/audible/audible.csv\"\n","    EMBEDDING_PATH = \"/content/drive/MyDrive/review_helpfulness/PADA/embedding/audible_SentenceBERT.npy\"\n","\n","    # 🌟 2. 최종 결과 CSV 파일 저장 경로 설정\n","    OUTPUT_CSV_PATH = \"/content/drive/MyDrive/review_helpfulness/PADA/results/s2/audible/MLP/MLP_audible_with_SentenceBERT_predictions.csv\"\n","\n","    # --- 데이터 정보 ---\n","    TARGET_COLUMN = 'binary_helpfulness'\n","\n","    # --- 데이터 분할 ---\n","    TEST_SPLIT_RATIO = 0.2\n","    RANDOM_STATE = 42\n","\n","    # --- PyTorch 모델 및 학습 설정 ---\n","    EPOCHS = 50\n","    BATCH_SIZE = 256\n","    VALIDATION_EARLY_STOPPING_PATIENCE = 5 # 개별 Trial 내 검증 성능 기반 조기 종료\n","\n","    # --- Optuna 튜닝 설정 ---\n","    N_TRIALS = 50\n","    TUNING_METRIC = 'pr_auc'\n","    STUDY_EARLY_STOPPING_ROUNDS = 10 # 전체 Study 조기 종료\n","\n","# === 3. MLP 모델 클래스 (PyTorch) ===\n","class MLP(nn.Module):\n","    def __init__(self, input_dim, trial):\n","        super(MLP, self).__init__()\n","        layers = []\n","\n","        # ✅ 은닉층 탐색 범위를 1~5개로 확장\n","        n_layers = trial.suggest_int('n_layers', 1, 5)\n","\n","        in_features = input_dim\n","        for i in range(n_layers):\n","            out_features = trial.suggest_int(f'n_units_l{i}', 32, 512, log=True)\n","            layers.append(nn.Linear(in_features, out_features))\n","            layers.append(nn.ReLU())\n","            p = trial.suggest_float(f'dropout_l{i}', 0.1, 0.5)\n","            layers.append(nn.Dropout(p))\n","            in_features = out_features\n","\n","        layers.append(nn.Linear(in_features, 1))\n","        self.layers = nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        return torch.sigmoid(self.layers(x).squeeze(-1))\n","\n","# === 4. 학습 및 평가 함수 ===\n","def train_model(model, loader, optimizer, criterion):\n","    model.train()\n","    for inputs, labels in loader:\n","        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n","        optimizer.zero_grad()\n","        outputs = model(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","def evaluate_model(model, loader):\n","    model.eval()\n","    all_preds = []\n","    all_labels = []\n","    with torch.no_grad():\n","        for inputs, labels in loader:\n","            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n","            outputs = model(inputs)\n","            all_preds.extend(outputs.cpu().numpy())\n","            all_labels.extend(labels.cpu().numpy())\n","    return np.array(all_preds), np.array(all_labels)\n","\n","# === 5. Optuna Objective 함수 (PyTorch용) ===\n","def objective(trial, X, y):\n","    X_train, X_val, y_train, y_val = train_test_split(\n","        X, y, test_size=0.25, random_state=Config.RANDOM_STATE, stratify=y)\n","\n","    train_dataset = TensorDataset(torch.FloatTensor(X_train), torch.FloatTensor(y_train))\n","    val_dataset = TensorDataset(torch.FloatTensor(X_val), torch.FloatTensor(y_val))\n","    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)\n","    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE)\n","\n","    input_dim = X_train.shape[1]\n","    model = MLP(input_dim, trial).to(DEVICE)\n","    lr = trial.suggest_float('learning_rate', 1e-5, 1e-2, log=True)\n","    optimizer = optim.Adam(model.parameters(), lr=lr)\n","    criterion = nn.BCELoss()\n","\n","    best_score = -1\n","    patience_counter = 0\n","\n","    for epoch in range(Config.EPOCHS):\n","        train_model(model, train_loader, optimizer, criterion)\n","        y_pred_proba, y_true = evaluate_model(model, val_loader)\n","        score = average_precision_score(y_true, y_pred_proba)\n","\n","        trial.report(score, epoch)\n","        if trial.should_prune():\n","            raise optuna.exceptions.TrialPruned()\n","\n","        if score > best_score:\n","            best_score = score\n","            patience_counter = 0\n","        else:\n","            patience_counter += 1\n","\n","        if patience_counter >= Config.VALIDATION_EARLY_STOPPING_PATIENCE:\n","            break\n","\n","    return best_score\n","\n","# === 6. Optuna 조기 종료 콜백 ===\n","class EarlyStoppingCallback:\n","    def __init__(self, early_stopping_rounds: int):\n","        self._early_stopping_rounds = early_stopping_rounds\n","        self._best_value = -float(\"inf\")\n","        self._counter = 0\n","\n","    def __call__(self, study: optuna.study.Study, trial: optuna.trial.Trial):\n","        current_best_value = study.best_value\n","        if current_best_value is not None and current_best_value > self._best_value:\n","            self._best_value = current_best_value\n","            self._counter = 0\n","        else:\n","            self._counter += 1\n","\n","        if self._counter >= self._early_stopping_rounds:\n","            print(f\"\\n[Optuna 조기 종료] {self._early_stopping_rounds}번의 trial 동안 최고 점수가 갱신되지 않아 튜닝을 중단합니다.\")\n","            study.stop()\n","\n","\n","# === 7. 메인 실행 블록 ===\n","if __name__ == '__main__':\n","    config = Config()\n","\n","    # --- Step 1: 데이터 로드 및 분할 ---\n","    print(\"\\n\" + \"=\"*50)\n","    print(\"📊 Step 1: 데이터 로드 및 분할\")\n","    try:\n","        df = pd.read_csv(config.CSV_FILE_PATH)\n","        labels = df[config.TARGET_COLUMN].values\n","        embeddings = np.load(config.EMBEDDING_PATH)\n","    except Exception as e:\n","        print(f\"🔥 파일 로드 실패: {e}\"); exit()\n","\n","    indices = np.arange(len(df))\n","    train_indices, test_indices = train_test_split(\n","        indices, test_size=config.TEST_SPLIT_RATIO, random_state=config.RANDOM_STATE, stratify=labels)\n","    X_train, X_test = embeddings[train_indices], embeddings[test_indices]\n","    y_train, y_test = labels[train_indices], labels[test_indices]\n","    print(f\"✅ 완료 (학습용: {len(y_train)}건, 테스트용: {len(y_test)}건)\")\n","\n","    # --- Step 2: Optuna 튜닝 수행 ---\n","    print(\"\\n\" + \"=\"*50)\n","    print(f\"🔬 Step 2: Optuna 하이퍼파라미터 튜닝 시작 (PyTorch)\")\n","    print(f\"(최대 {config.N_TRIALS}번 시도, {config.STUDY_EARLY_STOPPING_ROUNDS}번 개선 없으면 스터디 조기 종료)\")\n","    print(\"=\"*50)\n","\n","    study = optuna.create_study(direction='maximize', pruner=optuna.pruners.MedianPruner())\n","    pbar = tqdm(total=config.N_TRIALS, desc=\"Optuna 튜닝 진행률\")\n","\n","    try:\n","        study.optimize(lambda trial: objective(trial, X_train, y_train),\n","                       n_trials=config.N_TRIALS,\n","                       callbacks=[lambda s, t: pbar.update(1), EarlyStoppingCallback(config.STUDY_EARLY_STOPPING_ROUNDS)])\n","    except optuna.exceptions.OptunaError:\n","        pass # 조기 종료 시 예외 처리\n","    pbar.close()\n","\n","    # --- Step 3: 최적 모델 학습 및 평가 ---\n","    print(f\"\\n✅ 튜닝 완료!\")\n","    print(\"\\n\" + \"=\"*50)\n","    print(\"🔬 최적 하이퍼파라미터\")\n","    print(\"=\"*50)\n","    best_params = study.best_params\n","    for key, value in best_params.items():\n","        print(f\"{key:>20s}: {value}\")\n","    print(\"=\"*50)\n","\n","    print(f\"\\n🔬 Step 3: 튜닝된 최종 PyTorch 모델 학습 및 평가...\")\n","    train_dataset = TensorDataset(torch.FloatTensor(X_train), torch.FloatTensor(y_train))\n","    train_loader = DataLoader(train_dataset, batch_size=config.BATCH_SIZE, shuffle=True)\n","    test_dataset = TensorDataset(torch.FloatTensor(X_test), torch.FloatTensor(y_test))\n","    test_loader = DataLoader(test_dataset, batch_size=config.BATCH_SIZE)\n","\n","    # Optuna study 객체를 모의 trial로 사용하여 최종 모델 생성\n","    final_model = MLP(X_train.shape[1], study.best_trial).to(DEVICE)\n","    optimizer = optim.Adam(final_model.parameters(), lr=best_params['learning_rate'])\n","    criterion = nn.BCELoss()\n","\n","    # 최종 모델은 전체 학습 데이터로 학습\n","    for epoch in tqdm(range(config.EPOCHS), desc=\"최종 모델 학습\"):\n","        train_model(final_model, train_loader, optimizer, criterion)\n","\n","    y_pred_proba_tuned, y_true_test = evaluate_model(final_model, test_loader)\n","    y_pred_class_tuned = (y_pred_proba_tuned > 0.5).astype(int)\n","\n","    results = {\n","        \"PR AUC\": average_precision_score(y_true_test, y_pred_proba_tuned),\n","        \"ROC AUC\": roc_auc_score(y_true_test, y_pred_proba_tuned),\n","        \"F1-Score\": f1_score(y_true_test, y_pred_class_tuned),\n","    }\n","    print(\"✅ 튜닝된 PyTorch 모델 평가 완료.\")\n","    print(pd.DataFrame(results, index=['Optuna_Tuned_PyTorch']).round(4))\n","\n","    # --- Step 4: 결과 저장 ---\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"💾 Step 4: 최종 모델 예측 결과를 원본 CSV에 추가하여 저장\")\n","    print(\"=\"*60)\n","\n","    all_dataset = TensorDataset(torch.FloatTensor(embeddings))\n","    all_loader = DataLoader(all_dataset, batch_size=config.BATCH_SIZE * 2) # 예측 시에는 더 큰 배치 사용 가능\n","\n","    final_model.eval()\n","    all_predictions = []\n","    with torch.no_grad():\n","        for (inputs,) in tqdm(all_loader, desc=\"전체 데이터 예측\"):\n","            inputs = inputs.to(DEVICE)\n","            outputs = final_model(inputs)\n","            all_predictions.extend(outputs.cpu().numpy())\n","\n","    df['s2_pred_proba'] = all_predictions\n","    df['s2_pred_class'] = (df['s2_pred_proba'] > 0.5).astype(int)\n","\n","    df.to_csv(config.OUTPUT_CSV_PATH, index=False, encoding='utf-8-sig')\n","    print(f\"✅ 모든 데이터의 예측 결과가 '{config.OUTPUT_CSV_PATH}' 파일에 성공적으로 저장되었습니다.\")\n","\n","    # --- Step 5: 메모리 정리 ---\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"🧹 Step 5: 메모리 정리\")\n","    print(\"=\"*60)\n","    del df, labels, embeddings, X_train, X_test, y_train, y_test, final_model, study\n","    gc.collect()\n","    if torch.cuda.is_available():\n","        torch.cuda.empty_cache()\n","    print(\"✅ 메모리 정리가 완료되었습니다.\")\n","\n","    print(\"\\n🎉 모든 과정이 완료되었습니다!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["3361779c4a6f42c08999bdeb6274451a","055a4c6e69ab4cbcbbaa93c718bf807c","5e5c65ab15b14ef38d7b0119a89d725b","2841bc4c21374afc9940a006e55b135d","45160580d2174f31af2ec3aba98b1b42","97414ddbd2ac444abc8395e0d0d824d3","12b92bf2caa5499888a9f3a03e410639","3064a105dabd401b9fba9c161dd8e0a2","6604ecc96b944597a99d4c6cc6ef92e4","c746309f96d84f97b8d17b5cc7b39526","586c08150d7a4b7e9cd8964850341808","134b4e5825f0481fafb314b96434def5","03d3744ef9e149778da7cc881b4f994d","d8977955e7654d2ca13d0028853e151d","b3f793441cdf4f72ba4db1b172ff4df9","047952de6b2f4284b74cf3eca335f7b1","9de40692da164fe3b6df887d0c89a2cc","8d68dedd3bb7423cb8821fe97e484761","58a6b199129b46f4b8ec8c20bbc3411c","1eba94b6626f4473b380e16aacd40ed8","0bf00a7fb67a4e728ddee38e34d6b670","123452e5693142c2b1b2e49c9faa26eb","96fc8f01e9f6415a8eaf7d1489f928a7","191cfdcff8c64c189171784b3ce13d43","dcd0596d2164463386d7cc630214fc4c","37c0ab1f978e45a890d4365610d7273c","52d5f1579dff49988bb80feadaf17b87","5666a03f60454c9fa769b2d894450b60","c3d3f85968d54c269418ab42feb5d7e0","60b16eaf9cc245cfbaba4dcb604930de","b2325009d4494a06a82cf2218b6f5594","267bf87cf3f5447aa211b5e8f56b5f8c","e1c1c0c3529a44aba678c01c1bc0961a"]},"id":"eGoZVAXR8DlT","executionInfo":{"status":"ok","timestamp":1760284691694,"user_tz":-540,"elapsed":326789,"user":{"displayName":"KW-data-analytics","userId":"09651493752354345908"}},"outputId":"33c66210-506e-4693-c37b-32d4889c2787"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================================================\n","📊 Step 1: 데이터 로드 및 분할\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-10-12 15:52:52,213] A new study created in memory with name: no-name-177ff7b4-ba18-4b9f-94dd-3eb6ecdac401\n"]},{"output_type":"stream","name":"stdout","text":["✅ 완료 (학습용: 74391건, 테스트용: 18598건)\n","\n","==================================================\n","🔬 Step 2: Optuna 하이퍼파라미터 튜닝 시작 (PyTorch)\n","(최대 50번 시도, 10번 개선 없으면 스터디 조기 종료)\n","==================================================\n"]},{"output_type":"display_data","data":{"text/plain":["Optuna 튜닝 진행률:   0%|          | 0/50 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3361779c4a6f42c08999bdeb6274451a"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2025-10-12 15:53:00,136] Trial 0 finished with value: 0.14274299459979978 and parameters: {'n_layers': 1, 'n_units_l0': 487, 'dropout_l0': 0.45139303578864476, 'learning_rate': 0.007236977124199203}. Best is trial 0 with value: 0.14274299459979978.\n","[I 2025-10-12 15:54:00,763] Trial 1 finished with value: 0.13933499637589408 and parameters: {'n_layers': 5, 'n_units_l0': 44, 'dropout_l0': 0.18041571475643053, 'n_units_l1': 215, 'dropout_l1': 0.19838884725967107, 'n_units_l2': 46, 'dropout_l2': 0.41204714975308, 'n_units_l3': 62, 'dropout_l3': 0.22267341299817814, 'n_units_l4': 61, 'dropout_l4': 0.13538531395420722, 'learning_rate': 2.1675754163090682e-05}. Best is trial 0 with value: 0.14274299459979978.\n","[I 2025-10-12 15:54:58,619] Trial 2 finished with value: 0.1373829923412832 and parameters: {'n_layers': 4, 'n_units_l0': 59, 'dropout_l0': 0.3403626530764686, 'n_units_l1': 510, 'dropout_l1': 0.22659566107586193, 'n_units_l2': 38, 'dropout_l2': 0.47471210345369197, 'n_units_l3': 165, 'dropout_l3': 0.33738029967863437, 'learning_rate': 1.5654003756971042e-05}. Best is trial 0 with value: 0.14274299459979978.\n","[I 2025-10-12 15:55:05,839] Trial 3 finished with value: 0.08155622211879647 and parameters: {'n_layers': 4, 'n_units_l0': 50, 'dropout_l0': 0.18265796073636198, 'n_units_l1': 71, 'dropout_l1': 0.3363685981806658, 'n_units_l2': 55, 'dropout_l2': 0.3076982181577753, 'n_units_l3': 39, 'dropout_l3': 0.17882851256398255, 'learning_rate': 2.138338382700276e-05}. Best is trial 0 with value: 0.14274299459979978.\n","[I 2025-10-12 15:55:44,230] Trial 4 finished with value: 0.14106655697903858 and parameters: {'n_layers': 2, 'n_units_l0': 139, 'dropout_l0': 0.10263771790601953, 'n_units_l1': 256, 'dropout_l1': 0.32606643774666766, 'learning_rate': 6.959007337359937e-05}. Best is trial 0 with value: 0.14274299459979978.\n","[I 2025-10-12 15:55:45,358] Trial 5 pruned. \n","[I 2025-10-12 15:55:54,710] Trial 6 finished with value: 0.14068548720053892 and parameters: {'n_layers': 2, 'n_units_l0': 346, 'dropout_l0': 0.32673895833433547, 'n_units_l1': 463, 'dropout_l1': 0.2595420047392294, 'learning_rate': 0.008468472831683999}. Best is trial 0 with value: 0.14274299459979978.\n","[I 2025-10-12 15:55:56,159] Trial 7 pruned. \n","[I 2025-10-12 15:56:04,528] Trial 8 finished with value: 0.1426251766519013 and parameters: {'n_layers': 2, 'n_units_l0': 131, 'dropout_l0': 0.10570385612265172, 'n_units_l1': 216, 'dropout_l1': 0.21666190328035803, 'learning_rate': 0.0031934826695671297}. Best is trial 0 with value: 0.14274299459979978.\n","[I 2025-10-12 15:56:05,899] Trial 9 pruned. \n","[I 2025-10-12 15:56:23,532] Trial 10 finished with value: 0.14681246680088567 and parameters: {'n_layers': 1, 'n_units_l0': 510, 'dropout_l0': 0.48690023179074754, 'learning_rate': 0.0013577352771724437}. Best is trial 10 with value: 0.14681246680088567.\n","[I 2025-10-12 15:56:37,234] Trial 11 finished with value: 0.1453956179117674 and parameters: {'n_layers': 1, 'n_units_l0': 503, 'dropout_l0': 0.4966463832838817, 'learning_rate': 0.0015291940690920103}. Best is trial 10 with value: 0.14681246680088567.\n","[I 2025-10-12 15:56:38,364] Trial 12 pruned. \n","[I 2025-10-12 15:56:39,669] Trial 13 pruned. \n","[I 2025-10-12 15:56:40,886] Trial 14 pruned. \n","[I 2025-10-12 15:56:49,744] Trial 15 finished with value: 0.14227274118396466 and parameters: {'n_layers': 3, 'n_units_l0': 200, 'dropout_l0': 0.2633152199532143, 'n_units_l1': 33, 'dropout_l1': 0.4676147417144445, 'n_units_l2': 511, 'dropout_l2': 0.31264286255016493, 'learning_rate': 0.0021846078752904285}. Best is trial 10 with value: 0.14681246680088567.\n","[I 2025-10-12 15:56:50,885] Trial 16 pruned. \n","[I 2025-10-12 15:56:59,835] Trial 17 finished with value: 0.14298984684111013 and parameters: {'n_layers': 3, 'n_units_l0': 360, 'dropout_l0': 0.37518609219469196, 'n_units_l1': 98, 'dropout_l1': 0.3789367466554093, 'n_units_l2': 126, 'dropout_l2': 0.11352506221716091, 'learning_rate': 0.002152535283807957}. Best is trial 10 with value: 0.14681246680088567.\n","[I 2025-10-12 15:57:01,214] Trial 18 pruned. \n","[I 2025-10-12 15:57:02,374] Trial 19 pruned. \n","[I 2025-10-12 15:57:15,756] Trial 20 finished with value: 0.14168524427281226 and parameters: {'n_layers': 3, 'n_units_l0': 179, 'dropout_l0': 0.46025310474010817, 'n_units_l1': 130, 'dropout_l1': 0.11292166745117774, 'n_units_l2': 136, 'dropout_l2': 0.23555113714408854, 'learning_rate': 0.00389654987669139}. Best is trial 10 with value: 0.14681246680088567.\n"]},{"output_type":"stream","name":"stdout","text":["\n","[Optuna 조기 종료] 10번의 trial 동안 최고 점수가 갱신되지 않아 튜닝을 중단합니다.\n","\n","✅ 튜닝 완료!\n","\n","==================================================\n","🔬 최적 하이퍼파라미터\n","==================================================\n","            n_layers: 1\n","          n_units_l0: 510\n","          dropout_l0: 0.48690023179074754\n","       learning_rate: 0.0013577352771724437\n","==================================================\n","\n","🔬 Step 3: 튜닝된 최종 PyTorch 모델 학습 및 평가...\n"]},{"output_type":"display_data","data":{"text/plain":["최종 모델 학습:   0%|          | 0/50 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"134b4e5825f0481fafb314b96434def5"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["✅ 튜닝된 PyTorch 모델 평가 완료.\n","                      PR AUC  ROC AUC  F1-Score\n","Optuna_Tuned_PyTorch  0.1335   0.6256    0.0513\n","\n","============================================================\n","💾 Step 4: 최종 모델 예측 결과를 원본 CSV에 추가하여 저장\n","============================================================\n"]},{"output_type":"display_data","data":{"text/plain":["전체 데이터 예측:   0%|          | 0/182 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"96fc8f01e9f6415a8eaf7d1489f928a7"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["✅ 모든 데이터의 예측 결과가 '/content/drive/MyDrive/review_helpfulness/PADA/results/s2/audible/MLP/MLP_audible_with_SentenceBERT_predictions.csv' 파일에 성공적으로 저장되었습니다.\n","\n","============================================================\n","🧹 Step 5: 메모리 정리\n","============================================================\n","✅ 메모리 정리가 완료되었습니다.\n","\n","🎉 모든 과정이 완료되었습니다!\n"]}]},{"cell_type":"markdown","source":["## RoBERTa"],"metadata":{"id":"I8lf0hd25Uvs"}},{"cell_type":"code","source":["# === 2. 환경설정 클래스 ===\n","class Config:\n","    \"\"\"실행에 필요한 모든 설정값을 중앙에서 관리합니다.\"\"\"\n","    # 🌟 1. 파일 경로 설정\n","    CSV_FILE_PATH = \"/content/drive/MyDrive/review_helpfulness/PADA/data/audible/audible.csv\"\n","    EMBEDDING_PATH = \"/content/drive/MyDrive/review_helpfulness/PADA/embedding/audible_RoBERTa.npy\"\n","\n","    # 🌟 2. 최종 결과 CSV 파일 저장 경로 설정\n","    OUTPUT_CSV_PATH = \"/content/drive/MyDrive/review_helpfulness/PADA/results/s2/audible/MLP/MLP_audible_with_RoBERTa_predictions.csv\"\n","\n","    # --- 데이터 정보 ---\n","    TARGET_COLUMN = 'binary_helpfulness'\n","\n","    # --- 데이터 분할 ---\n","    TEST_SPLIT_RATIO = 0.2\n","    RANDOM_STATE = 42\n","\n","    # --- PyTorch 모델 및 학습 설정 ---\n","    EPOCHS = 50\n","    BATCH_SIZE = 256\n","    VALIDATION_EARLY_STOPPING_PATIENCE = 5 # 개별 Trial 내 검증 성능 기반 조기 종료\n","\n","    # --- Optuna 튜닝 설정 ---\n","    N_TRIALS = 50\n","    TUNING_METRIC = 'pr_auc'\n","    STUDY_EARLY_STOPPING_ROUNDS = 10 # 전체 Study 조기 종료\n","\n","# === 3. MLP 모델 클래스 (PyTorch) ===\n","class MLP(nn.Module):\n","    def __init__(self, input_dim, trial):\n","        super(MLP, self).__init__()\n","        layers = []\n","\n","        # ✅ 은닉층 탐색 범위를 1~5개로 확장\n","        n_layers = trial.suggest_int('n_layers', 1, 5)\n","\n","        in_features = input_dim\n","        for i in range(n_layers):\n","            out_features = trial.suggest_int(f'n_units_l{i}', 32, 512, log=True)\n","            layers.append(nn.Linear(in_features, out_features))\n","            layers.append(nn.ReLU())\n","            p = trial.suggest_float(f'dropout_l{i}', 0.1, 0.5)\n","            layers.append(nn.Dropout(p))\n","            in_features = out_features\n","\n","        layers.append(nn.Linear(in_features, 1))\n","        self.layers = nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        return torch.sigmoid(self.layers(x).squeeze(-1))\n","\n","# === 4. 학습 및 평가 함수 ===\n","def train_model(model, loader, optimizer, criterion):\n","    model.train()\n","    for inputs, labels in loader:\n","        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n","        optimizer.zero_grad()\n","        outputs = model(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","def evaluate_model(model, loader):\n","    model.eval()\n","    all_preds = []\n","    all_labels = []\n","    with torch.no_grad():\n","        for inputs, labels in loader:\n","            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n","            outputs = model(inputs)\n","            all_preds.extend(outputs.cpu().numpy())\n","            all_labels.extend(labels.cpu().numpy())\n","    return np.array(all_preds), np.array(all_labels)\n","\n","# === 5. Optuna Objective 함수 (PyTorch용) ===\n","def objective(trial, X, y):\n","    X_train, X_val, y_train, y_val = train_test_split(\n","        X, y, test_size=0.25, random_state=Config.RANDOM_STATE, stratify=y)\n","\n","    train_dataset = TensorDataset(torch.FloatTensor(X_train), torch.FloatTensor(y_train))\n","    val_dataset = TensorDataset(torch.FloatTensor(X_val), torch.FloatTensor(y_val))\n","    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)\n","    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE)\n","\n","    input_dim = X_train.shape[1]\n","    model = MLP(input_dim, trial).to(DEVICE)\n","    lr = trial.suggest_float('learning_rate', 1e-5, 1e-2, log=True)\n","    optimizer = optim.Adam(model.parameters(), lr=lr)\n","    criterion = nn.BCELoss()\n","\n","    best_score = -1\n","    patience_counter = 0\n","\n","    for epoch in range(Config.EPOCHS):\n","        train_model(model, train_loader, optimizer, criterion)\n","        y_pred_proba, y_true = evaluate_model(model, val_loader)\n","        score = average_precision_score(y_true, y_pred_proba)\n","\n","        trial.report(score, epoch)\n","        if trial.should_prune():\n","            raise optuna.exceptions.TrialPruned()\n","\n","        if score > best_score:\n","            best_score = score\n","            patience_counter = 0\n","        else:\n","            patience_counter += 1\n","\n","        if patience_counter >= Config.VALIDATION_EARLY_STOPPING_PATIENCE:\n","            break\n","\n","    return best_score\n","\n","# === 6. Optuna 조기 종료 콜백 ===\n","class EarlyStoppingCallback:\n","    def __init__(self, early_stopping_rounds: int):\n","        self._early_stopping_rounds = early_stopping_rounds\n","        self._best_value = -float(\"inf\")\n","        self._counter = 0\n","\n","    def __call__(self, study: optuna.study.Study, trial: optuna.trial.Trial):\n","        current_best_value = study.best_value\n","        if current_best_value is not None and current_best_value > self._best_value:\n","            self._best_value = current_best_value\n","            self._counter = 0\n","        else:\n","            self._counter += 1\n","\n","        if self._counter >= self._early_stopping_rounds:\n","            print(f\"\\n[Optuna 조기 종료] {self._early_stopping_rounds}번의 trial 동안 최고 점수가 갱신되지 않아 튜닝을 중단합니다.\")\n","            study.stop()\n","\n","\n","# === 7. 메인 실행 블록 ===\n","if __name__ == '__main__':\n","    config = Config()\n","\n","    # --- Step 1: 데이터 로드 및 분할 ---\n","    print(\"\\n\" + \"=\"*50)\n","    print(\"📊 Step 1: 데이터 로드 및 분할\")\n","    try:\n","        df = pd.read_csv(config.CSV_FILE_PATH)\n","        labels = df[config.TARGET_COLUMN].values\n","        embeddings = np.load(config.EMBEDDING_PATH)\n","    except Exception as e:\n","        print(f\"🔥 파일 로드 실패: {e}\"); exit()\n","\n","    indices = np.arange(len(df))\n","    train_indices, test_indices = train_test_split(\n","        indices, test_size=config.TEST_SPLIT_RATIO, random_state=config.RANDOM_STATE, stratify=labels)\n","    X_train, X_test = embeddings[train_indices], embeddings[test_indices]\n","    y_train, y_test = labels[train_indices], labels[test_indices]\n","    print(f\"✅ 완료 (학습용: {len(y_train)}건, 테스트용: {len(y_test)}건)\")\n","\n","    # --- Step 2: Optuna 튜닝 수행 ---\n","    print(\"\\n\" + \"=\"*50)\n","    print(f\"🔬 Step 2: Optuna 하이퍼파라미터 튜닝 시작 (PyTorch)\")\n","    print(f\"(최대 {config.N_TRIALS}번 시도, {config.STUDY_EARLY_STOPPING_ROUNDS}번 개선 없으면 스터디 조기 종료)\")\n","    print(\"=\"*50)\n","\n","    study = optuna.create_study(direction='maximize', pruner=optuna.pruners.MedianPruner())\n","    pbar = tqdm(total=config.N_TRIALS, desc=\"Optuna 튜닝 진행률\")\n","\n","    try:\n","        study.optimize(lambda trial: objective(trial, X_train, y_train),\n","                       n_trials=config.N_TRIALS,\n","                       callbacks=[lambda s, t: pbar.update(1), EarlyStoppingCallback(config.STUDY_EARLY_STOPPING_ROUNDS)])\n","    except optuna.exceptions.OptunaError:\n","        pass # 조기 종료 시 예외 처리\n","    pbar.close()\n","\n","    # --- Step 3: 최적 모델 학습 및 평가 ---\n","    print(f\"\\n✅ 튜닝 완료!\")\n","    print(\"\\n\" + \"=\"*50)\n","    print(\"🔬 최적 하이퍼파라미터\")\n","    print(\"=\"*50)\n","    best_params = study.best_params\n","    for key, value in best_params.items():\n","        print(f\"{key:>20s}: {value}\")\n","    print(\"=\"*50)\n","\n","    print(f\"\\n🔬 Step 3: 튜닝된 최종 PyTorch 모델 학습 및 평가...\")\n","    train_dataset = TensorDataset(torch.FloatTensor(X_train), torch.FloatTensor(y_train))\n","    train_loader = DataLoader(train_dataset, batch_size=config.BATCH_SIZE, shuffle=True)\n","    test_dataset = TensorDataset(torch.FloatTensor(X_test), torch.FloatTensor(y_test))\n","    test_loader = DataLoader(test_dataset, batch_size=config.BATCH_SIZE)\n","\n","    # Optuna study 객체를 모의 trial로 사용하여 최종 모델 생성\n","    final_model = MLP(X_train.shape[1], study.best_trial).to(DEVICE)\n","    optimizer = optim.Adam(final_model.parameters(), lr=best_params['learning_rate'])\n","    criterion = nn.BCELoss()\n","\n","    # 최종 모델은 전체 학습 데이터로 학습\n","    for epoch in tqdm(range(config.EPOCHS), desc=\"최종 모델 학습\"):\n","        train_model(final_model, train_loader, optimizer, criterion)\n","\n","    y_pred_proba_tuned, y_true_test = evaluate_model(final_model, test_loader)\n","    y_pred_class_tuned = (y_pred_proba_tuned > 0.5).astype(int)\n","\n","    results = {\n","        \"PR AUC\": average_precision_score(y_true_test, y_pred_proba_tuned),\n","        \"ROC AUC\": roc_auc_score(y_true_test, y_pred_proba_tuned),\n","        \"F1-Score\": f1_score(y_true_test, y_pred_class_tuned),\n","    }\n","    print(\"✅ 튜닝된 PyTorch 모델 평가 완료.\")\n","    print(pd.DataFrame(results, index=['Optuna_Tuned_PyTorch']).round(4))\n","\n","    # --- Step 4: 결과 저장 ---\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"💾 Step 4: 최종 모델 예측 결과를 원본 CSV에 추가하여 저장\")\n","    print(\"=\"*60)\n","\n","    all_dataset = TensorDataset(torch.FloatTensor(embeddings))\n","    all_loader = DataLoader(all_dataset, batch_size=config.BATCH_SIZE * 2) # 예측 시에는 더 큰 배치 사용 가능\n","\n","    final_model.eval()\n","    all_predictions = []\n","    with torch.no_grad():\n","        for (inputs,) in tqdm(all_loader, desc=\"전체 데이터 예측\"):\n","            inputs = inputs.to(DEVICE)\n","            outputs = final_model(inputs)\n","            all_predictions.extend(outputs.cpu().numpy())\n","\n","    df['s2_pred_proba'] = all_predictions\n","    df['s2_pred_class'] = (df['s2_pred_proba'] > 0.5).astype(int)\n","\n","    df.to_csv(config.OUTPUT_CSV_PATH, index=False, encoding='utf-8-sig')\n","    print(f\"✅ 모든 데이터의 예측 결과가 '{config.OUTPUT_CSV_PATH}' 파일에 성공적으로 저장되었습니다.\")\n","\n","    # --- Step 5: 메모리 정리 ---\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"🧹 Step 5: 메모리 정리\")\n","    print(\"=\"*60)\n","    del df, labels, embeddings, X_train, X_test, y_train, y_test, final_model, study\n","    gc.collect()\n","    if torch.cuda.is_available():\n","        torch.cuda.empty_cache()\n","    print(\"✅ 메모리 정리가 완료되었습니다.\")\n","\n","    print(\"\\n🎉 모든 과정이 완료되었습니다!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["dc9013c6bf194d2898383c04ecade3aa","ee3b88347ed94377b63f5e82358ac19e","4544a0d935224297bbd56fa6862a1e8e","1e6ac94acf654937a8982463d7854ebd","06c095b5441b439c8c57c6224fb429cd","d2a34fe53fc247fab19bea5bd933386d","4ad161787f6e43cc93c32b5194377987","4f4bda885a634cae8ecb6a356a1ee623","333c0cbb80ea4a2ba2e03c19091b7d9f","6eada2a3ad9048d388a9f32df647eb7b","693bb7771eea4b6f823387f7a3961cb6","3e96d162c3d3441aabc18cb190db7b9b","2d12a40656c14a1c9c3ee4c4ebbea5eb","b3e9e2e5e7254fbcbb3344d2e9a13028","6557f027fe674dfaa55e94d1845c8cd3","961231f972ba426eb8387ef923458304","dd500401af1a4c77b3b8338490821096","88ed3a132536428eb825ac892a277b25","7532473d934f43df92059f1a90ca8ecd","2a568776fbd148c295103580ebfdb472","4adbbddc998e4c49994896031acbc9dd","3062dab1f420436e823fdfe208c19a85","d1251744a38f40269a6bbf3334c6f102","603052a6d8ca4e9994776d30a5f889d7","bc1dc29a9b1c45f6aee973a3f9cf8f08","0b00f6110aa94dbbaec24a31ac4fccba","c1fbbb120f8646fe88435290be3c1306","afb51f1ddfaa48d9888ab4a1e96a42a0","3fd91c2ea3ae40aca8d570ac4b389b60","d36d0071f90d4d4fb2d2a006499f90d8","a95fabe00cb246aba4eb1f293914a20b","1ce2767c0a3949c096feee0faf8fdbd8","c6358750ef89400fb50029815c6e9158"]},"id":"ENNgZG1R8Lzd","executionInfo":{"status":"ok","timestamp":1760284979884,"user_tz":-540,"elapsed":288181,"user":{"displayName":"KW-data-analytics","userId":"09651493752354345908"}},"outputId":"f58b7828-a227-40be-fadc-1c48bcb156df"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================================================\n","📊 Step 1: 데이터 로드 및 분할\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-10-12 15:58:16,160] A new study created in memory with name: no-name-eb07c62e-56c0-4652-9561-eded89fb6207\n"]},{"output_type":"stream","name":"stdout","text":["✅ 완료 (학습용: 74391건, 테스트용: 18598건)\n","\n","==================================================\n","🔬 Step 2: Optuna 하이퍼파라미터 튜닝 시작 (PyTorch)\n","(최대 50번 시도, 10번 개선 없으면 스터디 조기 종료)\n","==================================================\n"]},{"output_type":"display_data","data":{"text/plain":["Optuna 튜닝 진행률:   0%|          | 0/50 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dc9013c6bf194d2898383c04ecade3aa"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2025-10-12 15:58:24,705] Trial 0 finished with value: 0.13174112968441126 and parameters: {'n_layers': 5, 'n_units_l0': 58, 'dropout_l0': 0.1872427037226173, 'n_units_l1': 41, 'dropout_l1': 0.16937730376870713, 'n_units_l2': 202, 'dropout_l2': 0.188976356249764, 'n_units_l3': 53, 'dropout_l3': 0.42253734889555805, 'n_units_l4': 107, 'dropout_l4': 0.45965439544069386, 'learning_rate': 0.007404959507944304}. Best is trial 0 with value: 0.13174112968441126.\n","[I 2025-10-12 15:58:57,521] Trial 1 finished with value: 0.16151646996896424 and parameters: {'n_layers': 3, 'n_units_l0': 45, 'dropout_l0': 0.43854356508708436, 'n_units_l1': 139, 'dropout_l1': 0.4815581827609485, 'n_units_l2': 256, 'dropout_l2': 0.47767365546224894, 'learning_rate': 0.0002771045602238846}. Best is trial 1 with value: 0.16151646996896424.\n","[I 2025-10-12 15:59:45,848] Trial 2 finished with value: 0.15098698276991518 and parameters: {'n_layers': 1, 'n_units_l0': 318, 'dropout_l0': 0.1870650144335862, 'learning_rate': 2.9713259019973843e-05}. Best is trial 1 with value: 0.16151646996896424.\n","[I 2025-10-12 16:00:30,117] Trial 3 finished with value: 0.15649577709739088 and parameters: {'n_layers': 5, 'n_units_l0': 35, 'dropout_l0': 0.1127546177221218, 'n_units_l1': 257, 'dropout_l1': 0.25531378403735994, 'n_units_l2': 92, 'dropout_l2': 0.2829549085072849, 'n_units_l3': 52, 'dropout_l3': 0.11233610478599294, 'n_units_l4': 63, 'dropout_l4': 0.2655864205996825, 'learning_rate': 0.00013271687334397793}. Best is trial 1 with value: 0.16151646996896424.\n","[I 2025-10-12 16:00:46,714] Trial 4 finished with value: 0.15665180621498415 and parameters: {'n_layers': 2, 'n_units_l0': 185, 'dropout_l0': 0.45687920005705085, 'n_units_l1': 58, 'dropout_l1': 0.17944312763072673, 'learning_rate': 0.0006381369121052317}. Best is trial 1 with value: 0.16151646996896424.\n","[I 2025-10-12 16:00:47,996] Trial 5 pruned. \n","[I 2025-10-12 16:00:57,666] Trial 6 pruned. \n","[I 2025-10-12 16:00:59,056] Trial 7 pruned. \n","[I 2025-10-12 16:01:25,275] Trial 8 finished with value: 0.15952492935195028 and parameters: {'n_layers': 4, 'n_units_l0': 298, 'dropout_l0': 0.3842221439475201, 'n_units_l1': 57, 'dropout_l1': 0.19575209329174403, 'n_units_l2': 328, 'dropout_l2': 0.19690517050314083, 'n_units_l3': 42, 'dropout_l3': 0.1406946347462159, 'learning_rate': 0.00025341973837404133}. Best is trial 1 with value: 0.16151646996896424.\n","[I 2025-10-12 16:01:43,801] Trial 9 finished with value: 0.15669008579139168 and parameters: {'n_layers': 3, 'n_units_l0': 296, 'dropout_l0': 0.20538116994872527, 'n_units_l1': 189, 'dropout_l1': 0.21696949826632275, 'n_units_l2': 344, 'dropout_l2': 0.10732687763458189, 'learning_rate': 0.0004086498289587861}. Best is trial 1 with value: 0.16151646996896424.\n","[I 2025-10-12 16:01:55,220] Trial 10 pruned. \n","[I 2025-10-12 16:01:56,387] Trial 11 pruned. \n"]},{"output_type":"stream","name":"stdout","text":["\n","[Optuna 조기 종료] 10번의 trial 동안 최고 점수가 갱신되지 않아 튜닝을 중단합니다.\n","\n","✅ 튜닝 완료!\n","\n","==================================================\n","🔬 최적 하이퍼파라미터\n","==================================================\n","            n_layers: 3\n","          n_units_l0: 45\n","          dropout_l0: 0.43854356508708436\n","          n_units_l1: 139\n","          dropout_l1: 0.4815581827609485\n","          n_units_l2: 256\n","          dropout_l2: 0.47767365546224894\n","       learning_rate: 0.0002771045602238846\n","==================================================\n","\n","🔬 Step 3: 튜닝된 최종 PyTorch 모델 학습 및 평가...\n"]},{"output_type":"display_data","data":{"text/plain":["최종 모델 학습:   0%|          | 0/50 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3e96d162c3d3441aabc18cb190db7b9b"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["✅ 튜닝된 PyTorch 모델 평가 완료.\n","                      PR AUC  ROC AUC  F1-Score\n","Optuna_Tuned_PyTorch  0.1642   0.6686       0.0\n","\n","============================================================\n","💾 Step 4: 최종 모델 예측 결과를 원본 CSV에 추가하여 저장\n","============================================================\n"]},{"output_type":"display_data","data":{"text/plain":["전체 데이터 예측:   0%|          | 0/182 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d1251744a38f40269a6bbf3334c6f102"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["✅ 모든 데이터의 예측 결과가 '/content/drive/MyDrive/review_helpfulness/PADA/results/s2/audible/MLP/MLP_audible_with_RoBERTa_predictions.csv' 파일에 성공적으로 저장되었습니다.\n","\n","============================================================\n","🧹 Step 5: 메모리 정리\n","============================================================\n","✅ 메모리 정리가 완료되었습니다.\n","\n","🎉 모든 과정이 완료되었습니다!\n"]}]},{"cell_type":"markdown","source":["## DistilBERT"],"metadata":{"id":"wd5ZNqBV5VCW"}},{"cell_type":"code","source":["# === 2. 환경설정 클래스 ===\n","class Config:\n","    \"\"\"실행에 필요한 모든 설정값을 중앙에서 관리합니다.\"\"\"\n","    # 🌟 1. 파일 경로 설정\n","    CSV_FILE_PATH = \"/content/drive/MyDrive/review_helpfulness/PADA/data/audible/audible.csv\"\n","    EMBEDDING_PATH = \"/content/drive/MyDrive/review_helpfulness/PADA/embedding/audible_DistilBERT.npy\"\n","\n","    # 🌟 2. 최종 결과 CSV 파일 저장 경로 설정\n","    OUTPUT_CSV_PATH = \"/content/drive/MyDrive/review_helpfulness/PADA/results/s2/audible/MLP/MLP_audible_with_DistilBERT_predictions.csv\"\n","\n","    # --- 데이터 정보 ---\n","    TARGET_COLUMN = 'binary_helpfulness'\n","\n","    # --- 데이터 분할 ---\n","    TEST_SPLIT_RATIO = 0.2\n","    RANDOM_STATE = 42\n","\n","    # --- PyTorch 모델 및 학습 설정 ---\n","    EPOCHS = 50\n","    BATCH_SIZE = 256\n","    VALIDATION_EARLY_STOPPING_PATIENCE = 5 # 개별 Trial 내 검증 성능 기반 조기 종료\n","\n","    # --- Optuna 튜닝 설정 ---\n","    N_TRIALS = 50\n","    TUNING_METRIC = 'pr_auc'\n","    STUDY_EARLY_STOPPING_ROUNDS = 10 # 전체 Study 조기 종료\n","\n","# === 3. MLP 모델 클래스 (PyTorch) ===\n","class MLP(nn.Module):\n","    def __init__(self, input_dim, trial):\n","        super(MLP, self).__init__()\n","        layers = []\n","\n","        # ✅ 은닉층 탐색 범위를 1~5개로 확장\n","        n_layers = trial.suggest_int('n_layers', 1, 5)\n","\n","        in_features = input_dim\n","        for i in range(n_layers):\n","            out_features = trial.suggest_int(f'n_units_l{i}', 32, 512, log=True)\n","            layers.append(nn.Linear(in_features, out_features))\n","            layers.append(nn.ReLU())\n","            p = trial.suggest_float(f'dropout_l{i}', 0.1, 0.5)\n","            layers.append(nn.Dropout(p))\n","            in_features = out_features\n","\n","        layers.append(nn.Linear(in_features, 1))\n","        self.layers = nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        return torch.sigmoid(self.layers(x).squeeze(-1))\n","\n","# === 4. 학습 및 평가 함수 ===\n","def train_model(model, loader, optimizer, criterion):\n","    model.train()\n","    for inputs, labels in loader:\n","        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n","        optimizer.zero_grad()\n","        outputs = model(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","def evaluate_model(model, loader):\n","    model.eval()\n","    all_preds = []\n","    all_labels = []\n","    with torch.no_grad():\n","        for inputs, labels in loader:\n","            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n","            outputs = model(inputs)\n","            all_preds.extend(outputs.cpu().numpy())\n","            all_labels.extend(labels.cpu().numpy())\n","    return np.array(all_preds), np.array(all_labels)\n","\n","# === 5. Optuna Objective 함수 (PyTorch용) ===\n","def objective(trial, X, y):\n","    X_train, X_val, y_train, y_val = train_test_split(\n","        X, y, test_size=0.25, random_state=Config.RANDOM_STATE, stratify=y)\n","\n","    train_dataset = TensorDataset(torch.FloatTensor(X_train), torch.FloatTensor(y_train))\n","    val_dataset = TensorDataset(torch.FloatTensor(X_val), torch.FloatTensor(y_val))\n","    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)\n","    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE)\n","\n","    input_dim = X_train.shape[1]\n","    model = MLP(input_dim, trial).to(DEVICE)\n","    lr = trial.suggest_float('learning_rate', 1e-5, 1e-2, log=True)\n","    optimizer = optim.Adam(model.parameters(), lr=lr)\n","    criterion = nn.BCELoss()\n","\n","    best_score = -1\n","    patience_counter = 0\n","\n","    for epoch in range(Config.EPOCHS):\n","        train_model(model, train_loader, optimizer, criterion)\n","        y_pred_proba, y_true = evaluate_model(model, val_loader)\n","        score = average_precision_score(y_true, y_pred_proba)\n","\n","        trial.report(score, epoch)\n","        if trial.should_prune():\n","            raise optuna.exceptions.TrialPruned()\n","\n","        if score > best_score:\n","            best_score = score\n","            patience_counter = 0\n","        else:\n","            patience_counter += 1\n","\n","        if patience_counter >= Config.VALIDATION_EARLY_STOPPING_PATIENCE:\n","            break\n","\n","    return best_score\n","\n","# === 6. Optuna 조기 종료 콜백 ===\n","class EarlyStoppingCallback:\n","    def __init__(self, early_stopping_rounds: int):\n","        self._early_stopping_rounds = early_stopping_rounds\n","        self._best_value = -float(\"inf\")\n","        self._counter = 0\n","\n","    def __call__(self, study: optuna.study.Study, trial: optuna.trial.Trial):\n","        current_best_value = study.best_value\n","        if current_best_value is not None and current_best_value > self._best_value:\n","            self._best_value = current_best_value\n","            self._counter = 0\n","        else:\n","            self._counter += 1\n","\n","        if self._counter >= self._early_stopping_rounds:\n","            print(f\"\\n[Optuna 조기 종료] {self._early_stopping_rounds}번의 trial 동안 최고 점수가 갱신되지 않아 튜닝을 중단합니다.\")\n","            study.stop()\n","\n","\n","# === 7. 메인 실행 블록 ===\n","if __name__ == '__main__':\n","    config = Config()\n","\n","    # --- Step 1: 데이터 로드 및 분할 ---\n","    print(\"\\n\" + \"=\"*50)\n","    print(\"📊 Step 1: 데이터 로드 및 분할\")\n","    try:\n","        df = pd.read_csv(config.CSV_FILE_PATH)\n","        labels = df[config.TARGET_COLUMN].values\n","        embeddings = np.load(config.EMBEDDING_PATH)\n","    except Exception as e:\n","        print(f\"🔥 파일 로드 실패: {e}\"); exit()\n","\n","    indices = np.arange(len(df))\n","    train_indices, test_indices = train_test_split(\n","        indices, test_size=config.TEST_SPLIT_RATIO, random_state=config.RANDOM_STATE, stratify=labels)\n","    X_train, X_test = embeddings[train_indices], embeddings[test_indices]\n","    y_train, y_test = labels[train_indices], labels[test_indices]\n","    print(f\"✅ 완료 (학습용: {len(y_train)}건, 테스트용: {len(y_test)}건)\")\n","\n","    # --- Step 2: Optuna 튜닝 수행 ---\n","    print(\"\\n\" + \"=\"*50)\n","    print(f\"🔬 Step 2: Optuna 하이퍼파라미터 튜닝 시작 (PyTorch)\")\n","    print(f\"(최대 {config.N_TRIALS}번 시도, {config.STUDY_EARLY_STOPPING_ROUNDS}번 개선 없으면 스터디 조기 종료)\")\n","    print(\"=\"*50)\n","\n","    study = optuna.create_study(direction='maximize', pruner=optuna.pruners.MedianPruner())\n","    pbar = tqdm(total=config.N_TRIALS, desc=\"Optuna 튜닝 진행률\")\n","\n","    try:\n","        study.optimize(lambda trial: objective(trial, X_train, y_train),\n","                       n_trials=config.N_TRIALS,\n","                       callbacks=[lambda s, t: pbar.update(1), EarlyStoppingCallback(config.STUDY_EARLY_STOPPING_ROUNDS)])\n","    except optuna.exceptions.OptunaError:\n","        pass # 조기 종료 시 예외 처리\n","    pbar.close()\n","\n","    # --- Step 3: 최적 모델 학습 및 평가 ---\n","    print(f\"\\n✅ 튜닝 완료!\")\n","    print(\"\\n\" + \"=\"*50)\n","    print(\"🔬 최적 하이퍼파라미터\")\n","    print(\"=\"*50)\n","    best_params = study.best_params\n","    for key, value in best_params.items():\n","        print(f\"{key:>20s}: {value}\")\n","    print(\"=\"*50)\n","\n","    print(f\"\\n🔬 Step 3: 튜닝된 최종 PyTorch 모델 학습 및 평가...\")\n","    train_dataset = TensorDataset(torch.FloatTensor(X_train), torch.FloatTensor(y_train))\n","    train_loader = DataLoader(train_dataset, batch_size=config.BATCH_SIZE, shuffle=True)\n","    test_dataset = TensorDataset(torch.FloatTensor(X_test), torch.FloatTensor(y_test))\n","    test_loader = DataLoader(test_dataset, batch_size=config.BATCH_SIZE)\n","\n","    # Optuna study 객체를 모의 trial로 사용하여 최종 모델 생성\n","    final_model = MLP(X_train.shape[1], study.best_trial).to(DEVICE)\n","    optimizer = optim.Adam(final_model.parameters(), lr=best_params['learning_rate'])\n","    criterion = nn.BCELoss()\n","\n","    # 최종 모델은 전체 학습 데이터로 학습\n","    for epoch in tqdm(range(config.EPOCHS), desc=\"최종 모델 학습\"):\n","        train_model(final_model, train_loader, optimizer, criterion)\n","\n","    y_pred_proba_tuned, y_true_test = evaluate_model(final_model, test_loader)\n","    y_pred_class_tuned = (y_pred_proba_tuned > 0.5).astype(int)\n","\n","    results = {\n","        \"PR AUC\": average_precision_score(y_true_test, y_pred_proba_tuned),\n","        \"ROC AUC\": roc_auc_score(y_true_test, y_pred_proba_tuned),\n","        \"F1-Score\": f1_score(y_true_test, y_pred_class_tuned),\n","    }\n","    print(\"✅ 튜닝된 PyTorch 모델 평가 완료.\")\n","    print(pd.DataFrame(results, index=['Optuna_Tuned_PyTorch']).round(4))\n","\n","    # --- Step 4: 결과 저장 ---\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"💾 Step 4: 최종 모델 예측 결과를 원본 CSV에 추가하여 저장\")\n","    print(\"=\"*60)\n","\n","    all_dataset = TensorDataset(torch.FloatTensor(embeddings))\n","    all_loader = DataLoader(all_dataset, batch_size=config.BATCH_SIZE * 2) # 예측 시에는 더 큰 배치 사용 가능\n","\n","    final_model.eval()\n","    all_predictions = []\n","    with torch.no_grad():\n","        for (inputs,) in tqdm(all_loader, desc=\"전체 데이터 예측\"):\n","            inputs = inputs.to(DEVICE)\n","            outputs = final_model(inputs)\n","            all_predictions.extend(outputs.cpu().numpy())\n","\n","    df['s2_pred_proba'] = all_predictions\n","    df['s2_pred_class'] = (df['s2_pred_proba'] > 0.5).astype(int)\n","\n","    df.to_csv(config.OUTPUT_CSV_PATH, index=False, encoding='utf-8-sig')\n","    print(f\"✅ 모든 데이터의 예측 결과가 '{config.OUTPUT_CSV_PATH}' 파일에 성공적으로 저장되었습니다.\")\n","\n","    # --- Step 5: 메모리 정리 ---\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"🧹 Step 5: 메모리 정리\")\n","    print(\"=\"*60)\n","    del df, labels, embeddings, X_train, X_test, y_train, y_test, final_model, study\n","    gc.collect()\n","    if torch.cuda.is_available():\n","        torch.cuda.empty_cache()\n","    print(\"✅ 메모리 정리가 완료되었습니다.\")\n","\n","    print(\"\\n🎉 모든 과정이 완료되었습니다!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["b05dd6a8218b4214905ae047a66d7569","69e2f14075994122bd13fa413e197f62","86e0b05e6d8048d4ac3800ad83c82dc3","7326ff0683794ef994d481e6c20791ae","fae00141112d4728bd317fa63d00f425","85b386b61c194477bec1a9777de481a5","461d8e9c495648108854f71872c8fbbb","7637a9d9f7b943c184025c78e181ce11","2f5e01975281416d95e583edf8c5bfab","8adafd2988dc4fd3880274c260da7327","d60df48179f34ae4b36bfa54f5b5189f","6b391705a5314ed5a1dd55e1c6a54254","8534e60491ff4b0ba6fbe1d93a829f58","ad72ce2b064d4506b9f1545bb8ff42c1","9e0f5da9cc334d2fa4b4bab5324743e7","1d4fef4d26af40b29063ae8ab9577a46","c0b3b47d32f14274b60e50e045e81c10","f7b46f6d93d342a6943dd130f23450bc","40233cbc790d4c99a55262a3fcc6e5c4","c2abbaaa49954e8fbbd00135d418f05d","7f2b043d41d94da3accb2a5b24b51d08","1e04b655aab04e6faea3dec2a9957cc3","e3198cf46ff0445289c751b5e31f054c","5131dbd30be24cc8a6db1e0f31acd0f3","486ba97899f74a2d88cd3ceeb6fc5da8","5bcb82440d114fa990d230f1685513e9","24dbeab8d7f94a9cb47b01359a6c6dc0","64c481014fc744868b0335e0b2a20811","ed33283562b344b3a02a85e71b1108c3","f70e28f1441d4848870a17ce6443470d","fc4caa7df9164818b84ea26ba64df6af","de16608c49124a99a25c631ea9a2e325","e64710ae490848bcb9d4e94ce2f8d0ec"]},"id":"ixrUCNgK8SNq","executionInfo":{"status":"ok","timestamp":1760285155021,"user_tz":-540,"elapsed":175128,"user":{"displayName":"KW-data-analytics","userId":"09651493752354345908"}},"outputId":"05113b1e-d69c-46b6-9baa-9fd90987ff12"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================================================\n","📊 Step 1: 데이터 로드 및 분할\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-10-12 16:03:04,333] A new study created in memory with name: no-name-d1ca03ac-c021-47e4-b83a-cca013693f19\n"]},{"output_type":"stream","name":"stdout","text":["✅ 완료 (학습용: 74391건, 테스트용: 18598건)\n","\n","==================================================\n","🔬 Step 2: Optuna 하이퍼파라미터 튜닝 시작 (PyTorch)\n","(최대 50번 시도, 10번 개선 없으면 스터디 조기 종료)\n","==================================================\n"]},{"output_type":"display_data","data":{"text/plain":["Optuna 튜닝 진행률:   0%|          | 0/50 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b05dd6a8218b4214905ae047a66d7569"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2025-10-12 16:03:11,788] Trial 0 finished with value: 0.13825621897110735 and parameters: {'n_layers': 5, 'n_units_l0': 100, 'dropout_l0': 0.31830034455787315, 'n_units_l1': 331, 'dropout_l1': 0.3558231209432291, 'n_units_l2': 162, 'dropout_l2': 0.16116065334673768, 'n_units_l3': 248, 'dropout_l3': 0.26019555960527124, 'n_units_l4': 274, 'dropout_l4': 0.4775818024222245, 'learning_rate': 0.003335294747810453}. Best is trial 0 with value: 0.13825621897110735.\n","[I 2025-10-12 16:03:35,972] Trial 1 finished with value: 0.15401570025082523 and parameters: {'n_layers': 5, 'n_units_l0': 319, 'dropout_l0': 0.3010126367862981, 'n_units_l1': 40, 'dropout_l1': 0.33554788935568425, 'n_units_l2': 203, 'dropout_l2': 0.46984624774219397, 'n_units_l3': 77, 'dropout_l3': 0.3838172560202051, 'n_units_l4': 45, 'dropout_l4': 0.43901527711761834, 'learning_rate': 0.0009127294789640938}. Best is trial 1 with value: 0.15401570025082523.\n","[I 2025-10-12 16:03:55,654] Trial 2 finished with value: 0.15460965771538474 and parameters: {'n_layers': 4, 'n_units_l0': 63, 'dropout_l0': 0.10338976975277406, 'n_units_l1': 179, 'dropout_l1': 0.14004911185529656, 'n_units_l2': 125, 'dropout_l2': 0.34161489081016616, 'n_units_l3': 200, 'dropout_l3': 0.23758740993938174, 'learning_rate': 0.0004524147038511728}. Best is trial 2 with value: 0.15460965771538474.\n","[I 2025-10-12 16:04:14,467] Trial 3 finished with value: 0.1504084498768373 and parameters: {'n_layers': 3, 'n_units_l0': 135, 'dropout_l0': 0.4211239569408507, 'n_units_l1': 47, 'dropout_l1': 0.10940859451919126, 'n_units_l2': 206, 'dropout_l2': 0.2436694018126509, 'learning_rate': 0.0009585995926417573}. Best is trial 2 with value: 0.15460965771538474.\n","[I 2025-10-12 16:04:35,217] Trial 4 finished with value: 0.15269768804965944 and parameters: {'n_layers': 3, 'n_units_l0': 331, 'dropout_l0': 0.2769838535334844, 'n_units_l1': 59, 'dropout_l1': 0.3279767315246501, 'n_units_l2': 457, 'dropout_l2': 0.15315012176288417, 'learning_rate': 0.000400742490481772}. Best is trial 2 with value: 0.15460965771538474.\n","[I 2025-10-12 16:04:36,397] Trial 5 pruned. \n","[I 2025-10-12 16:04:37,606] Trial 6 pruned. \n","[I 2025-10-12 16:04:41,234] Trial 7 pruned. \n","[I 2025-10-12 16:04:42,523] Trial 8 pruned. \n","[I 2025-10-12 16:04:43,805] Trial 9 pruned. \n","[I 2025-10-12 16:04:45,015] Trial 10 pruned. \n","[I 2025-10-12 16:04:46,265] Trial 11 pruned. \n","[I 2025-10-12 16:04:47,526] Trial 12 pruned. \n"]},{"output_type":"stream","name":"stdout","text":["\n","[Optuna 조기 종료] 10번의 trial 동안 최고 점수가 갱신되지 않아 튜닝을 중단합니다.\n","\n","✅ 튜닝 완료!\n","\n","==================================================\n","🔬 최적 하이퍼파라미터\n","==================================================\n","            n_layers: 4\n","          n_units_l0: 63\n","          dropout_l0: 0.10338976975277406\n","          n_units_l1: 179\n","          dropout_l1: 0.14004911185529656\n","          n_units_l2: 125\n","          dropout_l2: 0.34161489081016616\n","          n_units_l3: 200\n","          dropout_l3: 0.23758740993938174\n","       learning_rate: 0.0004524147038511728\n","==================================================\n","\n","🔬 Step 3: 튜닝된 최종 PyTorch 모델 학습 및 평가...\n"]},{"output_type":"display_data","data":{"text/plain":["최종 모델 학습:   0%|          | 0/50 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6b391705a5314ed5a1dd55e1c6a54254"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["✅ 튜닝된 PyTorch 모델 평가 완료.\n","                      PR AUC  ROC AUC  F1-Score\n","Optuna_Tuned_PyTorch  0.1204   0.6192    0.1106\n","\n","============================================================\n","💾 Step 4: 최종 모델 예측 결과를 원본 CSV에 추가하여 저장\n","============================================================\n"]},{"output_type":"display_data","data":{"text/plain":["전체 데이터 예측:   0%|          | 0/182 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e3198cf46ff0445289c751b5e31f054c"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["✅ 모든 데이터의 예측 결과가 '/content/drive/MyDrive/review_helpfulness/PADA/results/s2/audible/MLP/MLP_audible_with_DistilBERT_predictions.csv' 파일에 성공적으로 저장되었습니다.\n","\n","============================================================\n","🧹 Step 5: 메모리 정리\n","============================================================\n","✅ 메모리 정리가 완료되었습니다.\n","\n","🎉 모든 과정이 완료되었습니다!\n"]}]},{"cell_type":"markdown","source":["# Hotel"],"metadata":{"id":"Xad7gio75cJB"}},{"cell_type":"markdown","source":["## T5"],"metadata":{"id":"Slc92SZX5eQI"}},{"cell_type":"code","source":["# === 2. 환경설정 클래스 ===\n","class Config:\n","    \"\"\"실행에 필요한 모든 설정값을 중앙에서 관리합니다.\"\"\"\n","    # 🌟 1. 파일 경로 설정\n","    CSV_FILE_PATH = \"/content/drive/MyDrive/review_helpfulness/PADA/data/hotel/hotel.csv\"\n","    EMBEDDING_PATH = \"/content/drive/MyDrive/review_helpfulness/PADA/embedding/hotel_T5.npy\"\n","\n","    # 🌟 2. 최종 결과 CSV 파일 저장 경로 설정\n","    OUTPUT_CSV_PATH = \"/content/drive/MyDrive/review_helpfulness/PADA/results/s2/hotel/MLP/MLP_hotel_with_T5_predictions.csv\"\n","\n","    # --- 데이터 정보 ---\n","    TARGET_COLUMN = 'binary_helpfulness'\n","\n","    # --- 데이터 분할 ---\n","    TEST_SPLIT_RATIO = 0.2\n","    RANDOM_STATE = 42\n","\n","    # --- PyTorch 모델 및 학습 설정 ---\n","    EPOCHS = 50\n","    BATCH_SIZE = 256\n","    VALIDATION_EARLY_STOPPING_PATIENCE = 5 # 개별 Trial 내 검증 성능 기반 조기 종료\n","\n","    # --- Optuna 튜닝 설정 ---\n","    N_TRIALS = 50\n","    TUNING_METRIC = 'pr_auc'\n","    STUDY_EARLY_STOPPING_ROUNDS = 10 # 전체 Study 조기 종료\n","\n","# === 3. MLP 모델 클래스 (PyTorch) ===\n","class MLP(nn.Module):\n","    def __init__(self, input_dim, trial):\n","        super(MLP, self).__init__()\n","        layers = []\n","\n","        # ✅ 은닉층 탐색 범위를 1~5개로 확장\n","        n_layers = trial.suggest_int('n_layers', 1, 5)\n","\n","        in_features = input_dim\n","        for i in range(n_layers):\n","            out_features = trial.suggest_int(f'n_units_l{i}', 32, 512, log=True)\n","            layers.append(nn.Linear(in_features, out_features))\n","            layers.append(nn.ReLU())\n","            p = trial.suggest_float(f'dropout_l{i}', 0.1, 0.5)\n","            layers.append(nn.Dropout(p))\n","            in_features = out_features\n","\n","        layers.append(nn.Linear(in_features, 1))\n","        self.layers = nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        return torch.sigmoid(self.layers(x).squeeze(-1))\n","\n","# === 4. 학습 및 평가 함수 ===\n","def train_model(model, loader, optimizer, criterion):\n","    model.train()\n","    for inputs, labels in loader:\n","        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n","        optimizer.zero_grad()\n","        outputs = model(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","def evaluate_model(model, loader):\n","    model.eval()\n","    all_preds = []\n","    all_labels = []\n","    with torch.no_grad():\n","        for inputs, labels in loader:\n","            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n","            outputs = model(inputs)\n","            all_preds.extend(outputs.cpu().numpy())\n","            all_labels.extend(labels.cpu().numpy())\n","    return np.array(all_preds), np.array(all_labels)\n","\n","# === 5. Optuna Objective 함수 (PyTorch용) ===\n","def objective(trial, X, y):\n","    X_train, X_val, y_train, y_val = train_test_split(\n","        X, y, test_size=0.25, random_state=Config.RANDOM_STATE, stratify=y)\n","\n","    train_dataset = TensorDataset(torch.FloatTensor(X_train), torch.FloatTensor(y_train))\n","    val_dataset = TensorDataset(torch.FloatTensor(X_val), torch.FloatTensor(y_val))\n","    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)\n","    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE)\n","\n","    input_dim = X_train.shape[1]\n","    model = MLP(input_dim, trial).to(DEVICE)\n","    lr = trial.suggest_float('learning_rate', 1e-5, 1e-2, log=True)\n","    optimizer = optim.Adam(model.parameters(), lr=lr)\n","    criterion = nn.BCELoss()\n","\n","    best_score = -1\n","    patience_counter = 0\n","\n","    for epoch in range(Config.EPOCHS):\n","        train_model(model, train_loader, optimizer, criterion)\n","        y_pred_proba, y_true = evaluate_model(model, val_loader)\n","        score = average_precision_score(y_true, y_pred_proba)\n","\n","        trial.report(score, epoch)\n","        if trial.should_prune():\n","            raise optuna.exceptions.TrialPruned()\n","\n","        if score > best_score:\n","            best_score = score\n","            patience_counter = 0\n","        else:\n","            patience_counter += 1\n","\n","        if patience_counter >= Config.VALIDATION_EARLY_STOPPING_PATIENCE:\n","            break\n","\n","    return best_score\n","\n","# === 6. Optuna 조기 종료 콜백 ===\n","class EarlyStoppingCallback:\n","    def __init__(self, early_stopping_rounds: int):\n","        self._early_stopping_rounds = early_stopping_rounds\n","        self._best_value = -float(\"inf\")\n","        self._counter = 0\n","\n","    def __call__(self, study: optuna.study.Study, trial: optuna.trial.Trial):\n","        current_best_value = study.best_value\n","        if current_best_value is not None and current_best_value > self._best_value:\n","            self._best_value = current_best_value\n","            self._counter = 0\n","        else:\n","            self._counter += 1\n","\n","        if self._counter >= self._early_stopping_rounds:\n","            print(f\"\\n[Optuna 조기 종료] {self._early_stopping_rounds}번의 trial 동안 최고 점수가 갱신되지 않아 튜닝을 중단합니다.\")\n","            study.stop()\n","\n","\n","# === 7. 메인 실행 블록 ===\n","if __name__ == '__main__':\n","    config = Config()\n","\n","    # --- Step 1: 데이터 로드 및 분할 ---\n","    print(\"\\n\" + \"=\"*50)\n","    print(\"📊 Step 1: 데이터 로드 및 분할\")\n","    try:\n","        df = pd.read_csv(config.CSV_FILE_PATH)\n","        labels = df[config.TARGET_COLUMN].values\n","        embeddings = np.load(config.EMBEDDING_PATH)\n","    except Exception as e:\n","        print(f\"🔥 파일 로드 실패: {e}\"); exit()\n","\n","    indices = np.arange(len(df))\n","    train_indices, test_indices = train_test_split(\n","        indices, test_size=config.TEST_SPLIT_RATIO, random_state=config.RANDOM_STATE, stratify=labels)\n","    X_train, X_test = embeddings[train_indices], embeddings[test_indices]\n","    y_train, y_test = labels[train_indices], labels[test_indices]\n","    print(f\"✅ 완료 (학습용: {len(y_train)}건, 테스트용: {len(y_test)}건)\")\n","\n","    # --- Step 2: Optuna 튜닝 수행 ---\n","    print(\"\\n\" + \"=\"*50)\n","    print(f\"🔬 Step 2: Optuna 하이퍼파라미터 튜닝 시작 (PyTorch)\")\n","    print(f\"(최대 {config.N_TRIALS}번 시도, {config.STUDY_EARLY_STOPPING_ROUNDS}번 개선 없으면 스터디 조기 종료)\")\n","    print(\"=\"*50)\n","\n","    study = optuna.create_study(direction='maximize', pruner=optuna.pruners.MedianPruner())\n","    pbar = tqdm(total=config.N_TRIALS, desc=\"Optuna 튜닝 진행률\")\n","\n","    try:\n","        study.optimize(lambda trial: objective(trial, X_train, y_train),\n","                       n_trials=config.N_TRIALS,\n","                       callbacks=[lambda s, t: pbar.update(1), EarlyStoppingCallback(config.STUDY_EARLY_STOPPING_ROUNDS)])\n","    except optuna.exceptions.OptunaError:\n","        pass # 조기 종료 시 예외 처리\n","    pbar.close()\n","\n","    # --- Step 3: 최적 모델 학습 및 평가 ---\n","    print(f\"\\n✅ 튜닝 완료!\")\n","    print(\"\\n\" + \"=\"*50)\n","    print(\"🔬 최적 하이퍼파라미터\")\n","    print(\"=\"*50)\n","    best_params = study.best_params\n","    for key, value in best_params.items():\n","        print(f\"{key:>20s}: {value}\")\n","    print(\"=\"*50)\n","\n","    print(f\"\\n🔬 Step 3: 튜닝된 최종 PyTorch 모델 학습 및 평가...\")\n","    train_dataset = TensorDataset(torch.FloatTensor(X_train), torch.FloatTensor(y_train))\n","    train_loader = DataLoader(train_dataset, batch_size=config.BATCH_SIZE, shuffle=True)\n","    test_dataset = TensorDataset(torch.FloatTensor(X_test), torch.FloatTensor(y_test))\n","    test_loader = DataLoader(test_dataset, batch_size=config.BATCH_SIZE)\n","\n","    # Optuna study 객체를 모의 trial로 사용하여 최종 모델 생성\n","    final_model = MLP(X_train.shape[1], study.best_trial).to(DEVICE)\n","    optimizer = optim.Adam(final_model.parameters(), lr=best_params['learning_rate'])\n","    criterion = nn.BCELoss()\n","\n","    # 최종 모델은 전체 학습 데이터로 학습\n","    for epoch in tqdm(range(config.EPOCHS), desc=\"최종 모델 학습\"):\n","        train_model(final_model, train_loader, optimizer, criterion)\n","\n","    y_pred_proba_tuned, y_true_test = evaluate_model(final_model, test_loader)\n","    y_pred_class_tuned = (y_pred_proba_tuned > 0.5).astype(int)\n","\n","    results = {\n","        \"PR AUC\": average_precision_score(y_true_test, y_pred_proba_tuned),\n","        \"ROC AUC\": roc_auc_score(y_true_test, y_pred_proba_tuned),\n","        \"F1-Score\": f1_score(y_true_test, y_pred_class_tuned),\n","    }\n","    print(\"✅ 튜닝된 PyTorch 모델 평가 완료.\")\n","    print(pd.DataFrame(results, index=['Optuna_Tuned_PyTorch']).round(4))\n","\n","    # --- Step 4: 결과 저장 ---\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"💾 Step 4: 최종 모델 예측 결과를 원본 CSV에 추가하여 저장\")\n","    print(\"=\"*60)\n","\n","    all_dataset = TensorDataset(torch.FloatTensor(embeddings))\n","    all_loader = DataLoader(all_dataset, batch_size=config.BATCH_SIZE * 2) # 예측 시에는 더 큰 배치 사용 가능\n","\n","    final_model.eval()\n","    all_predictions = []\n","    with torch.no_grad():\n","        for (inputs,) in tqdm(all_loader, desc=\"전체 데이터 예측\"):\n","            inputs = inputs.to(DEVICE)\n","            outputs = final_model(inputs)\n","            all_predictions.extend(outputs.cpu().numpy())\n","\n","    df['s2_pred_proba'] = all_predictions\n","    df['s2_pred_class'] = (df['s2_pred_proba'] > 0.5).astype(int)\n","\n","    df.to_csv(config.OUTPUT_CSV_PATH, index=False, encoding='utf-8-sig')\n","    print(f\"✅ 모든 데이터의 예측 결과가 '{config.OUTPUT_CSV_PATH}' 파일에 성공적으로 저장되었습니다.\")\n","\n","    # --- Step 5: 메모리 정리 ---\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"🧹 Step 5: 메모리 정리\")\n","    print(\"=\"*60)\n","    del df, labels, embeddings, X_train, X_test, y_train, y_test, final_model, study\n","    gc.collect()\n","    if torch.cuda.is_available():\n","        torch.cuda.empty_cache()\n","    print(\"✅ 메모리 정리가 완료되었습니다.\")\n","\n","    print(\"\\n🎉 모든 과정이 완료되었습니다!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["5b60be2615e846b9b8a386f11ca04987","53be6671e3aa410aa034f5c8fab1c857","ab8f495f35a340c690c1de6826df9398","2096f498ba48488bb3864cc611f4cf12","5a96c559f10947cdb8c688f5ba594839","6dd4e0cf275047f1a6b5514cde6982ba","68f716ce09724cd89e6ea8ac541772fb","2b4124e2f98c436d8992ff6ef966ec7e","a26ec6b10cdc4e34973a664a3ae38282","1d067b658c3a4cb5a6fa2d89755c815a","9f9ddf22ece649c4ba4bd25535fe26fc","06ce44b840dd49aeaf7915166c6482d6","6753b379f69543c9958359a9ddb6d93f","3843e8cd20024e2e9ea33837f4df3f9a","2b2613b3760940e49e58db8bcab9dd09","920e1fcec2a94d2cb702ce96b33c22fa","08fb6ff3b7014521b6e9e35d8fe0f47c","23a034e2c2454be2ba82f6170522bfc2","a396967e50e546479c77f3223e2e746a","37d23728d2814e52a046ca6c3324cf8a","f62470bcae6643768ca2cc3be828863c","adf6d9cf29b14879a461a101d580e04c","aad68fc3c16c4bb2ba2c656004ae3644","a33ae8534262466ea31bc6621df89dfc","ddf50ff01ccd42ad86d9fd91dd24bed1","9f325aab75db410693695c0c35600c10","e33a9cc013d5487ea7aa32d3dad0bc1e","811ae03883f544669c93da8af6c0f6b1","a0cbd8b977254501828f0df9f7de99d3","ad4d0fb8abb34fc68fea83b0d756ed15","01ce99cbd5e24d30aab3c328d581886c","05a9cc6c6d394424962921059365f3f0","4dde4d1d5d234c98b3d2dc459113e6c3"]},"id":"VgNP8S5m8X8f","executionInfo":{"status":"ok","timestamp":1760285565844,"user_tz":-540,"elapsed":410225,"user":{"displayName":"KW-data-analytics","userId":"09651493752354345908"}},"outputId":"ea555612-853a-4905-c013-a239d096d5b6"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================================================\n","📊 Step 1: 데이터 로드 및 분할\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-10-12 16:06:01,286] A new study created in memory with name: no-name-3b496b69-0dc1-434f-a1e2-c816c87064a4\n"]},{"output_type":"stream","name":"stdout","text":["✅ 완료 (학습용: 71604건, 테스트용: 17901건)\n","\n","==================================================\n","🔬 Step 2: Optuna 하이퍼파라미터 튜닝 시작 (PyTorch)\n","(최대 50번 시도, 10번 개선 없으면 스터디 조기 종료)\n","==================================================\n"]},{"output_type":"display_data","data":{"text/plain":["Optuna 튜닝 진행률:   0%|          | 0/50 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5b60be2615e846b9b8a386f11ca04987"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2025-10-12 16:06:37,139] Trial 0 finished with value: 0.15161856912473623 and parameters: {'n_layers': 2, 'n_units_l0': 204, 'dropout_l0': 0.38539775517970076, 'n_units_l1': 37, 'dropout_l1': 0.21168123999466634, 'learning_rate': 0.0002877963856049959}. Best is trial 0 with value: 0.15161856912473623.\n","[I 2025-10-12 16:06:57,186] Trial 1 finished with value: 0.1528711980009655 and parameters: {'n_layers': 3, 'n_units_l0': 122, 'dropout_l0': 0.27529916434164037, 'n_units_l1': 230, 'dropout_l1': 0.4897739270964866, 'n_units_l2': 45, 'dropout_l2': 0.3621199109140255, 'learning_rate': 0.003349912006873451}. Best is trial 1 with value: 0.1528711980009655.\n","[I 2025-10-12 16:07:43,557] Trial 2 finished with value: 0.15006523292398286 and parameters: {'n_layers': 1, 'n_units_l0': 122, 'dropout_l0': 0.3329626027025907, 'learning_rate': 2.8862559756640022e-05}. Best is trial 1 with value: 0.1528711980009655.\n","[I 2025-10-12 16:08:02,234] Trial 3 finished with value: 0.15148220973489562 and parameters: {'n_layers': 5, 'n_units_l0': 71, 'dropout_l0': 0.15507725638707953, 'n_units_l1': 372, 'dropout_l1': 0.3797256801033204, 'n_units_l2': 57, 'dropout_l2': 0.1310832886628493, 'n_units_l3': 81, 'dropout_l3': 0.3029607563971276, 'n_units_l4': 189, 'dropout_l4': 0.14148701077394846, 'learning_rate': 0.0023925833672202787}. Best is trial 1 with value: 0.1528711980009655.\n","[I 2025-10-12 16:08:48,714] Trial 4 finished with value: 0.14970958205470666 and parameters: {'n_layers': 1, 'n_units_l0': 38, 'dropout_l0': 0.36005182996720175, 'learning_rate': 3.155692975865247e-05}. Best is trial 1 with value: 0.1528711980009655.\n","[I 2025-10-12 16:08:49,902] Trial 5 pruned. \n","[I 2025-10-12 16:08:56,969] Trial 6 finished with value: 0.15109796166588463 and parameters: {'n_layers': 2, 'n_units_l0': 183, 'dropout_l0': 0.41698302776907625, 'n_units_l1': 262, 'dropout_l1': 0.4375705596556957, 'learning_rate': 0.005497892875385977}. Best is trial 1 with value: 0.1528711980009655.\n","[I 2025-10-12 16:08:58,099] Trial 7 pruned. \n","[I 2025-10-12 16:09:13,151] Trial 8 finished with value: 0.151051360768712 and parameters: {'n_layers': 2, 'n_units_l0': 44, 'dropout_l0': 0.38401674470843916, 'n_units_l1': 189, 'dropout_l1': 0.37904302885424135, 'learning_rate': 0.00062132386955055}. Best is trial 1 with value: 0.1528711980009655.\n","[I 2025-10-12 16:09:33,030] Trial 9 finished with value: 0.15405365586164227 and parameters: {'n_layers': 5, 'n_units_l0': 93, 'dropout_l0': 0.2535067912349338, 'n_units_l1': 350, 'dropout_l1': 0.21047359199439045, 'n_units_l2': 299, 'dropout_l2': 0.23676201188898466, 'n_units_l3': 294, 'dropout_l3': 0.1238735409950142, 'n_units_l4': 48, 'dropout_l4': 0.2034552822520865, 'learning_rate': 0.0007362861200724239}. Best is trial 9 with value: 0.15405365586164227.\n","[I 2025-10-12 16:09:58,895] Trial 10 finished with value: 0.15640167409795352 and parameters: {'n_layers': 5, 'n_units_l0': 63, 'dropout_l0': 0.263680659400603, 'n_units_l1': 55, 'dropout_l1': 0.10568202750055611, 'n_units_l2': 291, 'dropout_l2': 0.4759803342847697, 'n_units_l3': 509, 'dropout_l3': 0.1375710460017681, 'n_units_l4': 34, 'dropout_l4': 0.3243266397204817, 'learning_rate': 0.00037486723905194493}. Best is trial 10 with value: 0.15640167409795352.\n","[I 2025-10-12 16:10:01,261] Trial 11 pruned. \n","[I 2025-10-12 16:10:02,526] Trial 12 pruned. \n","[I 2025-10-12 16:10:04,989] Trial 13 pruned. \n","[I 2025-10-12 16:10:06,189] Trial 14 pruned. \n","[I 2025-10-12 16:10:07,464] Trial 15 pruned. \n","[I 2025-10-12 16:10:29,895] Trial 16 finished with value: 0.15716158361643648 and parameters: {'n_layers': 4, 'n_units_l0': 494, 'dropout_l0': 0.24049679668559834, 'n_units_l1': 97, 'dropout_l1': 0.1564248789370703, 'n_units_l2': 104, 'dropout_l2': 0.25542965885665486, 'n_units_l3': 301, 'dropout_l3': 0.3685415777085128, 'learning_rate': 0.0008039619017433245}. Best is trial 16 with value: 0.15716158361643648.\n","[I 2025-10-12 16:10:45,502] Trial 17 finished with value: 0.15485890438356678 and parameters: {'n_layers': 4, 'n_units_l0': 457, 'dropout_l0': 0.1558557143123671, 'n_units_l1': 98, 'dropout_l1': 0.15734222882734566, 'n_units_l2': 112, 'dropout_l2': 0.41207052973906116, 'n_units_l3': 372, 'dropout_l3': 0.37427421593050303, 'learning_rate': 0.0013254556394695894}. Best is trial 16 with value: 0.15716158361643648.\n","[I 2025-10-12 16:10:46,708] Trial 18 pruned. \n","[I 2025-10-12 16:10:58,385] Trial 19 finished with value: 0.1519808522006272 and parameters: {'n_layers': 3, 'n_units_l0': 280, 'dropout_l0': 0.21935147373192235, 'n_units_l1': 99, 'dropout_l1': 0.2535697616881275, 'n_units_l2': 81, 'dropout_l2': 0.33407020722547365, 'learning_rate': 0.00784927664985238}. Best is trial 16 with value: 0.15716158361643648.\n","[I 2025-10-12 16:10:59,583] Trial 20 pruned. \n","[I 2025-10-12 16:11:14,118] Trial 21 finished with value: 0.15542258166592188 and parameters: {'n_layers': 4, 'n_units_l0': 509, 'dropout_l0': 0.14898677720902193, 'n_units_l1': 95, 'dropout_l1': 0.1509301838245028, 'n_units_l2': 102, 'dropout_l2': 0.4140849396489993, 'n_units_l3': 407, 'dropout_l3': 0.3842284568986577, 'learning_rate': 0.0012236022987338765}. Best is trial 16 with value: 0.15716158361643648.\n","[I 2025-10-12 16:11:34,278] Trial 22 finished with value: 0.15506528530388247 and parameters: {'n_layers': 4, 'n_units_l0': 365, 'dropout_l0': 0.10192465691823191, 'n_units_l1': 157, 'dropout_l1': 0.1418272909169277, 'n_units_l2': 74, 'dropout_l2': 0.43309745304832664, 'n_units_l3': 363, 'dropout_l3': 0.39553881005107916, 'learning_rate': 0.001332800235027098}. Best is trial 16 with value: 0.15716158361643648.\n","[I 2025-10-12 16:11:35,556] Trial 23 pruned. \n","[I 2025-10-12 16:11:36,768] Trial 24 pruned. \n","[I 2025-10-12 16:11:37,917] Trial 25 pruned. \n","[I 2025-10-12 16:11:40,568] Trial 26 pruned. \n"]},{"output_type":"stream","name":"stdout","text":["\n","[Optuna 조기 종료] 10번의 trial 동안 최고 점수가 갱신되지 않아 튜닝을 중단합니다.\n","\n","✅ 튜닝 완료!\n","\n","==================================================\n","🔬 최적 하이퍼파라미터\n","==================================================\n","            n_layers: 4\n","          n_units_l0: 494\n","          dropout_l0: 0.24049679668559834\n","          n_units_l1: 97\n","          dropout_l1: 0.1564248789370703\n","          n_units_l2: 104\n","          dropout_l2: 0.25542965885665486\n","          n_units_l3: 301\n","          dropout_l3: 0.3685415777085128\n","       learning_rate: 0.0008039619017433245\n","==================================================\n","\n","🔬 Step 3: 튜닝된 최종 PyTorch 모델 학습 및 평가...\n"]},{"output_type":"display_data","data":{"text/plain":["최종 모델 학습:   0%|          | 0/50 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"06ce44b840dd49aeaf7915166c6482d6"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["✅ 튜닝된 PyTorch 모델 평가 완료.\n","                      PR AUC  ROC AUC  F1-Score\n","Optuna_Tuned_PyTorch  0.1427   0.6092    0.0036\n","\n","============================================================\n","💾 Step 4: 최종 모델 예측 결과를 원본 CSV에 추가하여 저장\n","============================================================\n"]},{"output_type":"display_data","data":{"text/plain":["전체 데이터 예측:   0%|          | 0/175 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aad68fc3c16c4bb2ba2c656004ae3644"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["✅ 모든 데이터의 예측 결과가 '/content/drive/MyDrive/review_helpfulness/PADA/results/s2/hotel/MLP/MLP_hotel_with_T5_predictions.csv' 파일에 성공적으로 저장되었습니다.\n","\n","============================================================\n","🧹 Step 5: 메모리 정리\n","============================================================\n","✅ 메모리 정리가 완료되었습니다.\n","\n","🎉 모든 과정이 완료되었습니다!\n"]}]},{"cell_type":"markdown","source":["## BERT"],"metadata":{"id":"V5ZL0mAC5ed0"}},{"cell_type":"code","source":["# === 2. 환경설정 클래스 ===\n","class Config:\n","    \"\"\"실행에 필요한 모든 설정값을 중앙에서 관리합니다.\"\"\"\n","    # 🌟 1. 파일 경로 설정\n","    CSV_FILE_PATH = \"/content/drive/MyDrive/review_helpfulness/PADA/data/hotel/hotel.csv\"\n","    EMBEDDING_PATH = \"/content/drive/MyDrive/review_helpfulness/PADA/embedding/hotel_BERT.npy\"\n","\n","    # 🌟 2. 최종 결과 CSV 파일 저장 경로 설정\n","    OUTPUT_CSV_PATH = \"/content/drive/MyDrive/review_helpfulness/PADA/results/s2/hotel/MLP/MLP_hotel_with_BERT_predictions.csv\"\n","\n","    # --- 데이터 정보 ---\n","    TARGET_COLUMN = 'binary_helpfulness'\n","\n","    # --- 데이터 분할 ---\n","    TEST_SPLIT_RATIO = 0.2\n","    RANDOM_STATE = 42\n","\n","    # --- PyTorch 모델 및 학습 설정 ---\n","    EPOCHS = 50\n","    BATCH_SIZE = 256\n","    VALIDATION_EARLY_STOPPING_PATIENCE = 5 # 개별 Trial 내 검증 성능 기반 조기 종료\n","\n","    # --- Optuna 튜닝 설정 ---\n","    N_TRIALS = 50\n","    TUNING_METRIC = 'pr_auc'\n","    STUDY_EARLY_STOPPING_ROUNDS = 10 # 전체 Study 조기 종료\n","\n","# === 3. MLP 모델 클래스 (PyTorch) ===\n","class MLP(nn.Module):\n","    def __init__(self, input_dim, trial):\n","        super(MLP, self).__init__()\n","        layers = []\n","\n","        # ✅ 은닉층 탐색 범위를 1~5개로 확장\n","        n_layers = trial.suggest_int('n_layers', 1, 5)\n","\n","        in_features = input_dim\n","        for i in range(n_layers):\n","            out_features = trial.suggest_int(f'n_units_l{i}', 32, 512, log=True)\n","            layers.append(nn.Linear(in_features, out_features))\n","            layers.append(nn.ReLU())\n","            p = trial.suggest_float(f'dropout_l{i}', 0.1, 0.5)\n","            layers.append(nn.Dropout(p))\n","            in_features = out_features\n","\n","        layers.append(nn.Linear(in_features, 1))\n","        self.layers = nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        return torch.sigmoid(self.layers(x).squeeze(-1))\n","\n","# === 4. 학습 및 평가 함수 ===\n","def train_model(model, loader, optimizer, criterion):\n","    model.train()\n","    for inputs, labels in loader:\n","        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n","        optimizer.zero_grad()\n","        outputs = model(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","def evaluate_model(model, loader):\n","    model.eval()\n","    all_preds = []\n","    all_labels = []\n","    with torch.no_grad():\n","        for inputs, labels in loader:\n","            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n","            outputs = model(inputs)\n","            all_preds.extend(outputs.cpu().numpy())\n","            all_labels.extend(labels.cpu().numpy())\n","    return np.array(all_preds), np.array(all_labels)\n","\n","# === 5. Optuna Objective 함수 (PyTorch용) ===\n","def objective(trial, X, y):\n","    X_train, X_val, y_train, y_val = train_test_split(\n","        X, y, test_size=0.25, random_state=Config.RANDOM_STATE, stratify=y)\n","\n","    train_dataset = TensorDataset(torch.FloatTensor(X_train), torch.FloatTensor(y_train))\n","    val_dataset = TensorDataset(torch.FloatTensor(X_val), torch.FloatTensor(y_val))\n","    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)\n","    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE)\n","\n","    input_dim = X_train.shape[1]\n","    model = MLP(input_dim, trial).to(DEVICE)\n","    lr = trial.suggest_float('learning_rate', 1e-5, 1e-2, log=True)\n","    optimizer = optim.Adam(model.parameters(), lr=lr)\n","    criterion = nn.BCELoss()\n","\n","    best_score = -1\n","    patience_counter = 0\n","\n","    for epoch in range(Config.EPOCHS):\n","        train_model(model, train_loader, optimizer, criterion)\n","        y_pred_proba, y_true = evaluate_model(model, val_loader)\n","        score = average_precision_score(y_true, y_pred_proba)\n","\n","        trial.report(score, epoch)\n","        if trial.should_prune():\n","            raise optuna.exceptions.TrialPruned()\n","\n","        if score > best_score:\n","            best_score = score\n","            patience_counter = 0\n","        else:\n","            patience_counter += 1\n","\n","        if patience_counter >= Config.VALIDATION_EARLY_STOPPING_PATIENCE:\n","            break\n","\n","    return best_score\n","\n","# === 6. Optuna 조기 종료 콜백 ===\n","class EarlyStoppingCallback:\n","    def __init__(self, early_stopping_rounds: int):\n","        self._early_stopping_rounds = early_stopping_rounds\n","        self._best_value = -float(\"inf\")\n","        self._counter = 0\n","\n","    def __call__(self, study: optuna.study.Study, trial: optuna.trial.Trial):\n","        current_best_value = study.best_value\n","        if current_best_value is not None and current_best_value > self._best_value:\n","            self._best_value = current_best_value\n","            self._counter = 0\n","        else:\n","            self._counter += 1\n","\n","        if self._counter >= self._early_stopping_rounds:\n","            print(f\"\\n[Optuna 조기 종료] {self._early_stopping_rounds}번의 trial 동안 최고 점수가 갱신되지 않아 튜닝을 중단합니다.\")\n","            study.stop()\n","\n","\n","# === 7. 메인 실행 블록 ===\n","if __name__ == '__main__':\n","    config = Config()\n","\n","    # --- Step 1: 데이터 로드 및 분할 ---\n","    print(\"\\n\" + \"=\"*50)\n","    print(\"📊 Step 1: 데이터 로드 및 분할\")\n","    try:\n","        df = pd.read_csv(config.CSV_FILE_PATH)\n","        labels = df[config.TARGET_COLUMN].values\n","        embeddings = np.load(config.EMBEDDING_PATH)\n","    except Exception as e:\n","        print(f\"🔥 파일 로드 실패: {e}\"); exit()\n","\n","    indices = np.arange(len(df))\n","    train_indices, test_indices = train_test_split(\n","        indices, test_size=config.TEST_SPLIT_RATIO, random_state=config.RANDOM_STATE, stratify=labels)\n","    X_train, X_test = embeddings[train_indices], embeddings[test_indices]\n","    y_train, y_test = labels[train_indices], labels[test_indices]\n","    print(f\"✅ 완료 (학습용: {len(y_train)}건, 테스트용: {len(y_test)}건)\")\n","\n","    # --- Step 2: Optuna 튜닝 수행 ---\n","    print(\"\\n\" + \"=\"*50)\n","    print(f\"🔬 Step 2: Optuna 하이퍼파라미터 튜닝 시작 (PyTorch)\")\n","    print(f\"(최대 {config.N_TRIALS}번 시도, {config.STUDY_EARLY_STOPPING_ROUNDS}번 개선 없으면 스터디 조기 종료)\")\n","    print(\"=\"*50)\n","\n","    study = optuna.create_study(direction='maximize', pruner=optuna.pruners.MedianPruner())\n","    pbar = tqdm(total=config.N_TRIALS, desc=\"Optuna 튜닝 진행률\")\n","\n","    try:\n","        study.optimize(lambda trial: objective(trial, X_train, y_train),\n","                       n_trials=config.N_TRIALS,\n","                       callbacks=[lambda s, t: pbar.update(1), EarlyStoppingCallback(config.STUDY_EARLY_STOPPING_ROUNDS)])\n","    except optuna.exceptions.OptunaError:\n","        pass # 조기 종료 시 예외 처리\n","    pbar.close()\n","\n","    # --- Step 3: 최적 모델 학습 및 평가 ---\n","    print(f\"\\n✅ 튜닝 완료!\")\n","    print(\"\\n\" + \"=\"*50)\n","    print(\"🔬 최적 하이퍼파라미터\")\n","    print(\"=\"*50)\n","    best_params = study.best_params\n","    for key, value in best_params.items():\n","        print(f\"{key:>20s}: {value}\")\n","    print(\"=\"*50)\n","\n","    print(f\"\\n🔬 Step 3: 튜닝된 최종 PyTorch 모델 학습 및 평가...\")\n","    train_dataset = TensorDataset(torch.FloatTensor(X_train), torch.FloatTensor(y_train))\n","    train_loader = DataLoader(train_dataset, batch_size=config.BATCH_SIZE, shuffle=True)\n","    test_dataset = TensorDataset(torch.FloatTensor(X_test), torch.FloatTensor(y_test))\n","    test_loader = DataLoader(test_dataset, batch_size=config.BATCH_SIZE)\n","\n","    # Optuna study 객체를 모의 trial로 사용하여 최종 모델 생성\n","    final_model = MLP(X_train.shape[1], study.best_trial).to(DEVICE)\n","    optimizer = optim.Adam(final_model.parameters(), lr=best_params['learning_rate'])\n","    criterion = nn.BCELoss()\n","\n","    # 최종 모델은 전체 학습 데이터로 학습\n","    for epoch in tqdm(range(config.EPOCHS), desc=\"최종 모델 학습\"):\n","        train_model(final_model, train_loader, optimizer, criterion)\n","\n","    y_pred_proba_tuned, y_true_test = evaluate_model(final_model, test_loader)\n","    y_pred_class_tuned = (y_pred_proba_tuned > 0.5).astype(int)\n","\n","    results = {\n","        \"PR AUC\": average_precision_score(y_true_test, y_pred_proba_tuned),\n","        \"ROC AUC\": roc_auc_score(y_true_test, y_pred_proba_tuned),\n","        \"F1-Score\": f1_score(y_true_test, y_pred_class_tuned),\n","    }\n","    print(\"✅ 튜닝된 PyTorch 모델 평가 완료.\")\n","    print(pd.DataFrame(results, index=['Optuna_Tuned_PyTorch']).round(4))\n","\n","    # --- Step 4: 결과 저장 ---\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"💾 Step 4: 최종 모델 예측 결과를 원본 CSV에 추가하여 저장\")\n","    print(\"=\"*60)\n","\n","    all_dataset = TensorDataset(torch.FloatTensor(embeddings))\n","    all_loader = DataLoader(all_dataset, batch_size=config.BATCH_SIZE * 2) # 예측 시에는 더 큰 배치 사용 가능\n","\n","    final_model.eval()\n","    all_predictions = []\n","    with torch.no_grad():\n","        for (inputs,) in tqdm(all_loader, desc=\"전체 데이터 예측\"):\n","            inputs = inputs.to(DEVICE)\n","            outputs = final_model(inputs)\n","            all_predictions.extend(outputs.cpu().numpy())\n","\n","    df['s2_pred_proba'] = all_predictions\n","    df['s2_pred_class'] = (df['s2_pred_proba'] > 0.5).astype(int)\n","\n","    df.to_csv(config.OUTPUT_CSV_PATH, index=False, encoding='utf-8-sig')\n","    print(f\"✅ 모든 데이터의 예측 결과가 '{config.OUTPUT_CSV_PATH}' 파일에 성공적으로 저장되었습니다.\")\n","\n","    # --- Step 5: 메모리 정리 ---\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"🧹 Step 5: 메모리 정리\")\n","    print(\"=\"*60)\n","    del df, labels, embeddings, X_train, X_test, y_train, y_test, final_model, study\n","    gc.collect()\n","    if torch.cuda.is_available():\n","        torch.cuda.empty_cache()\n","    print(\"✅ 메모리 정리가 완료되었습니다.\")\n","\n","    print(\"\\n🎉 모든 과정이 완료되었습니다!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["68848bb41bc145bb90ddae4524070005","c7180b450add453a8ac1628838255399","c87c054738274d6c83db40ac4e5eba6d","56beecfabd4b479e94d4fde631639cfc","49924efc0afe48a088606806b32e926a","0d94b167727640b1944c472b609c15de","4d3b19a1aebd4b758d15a329b762cb3a","f3056bef8dfe4d2f978bb94b8de4bb89","20631af4a07f4a228661e4a5929d65e2","30568d9888ae4854a53cc4b05276f917","d317372d3419416ea8a3e04f71fdb52f","c1341a768f7a41e3961aee306e90e875","8bad9f1923864d229c1f3fac53c1b569","1c18f387c6b54010953b7ffa6c96bb49","5f883673852a4defa86f08210fb78060","9cffcde819784cc180119878969dc28e","e61beb0485014b559ddbe999a9703d9e","a5bfd8b788c24507818a4ca93e132821","1692e3158d884ba6b865a9cb09de78e9","ee59a240575c40238ac9f2963fac5cff","6636f71c7dd74319b53e53add792c136","05216eff3fa649e48b6de7d327a6014e","afe10afcde8b40f49d6028da66efeaa6","c139418e741241d596e87cc839ed433d","86e7100e5ec343aba6e8c4e0c810d9fc","08a0b73d2fd941668fb40c373f182d87","52381221f61541e0a7c74dbdc65f8e5b","d0c70493bb4b487ca33a00d49c25309b","0fa39f140f36422db7da74b1824d576c","80dc71fd3c8f43d3a245d9addef56a5e","c3e45240b4754e818a25e88b9187e269","ac3b09338dca4c9f90cd0e8304b0c4a3","55abdca2dfd543febbcf7e24527d33a6"]},"id":"WD620dHs8uFp","executionInfo":{"status":"ok","timestamp":1760285692495,"user_tz":-540,"elapsed":126648,"user":{"displayName":"KW-data-analytics","userId":"09651493752354345908"}},"outputId":"1617b5e1-6f9b-4ca6-9734-e2fa81842a97"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================================================\n","📊 Step 1: 데이터 로드 및 분할\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-10-12 16:12:49,898] A new study created in memory with name: no-name-657a184c-851a-46cc-b0e2-6db5f873e222\n"]},{"output_type":"stream","name":"stdout","text":["✅ 완료 (학습용: 71604건, 테스트용: 17901건)\n","\n","==================================================\n","🔬 Step 2: Optuna 하이퍼파라미터 튜닝 시작 (PyTorch)\n","(최대 50번 시도, 10번 개선 없으면 스터디 조기 종료)\n","==================================================\n"]},{"output_type":"display_data","data":{"text/plain":["Optuna 튜닝 진행률:   0%|          | 0/50 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"68848bb41bc145bb90ddae4524070005"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2025-10-12 16:12:58,447] Trial 0 finished with value: 0.15443806758029965 and parameters: {'n_layers': 3, 'n_units_l0': 132, 'dropout_l0': 0.3829208090034567, 'n_units_l1': 166, 'dropout_l1': 0.4060705367536662, 'n_units_l2': 113, 'dropout_l2': 0.18885584021139606, 'learning_rate': 0.0007189667171637848}. Best is trial 0 with value: 0.15443806758029965.\n","[I 2025-10-12 16:13:04,546] Trial 1 finished with value: 0.15431950651794485 and parameters: {'n_layers': 2, 'n_units_l0': 90, 'dropout_l0': 0.43045288632302003, 'n_units_l1': 88, 'dropout_l1': 0.3850870912237738, 'learning_rate': 0.004143467874781397}. Best is trial 0 with value: 0.15443806758029965.\n","[I 2025-10-12 16:13:12,079] Trial 2 finished with value: 0.15485281270657641 and parameters: {'n_layers': 1, 'n_units_l0': 105, 'dropout_l0': 0.1413700523847067, 'learning_rate': 0.0004884039439928777}. Best is trial 2 with value: 0.15485281270657641.\n","[I 2025-10-12 16:13:24,822] Trial 3 finished with value: 0.15644305603190206 and parameters: {'n_layers': 3, 'n_units_l0': 442, 'dropout_l0': 0.16857907069749684, 'n_units_l1': 176, 'dropout_l1': 0.1120750139980193, 'n_units_l2': 165, 'dropout_l2': 0.20016020252389768, 'learning_rate': 4.732208733802798e-05}. Best is trial 3 with value: 0.15644305603190206.\n","[I 2025-10-12 16:13:31,993] Trial 4 finished with value: 0.1495959826267864 and parameters: {'n_layers': 5, 'n_units_l0': 278, 'dropout_l0': 0.1825267832567156, 'n_units_l1': 40, 'dropout_l1': 0.26314707520817376, 'n_units_l2': 124, 'dropout_l2': 0.2439598660040846, 'n_units_l3': 348, 'dropout_l3': 0.37708948915947227, 'n_units_l4': 115, 'dropout_l4': 0.3685114728678398, 'learning_rate': 0.004954578864425247}. Best is trial 3 with value: 0.15644305603190206.\n","[I 2025-10-12 16:13:33,139] Trial 5 pruned. \n","[I 2025-10-12 16:13:35,196] Trial 6 pruned. \n","[I 2025-10-12 16:13:36,272] Trial 7 pruned. \n","[I 2025-10-12 16:13:37,690] Trial 8 pruned. \n","[I 2025-10-12 16:13:38,894] Trial 9 pruned. \n","[I 2025-10-12 16:13:40,116] Trial 10 pruned. \n","[I 2025-10-12 16:13:41,154] Trial 11 pruned. \n","[I 2025-10-12 16:13:42,195] Trial 12 pruned. \n","[I 2025-10-12 16:13:50,795] Trial 13 pruned. \n"]},{"output_type":"stream","name":"stdout","text":["\n","[Optuna 조기 종료] 10번의 trial 동안 최고 점수가 갱신되지 않아 튜닝을 중단합니다.\n","\n","✅ 튜닝 완료!\n","\n","==================================================\n","🔬 최적 하이퍼파라미터\n","==================================================\n","            n_layers: 3\n","          n_units_l0: 442\n","          dropout_l0: 0.16857907069749684\n","          n_units_l1: 176\n","          dropout_l1: 0.1120750139980193\n","          n_units_l2: 165\n","          dropout_l2: 0.20016020252389768\n","       learning_rate: 4.732208733802798e-05\n","==================================================\n","\n","🔬 Step 3: 튜닝된 최종 PyTorch 모델 학습 및 평가...\n"]},{"output_type":"display_data","data":{"text/plain":["최종 모델 학습:   0%|          | 0/50 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c1341a768f7a41e3961aee306e90e875"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["✅ 튜닝된 PyTorch 모델 평가 완료.\n","                      PR AUC  ROC AUC  F1-Score\n","Optuna_Tuned_PyTorch  0.1289   0.5936    0.0358\n","\n","============================================================\n","💾 Step 4: 최종 모델 예측 결과를 원본 CSV에 추가하여 저장\n","============================================================\n"]},{"output_type":"display_data","data":{"text/plain":["전체 데이터 예측:   0%|          | 0/175 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"afe10afcde8b40f49d6028da66efeaa6"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["✅ 모든 데이터의 예측 결과가 '/content/drive/MyDrive/review_helpfulness/PADA/results/s2/hotel/MLP/MLP_hotel_with_BERT_predictions.csv' 파일에 성공적으로 저장되었습니다.\n","\n","============================================================\n","🧹 Step 5: 메모리 정리\n","============================================================\n","✅ 메모리 정리가 완료되었습니다.\n","\n","🎉 모든 과정이 완료되었습니다!\n"]}]},{"cell_type":"markdown","source":["## SentenceBERT"],"metadata":{"id":"1qwXWW4V5e5F"}},{"cell_type":"code","source":["# === 2. 환경설정 클래스 ===\n","class Config:\n","    \"\"\"실행에 필요한 모든 설정값을 중앙에서 관리합니다.\"\"\"\n","    # 🌟 1. 파일 경로 설정\n","    CSV_FILE_PATH = \"/content/drive/MyDrive/review_helpfulness/PADA/data/hotel/hotel.csv\"\n","    EMBEDDING_PATH = \"/content/drive/MyDrive/review_helpfulness/PADA/embedding/hotel_SentenceBERT.npy\"\n","\n","    # 🌟 2. 최종 결과 CSV 파일 저장 경로 설정\n","    OUTPUT_CSV_PATH = \"/content/drive/MyDrive/review_helpfulness/PADA/results/s2/hotel/MLP/MLP_hotel_with_SentenceBERT_predictions.csv\"\n","\n","    # --- 데이터 정보 ---\n","    TARGET_COLUMN = 'binary_helpfulness'\n","\n","    # --- 데이터 분할 ---\n","    TEST_SPLIT_RATIO = 0.2\n","    RANDOM_STATE = 42\n","\n","    # --- PyTorch 모델 및 학습 설정 ---\n","    EPOCHS = 50\n","    BATCH_SIZE = 256\n","    VALIDATION_EARLY_STOPPING_PATIENCE = 5 # 개별 Trial 내 검증 성능 기반 조기 종료\n","\n","    # --- Optuna 튜닝 설정 ---\n","    N_TRIALS = 50\n","    TUNING_METRIC = 'pr_auc'\n","    STUDY_EARLY_STOPPING_ROUNDS = 10 # 전체 Study 조기 종료\n","\n","# === 3. MLP 모델 클래스 (PyTorch) ===\n","class MLP(nn.Module):\n","    def __init__(self, input_dim, trial):\n","        super(MLP, self).__init__()\n","        layers = []\n","\n","        # ✅ 은닉층 탐색 범위를 1~5개로 확장\n","        n_layers = trial.suggest_int('n_layers', 1, 5)\n","\n","        in_features = input_dim\n","        for i in range(n_layers):\n","            out_features = trial.suggest_int(f'n_units_l{i}', 32, 512, log=True)\n","            layers.append(nn.Linear(in_features, out_features))\n","            layers.append(nn.ReLU())\n","            p = trial.suggest_float(f'dropout_l{i}', 0.1, 0.5)\n","            layers.append(nn.Dropout(p))\n","            in_features = out_features\n","\n","        layers.append(nn.Linear(in_features, 1))\n","        self.layers = nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        return torch.sigmoid(self.layers(x).squeeze(-1))\n","\n","# === 4. 학습 및 평가 함수 ===\n","def train_model(model, loader, optimizer, criterion):\n","    model.train()\n","    for inputs, labels in loader:\n","        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n","        optimizer.zero_grad()\n","        outputs = model(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","def evaluate_model(model, loader):\n","    model.eval()\n","    all_preds = []\n","    all_labels = []\n","    with torch.no_grad():\n","        for inputs, labels in loader:\n","            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n","            outputs = model(inputs)\n","            all_preds.extend(outputs.cpu().numpy())\n","            all_labels.extend(labels.cpu().numpy())\n","    return np.array(all_preds), np.array(all_labels)\n","\n","# === 5. Optuna Objective 함수 (PyTorch용) ===\n","def objective(trial, X, y):\n","    X_train, X_val, y_train, y_val = train_test_split(\n","        X, y, test_size=0.25, random_state=Config.RANDOM_STATE, stratify=y)\n","\n","    train_dataset = TensorDataset(torch.FloatTensor(X_train), torch.FloatTensor(y_train))\n","    val_dataset = TensorDataset(torch.FloatTensor(X_val), torch.FloatTensor(y_val))\n","    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)\n","    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE)\n","\n","    input_dim = X_train.shape[1]\n","    model = MLP(input_dim, trial).to(DEVICE)\n","    lr = trial.suggest_float('learning_rate', 1e-5, 1e-2, log=True)\n","    optimizer = optim.Adam(model.parameters(), lr=lr)\n","    criterion = nn.BCELoss()\n","\n","    best_score = -1\n","    patience_counter = 0\n","\n","    for epoch in range(Config.EPOCHS):\n","        train_model(model, train_loader, optimizer, criterion)\n","        y_pred_proba, y_true = evaluate_model(model, val_loader)\n","        score = average_precision_score(y_true, y_pred_proba)\n","\n","        trial.report(score, epoch)\n","        if trial.should_prune():\n","            raise optuna.exceptions.TrialPruned()\n","\n","        if score > best_score:\n","            best_score = score\n","            patience_counter = 0\n","        else:\n","            patience_counter += 1\n","\n","        if patience_counter >= Config.VALIDATION_EARLY_STOPPING_PATIENCE:\n","            break\n","\n","    return best_score\n","\n","# === 6. Optuna 조기 종료 콜백 ===\n","class EarlyStoppingCallback:\n","    def __init__(self, early_stopping_rounds: int):\n","        self._early_stopping_rounds = early_stopping_rounds\n","        self._best_value = -float(\"inf\")\n","        self._counter = 0\n","\n","    def __call__(self, study: optuna.study.Study, trial: optuna.trial.Trial):\n","        current_best_value = study.best_value\n","        if current_best_value is not None and current_best_value > self._best_value:\n","            self._best_value = current_best_value\n","            self._counter = 0\n","        else:\n","            self._counter += 1\n","\n","        if self._counter >= self._early_stopping_rounds:\n","            print(f\"\\n[Optuna 조기 종료] {self._early_stopping_rounds}번의 trial 동안 최고 점수가 갱신되지 않아 튜닝을 중단합니다.\")\n","            study.stop()\n","\n","\n","# === 7. 메인 실행 블록 ===\n","if __name__ == '__main__':\n","    config = Config()\n","\n","    # --- Step 1: 데이터 로드 및 분할 ---\n","    print(\"\\n\" + \"=\"*50)\n","    print(\"📊 Step 1: 데이터 로드 및 분할\")\n","    try:\n","        df = pd.read_csv(config.CSV_FILE_PATH)\n","        labels = df[config.TARGET_COLUMN].values\n","        embeddings = np.load(config.EMBEDDING_PATH)\n","    except Exception as e:\n","        print(f\"🔥 파일 로드 실패: {e}\"); exit()\n","\n","    indices = np.arange(len(df))\n","    train_indices, test_indices = train_test_split(\n","        indices, test_size=config.TEST_SPLIT_RATIO, random_state=config.RANDOM_STATE, stratify=labels)\n","    X_train, X_test = embeddings[train_indices], embeddings[test_indices]\n","    y_train, y_test = labels[train_indices], labels[test_indices]\n","    print(f\"✅ 완료 (학습용: {len(y_train)}건, 테스트용: {len(y_test)}건)\")\n","\n","    # --- Step 2: Optuna 튜닝 수행 ---\n","    print(\"\\n\" + \"=\"*50)\n","    print(f\"🔬 Step 2: Optuna 하이퍼파라미터 튜닝 시작 (PyTorch)\")\n","    print(f\"(최대 {config.N_TRIALS}번 시도, {config.STUDY_EARLY_STOPPING_ROUNDS}번 개선 없으면 스터디 조기 종료)\")\n","    print(\"=\"*50)\n","\n","    study = optuna.create_study(direction='maximize', pruner=optuna.pruners.MedianPruner())\n","    pbar = tqdm(total=config.N_TRIALS, desc=\"Optuna 튜닝 진행률\")\n","\n","    try:\n","        study.optimize(lambda trial: objective(trial, X_train, y_train),\n","                       n_trials=config.N_TRIALS,\n","                       callbacks=[lambda s, t: pbar.update(1), EarlyStoppingCallback(config.STUDY_EARLY_STOPPING_ROUNDS)])\n","    except optuna.exceptions.OptunaError:\n","        pass # 조기 종료 시 예외 처리\n","    pbar.close()\n","\n","    # --- Step 3: 최적 모델 학습 및 평가 ---\n","    print(f\"\\n✅ 튜닝 완료!\")\n","    print(\"\\n\" + \"=\"*50)\n","    print(\"🔬 최적 하이퍼파라미터\")\n","    print(\"=\"*50)\n","    best_params = study.best_params\n","    for key, value in best_params.items():\n","        print(f\"{key:>20s}: {value}\")\n","    print(\"=\"*50)\n","\n","    print(f\"\\n🔬 Step 3: 튜닝된 최종 PyTorch 모델 학습 및 평가...\")\n","    train_dataset = TensorDataset(torch.FloatTensor(X_train), torch.FloatTensor(y_train))\n","    train_loader = DataLoader(train_dataset, batch_size=config.BATCH_SIZE, shuffle=True)\n","    test_dataset = TensorDataset(torch.FloatTensor(X_test), torch.FloatTensor(y_test))\n","    test_loader = DataLoader(test_dataset, batch_size=config.BATCH_SIZE)\n","\n","    # Optuna study 객체를 모의 trial로 사용하여 최종 모델 생성\n","    final_model = MLP(X_train.shape[1], study.best_trial).to(DEVICE)\n","    optimizer = optim.Adam(final_model.parameters(), lr=best_params['learning_rate'])\n","    criterion = nn.BCELoss()\n","\n","    # 최종 모델은 전체 학습 데이터로 학습\n","    for epoch in tqdm(range(config.EPOCHS), desc=\"최종 모델 학습\"):\n","        train_model(final_model, train_loader, optimizer, criterion)\n","\n","    y_pred_proba_tuned, y_true_test = evaluate_model(final_model, test_loader)\n","    y_pred_class_tuned = (y_pred_proba_tuned > 0.5).astype(int)\n","\n","    results = {\n","        \"PR AUC\": average_precision_score(y_true_test, y_pred_proba_tuned),\n","        \"ROC AUC\": roc_auc_score(y_true_test, y_pred_proba_tuned),\n","        \"F1-Score\": f1_score(y_true_test, y_pred_class_tuned),\n","    }\n","    print(\"✅ 튜닝된 PyTorch 모델 평가 완료.\")\n","    print(pd.DataFrame(results, index=['Optuna_Tuned_PyTorch']).round(4))\n","\n","    # --- Step 4: 결과 저장 ---\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"💾 Step 4: 최종 모델 예측 결과를 원본 CSV에 추가하여 저장\")\n","    print(\"=\"*60)\n","\n","    all_dataset = TensorDataset(torch.FloatTensor(embeddings))\n","    all_loader = DataLoader(all_dataset, batch_size=config.BATCH_SIZE * 2) # 예측 시에는 더 큰 배치 사용 가능\n","\n","    final_model.eval()\n","    all_predictions = []\n","    with torch.no_grad():\n","        for (inputs,) in tqdm(all_loader, desc=\"전체 데이터 예측\"):\n","            inputs = inputs.to(DEVICE)\n","            outputs = final_model(inputs)\n","            all_predictions.extend(outputs.cpu().numpy())\n","\n","    df['s2_pred_proba'] = all_predictions\n","    df['s2_pred_class'] = (df['s2_pred_proba'] > 0.5).astype(int)\n","\n","    df.to_csv(config.OUTPUT_CSV_PATH, index=False, encoding='utf-8-sig')\n","    print(f\"✅ 모든 데이터의 예측 결과가 '{config.OUTPUT_CSV_PATH}' 파일에 성공적으로 저장되었습니다.\")\n","\n","    # --- Step 5: 메모리 정리 ---\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"🧹 Step 5: 메모리 정리\")\n","    print(\"=\"*60)\n","    del df, labels, embeddings, X_train, X_test, y_train, y_test, final_model, study\n","    gc.collect()\n","    if torch.cuda.is_available():\n","        torch.cuda.empty_cache()\n","    print(\"✅ 메모리 정리가 완료되었습니다.\")\n","\n","    print(\"\\n🎉 모든 과정이 완료되었습니다!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["deb064377633438cbe2ff73cae1ad40a","8595a44783ac497fa775377bab913a98","483b765959f64dd3b007c57ed8481f3f","e553d15fa5694374950c1904ce198b51","364eb6d295c6479380742f5e95468c97","cd00d0368aa5472a8d163750aa596f50","21c604080ad74291b0d40b33079259b1","85af6d6537e741419eba2c3f9c40ec64","1645c78125b84196b578d6e2a8965d74","0d4d503d03664fb1a03fee31614b924f","2873c6575ee64f2fa2b1ff1e9c9778c8","2d0e1b44be1e400b9ae43920511a9a1d","d08ebb5d271948e4830477b172cedc7d","fa3e6a9d85ff46f2bd289734236889d8","4234263be3cd4fcaa9ecf1906c53b5f1","8dd359c92b0c4b279ae46212da9ca370","2ccf0c250cc7490fbd60834f7c900342","e695ac7f755740b78a0bdd5da8283a09","8df3a9c126684d2ca5a67ed9fc5f72d9","507482cc093b469c8cdfe0aa75f52120","8895a3cfe6844065a0358a71e4337b3d","a1204a778fdf46b686fed65b7ff865fd","830c61dd0bf245d6b79c758a19cb6ad1","8680eb015f26488fbd6637458a281dd3","27d2ffd197e4458b827f5e2e358a5716","503917cc7b004658aa331311416c83a7","05288c1d5527471bb500a94a0a3bb870","cdd6ebe87e1441d2a60bded440d6a948","17743ff6591049adb01ddd22d9e57ec2","16934732f62c416983b45eb116357d56","2074833f0ed8414581890f4e8b88b63f","3ae1fb29935449839264b5386711e44a","8811b9cfacc8404e97a1ddb6fdafdfcc"]},"id":"-cSDZJ7L80Aw","executionInfo":{"status":"ok","timestamp":1760286019897,"user_tz":-540,"elapsed":327398,"user":{"displayName":"KW-data-analytics","userId":"09651493752354345908"}},"outputId":"09c434ef-fce1-486d-a9db-e994d986a7a1"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================================================\n","📊 Step 1: 데이터 로드 및 분할\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-10-12 16:14:58,801] A new study created in memory with name: no-name-c0c1fe7b-ed57-4609-845f-42b075f6e465\n"]},{"output_type":"stream","name":"stdout","text":["✅ 완료 (학습용: 71604건, 테스트용: 17901건)\n","\n","==================================================\n","🔬 Step 2: Optuna 하이퍼파라미터 튜닝 시작 (PyTorch)\n","(최대 50번 시도, 10번 개선 없으면 스터디 조기 종료)\n","==================================================\n"]},{"output_type":"display_data","data":{"text/plain":["Optuna 튜닝 진행률:   0%|          | 0/50 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"deb064377633438cbe2ff73cae1ad40a"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2025-10-12 16:15:45,827] Trial 0 finished with value: 0.1394514622129316 and parameters: {'n_layers': 1, 'n_units_l0': 52, 'dropout_l0': 0.24493390119485922, 'learning_rate': 5.818679387726616e-05}. Best is trial 0 with value: 0.1394514622129316.\n","[I 2025-10-12 16:15:54,216] Trial 1 finished with value: 0.14646327296663497 and parameters: {'n_layers': 5, 'n_units_l0': 347, 'dropout_l0': 0.20801956196523008, 'n_units_l1': 36, 'dropout_l1': 0.24089193072600193, 'n_units_l2': 34, 'dropout_l2': 0.11682141150713142, 'n_units_l3': 95, 'dropout_l3': 0.41770891758899786, 'n_units_l4': 214, 'dropout_l4': 0.186530464230526, 'learning_rate': 0.006815571577882868}. Best is trial 1 with value: 0.14646327296663497.\n","[I 2025-10-12 16:16:35,760] Trial 2 finished with value: 0.14945227143781514 and parameters: {'n_layers': 3, 'n_units_l0': 36, 'dropout_l0': 0.3067426899340481, 'n_units_l1': 53, 'dropout_l1': 0.49930225763893876, 'n_units_l2': 54, 'dropout_l2': 0.4954321943107519, 'learning_rate': 9.251178316698593e-05}. Best is trial 2 with value: 0.14945227143781514.\n","[I 2025-10-12 16:16:46,714] Trial 3 finished with value: 0.1492391021459843 and parameters: {'n_layers': 5, 'n_units_l0': 391, 'dropout_l0': 0.1169804479167532, 'n_units_l1': 124, 'dropout_l1': 0.3519900783622917, 'n_units_l2': 104, 'dropout_l2': 0.4582727057278255, 'n_units_l3': 408, 'dropout_l3': 0.3782460210798463, 'n_units_l4': 163, 'dropout_l4': 0.3383376111657686, 'learning_rate': 0.000649241412297284}. Best is trial 2 with value: 0.14945227143781514.\n","[I 2025-10-12 16:17:27,542] Trial 4 finished with value: 0.15016974838651867 and parameters: {'n_layers': 1, 'n_units_l0': 58, 'dropout_l0': 0.28996430422356256, 'learning_rate': 0.00035124534214030684}. Best is trial 4 with value: 0.15016974838651867.\n","[I 2025-10-12 16:17:44,536] Trial 5 finished with value: 0.15165147906676546 and parameters: {'n_layers': 4, 'n_units_l0': 44, 'dropout_l0': 0.12688177257518532, 'n_units_l1': 56, 'dropout_l1': 0.4918106729950765, 'n_units_l2': 82, 'dropout_l2': 0.35253946981545714, 'n_units_l3': 44, 'dropout_l3': 0.1484093312324812, 'learning_rate': 0.00034737510898948706}. Best is trial 5 with value: 0.15165147906676546.\n","[I 2025-10-12 16:17:53,007] Trial 6 finished with value: 0.1485305661107902 and parameters: {'n_layers': 1, 'n_units_l0': 70, 'dropout_l0': 0.2170158685897194, 'learning_rate': 0.003817385050093528}. Best is trial 5 with value: 0.15165147906676546.\n","[I 2025-10-12 16:18:04,957] Trial 7 finished with value: 0.14636848924721904 and parameters: {'n_layers': 3, 'n_units_l0': 43, 'dropout_l0': 0.2819675103886352, 'n_units_l1': 194, 'dropout_l1': 0.2949546827744872, 'n_units_l2': 251, 'dropout_l2': 0.2139199610915374, 'learning_rate': 0.005163987514761525}. Best is trial 5 with value: 0.15165147906676546.\n","[I 2025-10-12 16:18:06,304] Trial 8 pruned. \n","[I 2025-10-12 16:18:07,549] Trial 9 pruned. \n","[I 2025-10-12 16:18:20,099] Trial 10 finished with value: 0.15169177712306517 and parameters: {'n_layers': 4, 'n_units_l0': 115, 'dropout_l0': 0.10253259669850084, 'n_units_l1': 73, 'dropout_l1': 0.12053414413052671, 'n_units_l2': 368, 'dropout_l2': 0.36311543015501163, 'n_units_l3': 35, 'dropout_l3': 0.10746081457551612, 'learning_rate': 0.0005774385668473865}. Best is trial 10 with value: 0.15169177712306517.\n","[I 2025-10-12 16:18:30,363] Trial 11 finished with value: 0.1487188694240183 and parameters: {'n_layers': 4, 'n_units_l0': 119, 'dropout_l0': 0.10616672512648241, 'n_units_l1': 67, 'dropout_l1': 0.10583678404545199, 'n_units_l2': 470, 'dropout_l2': 0.3648000975300622, 'n_units_l3': 39, 'dropout_l3': 0.11067936774853879, 'learning_rate': 0.0011477479291801906}. Best is trial 10 with value: 0.15169177712306517.\n","[I 2025-10-12 16:18:31,681] Trial 12 pruned. \n","[I 2025-10-12 16:18:44,277] Trial 13 finished with value: 0.15080598353540492 and parameters: {'n_layers': 4, 'n_units_l0': 198, 'dropout_l0': 0.1576030292678655, 'n_units_l1': 33, 'dropout_l1': 0.2024947295350579, 'n_units_l2': 73, 'dropout_l2': 0.339572875242979, 'n_units_l3': 52, 'dropout_l3': 0.2146309661683502, 'learning_rate': 0.0014265111003049496}. Best is trial 10 with value: 0.15169177712306517.\n","[I 2025-10-12 16:18:45,466] Trial 14 pruned. \n","[I 2025-10-12 16:18:58,068] Trial 15 finished with value: 0.14981189863527788 and parameters: {'n_layers': 4, 'n_units_l0': 231, 'dropout_l0': 0.16508367171363086, 'n_units_l1': 50, 'dropout_l1': 0.3952415427631033, 'n_units_l2': 198, 'dropout_l2': 0.41994266429562693, 'n_units_l3': 61, 'dropout_l3': 0.20311145219399795, 'learning_rate': 0.0019211738745378857}. Best is trial 10 with value: 0.15169177712306517.\n","[I 2025-10-12 16:18:59,319] Trial 16 pruned. \n","[I 2025-10-12 16:19:00,505] Trial 17 pruned. \n","[I 2025-10-12 16:19:01,815] Trial 18 pruned. \n","[I 2025-10-12 16:19:03,172] Trial 19 pruned. \n","[I 2025-10-12 16:19:14,000] Trial 20 finished with value: 0.1495587671252698 and parameters: {'n_layers': 5, 'n_units_l0': 508, 'dropout_l0': 0.2393445430749649, 'n_units_l1': 114, 'dropout_l1': 0.34982840914419633, 'n_units_l2': 147, 'dropout_l2': 0.40872297146599534, 'n_units_l3': 64, 'dropout_l3': 0.29618438251365786, 'n_units_l4': 484, 'dropout_l4': 0.14824171929254776, 'learning_rate': 0.002446482853955933}. Best is trial 10 with value: 0.15169177712306517.\n"]},{"output_type":"stream","name":"stdout","text":["\n","[Optuna 조기 종료] 10번의 trial 동안 최고 점수가 갱신되지 않아 튜닝을 중단합니다.\n","\n","✅ 튜닝 완료!\n","\n","==================================================\n","🔬 최적 하이퍼파라미터\n","==================================================\n","            n_layers: 4\n","          n_units_l0: 115\n","          dropout_l0: 0.10253259669850084\n","          n_units_l1: 73\n","          dropout_l1: 0.12053414413052671\n","          n_units_l2: 368\n","          dropout_l2: 0.36311543015501163\n","          n_units_l3: 35\n","          dropout_l3: 0.10746081457551612\n","       learning_rate: 0.0005774385668473865\n","==================================================\n","\n","🔬 Step 3: 튜닝된 최종 PyTorch 모델 학습 및 평가...\n"]},{"output_type":"display_data","data":{"text/plain":["최종 모델 학습:   0%|          | 0/50 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2d0e1b44be1e400b9ae43920511a9a1d"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["✅ 튜닝된 PyTorch 모델 평가 완료.\n","                      PR AUC  ROC AUC  F1-Score\n","Optuna_Tuned_PyTorch  0.1022   0.5317    0.0544\n","\n","============================================================\n","💾 Step 4: 최종 모델 예측 결과를 원본 CSV에 추가하여 저장\n","============================================================\n"]},{"output_type":"display_data","data":{"text/plain":["전체 데이터 예측:   0%|          | 0/175 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"830c61dd0bf245d6b79c758a19cb6ad1"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["✅ 모든 데이터의 예측 결과가 '/content/drive/MyDrive/review_helpfulness/PADA/results/s2/hotel/MLP/MLP_hotel_with_SentenceBERT_predictions.csv' 파일에 성공적으로 저장되었습니다.\n","\n","============================================================\n","🧹 Step 5: 메모리 정리\n","============================================================\n","✅ 메모리 정리가 완료되었습니다.\n","\n","🎉 모든 과정이 완료되었습니다!\n"]}]},{"cell_type":"markdown","source":["## RoBERTa"],"metadata":{"id":"jwoqsVkc5fFy"}},{"cell_type":"code","source":["# === 2. 환경설정 클래스 ===\n","class Config:\n","    \"\"\"실행에 필요한 모든 설정값을 중앙에서 관리합니다.\"\"\"\n","    # 🌟 1. 파일 경로 설정\n","    CSV_FILE_PATH = \"/content/drive/MyDrive/review_helpfulness/PADA/data/hotel/hotel.csv\"\n","    EMBEDDING_PATH = \"/content/drive/MyDrive/review_helpfulness/PADA/embedding/hotel_RoBERTa.npy\"\n","\n","    # 🌟 2. 최종 결과 CSV 파일 저장 경로 설정\n","    OUTPUT_CSV_PATH = \"/content/drive/MyDrive/review_helpfulness/PADA/results/s2/hotel/MLP/MLP_hotel_with_RoBERTa_predictions.csv\"\n","\n","    # --- 데이터 정보 ---\n","    TARGET_COLUMN = 'binary_helpfulness'\n","\n","    # --- 데이터 분할 ---\n","    TEST_SPLIT_RATIO = 0.2\n","    RANDOM_STATE = 42\n","\n","    # --- PyTorch 모델 및 학습 설정 ---\n","    EPOCHS = 50\n","    BATCH_SIZE = 256\n","    VALIDATION_EARLY_STOPPING_PATIENCE = 5 # 개별 Trial 내 검증 성능 기반 조기 종료\n","\n","    # --- Optuna 튜닝 설정 ---\n","    N_TRIALS = 50\n","    TUNING_METRIC = 'pr_auc'\n","    STUDY_EARLY_STOPPING_ROUNDS = 10 # 전체 Study 조기 종료\n","\n","# === 3. MLP 모델 클래스 (PyTorch) ===\n","class MLP(nn.Module):\n","    def __init__(self, input_dim, trial):\n","        super(MLP, self).__init__()\n","        layers = []\n","\n","        # ✅ 은닉층 탐색 범위를 1~5개로 확장\n","        n_layers = trial.suggest_int('n_layers', 1, 5)\n","\n","        in_features = input_dim\n","        for i in range(n_layers):\n","            out_features = trial.suggest_int(f'n_units_l{i}', 32, 512, log=True)\n","            layers.append(nn.Linear(in_features, out_features))\n","            layers.append(nn.ReLU())\n","            p = trial.suggest_float(f'dropout_l{i}', 0.1, 0.5)\n","            layers.append(nn.Dropout(p))\n","            in_features = out_features\n","\n","        layers.append(nn.Linear(in_features, 1))\n","        self.layers = nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        return torch.sigmoid(self.layers(x).squeeze(-1))\n","\n","# === 4. 학습 및 평가 함수 ===\n","def train_model(model, loader, optimizer, criterion):\n","    model.train()\n","    for inputs, labels in loader:\n","        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n","        optimizer.zero_grad()\n","        outputs = model(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","def evaluate_model(model, loader):\n","    model.eval()\n","    all_preds = []\n","    all_labels = []\n","    with torch.no_grad():\n","        for inputs, labels in loader:\n","            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n","            outputs = model(inputs)\n","            all_preds.extend(outputs.cpu().numpy())\n","            all_labels.extend(labels.cpu().numpy())\n","    return np.array(all_preds), np.array(all_labels)\n","\n","# === 5. Optuna Objective 함수 (PyTorch용) ===\n","def objective(trial, X, y):\n","    X_train, X_val, y_train, y_val = train_test_split(\n","        X, y, test_size=0.25, random_state=Config.RANDOM_STATE, stratify=y)\n","\n","    train_dataset = TensorDataset(torch.FloatTensor(X_train), torch.FloatTensor(y_train))\n","    val_dataset = TensorDataset(torch.FloatTensor(X_val), torch.FloatTensor(y_val))\n","    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)\n","    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE)\n","\n","    input_dim = X_train.shape[1]\n","    model = MLP(input_dim, trial).to(DEVICE)\n","    lr = trial.suggest_float('learning_rate', 1e-5, 1e-2, log=True)\n","    optimizer = optim.Adam(model.parameters(), lr=lr)\n","    criterion = nn.BCELoss()\n","\n","    best_score = -1\n","    patience_counter = 0\n","\n","    for epoch in range(Config.EPOCHS):\n","        train_model(model, train_loader, optimizer, criterion)\n","        y_pred_proba, y_true = evaluate_model(model, val_loader)\n","        score = average_precision_score(y_true, y_pred_proba)\n","\n","        trial.report(score, epoch)\n","        if trial.should_prune():\n","            raise optuna.exceptions.TrialPruned()\n","\n","        if score > best_score:\n","            best_score = score\n","            patience_counter = 0\n","        else:\n","            patience_counter += 1\n","\n","        if patience_counter >= Config.VALIDATION_EARLY_STOPPING_PATIENCE:\n","            break\n","\n","    return best_score\n","\n","# === 6. Optuna 조기 종료 콜백 ===\n","class EarlyStoppingCallback:\n","    def __init__(self, early_stopping_rounds: int):\n","        self._early_stopping_rounds = early_stopping_rounds\n","        self._best_value = -float(\"inf\")\n","        self._counter = 0\n","\n","    def __call__(self, study: optuna.study.Study, trial: optuna.trial.Trial):\n","        current_best_value = study.best_value\n","        if current_best_value is not None and current_best_value > self._best_value:\n","            self._best_value = current_best_value\n","            self._counter = 0\n","        else:\n","            self._counter += 1\n","\n","        if self._counter >= self._early_stopping_rounds:\n","            print(f\"\\n[Optuna 조기 종료] {self._early_stopping_rounds}번의 trial 동안 최고 점수가 갱신되지 않아 튜닝을 중단합니다.\")\n","            study.stop()\n","\n","\n","# === 7. 메인 실행 블록 ===\n","if __name__ == '__main__':\n","    config = Config()\n","\n","    # --- Step 1: 데이터 로드 및 분할 ---\n","    print(\"\\n\" + \"=\"*50)\n","    print(\"📊 Step 1: 데이터 로드 및 분할\")\n","    try:\n","        df = pd.read_csv(config.CSV_FILE_PATH)\n","        labels = df[config.TARGET_COLUMN].values\n","        embeddings = np.load(config.EMBEDDING_PATH)\n","    except Exception as e:\n","        print(f\"🔥 파일 로드 실패: {e}\"); exit()\n","\n","    indices = np.arange(len(df))\n","    train_indices, test_indices = train_test_split(\n","        indices, test_size=config.TEST_SPLIT_RATIO, random_state=config.RANDOM_STATE, stratify=labels)\n","    X_train, X_test = embeddings[train_indices], embeddings[test_indices]\n","    y_train, y_test = labels[train_indices], labels[test_indices]\n","    print(f\"✅ 완료 (학습용: {len(y_train)}건, 테스트용: {len(y_test)}건)\")\n","\n","    # --- Step 2: Optuna 튜닝 수행 ---\n","    print(\"\\n\" + \"=\"*50)\n","    print(f\"🔬 Step 2: Optuna 하이퍼파라미터 튜닝 시작 (PyTorch)\")\n","    print(f\"(최대 {config.N_TRIALS}번 시도, {config.STUDY_EARLY_STOPPING_ROUNDS}번 개선 없으면 스터디 조기 종료)\")\n","    print(\"=\"*50)\n","\n","    study = optuna.create_study(direction='maximize', pruner=optuna.pruners.MedianPruner())\n","    pbar = tqdm(total=config.N_TRIALS, desc=\"Optuna 튜닝 진행률\")\n","\n","    try:\n","        study.optimize(lambda trial: objective(trial, X_train, y_train),\n","                       n_trials=config.N_TRIALS,\n","                       callbacks=[lambda s, t: pbar.update(1), EarlyStoppingCallback(config.STUDY_EARLY_STOPPING_ROUNDS)])\n","    except optuna.exceptions.OptunaError:\n","        pass # 조기 종료 시 예외 처리\n","    pbar.close()\n","\n","    # --- Step 3: 최적 모델 학습 및 평가 ---\n","    print(f\"\\n✅ 튜닝 완료!\")\n","    print(\"\\n\" + \"=\"*50)\n","    print(\"🔬 최적 하이퍼파라미터\")\n","    print(\"=\"*50)\n","    best_params = study.best_params\n","    for key, value in best_params.items():\n","        print(f\"{key:>20s}: {value}\")\n","    print(\"=\"*50)\n","\n","    print(f\"\\n🔬 Step 3: 튜닝된 최종 PyTorch 모델 학습 및 평가...\")\n","    train_dataset = TensorDataset(torch.FloatTensor(X_train), torch.FloatTensor(y_train))\n","    train_loader = DataLoader(train_dataset, batch_size=config.BATCH_SIZE, shuffle=True)\n","    test_dataset = TensorDataset(torch.FloatTensor(X_test), torch.FloatTensor(y_test))\n","    test_loader = DataLoader(test_dataset, batch_size=config.BATCH_SIZE)\n","\n","    # Optuna study 객체를 모의 trial로 사용하여 최종 모델 생성\n","    final_model = MLP(X_train.shape[1], study.best_trial).to(DEVICE)\n","    optimizer = optim.Adam(final_model.parameters(), lr=best_params['learning_rate'])\n","    criterion = nn.BCELoss()\n","\n","    # 최종 모델은 전체 학습 데이터로 학습\n","    for epoch in tqdm(range(config.EPOCHS), desc=\"최종 모델 학습\"):\n","        train_model(final_model, train_loader, optimizer, criterion)\n","\n","    y_pred_proba_tuned, y_true_test = evaluate_model(final_model, test_loader)\n","    y_pred_class_tuned = (y_pred_proba_tuned > 0.5).astype(int)\n","\n","    results = {\n","        \"PR AUC\": average_precision_score(y_true_test, y_pred_proba_tuned),\n","        \"ROC AUC\": roc_auc_score(y_true_test, y_pred_proba_tuned),\n","        \"F1-Score\": f1_score(y_true_test, y_pred_class_tuned),\n","    }\n","    print(\"✅ 튜닝된 PyTorch 모델 평가 완료.\")\n","    print(pd.DataFrame(results, index=['Optuna_Tuned_PyTorch']).round(4))\n","\n","    # --- Step 4: 결과 저장 ---\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"💾 Step 4: 최종 모델 예측 결과를 원본 CSV에 추가하여 저장\")\n","    print(\"=\"*60)\n","\n","    all_dataset = TensorDataset(torch.FloatTensor(embeddings))\n","    all_loader = DataLoader(all_dataset, batch_size=config.BATCH_SIZE * 2) # 예측 시에는 더 큰 배치 사용 가능\n","\n","    final_model.eval()\n","    all_predictions = []\n","    with torch.no_grad():\n","        for (inputs,) in tqdm(all_loader, desc=\"전체 데이터 예측\"):\n","            inputs = inputs.to(DEVICE)\n","            outputs = final_model(inputs)\n","            all_predictions.extend(outputs.cpu().numpy())\n","\n","    df['s2_pred_proba'] = all_predictions\n","    df['s2_pred_class'] = (df['s2_pred_proba'] > 0.5).astype(int)\n","\n","    df.to_csv(config.OUTPUT_CSV_PATH, index=False, encoding='utf-8-sig')\n","    print(f\"✅ 모든 데이터의 예측 결과가 '{config.OUTPUT_CSV_PATH}' 파일에 성공적으로 저장되었습니다.\")\n","\n","    # --- Step 5: 메모리 정리 ---\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"🧹 Step 5: 메모리 정리\")\n","    print(\"=\"*60)\n","    del df, labels, embeddings, X_train, X_test, y_train, y_test, final_model, study\n","    gc.collect()\n","    if torch.cuda.is_available():\n","        torch.cuda.empty_cache()\n","    print(\"✅ 메모리 정리가 완료되었습니다.\")\n","\n","    print(\"\\n🎉 모든 과정이 완료되었습니다!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["74ee21b548054a208c9cf65cbe5183b6","c446118c154d461b987d24f2d199009d","f8e7cb29355b41aeae9377f0e13cd54f","5deb20c992c644c4bc4edee8af6ed796","3593fce9219e4ac3a8867f9d4dab4e41","53311d4060fd4abf9403531214950336","e56620c0c6fc4dca9467db9ee5b3bc24","66da635189424b2ab8948a6ef61b89cd","bfc4a527fee049839822e485a116e022","5da0796230fa4b46bdc89b165aa00528","9455c48cfdc2443d97300181e26b576d","31bec6fc0bf243c487870009482d9ec1","6a181ad378a147268cae3766e9663305","b9b562266c4a4546a957d728241d7039","f1badbb2fd3b4007be2c3101facfe7cc","0377664fcda24e5bb3777adc636cb176","6849c5bb716249adb00d089165298141","469e31243e1541ddac9227486b6c067c","02e22a2c7a9a406d862a0a33cf712f43","e857804bddf4466dabce6cbd9cd32720","881df015d2dd459bb7a159d5f332f1ea","d51fd3cba9284b4e95f2a1814e188717","b028de5e99e94ad89c0ce0575f294c57","287299b4311a4fd4a3e1f723d445ade2","36a5eb257f6b44a28504d9588f5b486d","cfc831f1ccc142ef95f584766ae573a0","61aa07bd4f5d4ff9a2357de86a0cb66e","d3c6741ab36f4a7ab548aa67ebd17db2","9a78c94b44554e60b2322f8a0d8587a1","2f31da221525436cbd7338dadeac1a88","053e17bcd54c447b95a1dc8ce662cc3c","bb40e5d59f374d40946036219a5b7eb1","50dd4e5d3b134f58bce71707e5135577"]},"id":"a5mEfKHM843u","executionInfo":{"status":"ok","timestamp":1760286226847,"user_tz":-540,"elapsed":206948,"user":{"displayName":"KW-data-analytics","userId":"09651493752354345908"}},"outputId":"b8902a9e-6f99-4c68-8652-e9d3ca92596e"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================================================\n","📊 Step 1: 데이터 로드 및 분할\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-10-12 16:20:24,422] A new study created in memory with name: no-name-148c1b7b-ae25-4308-abec-b1833c6a043c\n"]},{"output_type":"stream","name":"stdout","text":["✅ 완료 (학습용: 71604건, 테스트용: 17901건)\n","\n","==================================================\n","🔬 Step 2: Optuna 하이퍼파라미터 튜닝 시작 (PyTorch)\n","(최대 50번 시도, 10번 개선 없으면 스터디 조기 종료)\n","==================================================\n"]},{"output_type":"display_data","data":{"text/plain":["Optuna 튜닝 진행률:   0%|          | 0/50 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"74ee21b548054a208c9cf65cbe5183b6"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2025-10-12 16:20:59,857] Trial 0 finished with value: 0.15153922519140822 and parameters: {'n_layers': 5, 'n_units_l0': 40, 'dropout_l0': 0.4141097242177517, 'n_units_l1': 315, 'dropout_l1': 0.1700179250458588, 'n_units_l2': 181, 'dropout_l2': 0.19070559408417234, 'n_units_l3': 42, 'dropout_l3': 0.22753625197916488, 'n_units_l4': 247, 'dropout_l4': 0.10506216334006711, 'learning_rate': 5.369980220053131e-05}. Best is trial 0 with value: 0.15153922519140822.\n","[I 2025-10-12 16:21:12,705] Trial 1 finished with value: 0.15160225054489201 and parameters: {'n_layers': 3, 'n_units_l0': 277, 'dropout_l0': 0.3507966483686322, 'n_units_l1': 49, 'dropout_l1': 0.49960437532807567, 'n_units_l2': 49, 'dropout_l2': 0.15885209008467438, 'learning_rate': 0.00571465090801897}. Best is trial 1 with value: 0.15160225054489201.\n","[I 2025-10-12 16:21:34,997] Trial 2 finished with value: 0.1510743327761971 and parameters: {'n_layers': 4, 'n_units_l0': 498, 'dropout_l0': 0.16365101283635924, 'n_units_l1': 203, 'dropout_l1': 0.34734623509830775, 'n_units_l2': 111, 'dropout_l2': 0.3579622852343818, 'n_units_l3': 461, 'dropout_l3': 0.26268986255177196, 'learning_rate': 2.6044879580968177e-05}. Best is trial 1 with value: 0.15160225054489201.\n","[I 2025-10-12 16:21:46,047] Trial 3 finished with value: 0.15357408448072743 and parameters: {'n_layers': 2, 'n_units_l0': 36, 'dropout_l0': 0.13268992421002965, 'n_units_l1': 133, 'dropout_l1': 0.2358006169880642, 'learning_rate': 0.00040597131085601674}. Best is trial 3 with value: 0.15357408448072743.\n","[I 2025-10-12 16:22:00,201] Trial 4 finished with value: 0.1489032929395805 and parameters: {'n_layers': 5, 'n_units_l0': 299, 'dropout_l0': 0.49662220706701343, 'n_units_l1': 37, 'dropout_l1': 0.35968895722256655, 'n_units_l2': 95, 'dropout_l2': 0.4023844652423405, 'n_units_l3': 39, 'dropout_l3': 0.34195100597636185, 'n_units_l4': 66, 'dropout_l4': 0.16230959874924206, 'learning_rate': 0.0027751208835689357}. Best is trial 3 with value: 0.15357408448072743.\n","[I 2025-10-12 16:22:13,336] Trial 5 finished with value: 0.15307845171733114 and parameters: {'n_layers': 2, 'n_units_l0': 140, 'dropout_l0': 0.474368858265805, 'n_units_l1': 112, 'dropout_l1': 0.404358343427902, 'learning_rate': 0.000301264027914461}. Best is trial 3 with value: 0.15357408448072743.\n","[I 2025-10-12 16:22:18,060] Trial 6 pruned. \n","[I 2025-10-12 16:22:20,429] Trial 7 pruned. \n","[I 2025-10-12 16:22:21,582] Trial 8 pruned. \n","[I 2025-10-12 16:22:22,743] Trial 9 pruned. \n","[I 2025-10-12 16:22:23,775] Trial 10 pruned. \n","[I 2025-10-12 16:22:24,797] Trial 11 pruned. \n","[I 2025-10-12 16:22:37,875] Trial 12 finished with value: 0.15339715274402888 and parameters: {'n_layers': 2, 'n_units_l0': 36, 'dropout_l0': 0.19894265021525354, 'n_units_l1': 179, 'dropout_l1': 0.1424343516140171, 'learning_rate': 0.0007534953284296556}. Best is trial 3 with value: 0.15357408448072743.\n","[I 2025-10-12 16:22:47,999] Trial 13 finished with value: 0.1533225466012617 and parameters: {'n_layers': 2, 'n_units_l0': 33, 'dropout_l0': 0.17435352591554856, 'n_units_l1': 203, 'dropout_l1': 0.10411010854820416, 'learning_rate': 0.0009352067876713862}. Best is trial 3 with value: 0.15357408448072743.\n"]},{"output_type":"stream","name":"stdout","text":["\n","[Optuna 조기 종료] 10번의 trial 동안 최고 점수가 갱신되지 않아 튜닝을 중단합니다.\n","\n","✅ 튜닝 완료!\n","\n","==================================================\n","🔬 최적 하이퍼파라미터\n","==================================================\n","            n_layers: 2\n","          n_units_l0: 36\n","          dropout_l0: 0.13268992421002965\n","          n_units_l1: 133\n","          dropout_l1: 0.2358006169880642\n","       learning_rate: 0.00040597131085601674\n","==================================================\n","\n","🔬 Step 3: 튜닝된 최종 PyTorch 모델 학습 및 평가...\n"]},{"output_type":"display_data","data":{"text/plain":["최종 모델 학습:   0%|          | 0/50 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"31bec6fc0bf243c487870009482d9ec1"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["✅ 튜닝된 PyTorch 모델 평가 완료.\n","                      PR AUC  ROC AUC  F1-Score\n","Optuna_Tuned_PyTorch  0.1463   0.6094    0.0107\n","\n","============================================================\n","💾 Step 4: 최종 모델 예측 결과를 원본 CSV에 추가하여 저장\n","============================================================\n"]},{"output_type":"display_data","data":{"text/plain":["전체 데이터 예측:   0%|          | 0/175 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b028de5e99e94ad89c0ce0575f294c57"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["✅ 모든 데이터의 예측 결과가 '/content/drive/MyDrive/review_helpfulness/PADA/results/s2/hotel/MLP/MLP_hotel_with_RoBERTa_predictions.csv' 파일에 성공적으로 저장되었습니다.\n","\n","============================================================\n","🧹 Step 5: 메모리 정리\n","============================================================\n","✅ 메모리 정리가 완료되었습니다.\n","\n","🎉 모든 과정이 완료되었습니다!\n"]}]},{"cell_type":"markdown","source":["## DistilBERT"],"metadata":{"id":"ds0U2_yg5fa6"}},{"cell_type":"code","source":["# === 2. 환경설정 클래스 ===\n","class Config:\n","    \"\"\"실행에 필요한 모든 설정값을 중앙에서 관리합니다.\"\"\"\n","    # 🌟 1. 파일 경로 설정\n","    CSV_FILE_PATH = \"/content/drive/MyDrive/review_helpfulness/PADA/data/hotel/hotel.csv\"\n","    EMBEDDING_PATH = \"/content/drive/MyDrive/review_helpfulness/PADA/embedding/hotel_DistilBERT.npy\"\n","\n","    # 🌟 2. 최종 결과 CSV 파일 저장 경로 설정\n","    OUTPUT_CSV_PATH = \"/content/drive/MyDrive/review_helpfulness/PADA/results/s2/hotel/MLP/MLP_hotel_with_DistilBERT_predictions.csv\"\n","\n","    # --- 데이터 정보 ---\n","    TARGET_COLUMN = 'binary_helpfulness'\n","\n","    # --- 데이터 분할 ---\n","    TEST_SPLIT_RATIO = 0.2\n","    RANDOM_STATE = 42\n","\n","    # --- PyTorch 모델 및 학습 설정 ---\n","    EPOCHS = 50\n","    BATCH_SIZE = 256\n","    VALIDATION_EARLY_STOPPING_PATIENCE = 5 # 개별 Trial 내 검증 성능 기반 조기 종료\n","\n","    # --- Optuna 튜닝 설정 ---\n","    N_TRIALS = 50\n","    TUNING_METRIC = 'pr_auc'\n","    STUDY_EARLY_STOPPING_ROUNDS = 10 # 전체 Study 조기 종료\n","\n","# === 3. MLP 모델 클래스 (PyTorch) ===\n","class MLP(nn.Module):\n","    def __init__(self, input_dim, trial):\n","        super(MLP, self).__init__()\n","        layers = []\n","\n","        # ✅ 은닉층 탐색 범위를 1~5개로 확장\n","        n_layers = trial.suggest_int('n_layers', 1, 5)\n","\n","        in_features = input_dim\n","        for i in range(n_layers):\n","            out_features = trial.suggest_int(f'n_units_l{i}', 32, 512, log=True)\n","            layers.append(nn.Linear(in_features, out_features))\n","            layers.append(nn.ReLU())\n","            p = trial.suggest_float(f'dropout_l{i}', 0.1, 0.5)\n","            layers.append(nn.Dropout(p))\n","            in_features = out_features\n","\n","        layers.append(nn.Linear(in_features, 1))\n","        self.layers = nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        return torch.sigmoid(self.layers(x).squeeze(-1))\n","\n","# === 4. 학습 및 평가 함수 ===\n","def train_model(model, loader, optimizer, criterion):\n","    model.train()\n","    for inputs, labels in loader:\n","        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n","        optimizer.zero_grad()\n","        outputs = model(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","def evaluate_model(model, loader):\n","    model.eval()\n","    all_preds = []\n","    all_labels = []\n","    with torch.no_grad():\n","        for inputs, labels in loader:\n","            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n","            outputs = model(inputs)\n","            all_preds.extend(outputs.cpu().numpy())\n","            all_labels.extend(labels.cpu().numpy())\n","    return np.array(all_preds), np.array(all_labels)\n","\n","# === 5. Optuna Objective 함수 (PyTorch용) ===\n","def objective(trial, X, y):\n","    X_train, X_val, y_train, y_val = train_test_split(\n","        X, y, test_size=0.25, random_state=Config.RANDOM_STATE, stratify=y)\n","\n","    train_dataset = TensorDataset(torch.FloatTensor(X_train), torch.FloatTensor(y_train))\n","    val_dataset = TensorDataset(torch.FloatTensor(X_val), torch.FloatTensor(y_val))\n","    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)\n","    val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE)\n","\n","    input_dim = X_train.shape[1]\n","    model = MLP(input_dim, trial).to(DEVICE)\n","    lr = trial.suggest_float('learning_rate', 1e-5, 1e-2, log=True)\n","    optimizer = optim.Adam(model.parameters(), lr=lr)\n","    criterion = nn.BCELoss()\n","\n","    best_score = -1\n","    patience_counter = 0\n","\n","    for epoch in range(Config.EPOCHS):\n","        train_model(model, train_loader, optimizer, criterion)\n","        y_pred_proba, y_true = evaluate_model(model, val_loader)\n","        score = average_precision_score(y_true, y_pred_proba)\n","\n","        trial.report(score, epoch)\n","        if trial.should_prune():\n","            raise optuna.exceptions.TrialPruned()\n","\n","        if score > best_score:\n","            best_score = score\n","            patience_counter = 0\n","        else:\n","            patience_counter += 1\n","\n","        if patience_counter >= Config.VALIDATION_EARLY_STOPPING_PATIENCE:\n","            break\n","\n","    return best_score\n","\n","# === 6. Optuna 조기 종료 콜백 ===\n","class EarlyStoppingCallback:\n","    def __init__(self, early_stopping_rounds: int):\n","        self._early_stopping_rounds = early_stopping_rounds\n","        self._best_value = -float(\"inf\")\n","        self._counter = 0\n","\n","    def __call__(self, study: optuna.study.Study, trial: optuna.trial.Trial):\n","        current_best_value = study.best_value\n","        if current_best_value is not None and current_best_value > self._best_value:\n","            self._best_value = current_best_value\n","            self._counter = 0\n","        else:\n","            self._counter += 1\n","\n","        if self._counter >= self._early_stopping_rounds:\n","            print(f\"\\n[Optuna 조기 종료] {self._early_stopping_rounds}번의 trial 동안 최고 점수가 갱신되지 않아 튜닝을 중단합니다.\")\n","            study.stop()\n","\n","\n","# === 7. 메인 실행 블록 ===\n","if __name__ == '__main__':\n","    config = Config()\n","\n","    # --- Step 1: 데이터 로드 및 분할 ---\n","    print(\"\\n\" + \"=\"*50)\n","    print(\"📊 Step 1: 데이터 로드 및 분할\")\n","    try:\n","        df = pd.read_csv(config.CSV_FILE_PATH)\n","        labels = df[config.TARGET_COLUMN].values\n","        embeddings = np.load(config.EMBEDDING_PATH)\n","    except Exception as e:\n","        print(f\"🔥 파일 로드 실패: {e}\"); exit()\n","\n","    indices = np.arange(len(df))\n","    train_indices, test_indices = train_test_split(\n","        indices, test_size=config.TEST_SPLIT_RATIO, random_state=config.RANDOM_STATE, stratify=labels)\n","    X_train, X_test = embeddings[train_indices], embeddings[test_indices]\n","    y_train, y_test = labels[train_indices], labels[test_indices]\n","    print(f\"✅ 완료 (학습용: {len(y_train)}건, 테스트용: {len(y_test)}건)\")\n","\n","    # --- Step 2: Optuna 튜닝 수행 ---\n","    print(\"\\n\" + \"=\"*50)\n","    print(f\"🔬 Step 2: Optuna 하이퍼파라미터 튜닝 시작 (PyTorch)\")\n","    print(f\"(최대 {config.N_TRIALS}번 시도, {config.STUDY_EARLY_STOPPING_ROUNDS}번 개선 없으면 스터디 조기 종료)\")\n","    print(\"=\"*50)\n","\n","    study = optuna.create_study(direction='maximize', pruner=optuna.pruners.MedianPruner())\n","    pbar = tqdm(total=config.N_TRIALS, desc=\"Optuna 튜닝 진행률\")\n","\n","    try:\n","        study.optimize(lambda trial: objective(trial, X_train, y_train),\n","                       n_trials=config.N_TRIALS,\n","                       callbacks=[lambda s, t: pbar.update(1), EarlyStoppingCallback(config.STUDY_EARLY_STOPPING_ROUNDS)])\n","    except optuna.exceptions.OptunaError:\n","        pass # 조기 종료 시 예외 처리\n","    pbar.close()\n","\n","    # --- Step 3: 최적 모델 학습 및 평가 ---\n","    print(f\"\\n✅ 튜닝 완료!\")\n","    print(\"\\n\" + \"=\"*50)\n","    print(\"🔬 최적 하이퍼파라미터\")\n","    print(\"=\"*50)\n","    best_params = study.best_params\n","    for key, value in best_params.items():\n","        print(f\"{key:>20s}: {value}\")\n","    print(\"=\"*50)\n","\n","    print(f\"\\n🔬 Step 3: 튜닝된 최종 PyTorch 모델 학습 및 평가...\")\n","    train_dataset = TensorDataset(torch.FloatTensor(X_train), torch.FloatTensor(y_train))\n","    train_loader = DataLoader(train_dataset, batch_size=config.BATCH_SIZE, shuffle=True)\n","    test_dataset = TensorDataset(torch.FloatTensor(X_test), torch.FloatTensor(y_test))\n","    test_loader = DataLoader(test_dataset, batch_size=config.BATCH_SIZE)\n","\n","    # Optuna study 객체를 모의 trial로 사용하여 최종 모델 생성\n","    final_model = MLP(X_train.shape[1], study.best_trial).to(DEVICE)\n","    optimizer = optim.Adam(final_model.parameters(), lr=best_params['learning_rate'])\n","    criterion = nn.BCELoss()\n","\n","    # 최종 모델은 전체 학습 데이터로 학습\n","    for epoch in tqdm(range(config.EPOCHS), desc=\"최종 모델 학습\"):\n","        train_model(final_model, train_loader, optimizer, criterion)\n","\n","    y_pred_proba_tuned, y_true_test = evaluate_model(final_model, test_loader)\n","    y_pred_class_tuned = (y_pred_proba_tuned > 0.5).astype(int)\n","\n","    results = {\n","        \"PR AUC\": average_precision_score(y_true_test, y_pred_proba_tuned),\n","        \"ROC AUC\": roc_auc_score(y_true_test, y_pred_proba_tuned),\n","        \"F1-Score\": f1_score(y_true_test, y_pred_class_tuned),\n","    }\n","    print(\"✅ 튜닝된 PyTorch 모델 평가 완료.\")\n","    print(pd.DataFrame(results, index=['Optuna_Tuned_PyTorch']).round(4))\n","\n","    # --- Step 4: 결과 저장 ---\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"💾 Step 4: 최종 모델 예측 결과를 원본 CSV에 추가하여 저장\")\n","    print(\"=\"*60)\n","\n","    all_dataset = TensorDataset(torch.FloatTensor(embeddings))\n","    all_loader = DataLoader(all_dataset, batch_size=config.BATCH_SIZE * 2) # 예측 시에는 더 큰 배치 사용 가능\n","\n","    final_model.eval()\n","    all_predictions = []\n","    with torch.no_grad():\n","        for (inputs,) in tqdm(all_loader, desc=\"전체 데이터 예측\"):\n","            inputs = inputs.to(DEVICE)\n","            outputs = final_model(inputs)\n","            all_predictions.extend(outputs.cpu().numpy())\n","\n","    df['s2_pred_proba'] = all_predictions\n","    df['s2_pred_class'] = (df['s2_pred_proba'] > 0.5).astype(int)\n","\n","    df.to_csv(config.OUTPUT_CSV_PATH, index=False, encoding='utf-8-sig')\n","    print(f\"✅ 모든 데이터의 예측 결과가 '{config.OUTPUT_CSV_PATH}' 파일에 성공적으로 저장되었습니다.\")\n","\n","    # --- Step 5: 메모리 정리 ---\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"🧹 Step 5: 메모리 정리\")\n","    print(\"=\"*60)\n","    del df, labels, embeddings, X_train, X_test, y_train, y_test, final_model, study\n","    gc.collect()\n","    if torch.cuda.is_available():\n","        torch.cuda.empty_cache()\n","    print(\"✅ 메모리 정리가 완료되었습니다.\")\n","\n","    print(\"\\n🎉 모든 과정이 완료되었습니다!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["2ee964aeb0c34022ac357b2cbc0a25f2","7d1b61d3ac234b2c9f6c1e8b1171e4dd","e35bbbe8a5d44744810d83f7d4fc8753","ec6ec1b529f54b4da97c6edc9097a970","9b3bedb6a407446b8dec49470a033a2f","4c912ba697ff41848a5200d3fa5b01ff","5e09ee085ea54f35a4503bc6fff9a74c","ce1571c7280042089feb8f179eee7214","d02148e3908041a3ad80f957b4e851c6","92cb70ed762c4b57a65c91590fa48c92","547a4bc0774441f5b451e9805f518ae6","a10a5c79309d4465a93bfe2e61d4f92e","472ae2e809f5436d87469bf4a1fa5ab8","78c225f7e221498c9c66a4a559cfac46","007e161d8f8e420593aaf466562fb2ff","9e15ae2d644d48e6a40eef99696a5743","3cfd4f42de0241598ee3b3689ed9ec70","27cabce55c704e0f92d71ee2706ee829","5fa26702f2da4904b3c2307dec0598a3","5607ee686bd24beda014c416e4bacaa7","88c573b37e3f4bb0b6e85f6e13d7ca10","6db2562681be487fa1f9e603bafdfc90","b718599dc8d342b8b7fe13cb712385b4","2d53b4f5788340a1bef62e5322b914fa","e0f00c05cee04778b258b1997b39f86b","37026e1fa2c647059f04e11619039a2e","ab573e7e2801467dbf2ca6a62da3c094","8ab5b18dda8e47b3ba16475079eede11","582f3280693848e78165c32b3f2c9572","7b29f235ee0f486587d84ac10af1327b","4ce24e94b82e4bcbb1031efd0e0512e9","49e2f9ac1ffc4d61aaadd5b1c5fa6c7b","c968a48ccff84484856740bc423d4ab3"]},"id":"tGlLqSZX889K","executionInfo":{"status":"ok","timestamp":1760286469433,"user_tz":-540,"elapsed":242565,"user":{"displayName":"KW-data-analytics","userId":"09651493752354345908"}},"outputId":"8d715a0d-4140-463d-e1dd-100ac19dd4c8"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================================================\n","📊 Step 1: 데이터 로드 및 분할\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-10-12 16:23:51,532] A new study created in memory with name: no-name-8d0dc9e5-0b38-4f99-818a-a9656321d4b4\n"]},{"output_type":"stream","name":"stdout","text":["✅ 완료 (학습용: 71604건, 테스트용: 17901건)\n","\n","==================================================\n","🔬 Step 2: Optuna 하이퍼파라미터 튜닝 시작 (PyTorch)\n","(최대 50번 시도, 10번 개선 없으면 스터디 조기 종료)\n","==================================================\n"]},{"output_type":"display_data","data":{"text/plain":["Optuna 튜닝 진행률:   0%|          | 0/50 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2ee964aeb0c34022ac357b2cbc0a25f2"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2025-10-12 16:23:59,809] Trial 0 finished with value: 0.15560327030211793 and parameters: {'n_layers': 2, 'n_units_l0': 177, 'dropout_l0': 0.39519157513504966, 'n_units_l1': 148, 'dropout_l1': 0.2390976361447153, 'learning_rate': 0.006913910242036695}. Best is trial 0 with value: 0.15560327030211793.\n","[I 2025-10-12 16:24:53,357] Trial 1 finished with value: 0.15618580424512035 and parameters: {'n_layers': 3, 'n_units_l0': 45, 'dropout_l0': 0.16396598870782259, 'n_units_l1': 191, 'dropout_l1': 0.28651652033441466, 'n_units_l2': 196, 'dropout_l2': 0.2716078844980865, 'learning_rate': 1.0938916007472452e-05}. Best is trial 1 with value: 0.15618580424512035.\n","[I 2025-10-12 16:25:03,898] Trial 2 finished with value: 0.15753210413792404 and parameters: {'n_layers': 1, 'n_units_l0': 212, 'dropout_l0': 0.11523364915600696, 'learning_rate': 0.009251667139183774}. Best is trial 2 with value: 0.15753210413792404.\n","[I 2025-10-12 16:25:17,499] Trial 3 finished with value: 0.1579904473750274 and parameters: {'n_layers': 4, 'n_units_l0': 302, 'dropout_l0': 0.4021283542423828, 'n_units_l1': 154, 'dropout_l1': 0.1437402693720934, 'n_units_l2': 240, 'dropout_l2': 0.45059989981884596, 'n_units_l3': 36, 'dropout_l3': 0.14739806050946044, 'learning_rate': 0.00016387652919042103}. Best is trial 3 with value: 0.1579904473750274.\n","[I 2025-10-12 16:26:07,923] Trial 4 finished with value: 0.156901519763496 and parameters: {'n_layers': 2, 'n_units_l0': 99, 'dropout_l0': 0.2688579005391165, 'n_units_l1': 51, 'dropout_l1': 0.44778843345207087, 'learning_rate': 2.415628318827398e-05}. Best is trial 3 with value: 0.1579904473750274.\n","[I 2025-10-12 16:26:16,464] Trial 5 finished with value: 0.15724588694873254 and parameters: {'n_layers': 1, 'n_units_l0': 470, 'dropout_l0': 0.18712218447952178, 'learning_rate': 0.0010880564357808944}. Best is trial 3 with value: 0.1579904473750274.\n","[I 2025-10-12 16:26:22,195] Trial 6 finished with value: 0.15593687931072675 and parameters: {'n_layers': 1, 'n_units_l0': 178, 'dropout_l0': 0.1674778776181527, 'learning_rate': 0.004428330664829994}. Best is trial 3 with value: 0.1579904473750274.\n","[I 2025-10-12 16:26:23,390] Trial 7 pruned. \n","[I 2025-10-12 16:26:24,428] Trial 8 pruned. \n","[I 2025-10-12 16:26:25,464] Trial 9 pruned. \n","[I 2025-10-12 16:26:26,921] Trial 10 pruned. \n","[I 2025-10-12 16:26:33,729] Trial 11 finished with value: 0.1563171965522072 and parameters: {'n_layers': 4, 'n_units_l0': 306, 'dropout_l0': 0.282214799784531, 'n_units_l1': 314, 'dropout_l1': 0.10843160709999689, 'n_units_l2': 498, 'dropout_l2': 0.4950500775804123, 'n_units_l3': 34, 'dropout_l3': 0.10992353513762014, 'learning_rate': 0.0008875053923063426}. Best is trial 3 with value: 0.1579904473750274.\n","[I 2025-10-12 16:26:34,954] Trial 12 pruned. \n","[I 2025-10-12 16:26:43,576] Trial 13 finished with value: 0.15666208953575675 and parameters: {'n_layers': 3, 'n_units_l0': 242, 'dropout_l0': 0.35091481770935334, 'n_units_l1': 88, 'dropout_l1': 0.3595330520671858, 'n_units_l2': 136, 'dropout_l2': 0.3312193924175177, 'learning_rate': 0.0016397149747717596}. Best is trial 3 with value: 0.1579904473750274.\n"]},{"output_type":"stream","name":"stdout","text":["\n","[Optuna 조기 종료] 10번의 trial 동안 최고 점수가 갱신되지 않아 튜닝을 중단합니다.\n","\n","✅ 튜닝 완료!\n","\n","==================================================\n","🔬 최적 하이퍼파라미터\n","==================================================\n","            n_layers: 4\n","          n_units_l0: 302\n","          dropout_l0: 0.4021283542423828\n","          n_units_l1: 154\n","          dropout_l1: 0.1437402693720934\n","          n_units_l2: 240\n","          dropout_l2: 0.45059989981884596\n","          n_units_l3: 36\n","          dropout_l3: 0.14739806050946044\n","       learning_rate: 0.00016387652919042103\n","==================================================\n","\n","🔬 Step 3: 튜닝된 최종 PyTorch 모델 학습 및 평가...\n"]},{"output_type":"display_data","data":{"text/plain":["최종 모델 학습:   0%|          | 0/50 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a10a5c79309d4465a93bfe2e61d4f92e"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["✅ 튜닝된 PyTorch 모델 평가 완료.\n","                      PR AUC  ROC AUC  F1-Score\n","Optuna_Tuned_PyTorch  0.1316   0.5963    0.0282\n","\n","============================================================\n","💾 Step 4: 최종 모델 예측 결과를 원본 CSV에 추가하여 저장\n","============================================================\n"]},{"output_type":"display_data","data":{"text/plain":["전체 데이터 예측:   0%|          | 0/175 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b718599dc8d342b8b7fe13cb712385b4"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["✅ 모든 데이터의 예측 결과가 '/content/drive/MyDrive/review_helpfulness/PADA/results/s2/hotel/MLP/MLP_hotel_with_DistilBERT_predictions.csv' 파일에 성공적으로 저장되었습니다.\n","\n","============================================================\n","🧹 Step 5: 메모리 정리\n","============================================================\n","✅ 메모리 정리가 완료되었습니다.\n","\n","🎉 모든 과정이 완료되었습니다!\n"]}]}]}