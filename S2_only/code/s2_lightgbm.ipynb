{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["G1e60fe-eom3","Cvv9xmIcediR","srIut4sJewOz","qafu7gCEjvg1","TFdSa-mEkMZf","o3FmDWJJup2d","5dG09xq9vAGI","f39dc6bWvO22","KVbY_3OjvPFY","570R1n6evPqE","3tVSa3Z-vQBA","G7NH-0tcvQZ8"],"machine_shape":"hm","gpuType":"A100","authorship_tag":"ABX9TyMjRlRBTt1dVHwgFCzmPenn"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"da9b6486f46f4da5a1230953236e4fdc":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e4abaf27db8b487ab7024365e03ab21c","IPY_MODEL_c4992a2f12ca4a3484b32110595700d4","IPY_MODEL_59adb65e10904b369c180fda42325cc4"],"layout":"IPY_MODEL_c9db128360984f368f2d6835d0ec178a"}},"e4abaf27db8b487ab7024365e03ab21c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a7612c256bcf49eb82105f693c77fead","placeholder":"​","style":"IPY_MODEL_0005815617454cad9dab1dae8106a636","value":"Optuna 튜닝 진행률: 100%"}},"c4992a2f12ca4a3484b32110595700d4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8b481816bdc948fda404ccad9933e2f5","max":50,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a896723169fc4d3c99d9a571e2dd96c7","value":50}},"59adb65e10904b369c180fda42325cc4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8536fa13c6934973ad974b693701531f","placeholder":"​","style":"IPY_MODEL_132ec97988404cb3b038b0737adc98fd","value":" 50/50 [2:16:51&lt;00:00, 170.45s/it]"}},"c9db128360984f368f2d6835d0ec178a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a7612c256bcf49eb82105f693c77fead":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0005815617454cad9dab1dae8106a636":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8b481816bdc948fda404ccad9933e2f5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a896723169fc4d3c99d9a571e2dd96c7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8536fa13c6934973ad974b693701531f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"132ec97988404cb3b038b0737adc98fd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"679d058644e34d469a28ea0914235949":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cf72684b44a844b2a70b872108217f94","IPY_MODEL_aa489c64b9a2474aa7fa2ed273fbb544","IPY_MODEL_934006a2454e4d5f9174cf2499f14636"],"layout":"IPY_MODEL_513b977b2c6a4f729dd9611a090ca0a4"}},"cf72684b44a844b2a70b872108217f94":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_09ca48d6ffe945d98b9a6df2a8db2196","placeholder":"​","style":"IPY_MODEL_f4110a157fd649648eeb23c0d313f191","value":"Optuna 튜닝 진행률:  42%"}},"aa489c64b9a2474aa7fa2ed273fbb544":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_ef8dcdadec85462abfff980583a83e7e","max":50,"min":0,"orientation":"horizontal","style":"IPY_MODEL_33a992ae91fb42a9b9ca7b6043dcad88","value":21}},"934006a2454e4d5f9174cf2499f14636":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a06e94e976f0401d9e1c23b0384b7a4e","placeholder":"​","style":"IPY_MODEL_a9621fac6ca04c0eb3f95fb74d673b97","value":" 21/50 [20:23&lt;39:48, 82.35s/it]"}},"513b977b2c6a4f729dd9611a090ca0a4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"09ca48d6ffe945d98b9a6df2a8db2196":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f4110a157fd649648eeb23c0d313f191":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ef8dcdadec85462abfff980583a83e7e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"33a992ae91fb42a9b9ca7b6043dcad88":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a06e94e976f0401d9e1c23b0384b7a4e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a9621fac6ca04c0eb3f95fb74d673b97":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0c7788c37d8e4b7b952ab62c495a1fdb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cf46849400dc47ea924658da0f9a1a8a","IPY_MODEL_d86deca54ed14b5cb67a670d1a68d520","IPY_MODEL_91d01d98fc014d1496c5188ecf330b0d"],"layout":"IPY_MODEL_7aeb7a90ad35432a8242d52b9047e202"}},"cf46849400dc47ea924658da0f9a1a8a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c997881940e44cdeb64103bb075f519d","placeholder":"​","style":"IPY_MODEL_0320a77e7fbf483f97927e947aa582f4","value":"Optuna 튜닝 진행률:  60%"}},"d86deca54ed14b5cb67a670d1a68d520":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_c3598283aa674ed8969623f78c8d2756","max":50,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9ee1bb8bd5284effb90599caad33ced9","value":30}},"91d01d98fc014d1496c5188ecf330b0d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e50d9510622a45e9a2e2aa10fa9690a9","placeholder":"​","style":"IPY_MODEL_e36629a1434d49c4944eabaf4aeb0de6","value":" 30/50 [13:14&lt;05:42, 17.11s/it]"}},"7aeb7a90ad35432a8242d52b9047e202":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c997881940e44cdeb64103bb075f519d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0320a77e7fbf483f97927e947aa582f4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c3598283aa674ed8969623f78c8d2756":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9ee1bb8bd5284effb90599caad33ced9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e50d9510622a45e9a2e2aa10fa9690a9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e36629a1434d49c4944eabaf4aeb0de6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ce447eb274a9495199c1910c8773a1f7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5938d702a3a74401afb8bc26b5bc5d50","IPY_MODEL_e575747e46fa45029f6a272cf6912c05","IPY_MODEL_eb519f943f0a4f0ebd89a02c441e07ea"],"layout":"IPY_MODEL_312095d1db6e4e9d8c87d24ba65afaef"}},"5938d702a3a74401afb8bc26b5bc5d50":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a58ab785426f441b955ec9da99dec0e1","placeholder":"​","style":"IPY_MODEL_79c92abd4cbb449eae7c070d6bddcea3","value":"Optuna 튜닝 진행률:  24%"}},"e575747e46fa45029f6a272cf6912c05":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_22c7d90f29904a6eb1865b1fd5602587","max":50,"min":0,"orientation":"horizontal","style":"IPY_MODEL_60ee80b249ca4c60ac0067bf97118f08","value":12}},"eb519f943f0a4f0ebd89a02c441e07ea":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b5ca5e3d994e48e285549637bf26754d","placeholder":"​","style":"IPY_MODEL_6bdf5749155f4130aeeba73c3eed6fb5","value":" 12/50 [02:50&lt;06:57, 10.99s/it]"}},"312095d1db6e4e9d8c87d24ba65afaef":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a58ab785426f441b955ec9da99dec0e1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"79c92abd4cbb449eae7c070d6bddcea3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"22c7d90f29904a6eb1865b1fd5602587":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"60ee80b249ca4c60ac0067bf97118f08":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b5ca5e3d994e48e285549637bf26754d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6bdf5749155f4130aeeba73c3eed6fb5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"86d36f77612449a196c169894c66dbb8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5652c0cdf7384e639f517a96a1369817","IPY_MODEL_bed1ad5e599b432382ada5edb9a579ed","IPY_MODEL_59e1b86512394411bf1da923832d6b0f"],"layout":"IPY_MODEL_a9f646957c574cfd9b049ebe39e539d8"}},"5652c0cdf7384e639f517a96a1369817":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a5b7f6de00de42c2bc89a0d07fbd6ff7","placeholder":"​","style":"IPY_MODEL_2db6a3dac7c642d8a898abf2259893b2","value":"Optuna 튜닝 진행률:  58%"}},"bed1ad5e599b432382ada5edb9a579ed":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_4f32897c3cb544b7a932a4433e12ae30","max":50,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8c283fdb66184a30bdf164c3cf14ead7","value":29}},"59e1b86512394411bf1da923832d6b0f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fa1d1e7de79a4b2b8203b0e0e0d0054c","placeholder":"​","style":"IPY_MODEL_1b28462b78ce447b9f3c192942417c33","value":" 29/50 [30:56&lt;44:24, 126.87s/it]"}},"a9f646957c574cfd9b049ebe39e539d8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a5b7f6de00de42c2bc89a0d07fbd6ff7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2db6a3dac7c642d8a898abf2259893b2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4f32897c3cb544b7a932a4433e12ae30":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8c283fdb66184a30bdf164c3cf14ead7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"fa1d1e7de79a4b2b8203b0e0e0d0054c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1b28462b78ce447b9f3c192942417c33":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c1ad27919ab54646aa88ab58309a3408":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_27b15f6e052443379a4119682039e4d7","IPY_MODEL_212cf72fafe04de780f109d331dc48fd","IPY_MODEL_0969f7b3db7740c78d34fe1fe6b3446a"],"layout":"IPY_MODEL_70abafa8df054125be93c052676475b8"}},"27b15f6e052443379a4119682039e4d7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b53678641b65463db873d8bea835f8fd","placeholder":"​","style":"IPY_MODEL_95057d180c6e48709f4d3d29fc9e3331","value":"Optuna 튜닝 진행률:  22%"}},"212cf72fafe04de780f109d331dc48fd":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_bfef38c1899a415086955c7d79841b8a","max":50,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b326487fd7114ce18120e15d17d8deaf","value":11}},"0969f7b3db7740c78d34fe1fe6b3446a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d6b6d616598b439f9c381f4fa95fd0f6","placeholder":"​","style":"IPY_MODEL_b241d32b9db8439db25c484bbc0e3158","value":" 11/50 [06:33&lt;19:18, 29.70s/it]"}},"70abafa8df054125be93c052676475b8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b53678641b65463db873d8bea835f8fd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"95057d180c6e48709f4d3d29fc9e3331":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bfef38c1899a415086955c7d79841b8a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b326487fd7114ce18120e15d17d8deaf":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d6b6d616598b439f9c381f4fa95fd0f6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b241d32b9db8439db25c484bbc0e3158":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"101e646cafeb4b9a9dccee816b5859df":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_08e0e5409a4343babf163907fafcebe7","IPY_MODEL_266e865028c44f97adfd9604a4f6c7fa","IPY_MODEL_e45cb316b40d49029ada00196329cd4d"],"layout":"IPY_MODEL_4759c2c992104f6daaed3f47f59b4003"}},"08e0e5409a4343babf163907fafcebe7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3ec70efd33c348eb94006e7471d1133d","placeholder":"​","style":"IPY_MODEL_47411a8f4b544297892d1adf6793f33f","value":"Optuna 튜닝 진행률:  52%"}},"266e865028c44f97adfd9604a4f6c7fa":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_9babf8015160436c87995b978ebb4a57","max":50,"min":0,"orientation":"horizontal","style":"IPY_MODEL_175ac7384cac45a9a005a7f7aa1939cf","value":26}},"e45cb316b40d49029ada00196329cd4d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6830cbfc01c146d5b6a60dc350b49f02","placeholder":"​","style":"IPY_MODEL_5b96c6b621f44692b91d6ba128116c43","value":" 26/50 [24:09&lt;22:31, 56.31s/it]"}},"4759c2c992104f6daaed3f47f59b4003":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3ec70efd33c348eb94006e7471d1133d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"47411a8f4b544297892d1adf6793f33f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9babf8015160436c87995b978ebb4a57":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"175ac7384cac45a9a005a7f7aa1939cf":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6830cbfc01c146d5b6a60dc350b49f02":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5b96c6b621f44692b91d6ba128116c43":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b49512423c8a4524b610955db9535789":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3864b54203314c51986223fcc8f0639d","IPY_MODEL_79821e31432f4e86a323a1fe36eb9f01","IPY_MODEL_255fc2e1084840d09b6d804f9565ba37"],"layout":"IPY_MODEL_27a50ad15c4d493880da662df2fb4747"}},"3864b54203314c51986223fcc8f0639d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bcb0610e71a140328d436c0cc2c8cdc8","placeholder":"​","style":"IPY_MODEL_ed9b011d92f7435c9f2c565f46e94eb6","value":"Optuna 튜닝 진행률:  32%"}},"79821e31432f4e86a323a1fe36eb9f01":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_aef78176740c4899ac2f4ed786fd77f5","max":50,"min":0,"orientation":"horizontal","style":"IPY_MODEL_08c09b0411df432eb283b003b439e0d7","value":16}},"255fc2e1084840d09b6d804f9565ba37":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0ca44d1f8a714eb8be3edff5636c3a4f","placeholder":"​","style":"IPY_MODEL_631dd166b414446abef56e2342b712c2","value":" 16/50 [11:04&lt;25:51, 45.62s/it]"}},"27a50ad15c4d493880da662df2fb4747":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bcb0610e71a140328d436c0cc2c8cdc8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ed9b011d92f7435c9f2c565f46e94eb6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"aef78176740c4899ac2f4ed786fd77f5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"08c09b0411df432eb283b003b439e0d7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0ca44d1f8a714eb8be3edff5636c3a4f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"631dd166b414446abef56e2342b712c2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"76023f06b3004399a2189b351959b427":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3af8e5ba049a4ba5b75c018295867f05","IPY_MODEL_fb406027a268485ba6234e26b25c8c35","IPY_MODEL_220b4847fd0d4e4693a6dc22a858439d"],"layout":"IPY_MODEL_c274c6a261a14defaffd431cfc7345b8"}},"3af8e5ba049a4ba5b75c018295867f05":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3364d3f8b6d54503ab6efb4054d3d4d1","placeholder":"​","style":"IPY_MODEL_1dd48e13b4a24cefb2dbc221f0dd31b0","value":"Optuna 튜닝 진행률:  40%"}},"fb406027a268485ba6234e26b25c8c35":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_507567a0ba2c42f0b1c40e7a4c4a85a2","max":50,"min":0,"orientation":"horizontal","style":"IPY_MODEL_07999052b7e74e1c9ef381b242de0ca0","value":20}},"220b4847fd0d4e4693a6dc22a858439d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_83027739c00f4a0895fe1ea9b89ff695","placeholder":"​","style":"IPY_MODEL_a51c9bb214da40d39ac425ba26c69993","value":" 20/50 [07:37&lt;12:18, 24.62s/it]"}},"c274c6a261a14defaffd431cfc7345b8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3364d3f8b6d54503ab6efb4054d3d4d1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1dd48e13b4a24cefb2dbc221f0dd31b0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"507567a0ba2c42f0b1c40e7a4c4a85a2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"07999052b7e74e1c9ef381b242de0ca0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"83027739c00f4a0895fe1ea9b89ff695":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a51c9bb214da40d39ac425ba26c69993":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"74fcba6c467148a29b8cf9a476d1b958":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_82cd9f3482ef4b7b8cbe4576202ae9df","IPY_MODEL_549b1bf7ba864bffaa39695ea9e94d7e","IPY_MODEL_89b58c39934749c59f068e868768f682"],"layout":"IPY_MODEL_917e0d5525524088a9fa5bb95fd5049c"}},"82cd9f3482ef4b7b8cbe4576202ae9df":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6eb8d61c10324c959668444243a988f4","placeholder":"​","style":"IPY_MODEL_4390cf5f5ef74e178018784297742a83","value":"Optuna 튜닝 진행률:  84%"}},"549b1bf7ba864bffaa39695ea9e94d7e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_58c5d1002af74996842ad0ff9b4169a8","max":50,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3a896fb195cf45178ef19837a8ac3ebf","value":42}},"89b58c39934749c59f068e868768f682":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dc7724b0a0604821b8cfd3a19b409115","placeholder":"​","style":"IPY_MODEL_5573d8cdd67d4f7c869ce3de9476169f","value":" 42/50 [16:58&lt;04:05, 30.63s/it]"}},"917e0d5525524088a9fa5bb95fd5049c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6eb8d61c10324c959668444243a988f4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4390cf5f5ef74e178018784297742a83":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"58c5d1002af74996842ad0ff9b4169a8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3a896fb195cf45178ef19837a8ac3ebf":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"dc7724b0a0604821b8cfd3a19b409115":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5573d8cdd67d4f7c869ce3de9476169f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1ba6332055034a898979671c01173c80":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_584f2bf9a37a4a959175e97445c73515","IPY_MODEL_ddc3685b62f241a5b3389e221dc15878","IPY_MODEL_70e8c8104c484e19b3ab4c8e8f77870e"],"layout":"IPY_MODEL_e130719f081e44a28d3eabe8291b557b"}},"584f2bf9a37a4a959175e97445c73515":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_88b59307584f435382706ad81977d82a","placeholder":"​","style":"IPY_MODEL_ad10d090317c4eda94189fd556878536","value":"Optuna 튜닝 진행률:  26%"}},"ddc3685b62f241a5b3389e221dc15878":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_e68f3ad8ee2d4fd3a6394154f30fc561","max":50,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ec8ae113779c4fcda4b58ae4ed6eaaed","value":13}},"70e8c8104c484e19b3ab4c8e8f77870e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b300ba8300644c97ae9a5ad6ae60171e","placeholder":"​","style":"IPY_MODEL_ce2df40505284f598ea8efa487980fd4","value":" 13/50 [04:53&lt;11:51, 19.24s/it]"}},"e130719f081e44a28d3eabe8291b557b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"88b59307584f435382706ad81977d82a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ad10d090317c4eda94189fd556878536":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e68f3ad8ee2d4fd3a6394154f30fc561":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ec8ae113779c4fcda4b58ae4ed6eaaed":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b300ba8300644c97ae9a5ad6ae60171e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ce2df40505284f598ea8efa487980fd4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5568e6dca5cf4f339cd9f5bb695b8cf1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_09ecd53c609749018ff803f9e0a6af2b","IPY_MODEL_4f5676b2afaf43dc9db4567329d60e0d","IPY_MODEL_91a6d51816b34a7299c0f74fa4220b08"],"layout":"IPY_MODEL_d03e63daf9b340d4a264ae2bc34c1686"}},"09ecd53c609749018ff803f9e0a6af2b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3b01489a7283419191d9788ba1e0a3f1","placeholder":"​","style":"IPY_MODEL_6e9566eac5864e51bda16254a6ca67c0","value":"Optuna 튜닝 진행률:  30%"}},"4f5676b2afaf43dc9db4567329d60e0d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_b80221133e224e7391c8d2f7c2192279","max":50,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ae56566814d743ac874512137f415328","value":15}},"91a6d51816b34a7299c0f74fa4220b08":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8965258d3a5a4322a4374058c4aa0a58","placeholder":"​","style":"IPY_MODEL_01a726b70a6e4d48af9fc12bb076f912","value":" 15/50 [09:00&lt;28:14, 48.42s/it]"}},"d03e63daf9b340d4a264ae2bc34c1686":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3b01489a7283419191d9788ba1e0a3f1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6e9566eac5864e51bda16254a6ca67c0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b80221133e224e7391c8d2f7c2192279":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ae56566814d743ac874512137f415328":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8965258d3a5a4322a4374058c4aa0a58":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"01a726b70a6e4d48af9fc12bb076f912":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"10860ddc842942509f9f48fa823d1137":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2eb84d70cb63405d89a8eb545d1b2357","IPY_MODEL_fbeda94d79ca4101a79a90f32742c9de","IPY_MODEL_6e6a9ebcea58414d9bd7c51a31a7048c"],"layout":"IPY_MODEL_fce18f20ff504908977255f76c7eedf0"}},"2eb84d70cb63405d89a8eb545d1b2357":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fc6381417db140bb8a98b5586ff53ede","placeholder":"​","style":"IPY_MODEL_a35b1595c5b9412ba7687bba3d495681","value":"Optuna 튜닝 진행률:  66%"}},"fbeda94d79ca4101a79a90f32742c9de":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_f94fd1fcbd164ad8ab0d5f8961ecb6e1","max":50,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b3ec152d7bc3492a9da18953f5eff250","value":33}},"6e6a9ebcea58414d9bd7c51a31a7048c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7cd9d89cdc5243cf8d56c2686a296071","placeholder":"​","style":"IPY_MODEL_2b581eb3ff934fb3b8b47c5782df5663","value":" 33/50 [08:45&lt;02:55, 10.31s/it]"}},"fce18f20ff504908977255f76c7eedf0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fc6381417db140bb8a98b5586ff53ede":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a35b1595c5b9412ba7687bba3d495681":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f94fd1fcbd164ad8ab0d5f8961ecb6e1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b3ec152d7bc3492a9da18953f5eff250":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7cd9d89cdc5243cf8d56c2686a296071":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2b581eb3ff934fb3b8b47c5782df5663":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"999c30a9016a4288892a25f072f129e9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8639cf0fa79047738f0a8aae0aa9bf7e","IPY_MODEL_46cddae85d1a4f2d81001955c6db0856","IPY_MODEL_47a4dfe31a984f12a53d16b9868ea75b"],"layout":"IPY_MODEL_b2cb4990e58e4607b9973e39c53bcaf4"}},"8639cf0fa79047738f0a8aae0aa9bf7e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_23071aa7fe0e4ce58a015adeb2b67114","placeholder":"​","style":"IPY_MODEL_77208d37845f4da29483a1e56cc15d87","value":"Optuna 튜닝 진행률:  22%"}},"46cddae85d1a4f2d81001955c6db0856":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_ca5b06a231dd4d62b3eb216c8592fa61","max":50,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7299eb505d5f42b29f9dee53ad4dd841","value":11}},"47a4dfe31a984f12a53d16b9868ea75b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_07c07998533542209f83e4270659d873","placeholder":"​","style":"IPY_MODEL_2e41445600524e2b91e8538593c2714f","value":" 11/50 [05:27&lt;09:02, 13.91s/it]"}},"b2cb4990e58e4607b9973e39c53bcaf4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"23071aa7fe0e4ce58a015adeb2b67114":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"77208d37845f4da29483a1e56cc15d87":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ca5b06a231dd4d62b3eb216c8592fa61":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7299eb505d5f42b29f9dee53ad4dd841":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"07c07998533542209f83e4270659d873":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2e41445600524e2b91e8538593c2714f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7d6717639ac74cd3851140bdc413630c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0d29969b30cd4eed9f2146771232a9bd","IPY_MODEL_d531aeaad2964638b6fe542b7a1356c3","IPY_MODEL_c3c486bc71324d43b2b4ec2956e61b26"],"layout":"IPY_MODEL_86d20758499946e88ec8f182a16da1f5"}},"0d29969b30cd4eed9f2146771232a9bd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ae76cc972f0a43eb98020608b975bed4","placeholder":"​","style":"IPY_MODEL_cfb71c7b25854c4b8b7e9ce0a2d7e111","value":"Optuna 튜닝 진행률:  86%"}},"d531aeaad2964638b6fe542b7a1356c3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_be2746843d654fdab758b464546e8d14","max":50,"min":0,"orientation":"horizontal","style":"IPY_MODEL_388760b9cf66474489d5a83605a240ac","value":43}},"c3c486bc71324d43b2b4ec2956e61b26":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ce7bad216f48446e946efdbcfcb8970c","placeholder":"​","style":"IPY_MODEL_6c6f521942a64289b8a9b880581bdd8c","value":" 43/50 [23:34&lt;04:26, 38.03s/it]"}},"86d20758499946e88ec8f182a16da1f5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ae76cc972f0a43eb98020608b975bed4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cfb71c7b25854c4b8b7e9ce0a2d7e111":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"be2746843d654fdab758b464546e8d14":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"388760b9cf66474489d5a83605a240ac":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ce7bad216f48446e946efdbcfcb8970c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6c6f521942a64289b8a9b880581bdd8c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b10ca073771c421ba5f39826c93e722d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_acc2dded66ef4994840658817f2f5df8","IPY_MODEL_82342606e2fc428496499192dcffd4dc","IPY_MODEL_b9dd5d12a46d49cd95c3c96759635f50"],"layout":"IPY_MODEL_08035371cce34a4b8b81f6788441f9c2"}},"acc2dded66ef4994840658817f2f5df8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_91329570636e43af8e334c4aaaf72d71","placeholder":"​","style":"IPY_MODEL_e215865e537a4009b933dd1ad9e4787b","value":"Optuna 튜닝 진행률:  22%"}},"82342606e2fc428496499192dcffd4dc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_773a1d321a7346a19fe88acf37c61513","max":50,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c9b74b27f1db4c3987a79c281d282d17","value":11}},"b9dd5d12a46d49cd95c3c96759635f50":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7811c1e6d80a41539afdefea9f655a53","placeholder":"​","style":"IPY_MODEL_6cc738bf88de40bd83d949d78ab801a6","value":" 11/50 [05:38&lt;12:07, 18.65s/it]"}},"08035371cce34a4b8b81f6788441f9c2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"91329570636e43af8e334c4aaaf72d71":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e215865e537a4009b933dd1ad9e4787b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"773a1d321a7346a19fe88acf37c61513":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c9b74b27f1db4c3987a79c281d282d17":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7811c1e6d80a41539afdefea9f655a53":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6cc738bf88de40bd83d949d78ab801a6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3e22913477b0463799f4d75fab3f7c1d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_333470c373f44f18bd2dba276ee78c3b","IPY_MODEL_01c29d961d7f40808965e434f5e29b7f","IPY_MODEL_803cb2aacae04d08b8dbdcfcd62dd74f"],"layout":"IPY_MODEL_c4734536b2d147e49aecae71bb12641d"}},"333470c373f44f18bd2dba276ee78c3b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_934d9dcd6a9543f1a0d726398853639f","placeholder":"​","style":"IPY_MODEL_4b9096b1ce3c43e481f648d030722caa","value":"Optuna 튜닝 진행률:  28%"}},"01c29d961d7f40808965e434f5e29b7f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_d5ba3e3857c749f5a057ec1179f628f6","max":50,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a14c8b58d6134ee28a8fb226c7b953c9","value":14}},"803cb2aacae04d08b8dbdcfcd62dd74f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1bc52f6825024966b52c0465f7321244","placeholder":"​","style":"IPY_MODEL_db381bdb115744318b935c5920492088","value":" 14/50 [07:48&lt;27:33, 45.93s/it]"}},"c4734536b2d147e49aecae71bb12641d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"934d9dcd6a9543f1a0d726398853639f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4b9096b1ce3c43e481f648d030722caa":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d5ba3e3857c749f5a057ec1179f628f6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a14c8b58d6134ee28a8fb226c7b953c9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1bc52f6825024966b52c0465f7321244":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"db381bdb115744318b935c5920492088":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b90b17b1fd354057ba8001d2d2d66e83":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7e771fd7b5954adaacb9703695ac6f68","IPY_MODEL_d42dfac5c61e4ab0ad37013b60ec22b6","IPY_MODEL_bbdb07f8108846388066370eb9d67f4e"],"layout":"IPY_MODEL_2b882e2ab1f9412d9cd8efdd70aaa464"}},"7e771fd7b5954adaacb9703695ac6f68":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2b612e5016eb4fe99542c7a73a0e4298","placeholder":"​","style":"IPY_MODEL_b3d79089d1b64f5bab6d6ed412f89082","value":"Optuna 튜닝 진행률:  56%"}},"d42dfac5c61e4ab0ad37013b60ec22b6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_8f54965aefec4a35b1e7c7ece6ee7bc0","max":50,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b8c615610d1e41dc98c126b936e53e7c","value":28}},"bbdb07f8108846388066370eb9d67f4e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6c39ff3484b4435f972f0fea0fbd77c2","placeholder":"​","style":"IPY_MODEL_df37faa390f54d55b99b8901fdf7df17","value":" 28/50 [10:00&lt;07:29, 20.43s/it]"}},"2b882e2ab1f9412d9cd8efdd70aaa464":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2b612e5016eb4fe99542c7a73a0e4298":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b3d79089d1b64f5bab6d6ed412f89082":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8f54965aefec4a35b1e7c7ece6ee7bc0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b8c615610d1e41dc98c126b936e53e7c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6c39ff3484b4435f972f0fea0fbd77c2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"df37faa390f54d55b99b8901fdf7df17":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c9897f45fc824f40bc3c63441c6210f5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_921be6a91dfd4f7dbdb685f718f04c53","IPY_MODEL_107c227bbd6444e1a9fc7940705c9e1d","IPY_MODEL_492198bc880a449aadcc08cb35044a85"],"layout":"IPY_MODEL_68acb0cc96ae4ecbb2af864a3d672f36"}},"921be6a91dfd4f7dbdb685f718f04c53":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a9ee2db2513a44ed9ee28deb64eece97","placeholder":"​","style":"IPY_MODEL_ce3c0ac76def4db0910087e346e49880","value":"Optuna 튜닝 진행률:  64%"}},"107c227bbd6444e1a9fc7940705c9e1d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_2dd8f692129e4b8cbd107858c5551e64","max":50,"min":0,"orientation":"horizontal","style":"IPY_MODEL_eebcac7b67924d6a847d564f304fb070","value":32}},"492198bc880a449aadcc08cb35044a85":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_469766e4152a4f36bd83f593a9ac20a1","placeholder":"​","style":"IPY_MODEL_0c7c445e4c4e42df879f1643d5b19aed","value":" 32/50 [05:02&lt;01:49,  6.06s/it]"}},"68acb0cc96ae4ecbb2af864a3d672f36":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a9ee2db2513a44ed9ee28deb64eece97":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ce3c0ac76def4db0910087e346e49880":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2dd8f692129e4b8cbd107858c5551e64":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eebcac7b67924d6a847d564f304fb070":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"469766e4152a4f36bd83f593a9ac20a1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0c7c445e4c4e42df879f1643d5b19aed":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f1aa492dec9e4e5e884483e9da56145c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_54977e91f7ec4d5f889d10c0f2c3d76c","IPY_MODEL_e9b6689ab56a4ae0978daee1166ebdc9","IPY_MODEL_007ebcad2b1344d093aff8c030bdb0b7"],"layout":"IPY_MODEL_0655bc417a2c454ba87656444131fa59"}},"54977e91f7ec4d5f889d10c0f2c3d76c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_191a3a972b604312949d230d983b56d1","placeholder":"​","style":"IPY_MODEL_7a1380b34e5c4ce3b6b23c292a887e89","value":"Optuna 튜닝 진행률:  64%"}},"e9b6689ab56a4ae0978daee1166ebdc9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_17ae79b0219c412d924340657edfd08a","max":50,"min":0,"orientation":"horizontal","style":"IPY_MODEL_33f21f3aac7c4047bd84dbfb4b16b941","value":32}},"007ebcad2b1344d093aff8c030bdb0b7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_17988837387c4395acecb984f0028d41","placeholder":"​","style":"IPY_MODEL_4ae3d06358d144b692de01254f03de96","value":" 32/50 [23:04&lt;15:30, 51.72s/it]"}},"0655bc417a2c454ba87656444131fa59":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"191a3a972b604312949d230d983b56d1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7a1380b34e5c4ce3b6b23c292a887e89":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"17ae79b0219c412d924340657edfd08a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"33f21f3aac7c4047bd84dbfb4b16b941":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"17988837387c4395acecb984f0028d41":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4ae3d06358d144b692de01254f03de96":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"774a2007da144d5a95761044ba085343":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8ee3067ddf174102af385974aea595ff","IPY_MODEL_662832e895434edfaa746fcbaa63d02c","IPY_MODEL_ff5c630081b047a9ba507b57b6a066f5"],"layout":"IPY_MODEL_06b7c018bf4642f984664a2b7cf499a0"}},"8ee3067ddf174102af385974aea595ff":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_629e7689947647c19b36a5835bd347e9","placeholder":"​","style":"IPY_MODEL_0e1ad76036894bb783156ee02ab93ee6","value":"Optuna 튜닝 진행률:  40%"}},"662832e895434edfaa746fcbaa63d02c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_f5b02a375ab641a9a7dd7bbf007544fb","max":50,"min":0,"orientation":"horizontal","style":"IPY_MODEL_14803f7e8a904086a49c46aa96fd6cf0","value":20}},"ff5c630081b047a9ba507b57b6a066f5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_67cc19e50316462ea13317fa353b98bb","placeholder":"​","style":"IPY_MODEL_3c4e2e42f0ac4beda5a9c49465e3b9c7","value":" 20/50 [15:38&lt;26:40, 53.36s/it]"}},"06b7c018bf4642f984664a2b7cf499a0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"629e7689947647c19b36a5835bd347e9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0e1ad76036894bb783156ee02ab93ee6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f5b02a375ab641a9a7dd7bbf007544fb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"14803f7e8a904086a49c46aa96fd6cf0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"67cc19e50316462ea13317fa353b98bb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3c4e2e42f0ac4beda5a9c49465e3b9c7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["# Hyperparameter 설명"],"metadata":{"id":"tev0_Q9VipQ9"}},{"cell_type":"markdown","source":["## 🌳 모델의 전반적인 구조 (Boosting Process)\n","모델 전체의 학습 방향과 방식을 결정하는 가장 중요한 파라미터입니다.\n","\n","n_estimators: 생성할 결정 나무의 개수입니다.\n","\n","비유: 문제를 해결하기 위해 몇 명의 전문가를 투입할지 결정하는 것과 같습니다.\n","\n","영향: 값이 클수록 모델은 더 정교해지지만, 너무 많으면 과적합(overfitting)될 수 있고 학습 시간이 길어집니다. early_stopping 콜백이 최적의 개수를 찾아주는 역할을 보조합니다.\n","\n","learning_rate (학습률): 각 나무가 이전 나무의 오류를 얼마나 강하게 보정할지를 나타내는 값입니다. (0~1 사이의 값)\n","\n","비유: 새로운 전문가의 의견을 얼마나 신뢰하고 반영할지 결정하는 값입니다.\n","\n","영향: 값이 작을수록 더 많은 n_estimators가 필요하지만, 최적점에 더 안정적으로 도달할 수 있습니다. 값이 크면 학습이 빠르지만, 최적점을 지나쳐 버릴 수 있습니다.\n","\n","## 🍃 개별 나무의 복잡도 제어 (Tree Complexity)\n","각각의 나무가 얼마나 복잡한 규칙을 가질 수 있는지를 제어합니다.\n","\n","num_leaves: 하나의 나무가 가질 수 있는 최대 잎(leaf)의 개수입니다.\n","\n","비유: 의사결정 순서도에서 나올 수 있는 최종 결론의 최대 가짓수입니다.\n","\n","영향: 모델의 복잡도를 결정하는 가장 중요한 파라미터 중 하나입니다. 값이 클수록 복잡한 패턴을 학습할 수 있지만, 과적합에 매우 취약해집니다.\n","\n","max_depth: 나무의 최대 깊이입니다.\n","\n","비유: 결론에 도달하기까지 최대 몇 단계의 질문을 할 수 있는지 제한하는 것입니다.\n","\n","영향: 나무가 너무 깊어지는 것을 막아 과적합을 방지합니다. num_leaves와 함께 모델의 복잡도를 제어합니다.\n","\n","## ⚖️ 과적합 방지를 위한 정규화 (Regularization)\n","모델이 훈련 데이터에만 너무 치우쳐 학습되는 것을 막는 규제 장치입니다.\n","\n","lambda_l1 (L1 정규화): 모델의 가중치 합에 페널티를 부여합니다. 특정 피처의 가중치를 0으로 만들어 **피처 선택(feature selection)**의 효과를 낼 수 있습니다.\n","\n","lambda_l2 (L2 정규화): 모델 가중치의 제곱 합에 페널티를 부여합니다. 가중치 값을 전반적으로 부드럽게 만들어 과적합을 방지합니다.\n","\n","## 🎲 속도 및 일반화 성능을 위한 샘플링 (Subsampling)\n","훈련 데이터를 무작위로 샘플링하여 각 나무를 조금씩 다른 데이터로 학습시켜 모델의 일반화 성능을 높입니다.\n","\n","feature_fraction: 각 나무를 만들 때 무작위로 선택할 피처(열)의 비율입니다. 예를 들어 0.8이면, 매번 80%의 피처만 사용하여 나무를 만듭니다.\n","\n","bagging_fraction (subsample): 각 나무를 만들 때 무작위로 선택할 데이터(행)의 비율입니다. 예를 들어 0.8이면, 매번 80%의 데이터만 사용합니다.\n","\n","bagging_freq: 몇 번의 반복(나무 생성)마다 데이터 샘플링을 수행할지 결정합니다. 1이면 매번 새로운 데이터를 샘플링합니다."],"metadata":{"id":"SRF7iJBlzRhs"}},{"cell_type":"markdown","source":["# Setting"],"metadata":{"id":"Wqpc4AwGzWSY"}},{"cell_type":"code","source":["! pip install optuna"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vjN0pYrZWRte","executionInfo":{"status":"ok","timestamp":1760250322529,"user_tz":-540,"elapsed":6641,"user":{"displayName":"KW-data-analytics","userId":"09651493752354345908"}},"outputId":"44836a42-ba81-46e7-a0c7-1fb1549b44ef"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting optuna\n","  Downloading optuna-4.5.0-py3-none-any.whl.metadata (17 kB)\n","Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (1.16.5)\n","Collecting colorlog (from optuna)\n","  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (25.0)\n","Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.43)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from optuna) (4.67.1)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from optuna) (6.0.3)\n","Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (1.3.10)\n","Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (4.15.0)\n","Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.4)\n","Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.12/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.3)\n","Downloading optuna-4.5.0-py3-none-any.whl (400 kB)\n","\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/400.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m400.9/400.9 kB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n","Installing collected packages: colorlog, optuna\n","Successfully installed colorlog-6.9.0 optuna-4.5.0\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"id":"oWbY5uAz5URU","executionInfo":{"status":"ok","timestamp":1760250329190,"user_tz":-540,"elapsed":5321,"user":{"displayName":"KW-data-analytics","userId":"09651493752354345908"}}},"outputs":[],"source":["# === 1. 라이브러리 임포트 ===\n","import pandas as pd\n","import numpy as np\n","import lightgbm as lgb\n","import optuna\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import average_precision_score, roc_auc_score, f1_score, classification_report\n","import os\n","import warnings\n","from tqdm.auto import tqdm\n","import time\n","import gc  # 🌟 메모리 정리를 위한 가비지 컬렉터 임포트"]},{"cell_type":"code","source":["# --- 기본 설정 ---\n","warnings.filterwarnings('ignore')\n","# optuna.logging.set_verbosity(optuna.logging.WARNING)"],"metadata":{"id":"vGHEmaRec4RK","executionInfo":{"status":"ok","timestamp":1760250330364,"user_tz":-540,"elapsed":3,"user":{"displayName":"KW-data-analytics","userId":"09651493752354345908"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# --- 데이터 로드 및 전처리 ---\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yZpKGP0Hi4BV","executionInfo":{"status":"ok","timestamp":1760250356738,"user_tz":-540,"elapsed":25722,"user":{"displayName":"KW-data-analytics","userId":"09651493752354345908"}},"outputId":"be4722da-93c2-42dc-b19f-bca93ef2ee10"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["# Sample"],"metadata":{"id":"G1e60fe-eom3"}},{"cell_type":"code","source":["class Config:\n","    \"\"\"실행에 필요한 설정값을 관리합니다.\"\"\"\n","    # 🌟 TODO: 자신의 파일 전체 경로를 아래에 직접 입력해주세요.\n","    CSV_FILE_PATH = '/content/drive/MyDrive/review_helpfulness/PADA/data/amazon/amazon.csv'\n","    # 🌟 모든 토큰 정보가 담긴 3차원 Raw 임베딩 파일 경로\n","    EMBEDDING_PATH = \"/content/drive/MyDrive/review_helpfulness/PADA/embedding/amazon_T5.npy\"\n","\n","    # --- 데이터 정보 ---\n","    TARGET_COLUMN = 'binary_helpfulness'\n","\n","    # --- 데이터 분할 ---\n","    TEST_SPLIT_RATIO = 0.2\n","    RANDOM_STATE = 42\n","\n","    # --- Optuna 튜닝 설정 ---\n","    N_TRIALS = 50\n","    TUNING_METRIC = 'pr_auc'"],"metadata":{"id":"DPQbRQ7FWaB9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class EarlyStoppingCallback:\n","    def __init__(self, early_stopping_rounds: int):\n","        self._early_stopping_rounds = early_stopping_rounds\n","        self._best_value = -float(\"inf\")\n","        self._counter = 0\n","\n","    def __call__(self, study: optuna.study.Study, trial: optuna.trial.Trial):\n","        # 현재까지의 최고 점수 가져오기\n","        current_best_value = study.best_value\n","\n","        # 최고 점수가 갱신되었는지 확인\n","        if current_best_value is not None and current_best_value > self._best_value:\n","            self._best_value = current_best_value\n","            self._counter = 0  # 카운터 초기화\n","        else:\n","            self._counter += 1 # 점수 갱신 안되면 카운터 증가\n","\n","        # 정해진 횟수 이상 점수 갱신이 없으면 중단\n","        if self._counter >= self._early_stopping_rounds:\n","            print(f\"\\n[Optuna 조기 종료] {self._early_stopping_rounds}번의 trial 동안 최고 점수가 갱신되지 않아 튜닝을 중단합니다.\")\n","            study.stop()\n","\n","def objective(trial, X, y):\n","    \"\"\"Optuna가 최적의 하이퍼파라미터를 찾기 위해 반복 호출하는 함수\"\"\"\n","    X_train, X_val, y_train, y_val = train_test_split(\n","        X, y, test_size=0.25, random_state=Config.RANDOM_STATE, stratify=y\n","    )\n","\n","    params = {\n","        'objective': 'binary',\n","        'metric': 'logloss',\n","        'verbosity': -1,\n","        'boosting_type': 'gbdt',\n","        'random_state': Config.RANDOM_STATE,\n","        'n_estimators': trial.suggest_int('n_estimators', 100, 2000, step=100),\n","        'learning_rate': trial.suggest_float('learning_rate', 1e-3, 0.3, log=True),\n","        'num_leaves': trial.suggest_int('num_leaves', 20, 300),\n","        'max_depth': trial.suggest_int('max_depth', 3, 12),\n","        'lambda_l1': trial.suggest_float('lambda_l1', 1e-8, 10.0, log=True),\n","        'lambda_l2': trial.suggest_float('lambda_l2', 1e-8, 10.0, log=True),\n","        'feature_fraction': trial.suggest_float('feature_fraction', 0.6, 1.0),\n","        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.6, 1.0),\n","        'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\n","    }\n","\n","    # 🌟 GPU 사용을 위해 device='gpu' 파라미터 추가\n","    model = lgb.LGBMClassifier(device='gpu', **params)\n","\n","    model.fit(X_train, y_train,\n","              eval_set=[(X_val, y_val)],\n","              eval_metric='logloss',\n","              callbacks=[lgb.early_stopping(100, verbose=False)])\n","\n","    y_pred_proba = model.predict_proba(X_val)[:, 1]\n","    score = average_precision_score(y_val, y_pred_proba)\n","\n","    return score"],"metadata":{"id":"XlF8iPtrZT_4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["config = Config()"],"metadata":{"id":"1LUCBcRcZUKD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# --- Step 1: 데이터 로드 및 분할 ---\n","print(\"Step 1: 데이터 로드 및 분할 중...\")\n","try:\n","    df = pd.read_csv(config.CSV_FILE_PATH)\n","    labels = df[config.TARGET_COLUMN].values\n","    embeddings = np.load(config.EMBEDDING_PATH)\n","    assert len(df) == len(embeddings)\n","except Exception as e:\n","    print(f\"🔥 파일 로드 실패: {e}\"); exit()\n","\n","indices = np.arange(len(df))\n","train_indices, test_indices = train_test_split(\n","    indices, test_size=config.TEST_SPLIT_RATIO, random_state=config.RANDOM_STATE, stratify=labels\n",")\n","X_train, X_test = embeddings[train_indices], embeddings[test_indices]\n","y_train, y_test = labels[train_indices], labels[test_indices]\n","print(f\"✅ 완료 (학습용: {len(y_train)}건, 테스트용: {len(y_test)}건)\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ecVJgbAKZWi7","executionInfo":{"status":"ok","timestamp":1760192885460,"user_tz":-540,"elapsed":10691,"user":{"displayName":"KW-data-analytics","userId":"09651493752354345908"}},"outputId":"88502fee-1c64-42bf-f36a-169346431c17"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Step 1: 데이터 로드 및 분할 중...\n","✅ 완료 (학습용: 71941건, 테스트용: 17986건)\n"]}]},{"cell_type":"code","source":["# === 4. 메인 실행 블록 ===\n","if __name__ == '__main__':\n","\n","    # --- Step 2: 베이스라인 모델 성능 측정 ---\n","    print(\"\\n\" + \"=\"*50)\n","    print(\"📊 Step 2: 베이스라인 모델 성능 측정 (GPU 사용)\")\n","    print(\"=\"*50)\n","\n","    baseline_model = lgb.LGBMClassifier(device='gpu', random_state=config.RANDOM_STATE)\n","    baseline_model.fit(X_train, y_train)\n","\n","    y_pred_proba_base = baseline_model.predict_proba(X_test)[:, 1]\n","    y_pred_class_base = (y_pred_proba_base > 0.5).astype(int)\n","\n","    final_results = {}\n","    final_results['Baseline'] = {\n","        \"PR AUC\": average_precision_score(y_test, y_pred_proba_base),\n","        \"ROC AUC\": roc_auc_score(y_test, y_pred_proba_base),\n","        \"F1-Score\": f1_score(y_test, y_pred_class_base),\n","    }\n","    print(\"✅ 베이스라인 모델 평가 완료.\")\n","\n","    # --- Step 3: Optuna 튜닝 수행 ---\n","    print(\"\\n\" + \"=\"*50)\n","    print(f\"🔬 Step 3: Optuna 하이퍼파라미터 튜닝 시작 (GPU 사용)...\")\n","    print(\"=\"*50)\n","\n","    study = optuna.create_study(direction='maximize')\n","    pbar = tqdm(total=config.N_TRIALS, desc=\"Optuna 튜닝 진행률\")\n","    study.optimize(lambda trial: objective(trial, X_train, y_train),\n","                   n_trials=config.N_TRIALS,\n","                   callbacks=[lambda study, trial: pbar.update(1)])\n","    pbar.close()\n","\n","    # --- Step 4: 최적 하이퍼파라미터 명시적 출력 ---\n","    print(f\"\\n✅ 튜닝 완료!\")\n","    print(\"\\n\" + \"=\"*50)\n","    print(\"🔬 최적 하이퍼파라미터 (Best Hyperparameters)\")\n","    print(\"=\"*50)\n","    best_params = study.best_params\n","    for key, value in best_params.items():\n","        print(f\"{key:>20s}: {value}\")\n","    print(\"=\"*50)\n","\n","    # --- Step 5: 최종 모델 학습 및 평가 ---\n","    print(f\"\\n🔬 Step 5: 튜닝된 최종 모델 학습 및 평가...\")\n","    final_model = lgb.LGBMClassifier(device='gpu', objective='binary', verbosity=-1, random_state=config.RANDOM_STATE, **best_params)\n","    final_model.fit(X_train, y_train)\n","\n","    y_pred_proba_tuned = final_model.predict_proba(X_test)[:, 1]\n","    y_pred_class_tuned = (y_pred_proba_tuned > 0.5).astype(int)\n","\n","    final_results['Optuna Tuned'] = {\n","        \"PR AUC\": average_precision_score(y_test, y_pred_proba_tuned),\n","        \"ROC AUC\": roc_auc_score(y_test, y_pred_proba_tuned),\n","        \"F1-Score\": f1_score(y_test, y_pred_class_tuned),\n","    }\n","    print(\"✅ 튜닝된 모델 평가 완료.\")\n","\n","    # --- 최종 성능 비교 ---\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"📊 최종 성능 비교 결과 (Test Set)\")\n","    print(\"=\"*60)\n","    results_df = pd.DataFrame(final_results).T\n","    print(results_df.round(4))\n","\n","    # 🌟 --- Step 6: 전체 데이터에 대한 예측 결과 원본 CSV에 추가 후 저장 ---\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"💾 Step 6: 최종 모델 예측 결과를 원본 CSV에 추가하여 저장\")\n","    print(\"=\"*60)\n","\n","    # 1. 학습 데이터(Train Set)에 대한 예측 수행\n","    train_pred_proba = final_model.predict_proba(X_train)[:, 1]\n","    train_pred_class = (train_pred_proba > 0.5).astype(int)\n","\n","    # 2. 원본 DataFrame에 새로운 컬럼 추가 (초기값은 비워둠)\n","    df['s2_pred_proba'] = np.nan\n","\n","    # 3. 분할 시 사용했던 인덱스를 이용해 예측 결과를 원래 위치에 채워넣기\n","    df.loc[train_indices, 's2_pred_proba'] = train_pred_proba\n","\n","    df.loc[test_indices, 's2_pred_proba'] = y_pred_proba_tuned\n","\n","    # 4. 새로운 CSV 파일로 저장\n","    output_filename = os.path.join(os.path.dirname(config.CSV_FILE_PATH), \"T5_amazon_with_s2_predictions.csv\")\n","    df.to_csv(output_filename, index=False, encoding='utf-8-sig')\n","\n","    print(f\"✅ 모든 데이터의 예측 결과가 '{output_filename}' 파일에 성공적으로 저장되었습니다.\")\n","    print(\"\\n🎉 모든 과정이 완료되었습니다!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["da9b6486f46f4da5a1230953236e4fdc","e4abaf27db8b487ab7024365e03ab21c","c4992a2f12ca4a3484b32110595700d4","59adb65e10904b369c180fda42325cc4","c9db128360984f368f2d6835d0ec178a","a7612c256bcf49eb82105f693c77fead","0005815617454cad9dab1dae8106a636","8b481816bdc948fda404ccad9933e2f5","a896723169fc4d3c99d9a571e2dd96c7","8536fa13c6934973ad974b693701531f","132ec97988404cb3b038b0737adc98fd"]},"id":"92nk4HIHbnLL","executionInfo":{"status":"ok","timestamp":1760202185314,"user_tz":-540,"elapsed":4432422,"user":{"displayName":"KW-data-analytics","userId":"09651493752354345908"}},"outputId":"5056e493-a57c-453c-a800-6184999e9d23"},"execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","==================================================\n","📊 Step 2: 베이스라인 모델 성능 측정 (GPU 사용)\n","==================================================\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["[I 2025-10-11 14:39:21,617] A new study created in memory with name: no-name-f7928362-513a-4cbd-8f07-68750faab16c\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["✅ 베이스라인 모델 평가 완료.\n","\n","==================================================\n","🔬 Step 3: Optuna 하이퍼파라미터 튜닝 시작 (GPU 사용)...\n","==================================================\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"da9b6486f46f4da5a1230953236e4fdc","version_major":2,"version_minor":0},"text/plain":["Optuna 튜닝 진행률:   0%|          | 0/50 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"output_type":"stream","name":"stderr","text":["[I 2025-10-11 14:39:34,000] Trial 0 finished with value: 0.2956406522336126 and parameters: {'n_estimators': 400, 'learning_rate': 0.03184851035766648, 'num_leaves': 228, 'max_depth': 4, 'lambda_l1': 1.922753540301105, 'lambda_l2': 4.24008297585092, 'feature_fraction': 0.601543595164512, 'bagging_fraction': 0.6456228695497569, 'bagging_freq': 6}. Best is trial 0 with value: 0.2956406522336126.\n","[I 2025-10-11 14:39:59,101] Trial 1 finished with value: 0.29704213682239977 and parameters: {'n_estimators': 1200, 'learning_rate': 0.015380471142327334, 'num_leaves': 84, 'max_depth': 4, 'lambda_l1': 1.1641702209232268e-07, 'lambda_l2': 9.702731167645007, 'feature_fraction': 0.8030434117039636, 'bagging_fraction': 0.850404055880241, 'bagging_freq': 7}. Best is trial 1 with value: 0.29704213682239977.\n","[I 2025-10-11 14:40:09,649] Trial 2 finished with value: 0.2907487790108201 and parameters: {'n_estimators': 400, 'learning_rate': 0.034896183909109896, 'num_leaves': 152, 'max_depth': 3, 'lambda_l1': 1.383631034583124e-07, 'lambda_l2': 0.3190712235408052, 'feature_fraction': 0.7559373553348925, 'bagging_fraction': 0.8258328209586645, 'bagging_freq': 3}. Best is trial 1 with value: 0.29704213682239977.\n","[I 2025-10-11 14:41:08,919] Trial 3 finished with value: 0.29627992163967865 and parameters: {'n_estimators': 1100, 'learning_rate': 0.006989015310721744, 'num_leaves': 35, 'max_depth': 7, 'lambda_l1': 0.00015259420382812095, 'lambda_l2': 6.236000927137818e-07, 'feature_fraction': 0.9718248304639037, 'bagging_fraction': 0.9849143776840636, 'bagging_freq': 7}. Best is trial 1 with value: 0.29704213682239977.\n","[I 2025-10-11 14:41:16,632] Trial 4 finished with value: 0.28058747704863485 and parameters: {'n_estimators': 900, 'learning_rate': 0.12550340310306907, 'num_leaves': 65, 'max_depth': 3, 'lambda_l1': 0.00015726567833049764, 'lambda_l2': 1.020873280399383e-06, 'feature_fraction': 0.6112222167216605, 'bagging_fraction': 0.8265451088324575, 'bagging_freq': 2}. Best is trial 1 with value: 0.29704213682239977.\n","[I 2025-10-11 14:41:54,897] Trial 5 finished with value: 0.2887768227815404 and parameters: {'n_estimators': 400, 'learning_rate': 0.05423924785218909, 'num_leaves': 145, 'max_depth': 12, 'lambda_l1': 1.6705137295827405e-07, 'lambda_l2': 0.13047402790241522, 'feature_fraction': 0.964598753871384, 'bagging_fraction': 0.8481306907001448, 'bagging_freq': 6}. Best is trial 1 with value: 0.29704213682239977.\n","[I 2025-10-11 14:42:43,645] Trial 6 finished with value: 0.3001281035124923 and parameters: {'n_estimators': 1700, 'learning_rate': 0.01365327950698417, 'num_leaves': 294, 'max_depth': 7, 'lambda_l1': 1.266696467293224e-07, 'lambda_l2': 0.2773074909392821, 'feature_fraction': 0.9223192291746726, 'bagging_fraction': 0.6595923432746954, 'bagging_freq': 3}. Best is trial 6 with value: 0.3001281035124923.\n","[I 2025-10-11 14:43:08,708] Trial 7 finished with value: 0.2902504115694256 and parameters: {'n_estimators': 100, 'learning_rate': 0.006757172128156769, 'num_leaves': 150, 'max_depth': 12, 'lambda_l1': 0.00039901258101139017, 'lambda_l2': 0.08516400566339621, 'feature_fraction': 0.9086482735724434, 'bagging_fraction': 0.757903854344842, 'bagging_freq': 6}. Best is trial 6 with value: 0.3001281035124923.\n","[I 2025-10-11 14:43:42,690] Trial 8 finished with value: 0.294639181358871 and parameters: {'n_estimators': 1700, 'learning_rate': 0.003352002998305755, 'num_leaves': 272, 'max_depth': 4, 'lambda_l1': 7.637948712243925e-08, 'lambda_l2': 0.00679119008375881, 'feature_fraction': 0.6275568872373026, 'bagging_fraction': 0.7371027560352659, 'bagging_freq': 7}. Best is trial 6 with value: 0.3001281035124923.\n","[I 2025-10-11 14:43:57,974] Trial 9 finished with value: 0.2801542291759952 and parameters: {'n_estimators': 300, 'learning_rate': 0.08527839099725633, 'num_leaves': 102, 'max_depth': 7, 'lambda_l1': 7.090235608183077e-07, 'lambda_l2': 1.9820564882819502, 'feature_fraction': 0.6300791532955906, 'bagging_fraction': 0.6497319481004196, 'bagging_freq': 1}. Best is trial 6 with value: 0.3001281035124923.\n","[I 2025-10-11 14:50:07,732] Trial 10 finished with value: 0.30262269040608714 and parameters: {'n_estimators': 2000, 'learning_rate': 0.0010139859665180579, 'num_leaves': 297, 'max_depth': 9, 'lambda_l1': 0.026804411300674662, 'lambda_l2': 9.328579190304314e-05, 'feature_fraction': 0.8555504252155525, 'bagging_fraction': 0.6081880863002415, 'bagging_freq': 4}. Best is trial 10 with value: 0.30262269040608714.\n","[I 2025-10-11 14:55:39,537] Trial 11 finished with value: 0.30503694214464105 and parameters: {'n_estimators': 2000, 'learning_rate': 0.0017950086857897345, 'num_leaves': 295, 'max_depth': 9, 'lambda_l1': 0.08387632970052744, 'lambda_l2': 8.361277523538194e-05, 'feature_fraction': 0.8601866825979766, 'bagging_fraction': 0.6193545815988709, 'bagging_freq': 4}. Best is trial 11 with value: 0.30503694214464105.\n","[I 2025-10-11 15:03:15,097] Trial 12 finished with value: 0.3049830419159494 and parameters: {'n_estimators': 2000, 'learning_rate': 0.0013410298537387016, 'num_leaves': 234, 'max_depth': 10, 'lambda_l1': 0.3357398359324881, 'lambda_l2': 1.8730925217908677e-05, 'feature_fraction': 0.8301740428273859, 'bagging_fraction': 0.603343633986756, 'bagging_freq': 4}. Best is trial 11 with value: 0.30503694214464105.\n","[I 2025-10-11 15:09:10,357] Trial 13 finished with value: 0.3025994238692695 and parameters: {'n_estimators': 2000, 'learning_rate': 0.0012321156321609013, 'num_leaves': 224, 'max_depth': 10, 'lambda_l1': 4.3555109392710065, 'lambda_l2': 4.119665920309673e-05, 'feature_fraction': 0.7386749317805682, 'bagging_fraction': 0.712109407619087, 'bagging_freq': 4}. Best is trial 11 with value: 0.30503694214464105.\n","[I 2025-10-11 15:09:29,973] Trial 14 finished with value: 0.22672178502979357 and parameters: {'n_estimators': 1500, 'learning_rate': 0.2832384010422708, 'num_leaves': 232, 'max_depth': 9, 'lambda_l1': 0.11329435555544377, 'lambda_l2': 8.264055776033998e-06, 'feature_fraction': 0.8228750393834882, 'bagging_fraction': 0.6042179311818721, 'bagging_freq': 5}. Best is trial 11 with value: 0.30503694214464105.\n","[I 2025-10-11 15:14:56,060] Trial 15 finished with value: 0.30199269895885794 and parameters: {'n_estimators': 1500, 'learning_rate': 0.0023155081639717134, 'num_leaves': 203, 'max_depth': 10, 'lambda_l1': 0.030063014062547633, 'lambda_l2': 2.7697258284893288e-08, 'feature_fraction': 0.8765009330904996, 'bagging_fraction': 0.9174928519797321, 'bagging_freq': 3}. Best is trial 11 with value: 0.30503694214464105.\n","[I 2025-10-11 15:19:02,554] Trial 16 finished with value: 0.30278866392687553 and parameters: {'n_estimators': 1800, 'learning_rate': 0.002401200464212475, 'num_leaves': 252, 'max_depth': 9, 'lambda_l1': 0.003813122280477153, 'lambda_l2': 0.004008188051201275, 'feature_fraction': 0.7410570725303942, 'bagging_fraction': 0.6943627172127627, 'bagging_freq': 4}. Best is trial 11 with value: 0.30503694214464105.\n","[I 2025-10-11 15:21:36,516] Trial 17 finished with value: 0.3028239460055704 and parameters: {'n_estimators': 800, 'learning_rate': 0.004851592048438498, 'num_leaves': 185, 'max_depth': 11, 'lambda_l1': 0.17663925450403098, 'lambda_l2': 0.0003028674742979821, 'feature_fraction': 0.6942301625260703, 'bagging_fraction': 0.7599286352128994, 'bagging_freq': 5}. Best is trial 11 with value: 0.30503694214464105.\n","[I 2025-10-11 15:25:01,127] Trial 18 finished with value: 0.30160281584755266 and parameters: {'n_estimators': 1400, 'learning_rate': 0.0016169316528991638, 'num_leaves': 264, 'max_depth': 8, 'lambda_l1': 0.6244828818700254, 'lambda_l2': 0.0013281147059189793, 'feature_fraction': 0.8541617885654806, 'bagging_fraction': 0.6911032798236498, 'bagging_freq': 2}. Best is trial 11 with value: 0.30503694214464105.\n","[I 2025-10-11 15:26:02,265] Trial 19 finished with value: 0.30329562847935554 and parameters: {'n_estimators': 1900, 'learning_rate': 0.009464236126133294, 'num_leaves': 195, 'max_depth': 6, 'lambda_l1': 8.979247703402558, 'lambda_l2': 1.0454977945094412e-05, 'feature_fraction': 0.9245311364231412, 'bagging_fraction': 0.6033647582074515, 'bagging_freq': 5}. Best is trial 11 with value: 0.30503694214464105.\n","[I 2025-10-11 15:29:36,585] Trial 20 finished with value: 0.30194884456648047 and parameters: {'n_estimators': 1300, 'learning_rate': 0.0038797613642369256, 'num_leaves': 276, 'max_depth': 11, 'lambda_l1': 1.572660210888109e-05, 'lambda_l2': 2.3028498900894706e-08, 'feature_fraction': 0.774469565595416, 'bagging_fraction': 0.7888010974769455, 'bagging_freq': 4}. Best is trial 11 with value: 0.30503694214464105.\n","[I 2025-10-11 15:30:42,750] Trial 21 finished with value: 0.3031333502790101 and parameters: {'n_estimators': 1900, 'learning_rate': 0.010284943148301763, 'num_leaves': 187, 'max_depth': 6, 'lambda_l1': 3.992205991942833, 'lambda_l2': 5.05666425033295e-06, 'feature_fraction': 0.9173444778096886, 'bagging_fraction': 0.6107239575894661, 'bagging_freq': 5}. Best is trial 11 with value: 0.30503694214464105.\n","[I 2025-10-11 15:32:30,114] Trial 22 finished with value: 0.29837584152898755 and parameters: {'n_estimators': 1700, 'learning_rate': 0.002000792517797249, 'num_leaves': 204, 'max_depth': 6, 'lambda_l1': 0.606495437654833, 'lambda_l2': 3.5495680937169004e-07, 'feature_fraction': 0.8861524507148523, 'bagging_fraction': 0.6467037062580505, 'bagging_freq': 5}. Best is trial 11 with value: 0.30503694214464105.\n","[I 2025-10-11 15:33:13,566] Trial 23 finished with value: 0.3019688603253624 and parameters: {'n_estimators': 2000, 'learning_rate': 0.02531783814690921, 'num_leaves': 244, 'max_depth': 8, 'lambda_l1': 8.04571230820187, 'lambda_l2': 1.3074126390935802e-05, 'feature_fraction': 0.8338824544893805, 'bagging_fraction': 0.6319817967696678, 'bagging_freq': 4}. Best is trial 11 with value: 0.30503694214464105.\n","[I 2025-10-11 15:34:34,673] Trial 24 finished with value: 0.30419289952215334 and parameters: {'n_estimators': 1800, 'learning_rate': 0.006715106391035334, 'num_leaves': 184, 'max_depth': 6, 'lambda_l1': 0.0040390045680542335, 'lambda_l2': 0.00015238752047253, 'feature_fraction': 0.9479200623780079, 'bagging_fraction': 0.6738052249556647, 'bagging_freq': 3}. Best is trial 11 with value: 0.30503694214464105.\n","[I 2025-10-11 15:38:15,429] Trial 25 finished with value: 0.30210552828903015 and parameters: {'n_estimators': 1600, 'learning_rate': 0.0030489238733157347, 'num_leaves': 113, 'max_depth': 10, 'lambda_l1': 0.005329746998313361, 'lambda_l2': 0.0005964245891655119, 'feature_fraction': 0.9535381741693465, 'bagging_fraction': 0.6780188876949975, 'bagging_freq': 2}. Best is trial 11 with value: 0.30503694214464105.\n","[I 2025-10-11 15:39:29,304] Trial 26 finished with value: 0.2946826366916001 and parameters: {'n_estimators': 1800, 'learning_rate': 0.0015044008709725611, 'num_leaves': 175, 'max_depth': 5, 'lambda_l1': 0.001964268833053705, 'lambda_l2': 0.0001245526301037375, 'feature_fraction': 0.9892420811790341, 'bagging_fraction': 0.7205377310322342, 'bagging_freq': 3}. Best is trial 11 with value: 0.30503694214464105.\n","[I 2025-10-11 15:41:01,427] Trial 27 finished with value: 0.30328162214174637 and parameters: {'n_estimators': 700, 'learning_rate': 0.005503221004718014, 'num_leaves': 212, 'max_depth': 8, 'lambda_l1': 0.03235680238685309, 'lambda_l2': 0.017307268196381776, 'feature_fraction': 0.7820253735397206, 'bagging_fraction': 0.6739156444953042, 'bagging_freq': 1}. Best is trial 11 with value: 0.30503694214464105.\n","[I 2025-10-11 15:46:04,714] Trial 28 finished with value: 0.3034550802392571 and parameters: {'n_estimators': 1800, 'learning_rate': 0.0027245900970139943, 'num_leaves': 245, 'max_depth': 11, 'lambda_l1': 0.0007116454424493974, 'lambda_l2': 1.8068997406505454e-06, 'feature_fraction': 0.8794503602896809, 'bagging_fraction': 0.633645534913633, 'bagging_freq': 3}. Best is trial 11 with value: 0.30503694214464105.\n","[I 2025-10-11 15:49:43,650] Trial 29 finished with value: 0.29785718995804317 and parameters: {'n_estimators': 1500, 'learning_rate': 0.0010946904338703868, 'num_leaves': 123, 'max_depth': 9, 'lambda_l1': 1.5510994592052924e-05, 'lambda_l2': 4.005671591516806e-05, 'feature_fraction': 0.9429103310344661, 'bagging_fraction': 0.6291988674991233, 'bagging_freq': 2}. Best is trial 11 with value: 0.30503694214464105.\n","[I 2025-10-11 15:56:04,894] Trial 30 finished with value: 0.30404974385826755 and parameters: {'n_estimators': 2000, 'learning_rate': 0.0016837635108110402, 'num_leaves': 165, 'max_depth': 10, 'lambda_l1': 0.46005967956892074, 'lambda_l2': 1.8107882510608903e-07, 'feature_fraction': 0.8278694401933497, 'bagging_fraction': 0.6595266778404851, 'bagging_freq': 6}. Best is trial 11 with value: 0.30503694214464105.\n","[I 2025-10-11 16:01:27,041] Trial 31 finished with value: 0.30321545963267116 and parameters: {'n_estimators': 2000, 'learning_rate': 0.0019576980289678207, 'num_leaves': 169, 'max_depth': 10, 'lambda_l1': 0.6607680184020672, 'lambda_l2': 1.0836144645432014e-07, 'feature_fraction': 0.8174920067871524, 'bagging_fraction': 0.6600375328459028, 'bagging_freq': 6}. Best is trial 11 with value: 0.30503694214464105.\n","[I 2025-10-11 16:04:36,627] Trial 32 finished with value: 0.3015241653661459 and parameters: {'n_estimators': 1900, 'learning_rate': 0.004257740875163709, 'num_leaves': 227, 'max_depth': 11, 'lambda_l1': 0.13092941998435292, 'lambda_l2': 1.1503520238874515e-07, 'feature_fraction': 0.7973731451178642, 'bagging_fraction': 0.705726472515974, 'bagging_freq': 3}. Best is trial 11 with value: 0.30503694214464105.\n","[I 2025-10-11 16:05:41,402] Trial 33 finished with value: 0.2964383881139098 and parameters: {'n_estimators': 1800, 'learning_rate': 0.001569418161873047, 'num_leaves': 134, 'max_depth': 5, 'lambda_l1': 0.017651988748334842, 'lambda_l2': 0.0011032378790206022, 'feature_fraction': 0.8615176813362683, 'bagging_fraction': 0.6707456545583848, 'bagging_freq': 4}. Best is trial 11 with value: 0.30503694214464105.\n","[I 2025-10-11 16:06:23,170] Trial 34 finished with value: 0.29317176411697965 and parameters: {'n_estimators': 1600, 'learning_rate': 0.021905222111631352, 'num_leaves': 168, 'max_depth': 9, 'lambda_l1': 0.818468142660889, 'lambda_l2': 0.0001711634140561568, 'feature_fraction': 0.8420822926325812, 'bagging_fraction': 0.6325619252864093, 'bagging_freq': 4}. Best is trial 11 with value: 0.30503694214464105.\n","[I 2025-10-11 16:11:28,826] Trial 35 finished with value: 0.2972075013201515 and parameters: {'n_estimators': 1100, 'learning_rate': 0.0014358464638490527, 'num_leaves': 285, 'max_depth': 10, 'lambda_l1': 0.13462538489381834, 'lambda_l2': 3.148677977364484e-06, 'feature_fraction': 0.8959963870983128, 'bagging_fraction': 0.7419529091906187, 'bagging_freq': 7}. Best is trial 11 with value: 0.30503694214464105.\n","[I 2025-10-11 16:12:45,402] Trial 36 finished with value: 0.2964399740235676 and parameters: {'n_estimators': 1900, 'learning_rate': 0.007060019333614814, 'num_leaves': 89, 'max_depth': 8, 'lambda_l1': 0.00925753660290486, 'lambda_l2': 3.247185635751367e-05, 'feature_fraction': 0.9938712763878602, 'bagging_fraction': 0.8766174513574556, 'bagging_freq': 6}. Best is trial 11 with value: 0.30503694214464105.\n","[I 2025-10-11 16:13:03,505] Trial 37 finished with value: 0.29287006691750883 and parameters: {'n_estimators': 2000, 'learning_rate': 0.03768255618296216, 'num_leaves': 52, 'max_depth': 7, 'lambda_l1': 1.6992251398004696, 'lambda_l2': 2.6809782847314417e-07, 'feature_fraction': 0.8098680525112865, 'bagging_fraction': 0.62324568596056, 'bagging_freq': 3}. Best is trial 11 with value: 0.30503694214464105.\n","[I 2025-10-11 16:14:37,223] Trial 38 finished with value: 0.29923127525803606 and parameters: {'n_estimators': 1300, 'learning_rate': 0.012873273575546032, 'num_leaves': 260, 'max_depth': 12, 'lambda_l1': 0.052515182151823867, 'lambda_l2': 1.2798823831313947e-06, 'feature_fraction': 0.7613689398624036, 'bagging_fraction': 0.7956908600077754, 'bagging_freq': 5}. Best is trial 11 with value: 0.30503694214464105.\n","[I 2025-10-11 16:15:32,774] Trial 39 finished with value: 0.29551730723068126 and parameters: {'n_estimators': 1600, 'learning_rate': 0.003102955929571302, 'num_leaves': 148, 'max_depth': 5, 'lambda_l1': 0.0012339626166265553, 'lambda_l2': 0.02072088440335931, 'feature_fraction': 0.7148106103911804, 'bagging_fraction': 0.9814666402914342, 'bagging_freq': 2}. Best is trial 11 with value: 0.30503694214464105.\n","[I 2025-10-11 16:22:33,990] Trial 40 finished with value: 0.30216501521270117 and parameters: {'n_estimators': 1700, 'learning_rate': 0.001786756877033727, 'num_leaves': 218, 'max_depth': 11, 'lambda_l1': 0.00012168239118978745, 'lambda_l2': 3.17930975131132e-05, 'feature_fraction': 0.9368879603926396, 'bagging_fraction': 0.6500208037016139, 'bagging_freq': 6}. Best is trial 11 with value: 0.30503694214464105.\n","[I 2025-10-11 16:27:12,275] Trial 41 finished with value: 0.3038039880099501 and parameters: {'n_estimators': 1800, 'learning_rate': 0.002709357318908635, 'num_leaves': 233, 'max_depth': 11, 'lambda_l1': 6.759677293761301e-05, 'lambda_l2': 2.404201927247027e-06, 'feature_fraction': 0.8752198355219732, 'bagging_fraction': 0.6255578575803178, 'bagging_freq': 3}. Best is trial 11 with value: 0.30503694214464105.\n","[I 2025-10-11 16:32:13,682] Trial 42 finished with value: 0.30148748856893537 and parameters: {'n_estimators': 1900, 'learning_rate': 0.0024336206294551673, 'num_leaves': 239, 'max_depth': 10, 'lambda_l1': 7.124524113253233e-05, 'lambda_l2': 8.06514120562056e-08, 'feature_fraction': 0.9019866505709282, 'bagging_fraction': 0.685304708053184, 'bagging_freq': 3}. Best is trial 11 with value: 0.30503694214464105.\n","[I 2025-10-11 16:34:19,985] Trial 43 finished with value: 0.2999631240760756 and parameters: {'n_estimators': 1800, 'learning_rate': 0.006048841265385849, 'num_leaves': 159, 'max_depth': 12, 'lambda_l1': 3.629168089058587e-06, 'lambda_l2': 4.610945788651444e-07, 'feature_fraction': 0.8618583307847855, 'bagging_fraction': 0.659718188514843, 'bagging_freq': 4}. Best is trial 11 with value: 0.30503694214464105.\n","[I 2025-10-11 16:41:53,877] Trial 44 finished with value: 0.30344584758104365 and parameters: {'n_estimators': 1700, 'learning_rate': 0.0010060041046787642, 'num_leaves': 284, 'max_depth': 11, 'lambda_l1': 4.1372277977860866e-05, 'lambda_l2': 2.3280465875870143e-06, 'feature_fraction': 0.7952512361314685, 'bagging_fraction': 0.6214833255664476, 'bagging_freq': 4}. Best is trial 11 with value: 0.30503694214464105.\n","[I 2025-10-11 16:44:16,097] Trial 45 finished with value: 0.3016022387380931 and parameters: {'n_estimators': 2000, 'learning_rate': 0.0039116484863855735, 'num_leaves': 139, 'max_depth': 9, 'lambda_l1': 1.791046341490173e-08, 'lambda_l2': 1.7917422109449094e-05, 'feature_fraction': 0.8328540876028905, 'bagging_fraction': 0.6421299134017393, 'bagging_freq': 2}. Best is trial 11 with value: 0.30503694214464105.\n","[I 2025-10-11 16:51:02,456] Trial 46 finished with value: 0.3032430458052956 and parameters: {'n_estimators': 1900, 'learning_rate': 0.0013641442644340641, 'num_leaves': 209, 'max_depth': 10, 'lambda_l1': 0.00028128123574914534, 'lambda_l2': 0.00011298795819591764, 'feature_fraction': 0.8680358205723379, 'bagging_fraction': 0.6163864082413619, 'bagging_freq': 3}. Best is trial 11 with value: 0.30503694214464105.\n","[I 2025-10-11 16:51:27,014] Trial 47 finished with value: 0.2947628066750132 and parameters: {'n_estimators': 1700, 'learning_rate': 0.008396467987457579, 'num_leaves': 181, 'max_depth': 3, 'lambda_l1': 0.38559137729874177, 'lambda_l2': 7.788311561999103e-07, 'feature_fraction': 0.8926937836365624, 'bagging_fraction': 0.7265857470675814, 'bagging_freq': 3}. Best is trial 11 with value: 0.30503694214464105.\n","[I 2025-10-11 16:54:50,869] Trial 48 finished with value: 0.29832636549482416 and parameters: {'n_estimators': 1000, 'learning_rate': 0.002123703463866287, 'num_leaves': 196, 'max_depth': 9, 'lambda_l1': 0.07186461804342818, 'lambda_l2': 5.409655410605878e-06, 'feature_fraction': 0.9691480855433185, 'bagging_fraction': 0.6004377885557354, 'bagging_freq': 7}. Best is trial 11 with value: 0.30503694214464105.\n","[I 2025-10-11 16:56:12,978] Trial 49 finished with value: 0.29955891552270747 and parameters: {'n_estimators': 1800, 'learning_rate': 0.003356232402498385, 'num_leaves': 26, 'max_depth': 10, 'lambda_l1': 0.013625513255689196, 'lambda_l2': 0.0003996705438037211, 'feature_fraction': 0.8396469069622445, 'bagging_fraction': 0.6620025825641556, 'bagging_freq': 4}. Best is trial 11 with value: 0.30503694214464105.\n"]},{"output_type":"stream","name":"stdout","text":["\n","✅ 튜닝 완료!\n","\n","==================================================\n","🔬 최적 하이퍼파라미터 (Best Hyperparameters)\n","==================================================\n","        n_estimators: 2000\n","       learning_rate: 0.0017950086857897345\n","          num_leaves: 295\n","           max_depth: 9\n","           lambda_l1: 0.08387632970052744\n","           lambda_l2: 8.361277523538194e-05\n","    feature_fraction: 0.8601866825979766\n","    bagging_fraction: 0.6193545815988709\n","        bagging_freq: 4\n","==================================================\n","\n","🔬 Step 5: 튜닝된 최종 모델 학습 및 평가...\n","✅ 튜닝된 모델 평가 완료.\n","\n","============================================================\n","📊 최종 성능 비교 결과 (Test Set)\n","============================================================\n","              PR AUC  ROC AUC  F1-Score\n","Baseline      0.3127   0.7732    0.0997\n","Optuna Tuned  0.3365   0.7827    0.0700\n","\n","============================================================\n","💾 Step 6: 최종 모델 예측 결과를 원본 CSV에 추가하여 저장\n","============================================================\n","✅ 모든 데이터의 예측 결과가 '/content/drive/MyDrive/review_helpfulness/PADA/data/amazon/T5_amazon_with_s2_predictions.csv' 파일에 성공적으로 저장되었습니다.\n","\n","🎉 모든 과정이 완료되었습니다!\n"]}]},{"cell_type":"markdown","source":["# Amazon"],"metadata":{"id":"Cvv9xmIcediR"}},{"cell_type":"markdown","source":["## T5"],"metadata":{"id":"srIut4sJewOz"}},{"cell_type":"code","source":["# === 2. 환경설정 클래스 ===\n","class Config:\n","    \"\"\"실행에 필요한 모든 설정값을 중앙에서 관리합니다.\"\"\"\n","    # 🌟 1. 입력 파일 경로 설정\n","    CSV_FILE_PATH = \"/content/drive/MyDrive/review_helpfulness/PADA/data/amazon/amazon.csv\"\n","    EMBEDDING_PATH = \"/content/drive/MyDrive/review_helpfulness/PADA/embedding/amazon_T5.npy\"\n","\n","    # 🌟 2. 최종 결과 CSV 파일 저장 경로 설정\n","    OUTPUT_CSV_PATH = \"/content/drive/MyDrive/review_helpfulness/PADA/results/s2/amazon/T5_amazon_with_s2_predictions.csv\"\n","\n","    # --- 데이터 정보 ---\n","    TARGET_COLUMN = 'binary_helpfulness'\n","\n","    # --- 데이터 분할 ---\n","    TEST_SPLIT_RATIO = 0.2\n","    RANDOM_STATE = 42\n","\n","    # --- Optuna 튜닝 설정 ---\n","    N_TRIALS = 50\n","    TUNING_METRIC = 'pr_auc'\n","    EARLY_STOPPING_ROUNDS = 10 # 🌟 Optuna 조기 종료 횟수\n","\n","# === 3. Optuna 조기 종료 콜백 ===\n","class EarlyStoppingCallback:\n","    \"\"\"Optuna 스터디의 조기 종료를 위한 콜백 클래스\"\"\"\n","    def __init__(self, early_stopping_rounds: int):\n","        self._early_stopping_rounds = early_stopping_rounds\n","        self._best_value = -float(\"inf\")\n","        self._counter = 0\n","\n","    def __call__(self, study: optuna.study.Study, trial: optuna.trial.Trial):\n","        current_best_value = study.best_value\n","        if current_best_value is not None and current_best_value > self._best_value:\n","            self._best_value = current_best_value\n","            self._counter = 0\n","        else:\n","            self._counter += 1\n","\n","        if self._counter >= self._early_stopping_rounds:\n","            print(f\"\\n[Optuna 조기 종료] {self._early_stopping_rounds}번의 trial 동안 최고 점수가 갱신되지 않아 튜닝을 중단합니다.\")\n","            study.stop()\n","\n","# === 4. Optuna Objective 함수 ===\n","def objective(trial, X, y):\n","    \"\"\"Optuna가 최적의 하이퍼파라미터를 찾기 위해 반복 호출하는 함수\"\"\"\n","    X_train, X_val, y_train, y_val = train_test_split(\n","        X, y, test_size=0.25, random_state=Config.RANDOM_STATE, stratify=y\n","    )\n","\n","    params = {\n","        'objective': 'binary', 'metric': 'logloss', 'verbosity': -1,\n","        'boosting_type': 'gbdt', 'random_state': Config.RANDOM_STATE,\n","        'device': 'gpu',  # 🌟 Optuna Trial 내부에서도 GPU 사용\n","        'n_estimators': trial.suggest_int('n_estimators', 100, 2000, step=100),\n","        'learning_rate': trial.suggest_float('learning_rate', 1e-3, 0.3, log=True),\n","        'num_leaves': trial.suggest_int('num_leaves', 20, 300),\n","        'max_depth': trial.suggest_int('max_depth', 3, 12),\n","        'lambda_l1': trial.suggest_float('lambda_l1', 1e-8, 10.0, log=True),\n","        'lambda_l2': trial.suggest_float('lambda_l2', 1e-8, 10.0, log=True),\n","        'feature_fraction': trial.suggest_float('feature_fraction', 0.6, 1.0),\n","        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.6, 1.0),\n","        'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\n","    }\n","\n","    model = lgb.LGBMClassifier(**params)\n","    model.fit(X_train, y_train,\n","              eval_set=[(X_val, y_val)],\n","              eval_metric='logloss',\n","              callbacks=[lgb.early_stopping(100, verbose=False)])\n","\n","    y_pred_proba = model.predict_proba(X_val)[:, 1]\n","    score = average_precision_score(y_val, y_pred_proba)\n","    return score\n","\n","# === 5. 메인 실행 블록 ===\n","if __name__ == '__main__':\n","    config = Config()\n","\n","    # ... (Step 1 ~ 2: 데이터 로드, 분할, 베이스라인 측정) ...\n","    print(\"Step 1: 데이터 로드 및 분할 중...\")\n","    try:\n","        df = pd.read_csv(config.CSV_FILE_PATH)\n","        labels = df[config.TARGET_COLUMN].values\n","        embeddings = np.load(config.EMBEDDING_PATH)\n","        assert len(df) == len(embeddings)\n","    except Exception as e:\n","        print(f\"🔥 파일 로드 실패: {e}\"); exit()\n","\n","    indices = np.arange(len(df))\n","    train_indices, test_indices = train_test_split(\n","        indices, test_size=config.TEST_SPLIT_RATIO, random_state=config.RANDOM_STATE, stratify=labels\n","    )\n","    X_train, X_test = embeddings[train_indices], embeddings[test_indices]\n","    y_train, y_test = labels[train_indices], labels[test_indices]\n","    print(f\"✅ 완료 (학습용: {len(y_train)}건, 테스트용: {len(y_test)}건)\")\n","\n","    print(\"\\n\" + \"=\"*50)\n","    print(\"📊 Step 2: 베이스라인 모델 성능 측정 (GPU 사용)\")\n","    print(\"=\"*50)\n","\n","    baseline_model = lgb.LGBMClassifier(device='gpu', random_state=config.RANDOM_STATE)\n","    baseline_model.fit(X_train, y_train)\n","\n","    y_pred_proba_base = baseline_model.predict_proba(X_test)[:, 1]\n","    y_pred_class_base = (y_pred_proba_base > 0.5).astype(int)\n","\n","    final_results = {}\n","    final_results['Baseline'] = {\n","        \"PR AUC\": average_precision_score(y_test, y_pred_proba_base),\n","        \"ROC AUC\": roc_auc_score(y_test, y_pred_proba_base),\n","        \"F1-Score\": f1_score(y_test, y_pred_class_base),\n","    }\n","    print(\"✅ 베이스라인 모델 평가 완료.\")\n","\n","    # --- Step 3: Optuna 튜닝 수행 (조기 종료 포함) ---\n","    print(\"\\n\" + \"=\"*50)\n","    print(f\"🔬 Step 3: Optuna 하이퍼파라미터 튜닝 시작 (GPU 사용)...\")\n","    print(f\"(최대 {config.N_TRIALS}번 시도, {config.EARLY_STOPPING_ROUNDS}번 개선 없으면 조기 종료)\")\n","    print(\"=\"*50)\n","\n","    early_stopping_callback = EarlyStoppingCallback(early_stopping_rounds=config.EARLY_STOPPING_ROUNDS)\n","    study = optuna.create_study(direction='maximize')\n","    pbar = tqdm(total=config.N_TRIALS, desc=\"Optuna 튜닝 진행률\")\n","\n","    try:\n","        study.optimize(lambda trial: objective(trial, X_train, y_train),\n","                       n_trials=config.N_TRIALS,\n","                       callbacks=[lambda study, trial: pbar.update(1), early_stopping_callback])\n","    except optuna.exceptions.OptunaError:\n","        # 조기 종료 시 발생하는 예외를 정상 처리\n","        pass\n","    pbar.close()\n","\n","    # ... (Step 4 ~ 6: 결과 출력, 저장, 메모리 정리) ...\n","    print(f\"\\n✅ 튜닝 완료!\")\n","    print(\"\\n\" + \"=\"*50)\n","    print(\"🔬 최적 하이퍼파라미터 (Best Hyperparameters)\")\n","    print(\"=\"*50)\n","    best_params = study.best_params\n","    for key, value in best_params.items():\n","        print(f\"{key:>20s}: {value}\")\n","    print(\"=\"*50)\n","\n","    print(f\"\\n🔬 Step 5: 튜닝된 최종 모델 학습 및 평가...\")\n","    final_model = lgb.LGBMClassifier(device='gpu', objective='binary', verbosity=-1, random_state=config.RANDOM_STATE, **best_params)\n","    final_model.fit(X_train, y_train)\n","\n","    y_pred_proba_tuned = final_model.predict_proba(X_test)[:, 1]\n","    y_pred_class_tuned = (y_pred_proba_tuned > 0.5).astype(int)\n","\n","    final_results['Optuna Tuned'] = {\n","        \"PR AUC\": average_precision_score(y_test, y_pred_proba_tuned),\n","        \"ROC AUC\": roc_auc_score(y_test, y_pred_proba_tuned),\n","        \"F1-Score\": f1_score(y_test, y_pred_class_tuned),\n","    }\n","    print(\"✅ 튜닝된 모델 평가 완료.\")\n","\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"📊 최종 성능 비교 결과 (Test Set)\")\n","    print(\"=\"*60)\n","    results_df = pd.DataFrame(final_results).T\n","    print(results_df.round(4))\n","\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"💾 Step 6: 최종 모델 예측 결과를 원본 CSV에 추가하여 저장\")\n","    print(\"=\"*60)\n","\n","    train_pred_proba = final_model.predict_proba(X_train)[:, 1]\n","    train_pred_class = (train_pred_proba > 0.5).astype(int)\n","\n","    df['s2_pred_proba'] = np.nan\n","    df['s2_pred_class'] = np.nan\n","\n","    df.loc[train_indices, 's2_pred_proba'] = train_pred_proba\n","    df.loc[train_indices, 's2_pred_class'] = train_pred_class\n","\n","    df.loc[test_indices, 's2_pred_proba'] = y_pred_proba_tuned\n","    df.loc[test_indices, 's2_pred_class'] = y_pred_class_tuned\n","\n","    # 🌟 Config에 설정된 경로로 최종 파일 저장\n","    df.to_csv(config.OUTPUT_CSV_PATH, index=False, encoding='utf-8-sig')\n","\n","    print(f\"✅ 모든 데이터의 예측 결과가 '{config.OUTPUT_CSV_PATH}' 파일에 성공적으로 저장되었습니다.\")\n","\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"🧹 Step 7: 사용된 변수들을 메모리에서 정리\")\n","    print(\"=\"*60)\n","\n","    vars_to_delete = [\n","        'df', 'labels', 'embeddings', 'indices', 'X_train', 'X_test',\n","        'y_train', 'y_test', 'train_indices', 'test_indices',\n","        'baseline_model', 'final_model', 'study',\n","    ]\n","    for var_name in vars_to_delete:\n","        if var_name in locals() or var_name in globals():\n","            if var_name in globals(): del globals()[var_name]\n","\n","    gc.collect()\n","    print(\"✅ 메모리 정리가 완료되었습니다.\")\n","\n","    print(\"\\n🎉 모든 과정이 완료되었습니다!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["679d058644e34d469a28ea0914235949","cf72684b44a844b2a70b872108217f94","aa489c64b9a2474aa7fa2ed273fbb544","934006a2454e4d5f9174cf2499f14636","513b977b2c6a4f729dd9611a090ca0a4","09ca48d6ffe945d98b9a6df2a8db2196","f4110a157fd649648eeb23c0d313f191","ef8dcdadec85462abfff980583a83e7e","33a992ae91fb42a9b9ca7b6043dcad88","a06e94e976f0401d9e1c23b0384b7a4e","a9621fac6ca04c0eb3f95fb74d673b97"]},"id":"2xpAh3qHgwdZ","executionInfo":{"status":"ok","timestamp":1760209054880,"user_tz":-540,"elapsed":1457340,"user":{"displayName":"KW-data-analytics","userId":"09651493752354345908"}},"outputId":"fbea3e37-2552-4057-fba5-316b908dffd8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Step 1: 데이터 로드 및 분할 중...\n","✅ 완료 (학습용: 71941건, 테스트용: 17986건)\n","\n","==================================================\n","📊 Step 2: 베이스라인 모델 성능 측정 (GPU 사용)\n","==================================================\n","[LightGBM] [Info] Number of positive: 7076, number of negative: 64865\n","[LightGBM] [Info] This is the GPU trainer!!\n","[LightGBM] [Info] Total Bins 195840\n","[LightGBM] [Info] Number of data points in the train set: 71941, number of used features: 768\n","[LightGBM] [Info] Using GPU Device: NVIDIA A100-SXM4-80GB, Vendor: NVIDIA Corporation\n","[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n","[LightGBM] [Info] GPU programs have been built\n","[LightGBM] [Info] Size of histogram bin entry: 8\n","[LightGBM] [Info] 768 dense feature groups (52.69 MB) transferred to GPU in 0.041615 secs. 0 sparse feature groups\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.098358 -> initscore=-2.215599\n","[LightGBM] [Info] Start training from score -2.215599\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-10-11 18:33:39,267] A new study created in memory with name: no-name-338b1c2b-b157-4fd8-9b64-b26309478bca\n"]},{"output_type":"stream","name":"stdout","text":["✅ 베이스라인 모델 평가 완료.\n","\n","==================================================\n","🔬 Step 3: Optuna 하이퍼파라미터 튜닝 시작 (GPU 사용)...\n","(최대 50번 시도, 10번 개선 없으면 조기 종료)\n","==================================================\n"]},{"output_type":"display_data","data":{"text/plain":["Optuna 튜닝 진행률:   0%|          | 0/50 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"679d058644e34d469a28ea0914235949"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2025-10-11 18:33:49,599] Trial 0 finished with value: 0.29694767669840505 and parameters: {'n_estimators': 1200, 'learning_rate': 0.04915638806701335, 'num_leaves': 70, 'max_depth': 5, 'lambda_l1': 0.00033383742193826386, 'lambda_l2': 3.5192403569765944, 'feature_fraction': 0.785005665093617, 'bagging_fraction': 0.9891244923546361, 'bagging_freq': 1}. Best is trial 0 with value: 0.29694767669840505.\n","[I 2025-10-11 18:34:00,336] Trial 1 finished with value: 0.2932882557142812 and parameters: {'n_estimators': 400, 'learning_rate': 0.06368537216960567, 'num_leaves': 139, 'max_depth': 6, 'lambda_l1': 0.009511681403698553, 'lambda_l2': 7.928214068625509, 'feature_fraction': 0.7266926359340881, 'bagging_fraction': 0.8249621852756466, 'bagging_freq': 4}. Best is trial 0 with value: 0.29694767669840505.\n","[I 2025-10-11 18:36:26,748] Trial 2 finished with value: 0.30045609709731175 and parameters: {'n_estimators': 1700, 'learning_rate': 0.003431992492305313, 'num_leaves': 152, 'max_depth': 10, 'lambda_l1': 1.052639984914043e-05, 'lambda_l2': 4.501889645374784e-06, 'feature_fraction': 0.9079386871095632, 'bagging_fraction': 0.7723535534058249, 'bagging_freq': 2}. Best is trial 2 with value: 0.30045609709731175.\n","[I 2025-10-11 18:36:51,111] Trial 3 finished with value: 0.2885742631616348 and parameters: {'n_estimators': 2000, 'learning_rate': 0.001022033851120619, 'num_leaves': 229, 'max_depth': 4, 'lambda_l1': 0.00012292513114091938, 'lambda_l2': 0.059689296067968266, 'feature_fraction': 0.6172504769040287, 'bagging_fraction': 0.7550685728307305, 'bagging_freq': 7}. Best is trial 2 with value: 0.30045609709731175.\n","[I 2025-10-11 18:37:06,762] Trial 4 finished with value: 0.2925219116026877 and parameters: {'n_estimators': 900, 'learning_rate': 0.010201218119902704, 'num_leaves': 187, 'max_depth': 4, 'lambda_l1': 1.4327374612593008e-06, 'lambda_l2': 0.27384165637451524, 'feature_fraction': 0.9786615120650436, 'bagging_fraction': 0.8653625457119669, 'bagging_freq': 5}. Best is trial 2 with value: 0.30045609709731175.\n","[I 2025-10-11 18:37:24,172] Trial 5 finished with value: 0.30113084047462346 and parameters: {'n_estimators': 1200, 'learning_rate': 0.009984498264160537, 'num_leaves': 178, 'max_depth': 4, 'lambda_l1': 0.6615473840387707, 'lambda_l2': 0.008596957213618786, 'feature_fraction': 0.7433411355068388, 'bagging_fraction': 0.6640737571853156, 'bagging_freq': 1}. Best is trial 5 with value: 0.30113084047462346.\n","[I 2025-10-11 18:37:31,001] Trial 6 finished with value: 0.2875849215382669 and parameters: {'n_estimators': 400, 'learning_rate': 0.014928515997718947, 'num_leaves': 203, 'max_depth': 3, 'lambda_l1': 0.0006404517909267382, 'lambda_l2': 3.7459292104170137e-06, 'feature_fraction': 0.7318045474580523, 'bagging_fraction': 0.7131748980050154, 'bagging_freq': 4}. Best is trial 5 with value: 0.30113084047462346.\n","[I 2025-10-11 18:37:44,654] Trial 7 finished with value: 0.28161571863725693 and parameters: {'n_estimators': 800, 'learning_rate': 0.09239827428203026, 'num_leaves': 102, 'max_depth': 8, 'lambda_l1': 2.3172759491478692e-06, 'lambda_l2': 2.2629930950508466, 'feature_fraction': 0.8928637508451541, 'bagging_fraction': 0.969482507499551, 'bagging_freq': 3}. Best is trial 5 with value: 0.30113084047462346.\n","[I 2025-10-11 18:38:02,825] Trial 8 finished with value: 0.28828372694162474 and parameters: {'n_estimators': 700, 'learning_rate': 0.0017383003267913448, 'num_leaves': 29, 'max_depth': 5, 'lambda_l1': 0.0002665412157919844, 'lambda_l2': 3.236212994667662, 'feature_fraction': 0.736880194248032, 'bagging_fraction': 0.7051217664147563, 'bagging_freq': 3}. Best is trial 5 with value: 0.30113084047462346.\n","[I 2025-10-11 18:38:14,807] Trial 9 finished with value: 0.27207565755547625 and parameters: {'n_estimators': 1100, 'learning_rate': 0.09582405228640145, 'num_leaves': 275, 'max_depth': 8, 'lambda_l1': 1.8879480248811609e-06, 'lambda_l2': 0.07032137170924116, 'feature_fraction': 0.6507261516592222, 'bagging_fraction': 0.8706503544595977, 'bagging_freq': 7}. Best is trial 5 with value: 0.30113084047462346.\n","[I 2025-10-11 18:40:22,312] Trial 10 finished with value: 0.30522724879340096 and parameters: {'n_estimators': 1500, 'learning_rate': 0.005496229720566432, 'num_leaves': 292, 'max_depth': 12, 'lambda_l1': 9.664868582582134, 'lambda_l2': 0.0007024265444479108, 'feature_fraction': 0.8264808185445718, 'bagging_fraction': 0.6023293694775351, 'bagging_freq': 1}. Best is trial 10 with value: 0.30522724879340096.\n","[I 2025-10-11 18:42:14,740] Trial 11 finished with value: 0.3040350262720336 and parameters: {'n_estimators': 1500, 'learning_rate': 0.0053372127640190946, 'num_leaves': 298, 'max_depth': 12, 'lambda_l1': 6.200517243741689, 'lambda_l2': 0.0006424258646487173, 'feature_fraction': 0.8382509231391708, 'bagging_fraction': 0.6066024441771707, 'bagging_freq': 1}. Best is trial 10 with value: 0.30522724879340096.\n","[I 2025-10-11 18:44:42,122] Trial 12 finished with value: 0.30373469582192547 and parameters: {'n_estimators': 1600, 'learning_rate': 0.004005918963285898, 'num_leaves': 293, 'max_depth': 12, 'lambda_l1': 5.925962874199589, 'lambda_l2': 0.00026153610619252947, 'feature_fraction': 0.8592501583580665, 'bagging_fraction': 0.6052114071303618, 'bagging_freq': 1}. Best is trial 10 with value: 0.30522724879340096.\n","[I 2025-10-11 18:45:04,242] Trial 13 finished with value: 0.21082702628118632 and parameters: {'n_estimators': 1500, 'learning_rate': 0.2583101327398223, 'num_leaves': 257, 'max_depth': 12, 'lambda_l1': 1.0380871121951879e-08, 'lambda_l2': 0.00021831012398428626, 'feature_fraction': 0.8277921142499807, 'bagging_fraction': 0.6158546680701039, 'bagging_freq': 2}. Best is trial 10 with value: 0.30522724879340096.\n","[I 2025-10-11 18:47:01,613] Trial 14 finished with value: 0.2991587095377124 and parameters: {'n_estimators': 2000, 'learning_rate': 0.00493941457603391, 'num_leaves': 241, 'max_depth': 10, 'lambda_l1': 0.08923093519090954, 'lambda_l2': 1.2912565904713657e-08, 'feature_fraction': 0.9594312062034627, 'bagging_fraction': 0.6561042255493039, 'bagging_freq': 2}. Best is trial 10 with value: 0.30522724879340096.\n","[I 2025-10-11 18:47:37,780] Trial 15 finished with value: 0.298731763085613 and parameters: {'n_estimators': 1400, 'learning_rate': 0.019424602923193, 'num_leaves': 297, 'max_depth': 10, 'lambda_l1': 9.334195813983401, 'lambda_l2': 0.0025298205081022997, 'feature_fraction': 0.8054410268201769, 'bagging_fraction': 0.6622941703959687, 'bagging_freq': 5}. Best is trial 10 with value: 0.30522724879340096.\n","[I 2025-10-11 18:48:13,490] Trial 16 finished with value: 0.28583532157970204 and parameters: {'n_estimators': 1800, 'learning_rate': 0.027055662366318865, 'num_leaves': 218, 'max_depth': 11, 'lambda_l1': 0.19676648906215893, 'lambda_l2': 1.5683552191635745e-05, 'feature_fraction': 0.9165145056175277, 'bagging_fraction': 0.6023678741412121, 'bagging_freq': 3}. Best is trial 10 with value: 0.30522724879340096.\n","[I 2025-10-11 18:49:31,606] Trial 17 finished with value: 0.2977394612476143 and parameters: {'n_estimators': 1400, 'learning_rate': 0.006445038926198014, 'num_leaves': 264, 'max_depth': 9, 'lambda_l1': 0.01415258385828965, 'lambda_l2': 1.658685898358262e-07, 'feature_fraction': 0.8455271325131325, 'bagging_fraction': 0.7176500090234051, 'bagging_freq': 1}. Best is trial 10 with value: 0.30522724879340096.\n","[I 2025-10-11 18:49:53,816] Trial 18 finished with value: 0.29449901770750486 and parameters: {'n_estimators': 100, 'learning_rate': 0.0023533755070979704, 'num_leaves': 299, 'max_depth': 12, 'lambda_l1': 1.150882249073233, 'lambda_l2': 0.002240077655731906, 'feature_fraction': 0.7835180608140799, 'bagging_fraction': 0.6448527323628603, 'bagging_freq': 2}. Best is trial 10 with value: 0.30522724879340096.\n","[I 2025-10-11 18:53:13,587] Trial 19 finished with value: 0.300616383078958 and parameters: {'n_estimators': 1800, 'learning_rate': 0.0011905043668487074, 'num_leaves': 121, 'max_depth': 11, 'lambda_l1': 0.015011916131502384, 'lambda_l2': 7.893683869610123e-05, 'feature_fraction': 0.8729226225203902, 'bagging_fraction': 0.945537644385438, 'bagging_freq': 6}. Best is trial 10 with value: 0.30522724879340096.\n","[I 2025-10-11 18:54:02,394] Trial 20 finished with value: 0.30350383650970597 and parameters: {'n_estimators': 1300, 'learning_rate': 0.007424858154199155, 'num_leaves': 254, 'max_depth': 7, 'lambda_l1': 1.4298749406916145, 'lambda_l2': 0.004467731767801353, 'feature_fraction': 0.6720678892634919, 'bagging_fraction': 0.8126261316417107, 'bagging_freq': 4}. Best is trial 10 with value: 0.30522724879340096.\n"]},{"output_type":"stream","name":"stdout","text":["\n","[Optuna 조기 종료] 10번의 trial 동안 최고 점수가 갱신되지 않아 튜닝을 중단합니다.\n","\n","✅ 튜닝 완료!\n","\n","==================================================\n","🔬 최적 하이퍼파라미터 (Best Hyperparameters)\n","==================================================\n","        n_estimators: 1500\n","       learning_rate: 0.005496229720566432\n","          num_leaves: 292\n","           max_depth: 12\n","           lambda_l1: 9.664868582582134\n","           lambda_l2: 0.0007024265444479108\n","    feature_fraction: 0.8264808185445718\n","    bagging_fraction: 0.6023293694775351\n","        bagging_freq: 1\n","==================================================\n","\n","🔬 Step 5: 튜닝된 최종 모델 학습 및 평가...\n","✅ 튜닝된 모델 평가 완료.\n","\n","============================================================\n","📊 최종 성능 비교 결과 (Test Set)\n","============================================================\n","              PR AUC  ROC AUC  F1-Score\n","Baseline      0.3127   0.7732    0.0997\n","Optuna Tuned  0.3390   0.7872    0.1031\n","\n","============================================================\n","💾 Step 6: 최종 모델 예측 결과를 원본 CSV에 추가하여 저장\n","============================================================\n","✅ 모든 데이터의 예측 결과가 '/content/drive/MyDrive/review_helpfulness/PADA/results/s2/amazon/T5_amazon_with_s2_predictions.csv' 파일에 성공적으로 저장되었습니다.\n","\n","============================================================\n","🧹 Step 7: 사용된 변수들을 메모리에서 정리\n","============================================================\n","✅ 메모리 정리가 완료되었습니다.\n","\n","🎉 모든 과정이 완료되었습니다!\n"]}]},{"cell_type":"markdown","source":["## BERT"],"metadata":{"id":"qafu7gCEjvg1"}},{"cell_type":"code","source":["# === 2. 환경설정 클래스 ===\n","class Config:\n","    \"\"\"실행에 필요한 모든 설정값을 중앙에서 관리합니다.\"\"\"\n","    # 🌟 1. 입력 파일 경로 설정\n","    CSV_FILE_PATH = \"/content/drive/MyDrive/review_helpfulness/PADA/data/amazon/amazon.csv\"\n","    EMBEDDING_PATH = \"/content/drive/MyDrive/review_helpfulness/PADA/embedding/amazon_BERT.npy\"\n","\n","    # 🌟 2. 최종 결과 CSV 파일 저장 경로 설정\n","    OUTPUT_CSV_PATH = \"/content/drive/MyDrive/review_helpfulness/PADA/results/s2/amazon/BERT_amazon_with_s2_predictions.csv\"\n","\n","    # --- 데이터 정보 ---\n","    TARGET_COLUMN = 'binary_helpfulness'\n","\n","    # --- 데이터 분할 ---\n","    TEST_SPLIT_RATIO = 0.2\n","    RANDOM_STATE = 42\n","\n","    # --- Optuna 튜닝 설정 ---\n","    N_TRIALS = 50\n","    TUNING_METRIC = 'pr_auc'\n","    EARLY_STOPPING_ROUNDS = 10 # 🌟 Optuna 조기 종료 횟수\n","\n","# === 3. Optuna 조기 종료 콜백 ===\n","class EarlyStoppingCallback:\n","    \"\"\"Optuna 스터디의 조기 종료를 위한 콜백 클래스\"\"\"\n","    def __init__(self, early_stopping_rounds: int):\n","        self._early_stopping_rounds = early_stopping_rounds\n","        self._best_value = -float(\"inf\")\n","        self._counter = 0\n","\n","    def __call__(self, study: optuna.study.Study, trial: optuna.trial.Trial):\n","        current_best_value = study.best_value\n","        if current_best_value is not None and current_best_value > self._best_value:\n","            self._best_value = current_best_value\n","            self._counter = 0\n","        else:\n","            self._counter += 1\n","\n","        if self._counter >= self._early_stopping_rounds:\n","            print(f\"\\n[Optuna 조기 종료] {self._early_stopping_rounds}번의 trial 동안 최고 점수가 갱신되지 않아 튜닝을 중단합니다.\")\n","            study.stop()\n","\n","# === 4. Optuna Objective 함수 ===\n","def objective(trial, X, y):\n","    \"\"\"Optuna가 최적의 하이퍼파라미터를 찾기 위해 반복 호출하는 함수\"\"\"\n","    X_train, X_val, y_train, y_val = train_test_split(\n","        X, y, test_size=0.25, random_state=Config.RANDOM_STATE, stratify=y\n","    )\n","\n","    params = {\n","        'objective': 'binary', 'metric': 'logloss', 'verbosity': -1,\n","        'boosting_type': 'gbdt', 'random_state': Config.RANDOM_STATE,\n","        'device': 'gpu',  # 🌟 Optuna Trial 내부에서도 GPU 사용\n","        'n_estimators': trial.suggest_int('n_estimators', 100, 2000, step=100),\n","        'learning_rate': trial.suggest_float('learning_rate', 1e-3, 0.3, log=True),\n","        'num_leaves': trial.suggest_int('num_leaves', 20, 300),\n","        'max_depth': trial.suggest_int('max_depth', 3, 12),\n","        'lambda_l1': trial.suggest_float('lambda_l1', 1e-8, 10.0, log=True),\n","        'lambda_l2': trial.suggest_float('lambda_l2', 1e-8, 10.0, log=True),\n","        'feature_fraction': trial.suggest_float('feature_fraction', 0.6, 1.0),\n","        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.6, 1.0),\n","        'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\n","    }\n","\n","    model = lgb.LGBMClassifier(**params)\n","    model.fit(X_train, y_train,\n","              eval_set=[(X_val, y_val)],\n","              eval_metric='logloss',\n","              callbacks=[lgb.early_stopping(100, verbose=False)])\n","\n","    y_pred_proba = model.predict_proba(X_val)[:, 1]\n","    score = average_precision_score(y_val, y_pred_proba)\n","    return score\n","\n","# === 5. 메인 실행 블록 ===\n","if __name__ == '__main__':\n","    config = Config()\n","\n","    # ... (Step 1 ~ 2: 데이터 로드, 분할, 베이스라인 측정) ...\n","    print(\"Step 1: 데이터 로드 및 분할 중...\")\n","    try:\n","        df = pd.read_csv(config.CSV_FILE_PATH)\n","        labels = df[config.TARGET_COLUMN].values\n","        embeddings = np.load(config.EMBEDDING_PATH)\n","        assert len(df) == len(embeddings)\n","    except Exception as e:\n","        print(f\"🔥 파일 로드 실패: {e}\"); exit()\n","\n","    indices = np.arange(len(df))\n","    train_indices, test_indices = train_test_split(\n","        indices, test_size=config.TEST_SPLIT_RATIO, random_state=config.RANDOM_STATE, stratify=labels\n","    )\n","    X_train, X_test = embeddings[train_indices], embeddings[test_indices]\n","    y_train, y_test = labels[train_indices], labels[test_indices]\n","    print(f\"✅ 완료 (학습용: {len(y_train)}건, 테스트용: {len(y_test)}건)\")\n","\n","    print(\"\\n\" + \"=\"*50)\n","    print(\"📊 Step 2: 베이스라인 모델 성능 측정 (GPU 사용)\")\n","    print(\"=\"*50)\n","\n","    baseline_model = lgb.LGBMClassifier(device='gpu', random_state=config.RANDOM_STATE)\n","    baseline_model.fit(X_train, y_train)\n","\n","    y_pred_proba_base = baseline_model.predict_proba(X_test)[:, 1]\n","    y_pred_class_base = (y_pred_proba_base > 0.5).astype(int)\n","\n","    final_results = {}\n","    final_results['Baseline'] = {\n","        \"PR AUC\": average_precision_score(y_test, y_pred_proba_base),\n","        \"ROC AUC\": roc_auc_score(y_test, y_pred_proba_base),\n","        \"F1-Score\": f1_score(y_test, y_pred_class_base),\n","    }\n","    print(\"✅ 베이스라인 모델 평가 완료.\")\n","\n","    # --- Step 3: Optuna 튜닝 수행 (조기 종료 포함) ---\n","    print(\"\\n\" + \"=\"*50)\n","    print(f\"🔬 Step 3: Optuna 하이퍼파라미터 튜닝 시작 (GPU 사용)...\")\n","    print(f\"(최대 {config.N_TRIALS}번 시도, {config.EARLY_STOPPING_ROUNDS}번 개선 없으면 조기 종료)\")\n","    print(\"=\"*50)\n","\n","    early_stopping_callback = EarlyStoppingCallback(early_stopping_rounds=config.EARLY_STOPPING_ROUNDS)\n","    study = optuna.create_study(direction='maximize')\n","    pbar = tqdm(total=config.N_TRIALS, desc=\"Optuna 튜닝 진행률\")\n","\n","    try:\n","        study.optimize(lambda trial: objective(trial, X_train, y_train),\n","                       n_trials=config.N_TRIALS,\n","                       callbacks=[lambda study, trial: pbar.update(1), early_stopping_callback])\n","    except optuna.exceptions.OptunaError:\n","        # 조기 종료 시 발생하는 예외를 정상 처리\n","        pass\n","    pbar.close()\n","\n","    # ... (Step 4 ~ 6: 결과 출력, 저장, 메모리 정리) ...\n","    print(f\"\\n✅ 튜닝 완료!\")\n","    print(\"\\n\" + \"=\"*50)\n","    print(\"🔬 최적 하이퍼파라미터 (Best Hyperparameters)\")\n","    print(\"=\"*50)\n","    best_params = study.best_params\n","    for key, value in best_params.items():\n","        print(f\"{key:>20s}: {value}\")\n","    print(\"=\"*50)\n","\n","    print(f\"\\n🔬 Step 5: 튜닝된 최종 모델 학습 및 평가...\")\n","    final_model = lgb.LGBMClassifier(device='gpu', objective='binary', verbosity=-1, random_state=config.RANDOM_STATE, **best_params)\n","    final_model.fit(X_train, y_train)\n","\n","    y_pred_proba_tuned = final_model.predict_proba(X_test)[:, 1]\n","    y_pred_class_tuned = (y_pred_proba_tuned > 0.5).astype(int)\n","\n","    final_results['Optuna Tuned'] = {\n","        \"PR AUC\": average_precision_score(y_test, y_pred_proba_tuned),\n","        \"ROC AUC\": roc_auc_score(y_test, y_pred_proba_tuned),\n","        \"F1-Score\": f1_score(y_test, y_pred_class_tuned),\n","    }\n","    print(\"✅ 튜닝된 모델 평가 완료.\")\n","\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"📊 최종 성능 비교 결과 (Test Set)\")\n","    print(\"=\"*60)\n","    results_df = pd.DataFrame(final_results).T\n","    print(results_df.round(4))\n","\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"💾 Step 6: 최종 모델 예측 결과를 원본 CSV에 추가하여 저장\")\n","    print(\"=\"*60)\n","\n","    train_pred_proba = final_model.predict_proba(X_train)[:, 1]\n","    train_pred_class = (train_pred_proba > 0.5).astype(int)\n","\n","    df['s2_pred_proba'] = np.nan\n","    df['s2_pred_class'] = np.nan\n","\n","    df.loc[train_indices, 's2_pred_proba'] = train_pred_proba\n","    df.loc[train_indices, 's2_pred_class'] = train_pred_class\n","\n","    df.loc[test_indices, 's2_pred_proba'] = y_pred_proba_tuned\n","    df.loc[test_indices, 's2_pred_class'] = y_pred_class_tuned\n","\n","    # 🌟 Config에 설정된 경로로 최종 파일 저장\n","    df.to_csv(config.OUTPUT_CSV_PATH, index=False, encoding='utf-8-sig')\n","\n","    print(f\"✅ 모든 데이터의 예측 결과가 '{config.OUTPUT_CSV_PATH}' 파일에 성공적으로 저장되었습니다.\")\n","\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"🧹 Step 7: 사용된 변수들을 메모리에서 정리\")\n","    print(\"=\"*60)\n","\n","    vars_to_delete = [\n","        'df', 'labels', 'embeddings', 'indices', 'X_train', 'X_test',\n","        'y_train', 'y_test', 'train_indices', 'test_indices',\n","        'baseline_model', 'final_model', 'study',\n","    ]\n","    for var_name in vars_to_delete:\n","        if var_name in locals() or var_name in globals():\n","            if var_name in globals(): del globals()[var_name]\n","\n","    gc.collect()\n","    print(\"✅ 메모리 정리가 완료되었습니다.\")\n","\n","    print(\"\\n🎉 모든 과정이 완료되었습니다!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["0c7788c37d8e4b7b952ab62c495a1fdb","cf46849400dc47ea924658da0f9a1a8a","d86deca54ed14b5cb67a670d1a68d520","91d01d98fc014d1496c5188ecf330b0d","7aeb7a90ad35432a8242d52b9047e202","c997881940e44cdeb64103bb075f519d","0320a77e7fbf483f97927e947aa582f4","c3598283aa674ed8969623f78c8d2756","9ee1bb8bd5284effb90599caad33ced9","e50d9510622a45e9a2e2aa10fa9690a9","e36629a1434d49c4944eabaf4aeb0de6"]},"id":"GVQ3LB0hjrAh","executionInfo":{"status":"ok","timestamp":1760209890570,"user_tz":-540,"elapsed":835648,"user":{"displayName":"KW-data-analytics","userId":"09651493752354345908"}},"outputId":"6c52a8f0-58a5-48ed-846e-9188ab5ffe04"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Step 1: 데이터 로드 및 분할 중...\n","✅ 완료 (학습용: 71941건, 테스트용: 17986건)\n","\n","==================================================\n","📊 Step 2: 베이스라인 모델 성능 측정 (GPU 사용)\n","==================================================\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-10-11 18:57:46,820] A new study created in memory with name: no-name-478c9d9f-9ad4-41b3-a5fb-08060085e135\n"]},{"output_type":"stream","name":"stdout","text":["✅ 베이스라인 모델 평가 완료.\n","\n","==================================================\n","🔬 Step 3: Optuna 하이퍼파라미터 튜닝 시작 (GPU 사용)...\n","(최대 50번 시도, 10번 개선 없으면 조기 종료)\n","==================================================\n"]},{"output_type":"display_data","data":{"text/plain":["Optuna 튜닝 진행률:   0%|          | 0/50 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0c7788c37d8e4b7b952ab62c495a1fdb"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2025-10-11 18:58:02,987] Trial 0 finished with value: 0.242930227317717 and parameters: {'n_estimators': 600, 'learning_rate': 0.2011606089965192, 'num_leaves': 188, 'max_depth': 9, 'lambda_l1': 0.000655527579171505, 'lambda_l2': 3.3615343618624967e-06, 'feature_fraction': 0.7982463389762611, 'bagging_fraction': 0.7743520732714457, 'bagging_freq': 2}. Best is trial 0 with value: 0.242930227317717.\n","[I 2025-10-11 18:59:10,883] Trial 1 finished with value: 0.2904482025055546 and parameters: {'n_estimators': 600, 'learning_rate': 0.005222081618070164, 'num_leaves': 142, 'max_depth': 10, 'lambda_l1': 8.452617646318008e-06, 'lambda_l2': 2.2463890305510763e-06, 'feature_fraction': 0.8315848628818452, 'bagging_fraction': 0.9762653282723361, 'bagging_freq': 4}. Best is trial 1 with value: 0.2904482025055546.\n","[I 2025-10-11 18:59:30,572] Trial 2 finished with value: 0.28736341910265883 and parameters: {'n_estimators': 500, 'learning_rate': 0.0011256116717559155, 'num_leaves': 188, 'max_depth': 6, 'lambda_l1': 2.904972092421599e-05, 'lambda_l2': 6.400280765051173e-06, 'feature_fraction': 0.641731655485369, 'bagging_fraction': 0.7789694073873333, 'bagging_freq': 6}. Best is trial 1 with value: 0.2904482025055546.\n","[I 2025-10-11 19:01:32,396] Trial 3 finished with value: 0.2906518333909144 and parameters: {'n_estimators': 1700, 'learning_rate': 0.0014566459919567365, 'num_leaves': 101, 'max_depth': 7, 'lambda_l1': 0.748239524419288, 'lambda_l2': 0.08169119009463523, 'feature_fraction': 0.9498244974650463, 'bagging_fraction': 0.9747427918771859, 'bagging_freq': 1}. Best is trial 3 with value: 0.2906518333909144.\n","[I 2025-10-11 19:01:57,353] Trial 4 finished with value: 0.25687080609940394 and parameters: {'n_estimators': 800, 'learning_rate': 0.12920596854976857, 'num_leaves': 204, 'max_depth': 12, 'lambda_l1': 0.0014300292649755437, 'lambda_l2': 1.482595159925001e-08, 'feature_fraction': 0.9512264643709766, 'bagging_fraction': 0.7201896911251202, 'bagging_freq': 6}. Best is trial 3 with value: 0.2906518333909144.\n","[I 2025-10-11 19:02:05,512] Trial 5 finished with value: 0.27430678938506725 and parameters: {'n_estimators': 800, 'learning_rate': 0.16523551082656773, 'num_leaves': 273, 'max_depth': 6, 'lambda_l1': 1.0730042494269444e-06, 'lambda_l2': 0.18469089901899585, 'feature_fraction': 0.9383360754939694, 'bagging_fraction': 0.967456449813571, 'bagging_freq': 3}. Best is trial 3 with value: 0.2906518333909144.\n","[I 2025-10-11 19:04:21,473] Trial 6 finished with value: 0.29271304474908394 and parameters: {'n_estimators': 1800, 'learning_rate': 0.0011400688098361137, 'num_leaves': 109, 'max_depth': 8, 'lambda_l1': 0.0003608074205964753, 'lambda_l2': 0.9987870600137266, 'feature_fraction': 0.7068814700519777, 'bagging_fraction': 0.9671106382752981, 'bagging_freq': 5}. Best is trial 6 with value: 0.29271304474908394.\n","[I 2025-10-11 19:04:31,071] Trial 7 finished with value: 0.28899825843931193 and parameters: {'n_estimators': 300, 'learning_rate': 0.00601607017066222, 'num_leaves': 180, 'max_depth': 5, 'lambda_l1': 0.01132262304400695, 'lambda_l2': 0.9927530407204258, 'feature_fraction': 0.6263786718841492, 'bagging_fraction': 0.6912476552204796, 'bagging_freq': 6}. Best is trial 6 with value: 0.29271304474908394.\n","[I 2025-10-11 19:04:41,376] Trial 8 finished with value: 0.29416606127766126 and parameters: {'n_estimators': 1300, 'learning_rate': 0.017574437185627418, 'num_leaves': 117, 'max_depth': 3, 'lambda_l1': 8.986742144626755e-05, 'lambda_l2': 1.8575341209605358e-07, 'feature_fraction': 0.8625376682877257, 'bagging_fraction': 0.7015093402606956, 'bagging_freq': 5}. Best is trial 8 with value: 0.29416606127766126.\n","[I 2025-10-11 19:04:51,362] Trial 9 finished with value: 0.2645613788777234 and parameters: {'n_estimators': 1100, 'learning_rate': 0.10629880069050265, 'num_leaves': 204, 'max_depth': 7, 'lambda_l1': 0.000315337347980078, 'lambda_l2': 0.20755553457799175, 'feature_fraction': 0.6496944622364572, 'bagging_fraction': 0.6311037354131672, 'bagging_freq': 4}. Best is trial 8 with value: 0.29416606127766126.\n","[I 2025-10-11 19:04:59,175] Trial 10 finished with value: 0.29240971348835076 and parameters: {'n_estimators': 1300, 'learning_rate': 0.03390064536587181, 'num_leaves': 37, 'max_depth': 3, 'lambda_l1': 1.436595899966215e-07, 'lambda_l2': 1.035258889785351e-08, 'feature_fraction': 0.8395340404046104, 'bagging_fraction': 0.8684397792852103, 'bagging_freq': 7}. Best is trial 8 with value: 0.29416606127766126.\n","[I 2025-10-11 19:05:08,261] Trial 11 finished with value: 0.29237133429327833 and parameters: {'n_estimators': 1900, 'learning_rate': 0.022067218881466615, 'num_leaves': 83, 'max_depth': 3, 'lambda_l1': 0.26358575641537924, 'lambda_l2': 0.0017450449788533199, 'feature_fraction': 0.7356146445790328, 'bagging_fraction': 0.8717704905639364, 'bagging_freq': 5}. Best is trial 8 with value: 0.29416606127766126.\n","[I 2025-10-11 19:05:58,159] Trial 12 finished with value: 0.2941269556360129 and parameters: {'n_estimators': 1500, 'learning_rate': 0.007252740796173861, 'num_leaves': 118, 'max_depth': 9, 'lambda_l1': 1.2284977516633502e-08, 'lambda_l2': 0.00029917736911705476, 'feature_fraction': 0.7259729609734559, 'bagging_fraction': 0.6063118664440628, 'bagging_freq': 5}. Best is trial 8 with value: 0.29416606127766126.\n","[I 2025-10-11 19:06:35,273] Trial 13 finished with value: 0.29141693932225593 and parameters: {'n_estimators': 1400, 'learning_rate': 0.008116907174879664, 'num_leaves': 43, 'max_depth': 11, 'lambda_l1': 1.5059417052019536e-08, 'lambda_l2': 0.00030844270442080605, 'feature_fraction': 0.8805664068412867, 'bagging_fraction': 0.6132090665758526, 'bagging_freq': 4}. Best is trial 8 with value: 0.29416606127766126.\n","[I 2025-10-11 19:06:54,231] Trial 14 finished with value: 0.2786263399356169 and parameters: {'n_estimators': 1500, 'learning_rate': 0.04661701806519778, 'num_leaves': 141, 'max_depth': 9, 'lambda_l1': 4.6870415142871686e-08, 'lambda_l2': 0.0002635308084898957, 'feature_fraction': 0.7570543402849556, 'bagging_fraction': 0.6847594512867455, 'bagging_freq': 5}. Best is trial 8 with value: 0.29416606127766126.\n","[I 2025-10-11 19:07:07,577] Trial 15 finished with value: 0.29447840486716226 and parameters: {'n_estimators': 1100, 'learning_rate': 0.014688544527181076, 'num_leaves': 71, 'max_depth': 4, 'lambda_l1': 7.7460176213717125, 'lambda_l2': 9.32277380516133e-08, 'feature_fraction': 0.8863647315385292, 'bagging_fraction': 0.652402940494289, 'bagging_freq': 7}. Best is trial 15 with value: 0.29447840486716226.\n","[I 2025-10-11 19:07:23,033] Trial 16 finished with value: 0.2966176820357065 and parameters: {'n_estimators': 1100, 'learning_rate': 0.014929245712529453, 'num_leaves': 74, 'max_depth': 4, 'lambda_l1': 8.175083180070946, 'lambda_l2': 1.3898995152838435e-07, 'feature_fraction': 0.8917992632808561, 'bagging_fraction': 0.7323751100944504, 'bagging_freq': 7}. Best is trial 16 with value: 0.2966176820357065.\n","[I 2025-10-11 19:07:32,248] Trial 17 finished with value: 0.2904951054760967 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05142638028370518, 'num_leaves': 68, 'max_depth': 5, 'lambda_l1': 2.3008030844187832, 'lambda_l2': 1.9395798113010924e-07, 'feature_fraction': 0.99623429930027, 'bagging_fraction': 0.7439595719570484, 'bagging_freq': 7}. Best is trial 16 with value: 0.2966176820357065.\n","[I 2025-10-11 19:07:37,656] Trial 18 finished with value: 0.27647265560063194 and parameters: {'n_estimators': 100, 'learning_rate': 0.0032032258513226886, 'num_leaves': 71, 'max_depth': 4, 'lambda_l1': 0.06325972903146312, 'lambda_l2': 2.348427851604137e-07, 'feature_fraction': 0.8986881050031916, 'bagging_fraction': 0.655080508318249, 'bagging_freq': 7}. Best is trial 16 with value: 0.2966176820357065.\n","[I 2025-10-11 19:08:00,577] Trial 19 finished with value: 0.2995728996569773 and parameters: {'n_estimators': 1000, 'learning_rate': 0.011748629338705472, 'num_leaves': 29, 'max_depth': 5, 'lambda_l1': 6.047446186257771, 'lambda_l2': 2.6718555871817493e-05, 'feature_fraction': 0.7865464309584396, 'bagging_fraction': 0.8344669085489922, 'bagging_freq': 7}. Best is trial 19 with value: 0.2995728996569773.\n","[I 2025-10-11 19:08:19,765] Trial 20 finished with value: 0.2903432314240487 and parameters: {'n_estimators': 900, 'learning_rate': 0.0028739110606622264, 'num_leaves': 20, 'max_depth': 5, 'lambda_l1': 0.012904721853024173, 'lambda_l2': 2.5577772139037437e-05, 'feature_fraction': 0.7837384674571664, 'bagging_fraction': 0.8303537991198686, 'bagging_freq': 6}. Best is trial 19 with value: 0.2995728996569773.\n","[I 2025-10-11 19:08:36,579] Trial 21 finished with value: 0.2977680381479787 and parameters: {'n_estimators': 1100, 'learning_rate': 0.012345858424880039, 'num_leaves': 53, 'max_depth': 4, 'lambda_l1': 7.900933351039795, 'lambda_l2': 0.004726991256787296, 'feature_fraction': 0.9153566008452622, 'bagging_fraction': 0.8230438550919615, 'bagging_freq': 7}. Best is trial 19 with value: 0.2995728996569773.\n","[I 2025-10-11 19:08:54,602] Trial 22 finished with value: 0.2990612182753905 and parameters: {'n_estimators': 1200, 'learning_rate': 0.012256275049880258, 'num_leaves': 42, 'max_depth': 4, 'lambda_l1': 9.418672541036985, 'lambda_l2': 0.008019602319262686, 'feature_fraction': 0.9202540539207175, 'bagging_fraction': 0.824018206792021, 'bagging_freq': 7}. Best is trial 19 with value: 0.2995728996569773.\n","[I 2025-10-11 19:09:19,309] Trial 23 finished with value: 0.2914313064420836 and parameters: {'n_estimators': 1200, 'learning_rate': 0.011822575025927895, 'num_leaves': 43, 'max_depth': 6, 'lambda_l1': 0.3725897477736493, 'lambda_l2': 0.007880350120228696, 'feature_fraction': 0.9227737997571328, 'bagging_fraction': 0.8506621372139382, 'bagging_freq': 6}. Best is trial 19 with value: 0.2995728996569773.\n","[I 2025-10-11 19:09:30,111] Trial 24 finished with value: 0.2954054378217392 and parameters: {'n_estimators': 1600, 'learning_rate': 0.029047707222081408, 'num_leaves': 22, 'max_depth': 4, 'lambda_l1': 1.5859801486530938, 'lambda_l2': 0.008750120830297936, 'feature_fraction': 0.9905078208179116, 'bagging_fraction': 0.9033302407749385, 'bagging_freq': 7}. Best is trial 19 with value: 0.2995728996569773.\n","[I 2025-10-11 19:09:47,950] Trial 25 finished with value: 0.29560464783470897 and parameters: {'n_estimators': 700, 'learning_rate': 0.009409012295627487, 'num_leaves': 51, 'max_depth': 5, 'lambda_l1': 0.06679058566746424, 'lambda_l2': 5.1356166182331745e-05, 'feature_fraction': 0.827607886386674, 'bagging_fraction': 0.8071833959878845, 'bagging_freq': 6}. Best is trial 19 with value: 0.2995728996569773.\n","[I 2025-10-11 19:09:57,479] Trial 26 finished with value: 0.2801542257971116 and parameters: {'n_estimators': 900, 'learning_rate': 0.0029785582139170218, 'num_leaves': 242, 'max_depth': 3, 'lambda_l1': 7.442989620190123, 'lambda_l2': 7.484700810939641, 'feature_fraction': 0.7644467122086681, 'bagging_fraction': 0.921051052891219, 'bagging_freq': 3}. Best is trial 19 with value: 0.2995728996569773.\n","[I 2025-10-11 19:10:40,139] Trial 27 finished with value: 0.2963148539367472 and parameters: {'n_estimators': 1300, 'learning_rate': 0.004556926189657508, 'num_leaves': 96, 'max_depth': 6, 'lambda_l1': 0.036172321784507314, 'lambda_l2': 0.003094647143491008, 'feature_fraction': 0.6821813156978319, 'bagging_fraction': 0.8179898694820776, 'bagging_freq': 7}. Best is trial 19 with value: 0.2995728996569773.\n","[I 2025-10-11 19:10:47,464] Trial 28 finished with value: 0.2915978687204569 and parameters: {'n_estimators': 1000, 'learning_rate': 0.06523318847952714, 'num_leaves': 56, 'max_depth': 4, 'lambda_l1': 0.2290857536130262, 'lambda_l2': 0.016109643079724168, 'feature_fraction': 0.9697059439465187, 'bagging_fraction': 0.7689297679932688, 'bagging_freq': 6}. Best is trial 19 with value: 0.2995728996569773.\n","[I 2025-10-11 19:11:01,418] Trial 29 finished with value: 0.2946313226090806 and parameters: {'n_estimators': 500, 'learning_rate': 0.010760231789946423, 'num_leaves': 20, 'max_depth': 8, 'lambda_l1': 0.0031095051674874894, 'lambda_l2': 0.001635022275138107, 'feature_fraction': 0.8054776478904306, 'bagging_fraction': 0.7808879625068272, 'bagging_freq': 2}. Best is trial 19 with value: 0.2995728996569773.\n"]},{"output_type":"stream","name":"stdout","text":["\n","[Optuna 조기 종료] 10번의 trial 동안 최고 점수가 갱신되지 않아 튜닝을 중단합니다.\n","\n","✅ 튜닝 완료!\n","\n","==================================================\n","🔬 최적 하이퍼파라미터 (Best Hyperparameters)\n","==================================================\n","        n_estimators: 1000\n","       learning_rate: 0.011748629338705472\n","          num_leaves: 29\n","           max_depth: 5\n","           lambda_l1: 6.047446186257771\n","           lambda_l2: 2.6718555871817493e-05\n","    feature_fraction: 0.7865464309584396\n","    bagging_fraction: 0.8344669085489922\n","        bagging_freq: 7\n","==================================================\n","\n","🔬 Step 5: 튜닝된 최종 모델 학습 및 평가...\n","✅ 튜닝된 모델 평가 완료.\n","\n","============================================================\n","📊 최종 성능 비교 결과 (Test Set)\n","============================================================\n","              PR AUC  ROC AUC  F1-Score\n","Baseline      0.3152   0.7701    0.1401\n","Optuna Tuned  0.3274   0.7783    0.1373\n","\n","============================================================\n","💾 Step 6: 최종 모델 예측 결과를 원본 CSV에 추가하여 저장\n","============================================================\n","✅ 모든 데이터의 예측 결과가 '/content/drive/MyDrive/review_helpfulness/PADA/results/s2/amazon/BERT_amazon_with_s2_predictions.csv' 파일에 성공적으로 저장되었습니다.\n","\n","============================================================\n","🧹 Step 7: 사용된 변수들을 메모리에서 정리\n","============================================================\n","✅ 메모리 정리가 완료되었습니다.\n","\n","🎉 모든 과정이 완료되었습니다!\n"]}]},{"cell_type":"markdown","source":["## SentenceBERT"],"metadata":{"id":"kCOCbWbCj109"}},{"cell_type":"code","source":["# === 2. 환경설정 클래스 ===\n","class Config:\n","    \"\"\"실행에 필요한 모든 설정값을 중앙에서 관리합니다.\"\"\"\n","    # 🌟 1. 입력 파일 경로 설정\n","    CSV_FILE_PATH = \"/content/drive/MyDrive/review_helpfulness/PADA/data/amazon/amazon.csv\"\n","    EMBEDDING_PATH = \"/content/drive/MyDrive/review_helpfulness/PADA/embedding/amazon_SentenceBERT.npy\"\n","\n","    # 🌟 2. 최종 결과 CSV 파일 저장 경로 설정\n","    OUTPUT_CSV_PATH = \"/content/drive/MyDrive/review_helpfulness/PADA/results/s2/amazon/SentenceBERT_amazon_with_s2_predictions.csv\"\n","\n","    # --- 데이터 정보 ---\n","    TARGET_COLUMN = 'binary_helpfulness'\n","\n","    # --- 데이터 분할 ---\n","    TEST_SPLIT_RATIO = 0.2\n","    RANDOM_STATE = 42\n","\n","    # --- Optuna 튜닝 설정 ---\n","    N_TRIALS = 50\n","    TUNING_METRIC = 'pr_auc'\n","    EARLY_STOPPING_ROUNDS = 10 # 🌟 Optuna 조기 종료 횟수\n","\n","# === 3. Optuna 조기 종료 콜백 ===\n","class EarlyStoppingCallback:\n","    \"\"\"Optuna 스터디의 조기 종료를 위한 콜백 클래스\"\"\"\n","    def __init__(self, early_stopping_rounds: int):\n","        self._early_stopping_rounds = early_stopping_rounds\n","        self._best_value = -float(\"inf\")\n","        self._counter = 0\n","\n","    def __call__(self, study: optuna.study.Study, trial: optuna.trial.Trial):\n","        current_best_value = study.best_value\n","        if current_best_value is not None and current_best_value > self._best_value:\n","            self._best_value = current_best_value\n","            self._counter = 0\n","        else:\n","            self._counter += 1\n","\n","        if self._counter >= self._early_stopping_rounds:\n","            print(f\"\\n[Optuna 조기 종료] {self._early_stopping_rounds}번의 trial 동안 최고 점수가 갱신되지 않아 튜닝을 중단합니다.\")\n","            study.stop()\n","\n","# === 4. Optuna Objective 함수 ===\n","def objective(trial, X, y):\n","    \"\"\"Optuna가 최적의 하이퍼파라미터를 찾기 위해 반복 호출하는 함수\"\"\"\n","    X_train, X_val, y_train, y_val = train_test_split(\n","        X, y, test_size=0.25, random_state=Config.RANDOM_STATE, stratify=y\n","    )\n","\n","    params = {\n","        'objective': 'binary', 'metric': 'logloss', 'verbosity': -1,\n","        'boosting_type': 'gbdt', 'random_state': Config.RANDOM_STATE,\n","        'device': 'gpu',  # 🌟 Optuna Trial 내부에서도 GPU 사용\n","        'n_estimators': trial.suggest_int('n_estimators', 100, 2000, step=100),\n","        'learning_rate': trial.suggest_float('learning_rate', 1e-3, 0.3, log=True),\n","        'num_leaves': trial.suggest_int('num_leaves', 20, 300),\n","        'max_depth': trial.suggest_int('max_depth', 3, 12),\n","        'lambda_l1': trial.suggest_float('lambda_l1', 1e-8, 10.0, log=True),\n","        'lambda_l2': trial.suggest_float('lambda_l2', 1e-8, 10.0, log=True),\n","        'feature_fraction': trial.suggest_float('feature_fraction', 0.6, 1.0),\n","        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.6, 1.0),\n","        'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\n","    }\n","\n","    model = lgb.LGBMClassifier(**params)\n","    model.fit(X_train, y_train,\n","              eval_set=[(X_val, y_val)],\n","              eval_metric='logloss',\n","              callbacks=[lgb.early_stopping(100, verbose=False)])\n","\n","    y_pred_proba = model.predict_proba(X_val)[:, 1]\n","    score = average_precision_score(y_val, y_pred_proba)\n","    return score\n","\n","# === 5. 메인 실행 블록 ===\n","if __name__ == '__main__':\n","    config = Config()\n","\n","    # ... (Step 1 ~ 2: 데이터 로드, 분할, 베이스라인 측정) ...\n","    print(\"Step 1: 데이터 로드 및 분할 중...\")\n","    try:\n","        df = pd.read_csv(config.CSV_FILE_PATH)\n","        labels = df[config.TARGET_COLUMN].values\n","        embeddings = np.load(config.EMBEDDING_PATH)\n","        assert len(df) == len(embeddings)\n","    except Exception as e:\n","        print(f\"🔥 파일 로드 실패: {e}\"); exit()\n","\n","    indices = np.arange(len(df))\n","    train_indices, test_indices = train_test_split(\n","        indices, test_size=config.TEST_SPLIT_RATIO, random_state=config.RANDOM_STATE, stratify=labels\n","    )\n","    X_train, X_test = embeddings[train_indices], embeddings[test_indices]\n","    y_train, y_test = labels[train_indices], labels[test_indices]\n","    print(f\"✅ 완료 (학습용: {len(y_train)}건, 테스트용: {len(y_test)}건)\")\n","\n","    print(\"\\n\" + \"=\"*50)\n","    print(\"📊 Step 2: 베이스라인 모델 성능 측정 (GPU 사용)\")\n","    print(\"=\"*50)\n","\n","    baseline_model = lgb.LGBMClassifier(device='gpu', random_state=config.RANDOM_STATE)\n","    baseline_model.fit(X_train, y_train)\n","\n","    y_pred_proba_base = baseline_model.predict_proba(X_test)[:, 1]\n","    y_pred_class_base = (y_pred_proba_base > 0.5).astype(int)\n","\n","    final_results = {}\n","    final_results['Baseline'] = {\n","        \"PR AUC\": average_precision_score(y_test, y_pred_proba_base),\n","        \"ROC AUC\": roc_auc_score(y_test, y_pred_proba_base),\n","        \"F1-Score\": f1_score(y_test, y_pred_class_base),\n","    }\n","    print(\"✅ 베이스라인 모델 평가 완료.\")\n","\n","    # --- Step 3: Optuna 튜닝 수행 (조기 종료 포함) ---\n","    print(\"\\n\" + \"=\"*50)\n","    print(f\"🔬 Step 3: Optuna 하이퍼파라미터 튜닝 시작 (GPU 사용)...\")\n","    print(f\"(최대 {config.N_TRIALS}번 시도, {config.EARLY_STOPPING_ROUNDS}번 개선 없으면 조기 종료)\")\n","    print(\"=\"*50)\n","\n","    early_stopping_callback = EarlyStoppingCallback(early_stopping_rounds=config.EARLY_STOPPING_ROUNDS)\n","    study = optuna.create_study(direction='maximize')\n","    pbar = tqdm(total=config.N_TRIALS, desc=\"Optuna 튜닝 진행률\")\n","\n","    try:\n","        study.optimize(lambda trial: objective(trial, X_train, y_train),\n","                       n_trials=config.N_TRIALS,\n","                       callbacks=[lambda study, trial: pbar.update(1), early_stopping_callback])\n","    except optuna.exceptions.OptunaError:\n","        # 조기 종료 시 발생하는 예외를 정상 처리\n","        pass\n","    pbar.close()\n","\n","    # ... (Step 4 ~ 6: 결과 출력, 저장, 메모리 정리) ...\n","    print(f\"\\n✅ 튜닝 완료!\")\n","    print(\"\\n\" + \"=\"*50)\n","    print(\"🔬 최적 하이퍼파라미터 (Best Hyperparameters)\")\n","    print(\"=\"*50)\n","    best_params = study.best_params\n","    for key, value in best_params.items():\n","        print(f\"{key:>20s}: {value}\")\n","    print(\"=\"*50)\n","\n","    print(f\"\\n🔬 Step 5: 튜닝된 최종 모델 학습 및 평가...\")\n","    final_model = lgb.LGBMClassifier(device='gpu', objective='binary', verbosity=-1, random_state=config.RANDOM_STATE, **best_params)\n","    final_model.fit(X_train, y_train)\n","\n","    y_pred_proba_tuned = final_model.predict_proba(X_test)[:, 1]\n","    y_pred_class_tuned = (y_pred_proba_tuned > 0.5).astype(int)\n","\n","    final_results['Optuna Tuned'] = {\n","        \"PR AUC\": average_precision_score(y_test, y_pred_proba_tuned),\n","        \"ROC AUC\": roc_auc_score(y_test, y_pred_proba_tuned),\n","        \"F1-Score\": f1_score(y_test, y_pred_class_tuned),\n","    }\n","    print(\"✅ 튜닝된 모델 평가 완료.\")\n","\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"📊 최종 성능 비교 결과 (Test Set)\")\n","    print(\"=\"*60)\n","    results_df = pd.DataFrame(final_results).T\n","    print(results_df.round(4))\n","\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"💾 Step 6: 최종 모델 예측 결과를 원본 CSV에 추가하여 저장\")\n","    print(\"=\"*60)\n","\n","    train_pred_proba = final_model.predict_proba(X_train)[:, 1]\n","    train_pred_class = (train_pred_proba > 0.5).astype(int)\n","\n","    df['s2_pred_proba'] = np.nan\n","    df['s2_pred_class'] = np.nan\n","\n","    df.loc[train_indices, 's2_pred_proba'] = train_pred_proba\n","    df.loc[train_indices, 's2_pred_class'] = train_pred_class\n","\n","    df.loc[test_indices, 's2_pred_proba'] = y_pred_proba_tuned\n","    df.loc[test_indices, 's2_pred_class'] = y_pred_class_tuned\n","\n","    # 🌟 Config에 설정된 경로로 최종 파일 저장\n","    df.to_csv(config.OUTPUT_CSV_PATH, index=False, encoding='utf-8-sig')\n","\n","    print(f\"✅ 모든 데이터의 예측 결과가 '{config.OUTPUT_CSV_PATH}' 파일에 성공적으로 저장되었습니다.\")\n","\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"🧹 Step 7: 사용된 변수들을 메모리에서 정리\")\n","    print(\"=\"*60)\n","\n","    vars_to_delete = [\n","        'df', 'labels', 'embeddings', 'indices', 'X_train', 'X_test',\n","        'y_train', 'y_test', 'train_indices', 'test_indices',\n","        'baseline_model', 'final_model', 'study',\n","    ]\n","    for var_name in vars_to_delete:\n","        if var_name in locals() or var_name in globals():\n","            if var_name in globals(): del globals()[var_name]\n","\n","    gc.collect()\n","    print(\"✅ 메모리 정리가 완료되었습니다.\")\n","\n","    print(\"\\n🎉 모든 과정이 완료되었습니다!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["ce447eb274a9495199c1910c8773a1f7","5938d702a3a74401afb8bc26b5bc5d50","e575747e46fa45029f6a272cf6912c05","eb519f943f0a4f0ebd89a02c441e07ea","312095d1db6e4e9d8c87d24ba65afaef","a58ab785426f441b955ec9da99dec0e1","79c92abd4cbb449eae7c070d6bddcea3","22c7d90f29904a6eb1865b1fd5602587","60ee80b249ca4c60ac0067bf97118f08","b5ca5e3d994e48e285549637bf26754d","6bdf5749155f4130aeeba73c3eed6fb5"]},"id":"njCLY169j-kn","executionInfo":{"status":"ok","timestamp":1760210163369,"user_tz":-540,"elapsed":272796,"user":{"displayName":"KW-data-analytics","userId":"09651493752354345908"}},"outputId":"f616bd4e-320a-47c0-f7d1-1ce5bc579c4c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Step 1: 데이터 로드 및 분할 중...\n","✅ 완료 (학습용: 71941건, 테스트용: 17986건)\n","\n","==================================================\n","📊 Step 2: 베이스라인 모델 성능 측정 (GPU 사용)\n","==================================================\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-10-11 19:11:41,975] A new study created in memory with name: no-name-ff435be8-99d5-469c-8a3a-473ff8811f32\n"]},{"output_type":"stream","name":"stdout","text":["✅ 베이스라인 모델 평가 완료.\n","\n","==================================================\n","🔬 Step 3: Optuna 하이퍼파라미터 튜닝 시작 (GPU 사용)...\n","(최대 50번 시도, 10번 개선 없으면 조기 종료)\n","==================================================\n"]},{"output_type":"display_data","data":{"text/plain":["Optuna 튜닝 진행률:   0%|          | 0/50 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ce447eb274a9495199c1910c8773a1f7"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2025-10-11 19:11:54,132] Trial 0 finished with value: 0.2512513326101477 and parameters: {'n_estimators': 1600, 'learning_rate': 0.10164272201141614, 'num_leaves': 280, 'max_depth': 11, 'lambda_l1': 8.580120834098538e-07, 'lambda_l2': 0.7344840124454822, 'feature_fraction': 0.6530012516311727, 'bagging_fraction': 0.6301144516663705, 'bagging_freq': 3}. Best is trial 0 with value: 0.2512513326101477.\n","[I 2025-10-11 19:12:51,213] Trial 1 finished with value: 0.28817652242174085 and parameters: {'n_estimators': 1700, 'learning_rate': 0.004970170835827217, 'num_leaves': 240, 'max_depth': 8, 'lambda_l1': 0.0019450267592229246, 'lambda_l2': 6.0336511125194645e-05, 'feature_fraction': 0.9265819608159555, 'bagging_fraction': 0.8769593277719894, 'bagging_freq': 2}. Best is trial 1 with value: 0.28817652242174085.\n","[I 2025-10-11 19:13:02,994] Trial 2 finished with value: 0.2321169196744183 and parameters: {'n_estimators': 400, 'learning_rate': 0.16304016337811084, 'num_leaves': 182, 'max_depth': 12, 'lambda_l1': 0.07900531140158056, 'lambda_l2': 0.08246173105974465, 'feature_fraction': 0.8492944234756924, 'bagging_fraction': 0.7617788752768846, 'bagging_freq': 4}. Best is trial 1 with value: 0.28817652242174085.\n","[I 2025-10-11 19:13:16,062] Trial 3 finished with value: 0.25245412940231665 and parameters: {'n_estimators': 1500, 'learning_rate': 0.0824036131672393, 'num_leaves': 199, 'max_depth': 12, 'lambda_l1': 2.4100840891838518e-05, 'lambda_l2': 0.0028146961789846845, 'feature_fraction': 0.8324942388700565, 'bagging_fraction': 0.8285746397138639, 'bagging_freq': 3}. Best is trial 1 with value: 0.28817652242174085.\n","[I 2025-10-11 19:13:23,519] Trial 4 finished with value: 0.2606101837411975 and parameters: {'n_estimators': 1700, 'learning_rate': 0.0771796381968494, 'num_leaves': 88, 'max_depth': 10, 'lambda_l1': 9.262848140896138e-05, 'lambda_l2': 9.698945100183506e-07, 'feature_fraction': 0.7310414523736896, 'bagging_fraction': 0.7166759812685117, 'bagging_freq': 5}. Best is trial 1 with value: 0.28817652242174085.\n","[I 2025-10-11 19:13:35,056] Trial 5 finished with value: 0.2881056315190891 and parameters: {'n_estimators': 1300, 'learning_rate': 0.015228396327811214, 'num_leaves': 31, 'max_depth': 7, 'lambda_l1': 2.1581980861767623e-07, 'lambda_l2': 5.124432241652946e-06, 'feature_fraction': 0.7316542406484314, 'bagging_fraction': 0.9409208437020904, 'bagging_freq': 4}. Best is trial 1 with value: 0.28817652242174085.\n","[I 2025-10-11 19:13:50,101] Trial 6 finished with value: 0.26774751728606877 and parameters: {'n_estimators': 100, 'learning_rate': 0.03602581076859029, 'num_leaves': 295, 'max_depth': 12, 'lambda_l1': 3.2996985334047054e-07, 'lambda_l2': 1.2133150137573885, 'feature_fraction': 0.9948955331417347, 'bagging_fraction': 0.6110624816917629, 'bagging_freq': 4}. Best is trial 1 with value: 0.28817652242174085.\n","[I 2025-10-11 19:13:56,761] Trial 7 finished with value: 0.25156808275253795 and parameters: {'n_estimators': 1900, 'learning_rate': 0.15680210994601865, 'num_leaves': 71, 'max_depth': 9, 'lambda_l1': 2.8581298758755556, 'lambda_l2': 0.0008890381970534233, 'feature_fraction': 0.7802730734431024, 'bagging_fraction': 0.660505043319998, 'bagging_freq': 7}. Best is trial 1 with value: 0.28817652242174085.\n","[I 2025-10-11 19:14:02,464] Trial 8 finished with value: 0.28253673113013755 and parameters: {'n_estimators': 1700, 'learning_rate': 0.031828532700104446, 'num_leaves': 136, 'max_depth': 5, 'lambda_l1': 0.5315105035614566, 'lambda_l2': 3.1893083663609086e-06, 'feature_fraction': 0.7586275408892902, 'bagging_fraction': 0.9441412683923429, 'bagging_freq': 1}. Best is trial 1 with value: 0.28817652242174085.\n","[I 2025-10-11 19:14:08,010] Trial 9 finished with value: 0.24704646578753348 and parameters: {'n_estimators': 100, 'learning_rate': 0.25387862974696973, 'num_leaves': 182, 'max_depth': 7, 'lambda_l1': 1.7234432828205102, 'lambda_l2': 1.854561095986297, 'feature_fraction': 0.6876329723616516, 'bagging_fraction': 0.7138497264772923, 'bagging_freq': 1}. Best is trial 1 with value: 0.28817652242174085.\n","[I 2025-10-11 19:14:14,116] Trial 10 finished with value: 0.2641321108248019 and parameters: {'n_estimators': 900, 'learning_rate': 0.0023021571122545338, 'num_leaves': 242, 'max_depth': 3, 'lambda_l1': 0.00592950131427248, 'lambda_l2': 2.0936256909544394e-08, 'feature_fraction': 0.9472838096414424, 'bagging_fraction': 0.8603178910369279, 'bagging_freq': 2}. Best is trial 1 with value: 0.28817652242174085.\n","[I 2025-10-11 19:14:32,110] Trial 11 finished with value: 0.2803407043563072 and parameters: {'n_estimators': 1200, 'learning_rate': 0.0053513391939707, 'num_leaves': 23, 'max_depth': 7, 'lambda_l1': 0.001963897418579856, 'lambda_l2': 1.2023511283827938e-05, 'feature_fraction': 0.8903472603072039, 'bagging_fraction': 0.9973482049654421, 'bagging_freq': 6}. Best is trial 1 with value: 0.28817652242174085.\n"]},{"output_type":"stream","name":"stdout","text":["\n","[Optuna 조기 종료] 10번의 trial 동안 최고 점수가 갱신되지 않아 튜닝을 중단합니다.\n","\n","✅ 튜닝 완료!\n","\n","==================================================\n","🔬 최적 하이퍼파라미터 (Best Hyperparameters)\n","==================================================\n","        n_estimators: 1700\n","       learning_rate: 0.004970170835827217\n","          num_leaves: 240\n","           max_depth: 8\n","           lambda_l1: 0.0019450267592229246\n","           lambda_l2: 6.0336511125194645e-05\n","    feature_fraction: 0.9265819608159555\n","    bagging_fraction: 0.8769593277719894\n","        bagging_freq: 2\n","==================================================\n","\n","🔬 Step 5: 튜닝된 최종 모델 학습 및 평가...\n","✅ 튜닝된 모델 평가 완료.\n","\n","============================================================\n","📊 최종 성능 비교 결과 (Test Set)\n","============================================================\n","              PR AUC  ROC AUC  F1-Score\n","Baseline      0.3003   0.7642    0.0931\n","Optuna Tuned  0.3186   0.7751    0.0875\n","\n","============================================================\n","💾 Step 6: 최종 모델 예측 결과를 원본 CSV에 추가하여 저장\n","============================================================\n","✅ 모든 데이터의 예측 결과가 '/content/drive/MyDrive/review_helpfulness/PADA/results/s2/amazon/SentenceBERT_amazon_with_s2_predictions.csv' 파일에 성공적으로 저장되었습니다.\n","\n","============================================================\n","🧹 Step 7: 사용된 변수들을 메모리에서 정리\n","============================================================\n","✅ 메모리 정리가 완료되었습니다.\n","\n","🎉 모든 과정이 완료되었습니다!\n"]}]},{"cell_type":"markdown","source":["## RoBERTa"],"metadata":{"id":"TFdSa-mEkMZf"}},{"cell_type":"code","source":["# === 2. 환경설정 클래스 ===\n","class Config:\n","    \"\"\"실행에 필요한 모든 설정값을 중앙에서 관리합니다.\"\"\"\n","    # 🌟 1. 입력 파일 경로 설정\n","    CSV_FILE_PATH = \"/content/drive/MyDrive/review_helpfulness/PADA/data/amazon/amazon.csv\"\n","    EMBEDDING_PATH = \"/content/drive/MyDrive/review_helpfulness/PADA/embedding/amazon_RoBERTa.npy\"\n","\n","    # 🌟 2. 최종 결과 CSV 파일 저장 경로 설정\n","    OUTPUT_CSV_PATH = \"/content/drive/MyDrive/review_helpfulness/PADA/results/s2/amazon/RoBERTa_amazon_with_s2_predictions.csv\"\n","\n","    # --- 데이터 정보 ---\n","    TARGET_COLUMN = 'binary_helpfulness'\n","\n","    # --- 데이터 분할 ---\n","    TEST_SPLIT_RATIO = 0.2\n","    RANDOM_STATE = 42\n","\n","    # --- Optuna 튜닝 설정 ---\n","    N_TRIALS = 50\n","    TUNING_METRIC = 'pr_auc'\n","    EARLY_STOPPING_ROUNDS = 10 # 🌟 Optuna 조기 종료 횟수\n","\n","# === 3. Optuna 조기 종료 콜백 ===\n","class EarlyStoppingCallback:\n","    \"\"\"Optuna 스터디의 조기 종료를 위한 콜백 클래스\"\"\"\n","    def __init__(self, early_stopping_rounds: int):\n","        self._early_stopping_rounds = early_stopping_rounds\n","        self._best_value = -float(\"inf\")\n","        self._counter = 0\n","\n","    def __call__(self, study: optuna.study.Study, trial: optuna.trial.Trial):\n","        current_best_value = study.best_value\n","        if current_best_value is not None and current_best_value > self._best_value:\n","            self._best_value = current_best_value\n","            self._counter = 0\n","        else:\n","            self._counter += 1\n","\n","        if self._counter >= self._early_stopping_rounds:\n","            print(f\"\\n[Optuna 조기 종료] {self._early_stopping_rounds}번의 trial 동안 최고 점수가 갱신되지 않아 튜닝을 중단합니다.\")\n","            study.stop()\n","\n","# === 4. Optuna Objective 함수 ===\n","def objective(trial, X, y):\n","    \"\"\"Optuna가 최적의 하이퍼파라미터를 찾기 위해 반복 호출하는 함수\"\"\"\n","    X_train, X_val, y_train, y_val = train_test_split(\n","        X, y, test_size=0.25, random_state=Config.RANDOM_STATE, stratify=y\n","    )\n","\n","    params = {\n","        'objective': 'binary', 'metric': 'logloss', 'verbosity': -1,\n","        'boosting_type': 'gbdt', 'random_state': Config.RANDOM_STATE,\n","        'device': 'gpu',  # 🌟 Optuna Trial 내부에서도 GPU 사용\n","        'n_estimators': trial.suggest_int('n_estimators', 100, 2000, step=100),\n","        'learning_rate': trial.suggest_float('learning_rate', 1e-3, 0.3, log=True),\n","        'num_leaves': trial.suggest_int('num_leaves', 20, 300),\n","        'max_depth': trial.suggest_int('max_depth', 3, 12),\n","        'lambda_l1': trial.suggest_float('lambda_l1', 1e-8, 10.0, log=True),\n","        'lambda_l2': trial.suggest_float('lambda_l2', 1e-8, 10.0, log=True),\n","        'feature_fraction': trial.suggest_float('feature_fraction', 0.6, 1.0),\n","        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.6, 1.0),\n","        'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\n","    }\n","\n","    model = lgb.LGBMClassifier(**params)\n","    model.fit(X_train, y_train,\n","              eval_set=[(X_val, y_val)],\n","              eval_metric='logloss',\n","              callbacks=[lgb.early_stopping(100, verbose=False)])\n","\n","    y_pred_proba = model.predict_proba(X_val)[:, 1]\n","    score = average_precision_score(y_val, y_pred_proba)\n","    return score\n","\n","# === 5. 메인 실행 블록 ===\n","if __name__ == '__main__':\n","    config = Config()\n","\n","    # ... (Step 1 ~ 2: 데이터 로드, 분할, 베이스라인 측정) ...\n","    print(\"Step 1: 데이터 로드 및 분할 중...\")\n","    try:\n","        df = pd.read_csv(config.CSV_FILE_PATH)\n","        labels = df[config.TARGET_COLUMN].values\n","        embeddings = np.load(config.EMBEDDING_PATH)\n","        assert len(df) == len(embeddings)\n","    except Exception as e:\n","        print(f\"🔥 파일 로드 실패: {e}\"); exit()\n","\n","    indices = np.arange(len(df))\n","    train_indices, test_indices = train_test_split(\n","        indices, test_size=config.TEST_SPLIT_RATIO, random_state=config.RANDOM_STATE, stratify=labels\n","    )\n","    X_train, X_test = embeddings[train_indices], embeddings[test_indices]\n","    y_train, y_test = labels[train_indices], labels[test_indices]\n","    print(f\"✅ 완료 (학습용: {len(y_train)}건, 테스트용: {len(y_test)}건)\")\n","\n","    print(\"\\n\" + \"=\"*50)\n","    print(\"📊 Step 2: 베이스라인 모델 성능 측정 (GPU 사용)\")\n","    print(\"=\"*50)\n","\n","    baseline_model = lgb.LGBMClassifier(device='gpu', random_state=config.RANDOM_STATE)\n","    baseline_model.fit(X_train, y_train)\n","\n","    y_pred_proba_base = baseline_model.predict_proba(X_test)[:, 1]\n","    y_pred_class_base = (y_pred_proba_base > 0.5).astype(int)\n","\n","    final_results = {}\n","    final_results['Baseline'] = {\n","        \"PR AUC\": average_precision_score(y_test, y_pred_proba_base),\n","        \"ROC AUC\": roc_auc_score(y_test, y_pred_proba_base),\n","        \"F1-Score\": f1_score(y_test, y_pred_class_base),\n","    }\n","    print(\"✅ 베이스라인 모델 평가 완료.\")\n","\n","    # --- Step 3: Optuna 튜닝 수행 (조기 종료 포함) ---\n","    print(\"\\n\" + \"=\"*50)\n","    print(f\"🔬 Step 3: Optuna 하이퍼파라미터 튜닝 시작 (GPU 사용)...\")\n","    print(f\"(최대 {config.N_TRIALS}번 시도, {config.EARLY_STOPPING_ROUNDS}번 개선 없으면 조기 종료)\")\n","    print(\"=\"*50)\n","\n","    early_stopping_callback = EarlyStoppingCallback(early_stopping_rounds=config.EARLY_STOPPING_ROUNDS)\n","    study = optuna.create_study(direction='maximize')\n","    pbar = tqdm(total=config.N_TRIALS, desc=\"Optuna 튜닝 진행률\")\n","\n","    try:\n","        study.optimize(lambda trial: objective(trial, X_train, y_train),\n","                       n_trials=config.N_TRIALS,\n","                       callbacks=[lambda study, trial: pbar.update(1), early_stopping_callback])\n","    except optuna.exceptions.OptunaError:\n","        # 조기 종료 시 발생하는 예외를 정상 처리\n","        pass\n","    pbar.close()\n","\n","    # ... (Step 4 ~ 6: 결과 출력, 저장, 메모리 정리) ...\n","    print(f\"\\n✅ 튜닝 완료!\")\n","    print(\"\\n\" + \"=\"*50)\n","    print(\"🔬 최적 하이퍼파라미터 (Best Hyperparameters)\")\n","    print(\"=\"*50)\n","    best_params = study.best_params\n","    for key, value in best_params.items():\n","        print(f\"{key:>20s}: {value}\")\n","    print(\"=\"*50)\n","\n","    print(f\"\\n🔬 Step 5: 튜닝된 최종 모델 학습 및 평가...\")\n","    final_model = lgb.LGBMClassifier(device='gpu', objective='binary', verbosity=-1, random_state=config.RANDOM_STATE, **best_params)\n","    final_model.fit(X_train, y_train)\n","\n","    y_pred_proba_tuned = final_model.predict_proba(X_test)[:, 1]\n","    y_pred_class_tuned = (y_pred_proba_tuned > 0.5).astype(int)\n","\n","    final_results['Optuna Tuned'] = {\n","        \"PR AUC\": average_precision_score(y_test, y_pred_proba_tuned),\n","        \"ROC AUC\": roc_auc_score(y_test, y_pred_proba_tuned),\n","        \"F1-Score\": f1_score(y_test, y_pred_class_tuned),\n","    }\n","    print(\"✅ 튜닝된 모델 평가 완료.\")\n","\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"📊 최종 성능 비교 결과 (Test Set)\")\n","    print(\"=\"*60)\n","    results_df = pd.DataFrame(final_results).T\n","    print(results_df.round(4))\n","\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"💾 Step 6: 최종 모델 예측 결과를 원본 CSV에 추가하여 저장\")\n","    print(\"=\"*60)\n","\n","    train_pred_proba = final_model.predict_proba(X_train)[:, 1]\n","    train_pred_class = (train_pred_proba > 0.5).astype(int)\n","\n","    df['s2_pred_proba'] = np.nan\n","    df['s2_pred_class'] = np.nan\n","\n","    df.loc[train_indices, 's2_pred_proba'] = train_pred_proba\n","    df.loc[train_indices, 's2_pred_class'] = train_pred_class\n","\n","    df.loc[test_indices, 's2_pred_proba'] = y_pred_proba_tuned\n","    df.loc[test_indices, 's2_pred_class'] = y_pred_class_tuned\n","\n","    # 🌟 Config에 설정된 경로로 최종 파일 저장\n","    df.to_csv(config.OUTPUT_CSV_PATH, index=False, encoding='utf-8-sig')\n","\n","    print(f\"✅ 모든 데이터의 예측 결과가 '{config.OUTPUT_CSV_PATH}' 파일에 성공적으로 저장되었습니다.\")\n","\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"🧹 Step 7: 사용된 변수들을 메모리에서 정리\")\n","    print(\"=\"*60)\n","\n","    vars_to_delete = [\n","        'df', 'labels', 'embeddings', 'indices', 'X_train', 'X_test',\n","        'y_train', 'y_test', 'train_indices', 'test_indices',\n","        'baseline_model', 'final_model', 'study',\n","    ]\n","    for var_name in vars_to_delete:\n","        if var_name in locals() or var_name in globals():\n","            if var_name in globals(): del globals()[var_name]\n","\n","    gc.collect()\n","    print(\"✅ 메모리 정리가 완료되었습니다.\")\n","\n","    print(\"\\n🎉 모든 과정이 완료되었습니다!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","referenced_widgets":["86d36f77612449a196c169894c66dbb8","5652c0cdf7384e639f517a96a1369817","bed1ad5e599b432382ada5edb9a579ed","59e1b86512394411bf1da923832d6b0f","a9f646957c574cfd9b049ebe39e539d8","a5b7f6de00de42c2bc89a0d07fbd6ff7","2db6a3dac7c642d8a898abf2259893b2","4f32897c3cb544b7a932a4433e12ae30","8c283fdb66184a30bdf164c3cf14ead7","fa1d1e7de79a4b2b8203b0e0e0d0054c","1b28462b78ce447b9f3c192942417c33"]},"id":"CJNH9aHVkQUp","executionInfo":{"status":"ok","timestamp":1760212071691,"user_tz":-540,"elapsed":1908315,"user":{"displayName":"KW-data-analytics","userId":"09651493752354345908"}},"outputId":"ad2acb82-2c2a-4e7a-fdf0-79cd552702b3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Step 1: 데이터 로드 및 분할 중...\n","✅ 완료 (학습용: 71941건, 테스트용: 17986건)\n","\n","==================================================\n","📊 Step 2: 베이스라인 모델 성능 측정 (GPU 사용)\n","==================================================\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-10-11 19:16:15,357] A new study created in memory with name: no-name-6e2b4125-4bb0-4706-b2d8-f37c80d0fe44\n"]},{"output_type":"stream","name":"stdout","text":["✅ 베이스라인 모델 평가 완료.\n","\n","==================================================\n","🔬 Step 3: Optuna 하이퍼파라미터 튜닝 시작 (GPU 사용)...\n","(최대 50번 시도, 10번 개선 없으면 조기 종료)\n","==================================================\n"]},{"output_type":"display_data","data":{"text/plain":["Optuna 튜닝 진행률:   0%|          | 0/50 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"86d36f77612449a196c169894c66dbb8"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2025-10-11 19:20:28,274] Trial 0 finished with value: 0.2845765103552348 and parameters: {'n_estimators': 1300, 'learning_rate': 0.0022185345762837753, 'num_leaves': 254, 'max_depth': 12, 'lambda_l1': 0.00011466209579466375, 'lambda_l2': 1.4861703991610546e-06, 'feature_fraction': 0.9392497545512575, 'bagging_fraction': 0.8876835171895672, 'bagging_freq': 2}. Best is trial 0 with value: 0.2845765103552348.\n","[I 2025-10-11 19:20:57,127] Trial 1 finished with value: 0.28028550444176525 and parameters: {'n_estimators': 400, 'learning_rate': 0.04312195349220553, 'num_leaves': 237, 'max_depth': 12, 'lambda_l1': 2.17003435760872e-07, 'lambda_l2': 1.1205508654860938, 'feature_fraction': 0.7333691271136558, 'bagging_fraction': 0.9626757765544744, 'bagging_freq': 1}. Best is trial 0 with value: 0.2845765103552348.\n","[I 2025-10-11 19:21:14,535] Trial 2 finished with value: 0.2881075799334142 and parameters: {'n_estimators': 1100, 'learning_rate': 0.007148434987831936, 'num_leaves': 258, 'max_depth': 4, 'lambda_l1': 0.0003574333519921265, 'lambda_l2': 0.025835426987032603, 'feature_fraction': 0.953665612218138, 'bagging_fraction': 0.8141232119720605, 'bagging_freq': 5}. Best is trial 2 with value: 0.2881075799334142.\n","[I 2025-10-11 19:26:05,713] Trial 3 finished with value: 0.28680227405729863 and parameters: {'n_estimators': 1400, 'learning_rate': 0.0017745223352382436, 'num_leaves': 269, 'max_depth': 12, 'lambda_l1': 1.7898373437644988, 'lambda_l2': 1.7753504977223117e-05, 'feature_fraction': 0.9783331922240517, 'bagging_fraction': 0.870915104909235, 'bagging_freq': 1}. Best is trial 2 with value: 0.2881075799334142.\n","[I 2025-10-11 19:26:22,586] Trial 4 finished with value: 0.285260367458789 and parameters: {'n_estimators': 1400, 'learning_rate': 0.032542515083668594, 'num_leaves': 33, 'max_depth': 6, 'lambda_l1': 7.818478222962315e-08, 'lambda_l2': 1.6647862462125267e-07, 'feature_fraction': 0.9130946927712824, 'bagging_fraction': 0.7834795724912806, 'bagging_freq': 1}. Best is trial 2 with value: 0.2881075799334142.\n","[I 2025-10-11 19:26:30,603] Trial 5 finished with value: 0.2814991721786032 and parameters: {'n_estimators': 100, 'learning_rate': 0.03384317731368012, 'num_leaves': 296, 'max_depth': 6, 'lambda_l1': 0.0004554496915059884, 'lambda_l2': 0.009101888480146123, 'feature_fraction': 0.650799173291401, 'bagging_fraction': 0.8534870075139431, 'bagging_freq': 2}. Best is trial 2 with value: 0.2881075799334142.\n","[I 2025-10-11 19:26:49,392] Trial 6 finished with value: 0.28448641651474027 and parameters: {'n_estimators': 600, 'learning_rate': 0.0041876296430740515, 'num_leaves': 24, 'max_depth': 7, 'lambda_l1': 0.002119550375839638, 'lambda_l2': 0.12407515447809253, 'feature_fraction': 0.7060242713318683, 'bagging_fraction': 0.9066965678374107, 'bagging_freq': 4}. Best is trial 2 with value: 0.2881075799334142.\n","[I 2025-10-11 19:27:00,034] Trial 7 finished with value: 0.2887859380364804 and parameters: {'n_estimators': 800, 'learning_rate': 0.021612623777855805, 'num_leaves': 153, 'max_depth': 5, 'lambda_l1': 1.542166493524694e-07, 'lambda_l2': 0.0031290497848253124, 'feature_fraction': 0.6068556889385409, 'bagging_fraction': 0.9534215320565465, 'bagging_freq': 3}. Best is trial 7 with value: 0.2887859380364804.\n","[I 2025-10-11 19:29:10,096] Trial 8 finished with value: 0.28454803068033624 and parameters: {'n_estimators': 1300, 'learning_rate': 0.0013340917479794765, 'num_leaves': 104, 'max_depth': 11, 'lambda_l1': 0.032585682429102286, 'lambda_l2': 0.0001840570753269733, 'feature_fraction': 0.8770332940941143, 'bagging_fraction': 0.9441849992401293, 'bagging_freq': 1}. Best is trial 7 with value: 0.2887859380364804.\n","[I 2025-10-11 19:29:29,236] Trial 9 finished with value: 0.2786728165254313 and parameters: {'n_estimators': 200, 'learning_rate': 0.003827532858987758, 'num_leaves': 208, 'max_depth': 7, 'lambda_l1': 4.3782305898806504e-05, 'lambda_l2': 0.002710797501261903, 'feature_fraction': 0.9650344432648181, 'bagging_fraction': 0.9919533669837306, 'bagging_freq': 2}. Best is trial 7 with value: 0.2887859380364804.\n","[I 2025-10-11 19:29:34,699] Trial 10 finished with value: 0.27830232596263305 and parameters: {'n_estimators': 2000, 'learning_rate': 0.1842008679204361, 'num_leaves': 147, 'max_depth': 3, 'lambda_l1': 9.515483629569136e-07, 'lambda_l2': 6.819229890689399, 'feature_fraction': 0.6011824481581186, 'bagging_fraction': 0.6743459557522572, 'bagging_freq': 7}. Best is trial 7 with value: 0.2887859380364804.\n","[I 2025-10-11 19:29:45,286] Trial 11 finished with value: 0.28692222535445683 and parameters: {'n_estimators': 900, 'learning_rate': 0.010616979850050383, 'num_leaves': 182, 'max_depth': 3, 'lambda_l1': 3.6025532284167357e-06, 'lambda_l2': 0.05984821006284699, 'feature_fraction': 0.821768260046948, 'bagging_fraction': 0.7267705573270061, 'bagging_freq': 5}. Best is trial 7 with value: 0.2887859380364804.\n","[I 2025-10-11 19:30:04,660] Trial 12 finished with value: 0.28536272155676057 and parameters: {'n_estimators': 800, 'learning_rate': 0.011932984111003117, 'num_leaves': 135, 'max_depth': 5, 'lambda_l1': 0.030295485554170554, 'lambda_l2': 0.00042744895982171194, 'feature_fraction': 0.8171110514288076, 'bagging_fraction': 0.6156738305687182, 'bagging_freq': 4}. Best is trial 7 with value: 0.2887859380364804.\n","[I 2025-10-11 19:30:16,466] Trial 13 finished with value: 0.2585036063449058 and parameters: {'n_estimators': 1800, 'learning_rate': 0.10522074054963881, 'num_leaves': 76, 'max_depth': 9, 'lambda_l1': 1.6092890343853014e-08, 'lambda_l2': 1.1067739609069213e-08, 'feature_fraction': 0.7377598398481721, 'bagging_fraction': 0.7746798149538316, 'bagging_freq': 6}. Best is trial 7 with value: 0.2887859380364804.\n","[I 2025-10-11 19:30:33,550] Trial 14 finished with value: 0.28911373214777447 and parameters: {'n_estimators': 1000, 'learning_rate': 0.00666640410663645, 'num_leaves': 195, 'max_depth': 4, 'lambda_l1': 3.5178795653237785e-06, 'lambda_l2': 0.08867703771166262, 'feature_fraction': 0.8690533022040184, 'bagging_fraction': 0.8364722543379773, 'bagging_freq': 3}. Best is trial 14 with value: 0.28911373214777447.\n","[I 2025-10-11 19:31:07,347] Trial 15 finished with value: 0.2862698347942446 and parameters: {'n_estimators': 700, 'learning_rate': 0.022078040231289967, 'num_leaves': 190, 'max_depth': 9, 'lambda_l1': 5.135317219605171e-06, 'lambda_l2': 0.4671889015057583, 'feature_fraction': 0.8466097312577004, 'bagging_fraction': 0.9264761567857367, 'bagging_freq': 3}. Best is trial 14 with value: 0.28911373214777447.\n","[I 2025-10-11 19:31:15,508] Trial 16 finished with value: 0.28270837499898716 and parameters: {'n_estimators': 400, 'learning_rate': 0.06643160457681907, 'num_leaves': 118, 'max_depth': 5, 'lambda_l1': 1.2677481942800125e-08, 'lambda_l2': 0.0011706188465843656, 'feature_fraction': 0.7581273061991399, 'bagging_fraction': 0.8270877007485546, 'bagging_freq': 3}. Best is trial 14 with value: 0.28911373214777447.\n","[I 2025-10-11 19:31:27,468] Trial 17 finished with value: 0.2882652048256861 and parameters: {'n_estimators': 1000, 'learning_rate': 0.017717550898764988, 'num_leaves': 212, 'max_depth': 4, 'lambda_l1': 1.0414552958971686e-05, 'lambda_l2': 4.257811078692615e-05, 'feature_fraction': 0.8901296029860873, 'bagging_fraction': 0.997770726974993, 'bagging_freq': 3}. Best is trial 14 with value: 0.28911373214777447.\n","[I 2025-10-11 19:31:59,589] Trial 18 finished with value: 0.2921098064564619 and parameters: {'n_estimators': 1600, 'learning_rate': 0.004736672222231734, 'num_leaves': 165, 'max_depth': 5, 'lambda_l1': 1.0216786129101437e-07, 'lambda_l2': 8.246206027329432, 'feature_fraction': 0.6672178520176764, 'bagging_fraction': 0.7247545118086824, 'bagging_freq': 5}. Best is trial 18 with value: 0.2921098064564619.\n","[I 2025-10-11 19:33:32,153] Trial 19 finished with value: 0.28814742375309116 and parameters: {'n_estimators': 1700, 'learning_rate': 0.004900431312825472, 'num_leaves': 175, 'max_depth': 9, 'lambda_l1': 8.116869596006228e-07, 'lambda_l2': 8.125668530550387, 'feature_fraction': 0.670873359895285, 'bagging_fraction': 0.728615646288308, 'bagging_freq': 5}. Best is trial 18 with value: 0.2921098064564619.\n","[I 2025-10-11 19:33:56,574] Trial 20 finished with value: 0.28536784164226914 and parameters: {'n_estimators': 1600, 'learning_rate': 0.002373544948702033, 'num_leaves': 79, 'max_depth': 4, 'lambda_l1': 2.1476174558924467e-05, 'lambda_l2': 0.8993882975569096, 'feature_fraction': 0.7853878141927776, 'bagging_fraction': 0.7343454087032338, 'bagging_freq': 7}. Best is trial 18 with value: 0.2921098064564619.\n","[I 2025-10-11 19:34:21,093] Trial 21 finished with value: 0.2882646928981537 and parameters: {'n_estimators': 1100, 'learning_rate': 0.007799219904402441, 'num_leaves': 157, 'max_depth': 5, 'lambda_l1': 1.24374406846073e-07, 'lambda_l2': 0.00931881670914677, 'feature_fraction': 0.6001789128086281, 'bagging_fraction': 0.6762996341543517, 'bagging_freq': 4}. Best is trial 18 with value: 0.2921098064564619.\n","[I 2025-10-11 19:34:42,218] Trial 22 finished with value: 0.2896524729207652 and parameters: {'n_estimators': 500, 'learning_rate': 0.01318531154178768, 'num_leaves': 219, 'max_depth': 6, 'lambda_l1': 5.872042978740215e-07, 'lambda_l2': 0.09560885060659957, 'feature_fraction': 0.6498134845626153, 'bagging_fraction': 0.6714630685825971, 'bagging_freq': 3}. Best is trial 18 with value: 0.2921098064564619.\n","[I 2025-10-11 19:35:02,188] Trial 23 finished with value: 0.2874991643627762 and parameters: {'n_estimators': 500, 'learning_rate': 0.0060540954809575834, 'num_leaves': 221, 'max_depth': 6, 'lambda_l1': 1.1490759678855335e-06, 'lambda_l2': 0.6635784967964494, 'feature_fraction': 0.6531624796048991, 'bagging_fraction': 0.6021040544846081, 'bagging_freq': 6}. Best is trial 18 with value: 0.2921098064564619.\n","[I 2025-10-11 19:37:13,398] Trial 24 finished with value: 0.2900492882757443 and parameters: {'n_estimators': 2000, 'learning_rate': 0.003135843490938134, 'num_leaves': 191, 'max_depth': 8, 'lambda_l1': 4.4323460873933443e-08, 'lambda_l2': 3.0079817097110695, 'feature_fraction': 0.6965445588648522, 'bagging_fraction': 0.6632067837463145, 'bagging_freq': 4}. Best is trial 18 with value: 0.2921098064564619.\n","[I 2025-10-11 19:39:18,995] Trial 25 finished with value: 0.2906790785832034 and parameters: {'n_estimators': 2000, 'learning_rate': 0.0030730902820793925, 'num_leaves': 229, 'max_depth': 8, 'lambda_l1': 3.225085781454603e-08, 'lambda_l2': 4.480712884501033, 'feature_fraction': 0.698746612584479, 'bagging_fraction': 0.658102339027221, 'bagging_freq': 4}. Best is trial 18 with value: 0.2921098064564619.\n","[I 2025-10-11 19:42:23,055] Trial 26 finished with value: 0.28678134045705367 and parameters: {'n_estimators': 2000, 'learning_rate': 0.0010333794140192096, 'num_leaves': 239, 'max_depth': 8, 'lambda_l1': 3.126435036195339e-08, 'lambda_l2': 3.077446954498151, 'feature_fraction': 0.693137032442092, 'bagging_fraction': 0.6421585949784159, 'bagging_freq': 5}. Best is trial 18 with value: 0.2921098064564619.\n","[I 2025-10-11 19:44:55,093] Trial 27 finished with value: 0.2892901010465855 and parameters: {'n_estimators': 1800, 'learning_rate': 0.003203071947921622, 'num_leaves': 286, 'max_depth': 10, 'lambda_l1': 4.951088924681422e-08, 'lambda_l2': 2.9701515224314163, 'feature_fraction': 0.7079095305090551, 'bagging_fraction': 0.7024712592418165, 'bagging_freq': 6}. Best is trial 18 with value: 0.2921098064564619.\n","[I 2025-10-11 19:47:11,731] Trial 28 finished with value: 0.2912254769143702 and parameters: {'n_estimators': 1900, 'learning_rate': 0.0025724024267050178, 'num_leaves': 167, 'max_depth': 8, 'lambda_l1': 5.683705821957825, 'lambda_l2': 0.26070164474165486, 'feature_fraction': 0.7721371117029209, 'bagging_fraction': 0.758134997877626, 'bagging_freq': 4}. Best is trial 18 with value: 0.2921098064564619.\n"]},{"output_type":"stream","name":"stdout","text":["\n","[Optuna 조기 종료] 10번의 trial 동안 최고 점수가 갱신되지 않아 튜닝을 중단합니다.\n","\n","✅ 튜닝 완료!\n","\n","==================================================\n","🔬 최적 하이퍼파라미터 (Best Hyperparameters)\n","==================================================\n","        n_estimators: 1600\n","       learning_rate: 0.004736672222231734\n","          num_leaves: 165\n","           max_depth: 5\n","           lambda_l1: 1.0216786129101437e-07\n","           lambda_l2: 8.246206027329432\n","    feature_fraction: 0.6672178520176764\n","    bagging_fraction: 0.7247545118086824\n","        bagging_freq: 5\n","==================================================\n","\n","🔬 Step 5: 튜닝된 최종 모델 학습 및 평가...\n","✅ 튜닝된 모델 평가 완료.\n","\n","============================================================\n","📊 최종 성능 비교 결과 (Test Set)\n","============================================================\n","              PR AUC  ROC AUC  F1-Score\n","Baseline      0.3155   0.7633    0.1465\n","Optuna Tuned  0.3301   0.7756    0.1354\n","\n","============================================================\n","💾 Step 6: 최종 모델 예측 결과를 원본 CSV에 추가하여 저장\n","============================================================\n","✅ 모든 데이터의 예측 결과가 '/content/drive/MyDrive/review_helpfulness/PADA/results/s2/amazon/RoBERTa_amazon_with_s2_predictions.csv' 파일에 성공적으로 저장되었습니다.\n","\n","============================================================\n","🧹 Step 7: 사용된 변수들을 메모리에서 정리\n","============================================================\n","✅ 메모리 정리가 완료되었습니다.\n","\n","🎉 모든 과정이 완료되었습니다!\n"]}]},{"cell_type":"markdown","source":["## DistilBERT"],"metadata":{"id":"xZuFkHutkbvh"}},{"cell_type":"code","source":["# === 2. 환경설정 클래스 ===\n","class Config:\n","    \"\"\"실행에 필요한 모든 설정값을 중앙에서 관리합니다.\"\"\"\n","    # 🌟 1. 입력 파일 경로 설정\n","    CSV_FILE_PATH = \"/content/drive/MyDrive/review_helpfulness/PADA/data/amazon/amazon.csv\"\n","    EMBEDDING_PATH = \"/content/drive/MyDrive/review_helpfulness/PADA/embedding/amazon_DistilBERT.npy\"\n","\n","    # 🌟 2. 최종 결과 CSV 파일 저장 경로 설정\n","    OUTPUT_CSV_PATH = \"/content/drive/MyDrive/review_helpfulness/PADA/results/s2/amazon/DistilBERT_amazon_with_s2_predictions.csv\"\n","\n","    # --- 데이터 정보 ---\n","    TARGET_COLUMN = 'binary_helpfulness'\n","\n","    # --- 데이터 분할 ---\n","    TEST_SPLIT_RATIO = 0.2\n","    RANDOM_STATE = 42\n","\n","    # --- Optuna 튜닝 설정 ---\n","    N_TRIALS = 50\n","    TUNING_METRIC = 'pr_auc'\n","    EARLY_STOPPING_ROUNDS = 10 # 🌟 Optuna 조기 종료 횟수\n","\n","# === 3. Optuna 조기 종료 콜백 ===\n","class EarlyStoppingCallback:\n","    \"\"\"Optuna 스터디의 조기 종료를 위한 콜백 클래스\"\"\"\n","    def __init__(self, early_stopping_rounds: int):\n","        self._early_stopping_rounds = early_stopping_rounds\n","        self._best_value = -float(\"inf\")\n","        self._counter = 0\n","\n","    def __call__(self, study: optuna.study.Study, trial: optuna.trial.Trial):\n","        current_best_value = study.best_value\n","        if current_best_value is not None and current_best_value > self._best_value:\n","            self._best_value = current_best_value\n","            self._counter = 0\n","        else:\n","            self._counter += 1\n","\n","        if self._counter >= self._early_stopping_rounds:\n","            print(f\"\\n[Optuna 조기 종료] {self._early_stopping_rounds}번의 trial 동안 최고 점수가 갱신되지 않아 튜닝을 중단합니다.\")\n","            study.stop()\n","\n","# === 4. Optuna Objective 함수 ===\n","def objective(trial, X, y):\n","    \"\"\"Optuna가 최적의 하이퍼파라미터를 찾기 위해 반복 호출하는 함수\"\"\"\n","    X_train, X_val, y_train, y_val = train_test_split(\n","        X, y, test_size=0.25, random_state=Config.RANDOM_STATE, stratify=y\n","    )\n","\n","    params = {\n","        'objective': 'binary', 'metric': 'logloss', 'verbosity': -1,\n","        'boosting_type': 'gbdt', 'random_state': Config.RANDOM_STATE,\n","        'device': 'gpu',  # 🌟 Optuna Trial 내부에서도 GPU 사용\n","        'n_estimators': trial.suggest_int('n_estimators', 100, 2000, step=100),\n","        'learning_rate': trial.suggest_float('learning_rate', 1e-3, 0.3, log=True),\n","        'num_leaves': trial.suggest_int('num_leaves', 20, 300),\n","        'max_depth': trial.suggest_int('max_depth', 3, 12),\n","        'lambda_l1': trial.suggest_float('lambda_l1', 1e-8, 10.0, log=True),\n","        'lambda_l2': trial.suggest_float('lambda_l2', 1e-8, 10.0, log=True),\n","        'feature_fraction': trial.suggest_float('feature_fraction', 0.6, 1.0),\n","        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.6, 1.0),\n","        'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\n","    }\n","\n","    model = lgb.LGBMClassifier(**params)\n","    model.fit(X_train, y_train,\n","              eval_set=[(X_val, y_val)],\n","              eval_metric='logloss',\n","              callbacks=[lgb.early_stopping(100, verbose=False)])\n","\n","    y_pred_proba = model.predict_proba(X_val)[:, 1]\n","    score = average_precision_score(y_val, y_pred_proba)\n","    return score\n","\n","# === 5. 메인 실행 블록 ===\n","if __name__ == '__main__':\n","    config = Config()\n","\n","    # ... (Step 1 ~ 2: 데이터 로드, 분할, 베이스라인 측정) ...\n","    print(\"Step 1: 데이터 로드 및 분할 중...\")\n","    try:\n","        df = pd.read_csv(config.CSV_FILE_PATH)\n","        labels = df[config.TARGET_COLUMN].values\n","        embeddings = np.load(config.EMBEDDING_PATH)\n","        assert len(df) == len(embeddings)\n","    except Exception as e:\n","        print(f\"🔥 파일 로드 실패: {e}\"); exit()\n","\n","    indices = np.arange(len(df))\n","    train_indices, test_indices = train_test_split(\n","        indices, test_size=config.TEST_SPLIT_RATIO, random_state=config.RANDOM_STATE, stratify=labels\n","    )\n","    X_train, X_test = embeddings[train_indices], embeddings[test_indices]\n","    y_train, y_test = labels[train_indices], labels[test_indices]\n","    print(f\"✅ 완료 (학습용: {len(y_train)}건, 테스트용: {len(y_test)}건)\")\n","\n","    print(\"\\n\" + \"=\"*50)\n","    print(\"📊 Step 2: 베이스라인 모델 성능 측정 (GPU 사용)\")\n","    print(\"=\"*50)\n","\n","    baseline_model = lgb.LGBMClassifier(device='gpu', random_state=config.RANDOM_STATE)\n","    baseline_model.fit(X_train, y_train)\n","\n","    y_pred_proba_base = baseline_model.predict_proba(X_test)[:, 1]\n","    y_pred_class_base = (y_pred_proba_base > 0.5).astype(int)\n","\n","    final_results = {}\n","    final_results['Baseline'] = {\n","        \"PR AUC\": average_precision_score(y_test, y_pred_proba_base),\n","        \"ROC AUC\": roc_auc_score(y_test, y_pred_proba_base),\n","        \"F1-Score\": f1_score(y_test, y_pred_class_base),\n","    }\n","    print(\"✅ 베이스라인 모델 평가 완료.\")\n","\n","    # --- Step 3: Optuna 튜닝 수행 (조기 종료 포함) ---\n","    print(\"\\n\" + \"=\"*50)\n","    print(f\"🔬 Step 3: Optuna 하이퍼파라미터 튜닝 시작 (GPU 사용)...\")\n","    print(f\"(최대 {config.N_TRIALS}번 시도, {config.EARLY_STOPPING_ROUNDS}번 개선 없으면 조기 종료)\")\n","    print(\"=\"*50)\n","\n","    early_stopping_callback = EarlyStoppingCallback(early_stopping_rounds=config.EARLY_STOPPING_ROUNDS)\n","    study = optuna.create_study(direction='maximize')\n","    pbar = tqdm(total=config.N_TRIALS, desc=\"Optuna 튜닝 진행률\")\n","\n","    try:\n","        study.optimize(lambda trial: objective(trial, X_train, y_train),\n","                       n_trials=config.N_TRIALS,\n","                       callbacks=[lambda study, trial: pbar.update(1), early_stopping_callback])\n","    except optuna.exceptions.OptunaError:\n","        # 조기 종료 시 발생하는 예외를 정상 처리\n","        pass\n","    pbar.close()\n","\n","    # ... (Step 4 ~ 6: 결과 출력, 저장, 메모리 정리) ...\n","    print(f\"\\n✅ 튜닝 완료!\")\n","    print(\"\\n\" + \"=\"*50)\n","    print(\"🔬 최적 하이퍼파라미터 (Best Hyperparameters)\")\n","    print(\"=\"*50)\n","    best_params = study.best_params\n","    for key, value in best_params.items():\n","        print(f\"{key:>20s}: {value}\")\n","    print(\"=\"*50)\n","\n","    print(f\"\\n🔬 Step 5: 튜닝된 최종 모델 학습 및 평가...\")\n","    final_model = lgb.LGBMClassifier(device='gpu', objective='binary', verbosity=-1, random_state=config.RANDOM_STATE, **best_params)\n","    final_model.fit(X_train, y_train)\n","\n","    y_pred_proba_tuned = final_model.predict_proba(X_test)[:, 1]\n","    y_pred_class_tuned = (y_pred_proba_tuned > 0.5).astype(int)\n","\n","    final_results['Optuna Tuned'] = {\n","        \"PR AUC\": average_precision_score(y_test, y_pred_proba_tuned),\n","        \"ROC AUC\": roc_auc_score(y_test, y_pred_proba_tuned),\n","        \"F1-Score\": f1_score(y_test, y_pred_class_tuned),\n","    }\n","    print(\"✅ 튜닝된 모델 평가 완료.\")\n","\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"📊 최종 성능 비교 결과 (Test Set)\")\n","    print(\"=\"*60)\n","    results_df = pd.DataFrame(final_results).T\n","    print(results_df.round(4))\n","\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"💾 Step 6: 최종 모델 예측 결과를 원본 CSV에 추가하여 저장\")\n","    print(\"=\"*60)\n","\n","    train_pred_proba = final_model.predict_proba(X_train)[:, 1]\n","    train_pred_class = (train_pred_proba > 0.5).astype(int)\n","\n","    df['s2_pred_proba'] = np.nan\n","    df['s2_pred_class'] = np.nan\n","\n","    df.loc[train_indices, 's2_pred_proba'] = train_pred_proba\n","    df.loc[train_indices, 's2_pred_class'] = train_pred_class\n","\n","    df.loc[test_indices, 's2_pred_proba'] = y_pred_proba_tuned\n","    df.loc[test_indices, 's2_pred_class'] = y_pred_class_tuned\n","\n","    # 🌟 Config에 설정된 경로로 최종 파일 저장\n","    df.to_csv(config.OUTPUT_CSV_PATH, index=False, encoding='utf-8-sig')\n","\n","    print(f\"✅ 모든 데이터의 예측 결과가 '{config.OUTPUT_CSV_PATH}' 파일에 성공적으로 저장되었습니다.\")\n","\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"🧹 Step 7: 사용된 변수들을 메모리에서 정리\")\n","    print(\"=\"*60)\n","\n","    vars_to_delete = [\n","        'df', 'labels', 'embeddings', 'indices', 'X_train', 'X_test',\n","        'y_train', 'y_test', 'train_indices', 'test_indices',\n","        'baseline_model', 'final_model', 'study',\n","    ]\n","    for var_name in vars_to_delete:\n","        if var_name in locals() or var_name in globals():\n","            if var_name in globals(): del globals()[var_name]\n","\n","    gc.collect()\n","    print(\"✅ 메모리 정리가 완료되었습니다.\")\n","\n","    print(\"\\n🎉 모든 과정이 완료되었습니다!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["c1ad27919ab54646aa88ab58309a3408","27b15f6e052443379a4119682039e4d7","212cf72fafe04de780f109d331dc48fd","0969f7b3db7740c78d34fe1fe6b3446a","70abafa8df054125be93c052676475b8","b53678641b65463db873d8bea835f8fd","95057d180c6e48709f4d3d29fc9e3331","bfef38c1899a415086955c7d79841b8a","b326487fd7114ce18120e15d17d8deaf","d6b6d616598b439f9c381f4fa95fd0f6","b241d32b9db8439db25c484bbc0e3158"]},"id":"MOF2C-hMkcUi","executionInfo":{"status":"ok","timestamp":1760212677897,"user_tz":-540,"elapsed":606203,"user":{"displayName":"KW-data-analytics","userId":"09651493752354345908"}},"outputId":"e45a7009-5eaa-419b-abc7-df5f72666dca"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Step 1: 데이터 로드 및 분할 중...\n","✅ 완료 (학습용: 71941건, 테스트용: 17986건)\n","\n","==================================================\n","📊 Step 2: 베이스라인 모델 성능 측정 (GPU 사용)\n","==================================================\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-10-11 19:48:03,839] A new study created in memory with name: no-name-87f04557-6a25-4268-bb7e-b274394d7c19\n"]},{"output_type":"stream","name":"stdout","text":["✅ 베이스라인 모델 평가 완료.\n","\n","==================================================\n","🔬 Step 3: Optuna 하이퍼파라미터 튜닝 시작 (GPU 사용)...\n","(최대 50번 시도, 10번 개선 없으면 조기 종료)\n","==================================================\n"]},{"output_type":"display_data","data":{"text/plain":["Optuna 튜닝 진행률:   0%|          | 0/50 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c1ad27919ab54646aa88ab58309a3408"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2025-10-11 19:49:23,622] Trial 0 finished with value: 0.29355160766737765 and parameters: {'n_estimators': 900, 'learning_rate': 0.009295730322749328, 'num_leaves': 277, 'max_depth': 12, 'lambda_l1': 3.012658205207445e-05, 'lambda_l2': 1.0215215876064099, 'feature_fraction': 0.8316498356072956, 'bagging_fraction': 0.9139956440420921, 'bagging_freq': 1}. Best is trial 0 with value: 0.29355160766737765.\n","[I 2025-10-11 19:50:11,099] Trial 1 finished with value: 0.28981896281638114 and parameters: {'n_estimators': 1700, 'learning_rate': 0.007611179949916501, 'num_leaves': 76, 'max_depth': 10, 'lambda_l1': 0.00036541558170006454, 'lambda_l2': 0.0015393019511521647, 'feature_fraction': 0.875899037692794, 'bagging_fraction': 0.9530256503958171, 'bagging_freq': 2}. Best is trial 0 with value: 0.29355160766737765.\n","[I 2025-10-11 19:50:16,799] Trial 2 finished with value: 0.2775046981069139 and parameters: {'n_estimators': 200, 'learning_rate': 0.008285495992609285, 'num_leaves': 104, 'max_depth': 3, 'lambda_l1': 5.577573225238454, 'lambda_l2': 0.02935613159475788, 'feature_fraction': 0.8205979653565039, 'bagging_fraction': 0.9447883055063705, 'bagging_freq': 5}. Best is trial 0 with value: 0.29355160766737765.\n","[I 2025-10-11 19:52:11,649] Trial 3 finished with value: 0.29108013233324476 and parameters: {'n_estimators': 1300, 'learning_rate': 0.001122061624190169, 'num_leaves': 134, 'max_depth': 8, 'lambda_l1': 9.96713939559107e-08, 'lambda_l2': 7.864971638783689e-08, 'feature_fraction': 0.8786955770761593, 'bagging_fraction': 0.6232337388673108, 'bagging_freq': 6}. Best is trial 0 with value: 0.29355160766737765.\n","[I 2025-10-11 19:52:18,022] Trial 4 finished with value: 0.29320790559237697 and parameters: {'n_estimators': 200, 'learning_rate': 0.05600484124508939, 'num_leaves': 23, 'max_depth': 4, 'lambda_l1': 0.029377997227784797, 'lambda_l2': 3.8399626831766422, 'feature_fraction': 0.7889618179097436, 'bagging_fraction': 0.9709225855883021, 'bagging_freq': 1}. Best is trial 0 with value: 0.29355160766737765.\n","[I 2025-10-11 19:52:34,325] Trial 5 finished with value: 0.2618915000853479 and parameters: {'n_estimators': 700, 'learning_rate': 0.11087915017162696, 'num_leaves': 197, 'max_depth': 9, 'lambda_l1': 1.828670018806202e-06, 'lambda_l2': 1.107968979294027e-08, 'feature_fraction': 0.7100805100307324, 'bagging_fraction': 0.7073934721647498, 'bagging_freq': 6}. Best is trial 0 with value: 0.29355160766737765.\n","[I 2025-10-11 19:52:42,717] Trial 6 finished with value: 0.2800201683561848 and parameters: {'n_estimators': 200, 'learning_rate': 0.0019910275319691448, 'num_leaves': 144, 'max_depth': 5, 'lambda_l1': 5.401478662532602e-06, 'lambda_l2': 0.07453897183229212, 'feature_fraction': 0.7226773382090869, 'bagging_fraction': 0.6671962432503098, 'bagging_freq': 7}. Best is trial 0 with value: 0.29355160766737765.\n","[I 2025-10-11 19:52:58,420] Trial 7 finished with value: 0.27880858940129905 and parameters: {'n_estimators': 400, 'learning_rate': 0.0015964469466775294, 'num_leaves': 29, 'max_depth': 12, 'lambda_l1': 4.288365086342626, 'lambda_l2': 2.154296204705798e-05, 'feature_fraction': 0.8737403543409565, 'bagging_fraction': 0.7667118510152939, 'bagging_freq': 2}. Best is trial 0 with value: 0.29355160766737765.\n","[I 2025-10-11 19:53:32,064] Trial 8 finished with value: 0.2923249807224533 and parameters: {'n_estimators': 1100, 'learning_rate': 0.009199576441353169, 'num_leaves': 44, 'max_depth': 9, 'lambda_l1': 0.0350604767148027, 'lambda_l2': 5.8823729245129006e-08, 'feature_fraction': 0.8248272721042207, 'bagging_fraction': 0.8378923637127835, 'bagging_freq': 5}. Best is trial 0 with value: 0.29355160766737765.\n","[I 2025-10-11 19:54:03,628] Trial 9 finished with value: 0.28710402705780924 and parameters: {'n_estimators': 400, 'learning_rate': 0.007135960694802675, 'num_leaves': 80, 'max_depth': 8, 'lambda_l1': 6.66942265845175e-07, 'lambda_l2': 0.060852329072496436, 'feature_fraction': 0.9757640358970915, 'bagging_fraction': 0.9892141460609976, 'bagging_freq': 5}. Best is trial 0 with value: 0.29355160766737765.\n","[I 2025-10-11 19:54:37,249] Trial 10 finished with value: 0.28716505840956064 and parameters: {'n_estimators': 2000, 'learning_rate': 0.034437182446121706, 'num_leaves': 294, 'max_depth': 11, 'lambda_l1': 0.00013947918558883813, 'lambda_l2': 9.639404693672777, 'feature_fraction': 0.6054829195724096, 'bagging_fraction': 0.8497153870823795, 'bagging_freq': 3}. Best is trial 0 with value: 0.29355160766737765.\n"]},{"output_type":"stream","name":"stdout","text":["\n","[Optuna 조기 종료] 10번의 trial 동안 최고 점수가 갱신되지 않아 튜닝을 중단합니다.\n","\n","✅ 튜닝 완료!\n","\n","==================================================\n","🔬 최적 하이퍼파라미터 (Best Hyperparameters)\n","==================================================\n","        n_estimators: 900\n","       learning_rate: 0.009295730322749328\n","          num_leaves: 277\n","           max_depth: 12\n","           lambda_l1: 3.012658205207445e-05\n","           lambda_l2: 1.0215215876064099\n","    feature_fraction: 0.8316498356072956\n","    bagging_fraction: 0.9139956440420921\n","        bagging_freq: 1\n","==================================================\n","\n","🔬 Step 5: 튜닝된 최종 모델 학습 및 평가...\n","✅ 튜닝된 모델 평가 완료.\n","\n","============================================================\n","📊 최종 성능 비교 결과 (Test Set)\n","============================================================\n","              PR AUC  ROC AUC  F1-Score\n","Baseline      0.3090   0.7732    0.1364\n","Optuna Tuned  0.3259   0.7785    0.1296\n","\n","============================================================\n","💾 Step 6: 최종 모델 예측 결과를 원본 CSV에 추가하여 저장\n","============================================================\n","✅ 모든 데이터의 예측 결과가 '/content/drive/MyDrive/review_helpfulness/PADA/results/s2/amazon/DistilBERT_amazon_with_s2_predictions.csv' 파일에 성공적으로 저장되었습니다.\n","\n","============================================================\n","🧹 Step 7: 사용된 변수들을 메모리에서 정리\n","============================================================\n","✅ 메모리 정리가 완료되었습니다.\n","\n","🎉 모든 과정이 완료되었습니다!\n"]}]},{"cell_type":"markdown","source":["# Coursera"],"metadata":{"id":"o3FmDWJJup2d"}},{"cell_type":"markdown","source":["## T5"],"metadata":{"id":"iOMKMF6durPt"}},{"cell_type":"code","source":["# === 2. 환경설정 클래스 ===\n","class Config:\n","    \"\"\"실행에 필요한 모든 설정값을 중앙에서 관리합니다.\"\"\"\n","    # 🌟 1. 입력 파일 경로 설정\n","    CSV_FILE_PATH = \"/content/drive/MyDrive/review_helpfulness/PADA/data/coursera/coursera.csv\"\n","    EMBEDDING_PATH = \"/content/drive/MyDrive/review_helpfulness/PADA/embedding/coursera_T5.npy\"\n","\n","    # 🌟 2. 최종 결과 CSV 파일 저장 경로 설정\n","    OUTPUT_CSV_PATH = \"/content/drive/MyDrive/review_helpfulness/PADA/results/s2/coursera/T5_coursera_with_s2_predictions.csv\"\n","\n","    # --- 데이터 정보 ---\n","    TARGET_COLUMN = 'binary_helpfulness'\n","\n","    # --- 데이터 분할 ---\n","    TEST_SPLIT_RATIO = 0.2\n","    RANDOM_STATE = 42\n","\n","    # --- Optuna 튜닝 설정 ---\n","    N_TRIALS = 50\n","    TUNING_METRIC = 'pr_auc'\n","    EARLY_STOPPING_ROUNDS = 10 # 🌟 Optuna 조기 종료 횟수\n","\n","# === 3. Optuna 조기 종료 콜백 ===\n","class EarlyStoppingCallback:\n","    \"\"\"Optuna 스터디의 조기 종료를 위한 콜백 클래스\"\"\"\n","    def __init__(self, early_stopping_rounds: int):\n","        self._early_stopping_rounds = early_stopping_rounds\n","        self._best_value = -float(\"inf\")\n","        self._counter = 0\n","\n","    def __call__(self, study: optuna.study.Study, trial: optuna.trial.Trial):\n","        current_best_value = study.best_value\n","        if current_best_value is not None and current_best_value > self._best_value:\n","            self._best_value = current_best_value\n","            self._counter = 0\n","        else:\n","            self._counter += 1\n","\n","        if self._counter >= self._early_stopping_rounds:\n","            print(f\"\\n[Optuna 조기 종료] {self._early_stopping_rounds}번의 trial 동안 최고 점수가 갱신되지 않아 튜닝을 중단합니다.\")\n","            study.stop()\n","\n","# === 4. Optuna Objective 함수 ===\n","def objective(trial, X, y):\n","    \"\"\"Optuna가 최적의 하이퍼파라미터를 찾기 위해 반복 호출하는 함수\"\"\"\n","    X_train, X_val, y_train, y_val = train_test_split(\n","        X, y, test_size=0.25, random_state=Config.RANDOM_STATE, stratify=y\n","    )\n","\n","    params = {\n","        'objective': 'binary', 'metric': 'logloss', 'verbosity': -1,\n","        'boosting_type': 'gbdt', 'random_state': Config.RANDOM_STATE,\n","        'device': 'gpu',  # 🌟 Optuna Trial 내부에서도 GPU 사용\n","        'n_estimators': trial.suggest_int('n_estimators', 100, 2000, step=100),\n","        'learning_rate': trial.suggest_float('learning_rate', 1e-3, 0.3, log=True),\n","        'num_leaves': trial.suggest_int('num_leaves', 20, 300),\n","        'max_depth': trial.suggest_int('max_depth', 3, 12),\n","        'lambda_l1': trial.suggest_float('lambda_l1', 1e-8, 10.0, log=True),\n","        'lambda_l2': trial.suggest_float('lambda_l2', 1e-8, 10.0, log=True),\n","        'feature_fraction': trial.suggest_float('feature_fraction', 0.6, 1.0),\n","        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.6, 1.0),\n","        'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\n","    }\n","\n","    model = lgb.LGBMClassifier(**params)\n","    model.fit(X_train, y_train,\n","              eval_set=[(X_val, y_val)],\n","              eval_metric='logloss',\n","              callbacks=[lgb.early_stopping(100, verbose=False)])\n","\n","    y_pred_proba = model.predict_proba(X_val)[:, 1]\n","    score = average_precision_score(y_val, y_pred_proba)\n","    return score\n","\n","# === 5. 메인 실행 블록 ===\n","if __name__ == '__main__':\n","    config = Config()\n","\n","    # ... (Step 1 ~ 2: 데이터 로드, 분할, 베이스라인 측정) ...\n","    print(\"Step 1: 데이터 로드 및 분할 중...\")\n","    try:\n","        df = pd.read_csv(config.CSV_FILE_PATH)\n","        labels = df[config.TARGET_COLUMN].values\n","        embeddings = np.load(config.EMBEDDING_PATH)\n","        assert len(df) == len(embeddings)\n","    except Exception as e:\n","        print(f\"🔥 파일 로드 실패: {e}\"); exit()\n","\n","    indices = np.arange(len(df))\n","    train_indices, test_indices = train_test_split(\n","        indices, test_size=config.TEST_SPLIT_RATIO, random_state=config.RANDOM_STATE, stratify=labels\n","    )\n","    X_train, X_test = embeddings[train_indices], embeddings[test_indices]\n","    y_train, y_test = labels[train_indices], labels[test_indices]\n","    print(f\"✅ 완료 (학습용: {len(y_train)}건, 테스트용: {len(y_test)}건)\")\n","\n","    print(\"\\n\" + \"=\"*50)\n","    print(\"📊 Step 2: 베이스라인 모델 성능 측정 (GPU 사용)\")\n","    print(\"=\"*50)\n","\n","    baseline_model = lgb.LGBMClassifier(device='gpu', random_state=config.RANDOM_STATE)\n","    baseline_model.fit(X_train, y_train)\n","\n","    y_pred_proba_base = baseline_model.predict_proba(X_test)[:, 1]\n","    y_pred_class_base = (y_pred_proba_base > 0.5).astype(int)\n","\n","    final_results = {}\n","    final_results['Baseline'] = {\n","        \"PR AUC\": average_precision_score(y_test, y_pred_proba_base),\n","        \"ROC AUC\": roc_auc_score(y_test, y_pred_proba_base),\n","        \"F1-Score\": f1_score(y_test, y_pred_class_base),\n","    }\n","    print(\"✅ 베이스라인 모델 평가 완료.\")\n","\n","    # --- Step 3: Optuna 튜닝 수행 (조기 종료 포함) ---\n","    print(\"\\n\" + \"=\"*50)\n","    print(f\"🔬 Step 3: Optuna 하이퍼파라미터 튜닝 시작 (GPU 사용)...\")\n","    print(f\"(최대 {config.N_TRIALS}번 시도, {config.EARLY_STOPPING_ROUNDS}번 개선 없으면 조기 종료)\")\n","    print(\"=\"*50)\n","\n","    early_stopping_callback = EarlyStoppingCallback(early_stopping_rounds=config.EARLY_STOPPING_ROUNDS)\n","    study = optuna.create_study(direction='maximize')\n","    pbar = tqdm(total=config.N_TRIALS, desc=\"Optuna 튜닝 진행률\")\n","\n","    try:\n","        study.optimize(lambda trial: objective(trial, X_train, y_train),\n","                       n_trials=config.N_TRIALS,\n","                       callbacks=[lambda study, trial: pbar.update(1), early_stopping_callback])\n","    except optuna.exceptions.OptunaError:\n","        # 조기 종료 시 발생하는 예외를 정상 처리\n","        pass\n","    pbar.close()\n","\n","    # ... (Step 4 ~ 6: 결과 출력, 저장, 메모리 정리) ...\n","    print(f\"\\n✅ 튜닝 완료!\")\n","    print(\"\\n\" + \"=\"*50)\n","    print(\"🔬 최적 하이퍼파라미터 (Best Hyperparameters)\")\n","    print(\"=\"*50)\n","    best_params = study.best_params\n","    for key, value in best_params.items():\n","        print(f\"{key:>20s}: {value}\")\n","    print(\"=\"*50)\n","\n","    print(f\"\\n🔬 Step 5: 튜닝된 최종 모델 학습 및 평가...\")\n","    final_model = lgb.LGBMClassifier(device='gpu', objective='binary', verbosity=-1, random_state=config.RANDOM_STATE, **best_params)\n","    final_model.fit(X_train, y_train)\n","\n","    y_pred_proba_tuned = final_model.predict_proba(X_test)[:, 1]\n","    y_pred_class_tuned = (y_pred_proba_tuned > 0.5).astype(int)\n","\n","    final_results['Optuna Tuned'] = {\n","        \"PR AUC\": average_precision_score(y_test, y_pred_proba_tuned),\n","        \"ROC AUC\": roc_auc_score(y_test, y_pred_proba_tuned),\n","        \"F1-Score\": f1_score(y_test, y_pred_class_tuned),\n","    }\n","    print(\"✅ 튜닝된 모델 평가 완료.\")\n","\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"📊 최종 성능 비교 결과 (Test Set)\")\n","    print(\"=\"*60)\n","    results_df = pd.DataFrame(final_results).T\n","    print(results_df.round(4))\n","\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"💾 Step 6: 최종 모델 예측 결과를 원본 CSV에 추가하여 저장\")\n","    print(\"=\"*60)\n","\n","    train_pred_proba = final_model.predict_proba(X_train)[:, 1]\n","    train_pred_class = (train_pred_proba > 0.5).astype(int)\n","\n","    df['s2_pred_proba'] = np.nan\n","    df['s2_pred_class'] = np.nan\n","\n","    df.loc[train_indices, 's2_pred_proba'] = train_pred_proba\n","    df.loc[train_indices, 's2_pred_class'] = train_pred_class\n","\n","    df.loc[test_indices, 's2_pred_proba'] = y_pred_proba_tuned\n","    df.loc[test_indices, 's2_pred_class'] = y_pred_class_tuned\n","\n","    # 🌟 Config에 설정된 경로로 최종 파일 저장\n","    df.to_csv(config.OUTPUT_CSV_PATH, index=False, encoding='utf-8-sig')\n","\n","    print(f\"✅ 모든 데이터의 예측 결과가 '{config.OUTPUT_CSV_PATH}' 파일에 성공적으로 저장되었습니다.\")\n","\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"🧹 Step 7: 사용된 변수들을 메모리에서 정리\")\n","    print(\"=\"*60)\n","\n","    vars_to_delete = [\n","        'df', 'labels', 'embeddings', 'indices', 'X_train', 'X_test',\n","        'y_train', 'y_test', 'train_indices', 'test_indices',\n","        'baseline_model', 'final_model', 'study',\n","    ]\n","    for var_name in vars_to_delete:\n","        if var_name in locals() or var_name in globals():\n","            if var_name in globals(): del globals()[var_name]\n","\n","    gc.collect()\n","    print(\"✅ 메모리 정리가 완료되었습니다.\")\n","\n","    print(\"\\n🎉 모든 과정이 완료되었습니다!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","referenced_widgets":["101e646cafeb4b9a9dccee816b5859df","08e0e5409a4343babf163907fafcebe7","266e865028c44f97adfd9604a4f6c7fa","e45cb316b40d49029ada00196329cd4d","4759c2c992104f6daaed3f47f59b4003","3ec70efd33c348eb94006e7471d1133d","47411a8f4b544297892d1adf6793f33f","9babf8015160436c87995b978ebb4a57","175ac7384cac45a9a005a7f7aa1939cf","6830cbfc01c146d5b6a60dc350b49f02","5b96c6b621f44692b91d6ba128116c43"]},"id":"zabwpJfRvfnk","executionInfo":{"status":"ok","timestamp":1760214286109,"user_tz":-540,"elapsed":1607843,"user":{"displayName":"KW-data-analytics","userId":"09651493752354345908"}},"outputId":"fa1a0f0b-8299-43e0-eea7-3b01176a57e6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Step 1: 데이터 로드 및 분할 중...\n","✅ 완료 (학습용: 97108건, 테스트용: 24278건)\n","\n","==================================================\n","📊 Step 2: 베이스라인 모델 성능 측정 (GPU 사용)\n","==================================================\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-10-11 19:58:14,839] A new study created in memory with name: no-name-def89859-c8b9-4b6a-a916-79ceec6b97a7\n"]},{"output_type":"stream","name":"stdout","text":["✅ 베이스라인 모델 평가 완료.\n","\n","==================================================\n","🔬 Step 3: Optuna 하이퍼파라미터 튜닝 시작 (GPU 사용)...\n","(최대 50번 시도, 10번 개선 없으면 조기 종료)\n","==================================================\n"]},{"output_type":"display_data","data":{"text/plain":["Optuna 튜닝 진행률:   0%|          | 0/50 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"101e646cafeb4b9a9dccee816b5859df"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2025-10-11 19:58:52,379] Trial 0 finished with value: 0.21666437305240877 and parameters: {'n_estimators': 1200, 'learning_rate': 0.01637537335615552, 'num_leaves': 117, 'max_depth': 12, 'lambda_l1': 6.856253928276642e-05, 'lambda_l2': 4.898478761629054e-07, 'feature_fraction': 0.9192453560829086, 'bagging_fraction': 0.8581375935582478, 'bagging_freq': 7}. Best is trial 0 with value: 0.21666437305240877.\n","[I 2025-10-11 19:59:05,170] Trial 1 finished with value: 0.17487312258815896 and parameters: {'n_estimators': 500, 'learning_rate': 0.12511384415385518, 'num_leaves': 233, 'max_depth': 7, 'lambda_l1': 5.755964763444149e-06, 'lambda_l2': 4.174804057710874e-08, 'feature_fraction': 0.886551297588371, 'bagging_fraction': 0.742379760892753, 'bagging_freq': 2}. Best is trial 0 with value: 0.21666437305240877.\n","[I 2025-10-11 20:02:14,445] Trial 2 finished with value: 0.2212457955590728 and parameters: {'n_estimators': 1400, 'learning_rate': 0.0014421002981804564, 'num_leaves': 182, 'max_depth': 10, 'lambda_l1': 6.577530489108355e-08, 'lambda_l2': 5.8414126683959315, 'feature_fraction': 0.7287624783497497, 'bagging_fraction': 0.819038031268649, 'bagging_freq': 7}. Best is trial 2 with value: 0.2212457955590728.\n","[I 2025-10-11 20:02:23,507] Trial 3 finished with value: 0.2149983625169853 and parameters: {'n_estimators': 1900, 'learning_rate': 0.05399168655099511, 'num_leaves': 299, 'max_depth': 3, 'lambda_l1': 4.6711911689009775e-05, 'lambda_l2': 5.789003473948668e-07, 'feature_fraction': 0.9954135284422029, 'bagging_fraction': 0.8592680096847347, 'bagging_freq': 7}. Best is trial 2 with value: 0.2212457955590728.\n","[I 2025-10-11 20:02:38,764] Trial 4 finished with value: 0.2088105870942925 and parameters: {'n_estimators': 500, 'learning_rate': 0.001163384766285672, 'num_leaves': 235, 'max_depth': 5, 'lambda_l1': 2.755263194919178e-08, 'lambda_l2': 1.1169438699040195e-07, 'feature_fraction': 0.6282149305356378, 'bagging_fraction': 0.8912360870904059, 'bagging_freq': 2}. Best is trial 2 with value: 0.2212457955590728.\n","[I 2025-10-11 20:03:05,690] Trial 5 finished with value: 0.2146792354437671 and parameters: {'n_estimators': 600, 'learning_rate': 0.001588995228437029, 'num_leaves': 105, 'max_depth': 6, 'lambda_l1': 0.41733887358918204, 'lambda_l2': 1.1865026556196951e-05, 'feature_fraction': 0.6585155773489536, 'bagging_fraction': 0.8272831873174704, 'bagging_freq': 2}. Best is trial 2 with value: 0.2212457955590728.\n","[I 2025-10-11 20:03:41,845] Trial 6 finished with value: 0.21969340860993747 and parameters: {'n_estimators': 900, 'learning_rate': 0.0031451460752484734, 'num_leaves': 41, 'max_depth': 10, 'lambda_l1': 1.8433263279676317e-06, 'lambda_l2': 0.051421841573403765, 'feature_fraction': 0.6086617203493319, 'bagging_fraction': 0.7618161126015598, 'bagging_freq': 1}. Best is trial 2 with value: 0.2212457955590728.\n","[I 2025-10-11 20:03:56,011] Trial 7 finished with value: 0.2148583553949548 and parameters: {'n_estimators': 1800, 'learning_rate': 0.03806305987411714, 'num_leaves': 219, 'max_depth': 6, 'lambda_l1': 9.539439743125549e-07, 'lambda_l2': 2.7876461554743423e-08, 'feature_fraction': 0.7213804227014364, 'bagging_fraction': 0.8851126274813566, 'bagging_freq': 3}. Best is trial 2 with value: 0.2212457955590728.\n","[I 2025-10-11 20:04:07,337] Trial 8 finished with value: 0.21059641900870485 and parameters: {'n_estimators': 400, 'learning_rate': 0.08146061136708843, 'num_leaves': 172, 'max_depth': 6, 'lambda_l1': 2.7846788188901628, 'lambda_l2': 2.5312341462178524e-05, 'feature_fraction': 0.7491143794129219, 'bagging_fraction': 0.6089658309405196, 'bagging_freq': 1}. Best is trial 2 with value: 0.2212457955590728.\n","[I 2025-10-11 20:04:51,231] Trial 9 finished with value: 0.2236125204429349 and parameters: {'n_estimators': 700, 'learning_rate': 0.011207293834904791, 'num_leaves': 124, 'max_depth': 9, 'lambda_l1': 1.1718752303504693e-06, 'lambda_l2': 1.9773997555771682e-06, 'feature_fraction': 0.7995697898728117, 'bagging_fraction': 0.8713544123954466, 'bagging_freq': 3}. Best is trial 9 with value: 0.2236125204429349.\n","[I 2025-10-11 20:05:00,861] Trial 10 finished with value: 0.21248568104909155 and parameters: {'n_estimators': 100, 'learning_rate': 0.009930553479629985, 'num_leaves': 31, 'max_depth': 9, 'lambda_l1': 0.02375281041478612, 'lambda_l2': 0.002314339744292317, 'feature_fraction': 0.8266604252608021, 'bagging_fraction': 0.9654237982799783, 'bagging_freq': 5}. Best is trial 9 with value: 0.2236125204429349.\n","[I 2025-10-11 20:06:50,530] Trial 11 finished with value: 0.2254087626786821 and parameters: {'n_estimators': 1400, 'learning_rate': 0.0058282028893978455, 'num_leaves': 148, 'max_depth': 10, 'lambda_l1': 3.5826164629635885e-08, 'lambda_l2': 8.931626823939144, 'feature_fraction': 0.7931521842164905, 'bagging_fraction': 0.965524179305847, 'bagging_freq': 4}. Best is trial 11 with value: 0.2254087626786821.\n","[I 2025-10-11 20:08:10,771] Trial 12 finished with value: 0.22261419958495376 and parameters: {'n_estimators': 1500, 'learning_rate': 0.0063205794025326285, 'num_leaves': 103, 'max_depth': 12, 'lambda_l1': 0.0029776082050079573, 'lambda_l2': 2.9478743323191012, 'feature_fraction': 0.815202213898746, 'bagging_fraction': 0.9970077558793062, 'bagging_freq': 5}. Best is trial 11 with value: 0.2254087626786821.\n","[I 2025-10-11 20:09:36,731] Trial 13 finished with value: 0.22461093169549304 and parameters: {'n_estimators': 900, 'learning_rate': 0.004770209187045756, 'num_leaves': 150, 'max_depth': 9, 'lambda_l1': 2.224999410039729e-08, 'lambda_l2': 0.003213169647481561, 'feature_fraction': 0.859058627719844, 'bagging_fraction': 0.9387395737618882, 'bagging_freq': 4}. Best is trial 11 with value: 0.2254087626786821.\n","[I 2025-10-11 20:11:23,412] Trial 14 finished with value: 0.22090377039118653 and parameters: {'n_estimators': 1100, 'learning_rate': 0.00394524384137517, 'num_leaves': 147, 'max_depth': 9, 'lambda_l1': 2.059458852681788e-08, 'lambda_l2': 0.04332963856816502, 'feature_fraction': 0.88919808164994, 'bagging_fraction': 0.9444495870554166, 'bagging_freq': 5}. Best is trial 11 with value: 0.2254087626786821.\n","[I 2025-10-11 20:13:12,542] Trial 15 finished with value: 0.22690394257508217 and parameters: {'n_estimators': 1600, 'learning_rate': 0.0036738077327695073, 'num_leaves': 79, 'max_depth': 11, 'lambda_l1': 1.0074209283711079e-08, 'lambda_l2': 0.0011833529803131166, 'feature_fraction': 0.9543663161446166, 'bagging_fraction': 0.9363123245517312, 'bagging_freq': 4}. Best is trial 15 with value: 0.22690394257508217.\n","[I 2025-10-11 20:13:35,569] Trial 16 finished with value: 0.21860438623636594 and parameters: {'n_estimators': 1600, 'learning_rate': 0.03213292103695524, 'num_leaves': 71, 'max_depth': 11, 'lambda_l1': 1.538922729806063e-07, 'lambda_l2': 0.3452882454125982, 'feature_fraction': 0.9742568023441731, 'bagging_fraction': 0.9992363948731684, 'bagging_freq': 4}. Best is trial 15 with value: 0.22690394257508217.\n","[I 2025-10-11 20:13:49,048] Trial 17 finished with value: 0.15077944256030604 and parameters: {'n_estimators': 2000, 'learning_rate': 0.2724569704948421, 'num_leaves': 69, 'max_depth': 11, 'lambda_l1': 0.0008258612123583506, 'lambda_l2': 0.00030090998773960536, 'feature_fraction': 0.9410901102508124, 'bagging_fraction': 0.6881053996730574, 'bagging_freq': 6}. Best is trial 15 with value: 0.22690394257508217.\n","[I 2025-10-11 20:15:07,067] Trial 18 finished with value: 0.22558641884700667 and parameters: {'n_estimators': 1300, 'learning_rate': 0.00342033009102601, 'num_leaves': 73, 'max_depth': 8, 'lambda_l1': 2.2042169339989154e-07, 'lambda_l2': 0.00039056499362665235, 'feature_fraction': 0.7791319552952347, 'bagging_fraction': 0.9233714997895519, 'bagging_freq': 3}. Best is trial 15 with value: 0.22690394257508217.\n","[I 2025-10-11 20:16:39,088] Trial 19 finished with value: 0.223312520641473 and parameters: {'n_estimators': 1700, 'learning_rate': 0.0023885923211295545, 'num_leaves': 72, 'max_depth': 8, 'lambda_l1': 2.063578792833708e-05, 'lambda_l2': 0.00020616478717132652, 'feature_fraction': 0.6799955637458522, 'bagging_fraction': 0.916809933545661, 'bagging_freq': 3}. Best is trial 15 with value: 0.22690394257508217.\n","[I 2025-10-11 20:16:53,037] Trial 20 finished with value: 0.21807858557444654 and parameters: {'n_estimators': 1300, 'learning_rate': 0.009343448083527661, 'num_leaves': 51, 'max_depth': 3, 'lambda_l1': 2.5178852856648734e-07, 'lambda_l2': 0.006521701467687806, 'feature_fraction': 0.7607763489682535, 'bagging_fraction': 0.7674842029928013, 'bagging_freq': 4}. Best is trial 15 with value: 0.22690394257508217.\n","[I 2025-10-11 20:19:02,475] Trial 21 finished with value: 0.2223721230245415 and parameters: {'n_estimators': 1500, 'learning_rate': 0.0022676567924281286, 'num_leaves': 96, 'max_depth': 11, 'lambda_l1': 1.1020117976772446e-08, 'lambda_l2': 3.487838007091259e-05, 'feature_fraction': 0.7913110921259929, 'bagging_fraction': 0.9642489179890811, 'bagging_freq': 4}. Best is trial 15 with value: 0.22690394257508217.\n","[I 2025-10-11 20:20:13,679] Trial 22 finished with value: 0.22422517766699346 and parameters: {'n_estimators': 1300, 'learning_rate': 0.005745079784602556, 'num_leaves': 192, 'max_depth': 8, 'lambda_l1': 4.871691618040485e-07, 'lambda_l2': 0.42414331839352104, 'feature_fraction': 0.8505891573831208, 'bagging_fraction': 0.9071625750147336, 'bagging_freq': 3}. Best is trial 15 with value: 0.22690394257508217.\n","[I 2025-10-11 20:20:56,743] Trial 23 finished with value: 0.21883556570538523 and parameters: {'n_estimators': 1700, 'learning_rate': 0.002629450030445462, 'num_leaves': 22, 'max_depth': 10, 'lambda_l1': 7.858163486408153e-08, 'lambda_l2': 0.0007614883995604693, 'feature_fraction': 0.7765256259714639, 'bagging_fraction': 0.9284431482035719, 'bagging_freq': 5}. Best is trial 15 with value: 0.22690394257508217.\n","[I 2025-10-11 20:21:17,960] Trial 24 finished with value: 0.22053074350227447 and parameters: {'n_estimators': 1000, 'learning_rate': 0.020973091566987175, 'num_leaves': 134, 'max_depth': 7, 'lambda_l1': 6.69737772535223e-06, 'lambda_l2': 0.025650637198856734, 'feature_fraction': 0.7051553188729001, 'bagging_fraction': 0.9704041829122652, 'bagging_freq': 4}. Best is trial 15 with value: 0.22690394257508217.\n","[I 2025-10-11 20:22:24,611] Trial 25 finished with value: 0.22649697602277893 and parameters: {'n_estimators': 1400, 'learning_rate': 0.006533780978264494, 'num_leaves': 87, 'max_depth': 10, 'lambda_l1': 2.0167593090619033e-07, 'lambda_l2': 0.3881643349693795, 'feature_fraction': 0.8397123995262974, 'bagging_fraction': 0.9594367801648531, 'bagging_freq': 6}. Best is trial 15 with value: 0.22690394257508217.\n"]},{"output_type":"stream","name":"stdout","text":["\n","[Optuna 조기 종료] 10번의 trial 동안 최고 점수가 갱신되지 않아 튜닝을 중단합니다.\n","\n","✅ 튜닝 완료!\n","\n","==================================================\n","🔬 최적 하이퍼파라미터 (Best Hyperparameters)\n","==================================================\n","        n_estimators: 1600\n","       learning_rate: 0.0036738077327695073\n","          num_leaves: 79\n","           max_depth: 11\n","           lambda_l1: 1.0074209283711079e-08\n","           lambda_l2: 0.0011833529803131166\n","    feature_fraction: 0.9543663161446166\n","    bagging_fraction: 0.9363123245517312\n","        bagging_freq: 4\n","==================================================\n","\n","🔬 Step 5: 튜닝된 최종 모델 학습 및 평가...\n","✅ 튜닝된 모델 평가 완료.\n","\n","============================================================\n","📊 최종 성능 비교 결과 (Test Set)\n","============================================================\n","              PR AUC  ROC AUC  F1-Score\n","Baseline      0.2038   0.7835    0.0875\n","Optuna Tuned  0.2279   0.7967    0.0646\n","\n","============================================================\n","💾 Step 6: 최종 모델 예측 결과를 원본 CSV에 추가하여 저장\n","============================================================\n","✅ 모든 데이터의 예측 결과가 '/content/drive/MyDrive/review_helpfulness/PADA/results/s2/coursera/T5_coursera_with_s2_predictions.csv' 파일에 성공적으로 저장되었습니다.\n","\n","============================================================\n","🧹 Step 7: 사용된 변수들을 메모리에서 정리\n","============================================================\n","✅ 메모리 정리가 완료되었습니다.\n","\n","🎉 모든 과정이 완료되었습니다!\n"]}]},{"cell_type":"markdown","source":["## BERT"],"metadata":{"id":"U8GsgPUDurx4"}},{"cell_type":"code","source":["# === 2. 환경설정 클래스 ===\n","class Config:\n","    \"\"\"실행에 필요한 모든 설정값을 중앙에서 관리합니다.\"\"\"\n","    # 🌟 1. 입력 파일 경로 설정\n","    CSV_FILE_PATH = \"/content/drive/MyDrive/review_helpfulness/PADA/data/coursera/coursera.csv\"\n","    EMBEDDING_PATH = \"/content/drive/MyDrive/review_helpfulness/PADA/embedding/coursera_BERT.npy\"\n","\n","    # 🌟 2. 최종 결과 CSV 파일 저장 경로 설정\n","    OUTPUT_CSV_PATH = \"/content/drive/MyDrive/review_helpfulness/PADA/results/s2/coursera/BERT_coursera_with_s2_predictions.csv\"\n","\n","    # --- 데이터 정보 ---\n","    TARGET_COLUMN = 'binary_helpfulness'\n","\n","    # --- 데이터 분할 ---\n","    TEST_SPLIT_RATIO = 0.2\n","    RANDOM_STATE = 42\n","\n","    # --- Optuna 튜닝 설정 ---\n","    N_TRIALS = 50\n","    TUNING_METRIC = 'pr_auc'\n","    EARLY_STOPPING_ROUNDS = 10 # 🌟 Optuna 조기 종료 횟수\n","\n","# === 3. Optuna 조기 종료 콜백 ===\n","class EarlyStoppingCallback:\n","    \"\"\"Optuna 스터디의 조기 종료를 위한 콜백 클래스\"\"\"\n","    def __init__(self, early_stopping_rounds: int):\n","        self._early_stopping_rounds = early_stopping_rounds\n","        self._best_value = -float(\"inf\")\n","        self._counter = 0\n","\n","    def __call__(self, study: optuna.study.Study, trial: optuna.trial.Trial):\n","        current_best_value = study.best_value\n","        if current_best_value is not None and current_best_value > self._best_value:\n","            self._best_value = current_best_value\n","            self._counter = 0\n","        else:\n","            self._counter += 1\n","\n","        if self._counter >= self._early_stopping_rounds:\n","            print(f\"\\n[Optuna 조기 종료] {self._early_stopping_rounds}번의 trial 동안 최고 점수가 갱신되지 않아 튜닝을 중단합니다.\")\n","            study.stop()\n","\n","# === 4. Optuna Objective 함수 ===\n","def objective(trial, X, y):\n","    \"\"\"Optuna가 최적의 하이퍼파라미터를 찾기 위해 반복 호출하는 함수\"\"\"\n","    X_train, X_val, y_train, y_val = train_test_split(\n","        X, y, test_size=0.25, random_state=Config.RANDOM_STATE, stratify=y\n","    )\n","\n","    params = {\n","        'objective': 'binary', 'metric': 'logloss', 'verbosity': -1,\n","        'boosting_type': 'gbdt', 'random_state': Config.RANDOM_STATE,\n","        'device': 'gpu',  # 🌟 Optuna Trial 내부에서도 GPU 사용\n","        'n_estimators': trial.suggest_int('n_estimators', 100, 2000, step=100),\n","        'learning_rate': trial.suggest_float('learning_rate', 1e-3, 0.3, log=True),\n","        'num_leaves': trial.suggest_int('num_leaves', 20, 300),\n","        'max_depth': trial.suggest_int('max_depth', 3, 12),\n","        'lambda_l1': trial.suggest_float('lambda_l1', 1e-8, 10.0, log=True),\n","        'lambda_l2': trial.suggest_float('lambda_l2', 1e-8, 10.0, log=True),\n","        'feature_fraction': trial.suggest_float('feature_fraction', 0.6, 1.0),\n","        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.6, 1.0),\n","        'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\n","    }\n","\n","    model = lgb.LGBMClassifier(**params)\n","    model.fit(X_train, y_train,\n","              eval_set=[(X_val, y_val)],\n","              eval_metric='logloss',\n","              callbacks=[lgb.early_stopping(100, verbose=False)])\n","\n","    y_pred_proba = model.predict_proba(X_val)[:, 1]\n","    score = average_precision_score(y_val, y_pred_proba)\n","    return score\n","\n","# === 5. 메인 실행 블록 ===\n","if __name__ == '__main__':\n","    config = Config()\n","\n","    # ... (Step 1 ~ 2: 데이터 로드, 분할, 베이스라인 측정) ...\n","    print(\"Step 1: 데이터 로드 및 분할 중...\")\n","    try:\n","        df = pd.read_csv(config.CSV_FILE_PATH)\n","        labels = df[config.TARGET_COLUMN].values\n","        embeddings = np.load(config.EMBEDDING_PATH)\n","        assert len(df) == len(embeddings)\n","    except Exception as e:\n","        print(f\"🔥 파일 로드 실패: {e}\"); exit()\n","\n","    indices = np.arange(len(df))\n","    train_indices, test_indices = train_test_split(\n","        indices, test_size=config.TEST_SPLIT_RATIO, random_state=config.RANDOM_STATE, stratify=labels\n","    )\n","    X_train, X_test = embeddings[train_indices], embeddings[test_indices]\n","    y_train, y_test = labels[train_indices], labels[test_indices]\n","    print(f\"✅ 완료 (학습용: {len(y_train)}건, 테스트용: {len(y_test)}건)\")\n","\n","    print(\"\\n\" + \"=\"*50)\n","    print(\"📊 Step 2: 베이스라인 모델 성능 측정 (GPU 사용)\")\n","    print(\"=\"*50)\n","\n","    baseline_model = lgb.LGBMClassifier(device='gpu', random_state=config.RANDOM_STATE)\n","    baseline_model.fit(X_train, y_train)\n","\n","    y_pred_proba_base = baseline_model.predict_proba(X_test)[:, 1]\n","    y_pred_class_base = (y_pred_proba_base > 0.5).astype(int)\n","\n","    final_results = {}\n","    final_results['Baseline'] = {\n","        \"PR AUC\": average_precision_score(y_test, y_pred_proba_base),\n","        \"ROC AUC\": roc_auc_score(y_test, y_pred_proba_base),\n","        \"F1-Score\": f1_score(y_test, y_pred_class_base),\n","    }\n","    print(\"✅ 베이스라인 모델 평가 완료.\")\n","\n","    # --- Step 3: Optuna 튜닝 수행 (조기 종료 포함) ---\n","    print(\"\\n\" + \"=\"*50)\n","    print(f\"🔬 Step 3: Optuna 하이퍼파라미터 튜닝 시작 (GPU 사용)...\")\n","    print(f\"(최대 {config.N_TRIALS}번 시도, {config.EARLY_STOPPING_ROUNDS}번 개선 없으면 조기 종료)\")\n","    print(\"=\"*50)\n","\n","    early_stopping_callback = EarlyStoppingCallback(early_stopping_rounds=config.EARLY_STOPPING_ROUNDS)\n","    study = optuna.create_study(direction='maximize')\n","    pbar = tqdm(total=config.N_TRIALS, desc=\"Optuna 튜닝 진행률\")\n","\n","    try:\n","        study.optimize(lambda trial: objective(trial, X_train, y_train),\n","                       n_trials=config.N_TRIALS,\n","                       callbacks=[lambda study, trial: pbar.update(1), early_stopping_callback])\n","    except optuna.exceptions.OptunaError:\n","        # 조기 종료 시 발생하는 예외를 정상 처리\n","        pass\n","    pbar.close()\n","\n","    # ... (Step 4 ~ 6: 결과 출력, 저장, 메모리 정리) ...\n","    print(f\"\\n✅ 튜닝 완료!\")\n","    print(\"\\n\" + \"=\"*50)\n","    print(\"🔬 최적 하이퍼파라미터 (Best Hyperparameters)\")\n","    print(\"=\"*50)\n","    best_params = study.best_params\n","    for key, value in best_params.items():\n","        print(f\"{key:>20s}: {value}\")\n","    print(\"=\"*50)\n","\n","    print(f\"\\n🔬 Step 5: 튜닝된 최종 모델 학습 및 평가...\")\n","    final_model = lgb.LGBMClassifier(device='gpu', objective='binary', verbosity=-1, random_state=config.RANDOM_STATE, **best_params)\n","    final_model.fit(X_train, y_train)\n","\n","    y_pred_proba_tuned = final_model.predict_proba(X_test)[:, 1]\n","    y_pred_class_tuned = (y_pred_proba_tuned > 0.5).astype(int)\n","\n","    final_results['Optuna Tuned'] = {\n","        \"PR AUC\": average_precision_score(y_test, y_pred_proba_tuned),\n","        \"ROC AUC\": roc_auc_score(y_test, y_pred_proba_tuned),\n","        \"F1-Score\": f1_score(y_test, y_pred_class_tuned),\n","    }\n","    print(\"✅ 튜닝된 모델 평가 완료.\")\n","\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"📊 최종 성능 비교 결과 (Test Set)\")\n","    print(\"=\"*60)\n","    results_df = pd.DataFrame(final_results).T\n","    print(results_df.round(4))\n","\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"💾 Step 6: 최종 모델 예측 결과를 원본 CSV에 추가하여 저장\")\n","    print(\"=\"*60)\n","\n","    train_pred_proba = final_model.predict_proba(X_train)[:, 1]\n","    train_pred_class = (train_pred_proba > 0.5).astype(int)\n","\n","    df['s2_pred_proba'] = np.nan\n","    df['s2_pred_class'] = np.nan\n","\n","    df.loc[train_indices, 's2_pred_proba'] = train_pred_proba\n","    df.loc[train_indices, 's2_pred_class'] = train_pred_class\n","\n","    df.loc[test_indices, 's2_pred_proba'] = y_pred_proba_tuned\n","    df.loc[test_indices, 's2_pred_class'] = y_pred_class_tuned\n","\n","    # 🌟 Config에 설정된 경로로 최종 파일 저장\n","    df.to_csv(config.OUTPUT_CSV_PATH, index=False, encoding='utf-8-sig')\n","\n","    print(f\"✅ 모든 데이터의 예측 결과가 '{config.OUTPUT_CSV_PATH}' 파일에 성공적으로 저장되었습니다.\")\n","\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"🧹 Step 7: 사용된 변수들을 메모리에서 정리\")\n","    print(\"=\"*60)\n","\n","    vars_to_delete = [\n","        'df', 'labels', 'embeddings', 'indices', 'X_train', 'X_test',\n","        'y_train', 'y_test', 'train_indices', 'test_indices',\n","        'baseline_model', 'final_model', 'study',\n","    ]\n","    for var_name in vars_to_delete:\n","        if var_name in locals() or var_name in globals():\n","            if var_name in globals(): del globals()[var_name]\n","\n","    gc.collect()\n","    print(\"✅ 메모리 정리가 완료되었습니다.\")\n","\n","    print(\"\\n🎉 모든 과정이 완료되었습니다!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","referenced_widgets":["b49512423c8a4524b610955db9535789","3864b54203314c51986223fcc8f0639d","79821e31432f4e86a323a1fe36eb9f01","255fc2e1084840d09b6d804f9565ba37","27a50ad15c4d493880da662df2fb4747","bcb0610e71a140328d436c0cc2c8cdc8","ed9b011d92f7435c9f2c565f46e94eb6","aef78176740c4899ac2f4ed786fd77f5","08c09b0411df432eb283b003b439e0d7","0ca44d1f8a714eb8be3edff5636c3a4f","631dd166b414446abef56e2342b712c2"]},"id":"ryTYns4owBDe","executionInfo":{"status":"ok","timestamp":1760215020405,"user_tz":-540,"elapsed":734285,"user":{"displayName":"KW-data-analytics","userId":"09651493752354345908"}},"outputId":"7f69adfe-40a7-4e01-8672-145f4ac3772f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Step 1: 데이터 로드 및 분할 중...\n","✅ 완료 (학습용: 97108건, 테스트용: 24278건)\n","\n","==================================================\n","📊 Step 2: 베이스라인 모델 성능 측정 (GPU 사용)\n","==================================================\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-10-11 20:25:02,209] A new study created in memory with name: no-name-ef9c70cd-a5b8-4cc9-bd31-ae9454733e92\n"]},{"output_type":"stream","name":"stdout","text":["✅ 베이스라인 모델 평가 완료.\n","\n","==================================================\n","🔬 Step 3: Optuna 하이퍼파라미터 튜닝 시작 (GPU 사용)...\n","(최대 50번 시도, 10번 개선 없으면 조기 종료)\n","==================================================\n"]},{"output_type":"display_data","data":{"text/plain":["Optuna 튜닝 진행률:   0%|          | 0/50 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b49512423c8a4524b610955db9535789"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2025-10-11 20:25:15,995] Trial 0 finished with value: 0.1961827588130428 and parameters: {'n_estimators': 1100, 'learning_rate': 0.0048882465744390455, 'num_leaves': 120, 'max_depth': 3, 'lambda_l1': 0.2566080454504444, 'lambda_l2': 7.820734317823883e-07, 'feature_fraction': 0.8208990572375937, 'bagging_fraction': 0.8626004829490532, 'bagging_freq': 6}. Best is trial 0 with value: 0.1961827588130428.\n","[I 2025-10-11 20:25:34,835] Trial 1 finished with value: 0.19621297572660756 and parameters: {'n_estimators': 1200, 'learning_rate': 0.0034201821519429768, 'num_leaves': 133, 'max_depth': 4, 'lambda_l1': 4.966310551658748, 'lambda_l2': 8.374952468781421, 'feature_fraction': 0.7198332737984545, 'bagging_fraction': 0.6135450296561967, 'bagging_freq': 2}. Best is trial 1 with value: 0.19621297572660756.\n","[I 2025-10-11 20:25:44,492] Trial 2 finished with value: 0.14374891780567803 and parameters: {'n_estimators': 1400, 'learning_rate': 0.23457442196838957, 'num_leaves': 34, 'max_depth': 9, 'lambda_l1': 0.7113898139052276, 'lambda_l2': 3.2637833875735992e-06, 'feature_fraction': 0.8114065844857401, 'bagging_fraction': 0.6291542109300526, 'bagging_freq': 2}. Best is trial 1 with value: 0.19621297572660756.\n","[I 2025-10-11 20:26:01,331] Trial 3 finished with value: 0.17920252161110448 and parameters: {'n_estimators': 1500, 'learning_rate': 0.07972576714264636, 'num_leaves': 110, 'max_depth': 8, 'lambda_l1': 0.3294092372260025, 'lambda_l2': 0.0002675861605834232, 'feature_fraction': 0.8923496548515844, 'bagging_fraction': 0.915610815772144, 'bagging_freq': 4}. Best is trial 1 with value: 0.19621297572660756.\n","[I 2025-10-11 20:26:28,856] Trial 4 finished with value: 0.1989795219225206 and parameters: {'n_estimators': 1200, 'learning_rate': 0.004345868127485626, 'num_leaves': 257, 'max_depth': 5, 'lambda_l1': 0.0016316965904292838, 'lambda_l2': 1.2863973183642232e-08, 'feature_fraction': 0.6933960027318831, 'bagging_fraction': 0.8142101738620756, 'bagging_freq': 4}. Best is trial 4 with value: 0.1989795219225206.\n","[I 2025-10-11 20:27:14,302] Trial 5 finished with value: 0.20925148372165456 and parameters: {'n_estimators': 500, 'learning_rate': 0.011918054443761877, 'num_leaves': 113, 'max_depth': 10, 'lambda_l1': 0.0007441469827980438, 'lambda_l2': 4.252650394325436, 'feature_fraction': 0.6225137409030421, 'bagging_fraction': 0.7551596115189563, 'bagging_freq': 3}. Best is trial 5 with value: 0.20925148372165456.\n","[I 2025-10-11 20:27:37,502] Trial 6 finished with value: 0.19115834833817577 and parameters: {'n_estimators': 1100, 'learning_rate': 0.0301801746679467, 'num_leaves': 223, 'max_depth': 8, 'lambda_l1': 4.753514469262439e-07, 'lambda_l2': 1.805449779928728e-08, 'feature_fraction': 0.7154980023575012, 'bagging_fraction': 0.9578794638255357, 'bagging_freq': 6}. Best is trial 5 with value: 0.20925148372165456.\n","[I 2025-10-11 20:28:01,807] Trial 7 finished with value: 0.20332759674128265 and parameters: {'n_estimators': 900, 'learning_rate': 0.015753904127211775, 'num_leaves': 86, 'max_depth': 6, 'lambda_l1': 4.177979879170165e-07, 'lambda_l2': 7.519936161000146, 'feature_fraction': 0.9309452275456156, 'bagging_fraction': 0.6077180696855823, 'bagging_freq': 3}. Best is trial 5 with value: 0.20925148372165456.\n","[I 2025-10-11 20:31:49,550] Trial 8 finished with value: 0.2022963989762135 and parameters: {'n_estimators': 1700, 'learning_rate': 0.0017163986521072656, 'num_leaves': 204, 'max_depth': 12, 'lambda_l1': 7.154125044532523e-07, 'lambda_l2': 0.00021700274915939635, 'feature_fraction': 0.7659401576570125, 'bagging_fraction': 0.8033820997710823, 'bagging_freq': 6}. Best is trial 5 with value: 0.20925148372165456.\n","[I 2025-10-11 20:32:16,032] Trial 9 finished with value: 0.20009883672284678 and parameters: {'n_estimators': 1200, 'learning_rate': 0.008185127187524913, 'num_leaves': 139, 'max_depth': 5, 'lambda_l1': 1.2621850529938986e-08, 'lambda_l2': 4.851376823525711e-07, 'feature_fraction': 0.866902257526831, 'bagging_fraction': 0.817569191667519, 'bagging_freq': 7}. Best is trial 5 with value: 0.20925148372165456.\n","[I 2025-10-11 20:32:24,650] Trial 10 finished with value: 0.1780281458449099 and parameters: {'n_estimators': 100, 'learning_rate': 0.046684845258586384, 'num_leaves': 36, 'max_depth': 12, 'lambda_l1': 0.0004909992728921574, 'lambda_l2': 0.020690795943176948, 'feature_fraction': 0.611914276335048, 'bagging_fraction': 0.7120247213891844, 'bagging_freq': 1}. Best is trial 5 with value: 0.20925148372165456.\n","[I 2025-10-11 20:33:00,705] Trial 11 finished with value: 0.20189252994593287 and parameters: {'n_estimators': 400, 'learning_rate': 0.015184617627571796, 'num_leaves': 73, 'max_depth': 10, 'lambda_l1': 4.762342880398684e-06, 'lambda_l2': 6.079577002636482, 'feature_fraction': 0.9839073030584765, 'bagging_fraction': 0.7103482896316703, 'bagging_freq': 4}. Best is trial 5 with value: 0.20925148372165456.\n","[I 2025-10-11 20:33:25,951] Trial 12 finished with value: 0.19795742732414395 and parameters: {'n_estimators': 700, 'learning_rate': 0.015588113070930696, 'num_leaves': 81, 'max_depth': 6, 'lambda_l1': 3.454534150622596e-05, 'lambda_l2': 0.18315797506811474, 'feature_fraction': 0.9903943856657899, 'bagging_fraction': 0.7088773789251536, 'bagging_freq': 3}. Best is trial 5 with value: 0.20925148372165456.\n","[I 2025-10-11 20:35:05,564] Trial 13 finished with value: 0.19498718391477654 and parameters: {'n_estimators': 700, 'learning_rate': 0.001090408597504531, 'num_leaves': 174, 'max_depth': 10, 'lambda_l1': 0.005885038798285033, 'lambda_l2': 0.0966392962152352, 'feature_fraction': 0.9141287931969921, 'bagging_fraction': 0.7349618094949105, 'bagging_freq': 3}. Best is trial 5 with value: 0.20925148372165456.\n","[I 2025-10-11 20:35:18,406] Trial 14 finished with value: 0.17759475488937837 and parameters: {'n_estimators': 700, 'learning_rate': 0.08229289965254202, 'num_leaves': 93, 'max_depth': 7, 'lambda_l1': 1.1584224023330219e-08, 'lambda_l2': 0.4604856502533067, 'feature_fraction': 0.6022225715169169, 'bagging_fraction': 0.6581085688473131, 'bagging_freq': 2}. Best is trial 5 with value: 0.20925148372165456.\n","[I 2025-10-11 20:36:06,848] Trial 15 finished with value: 0.20104109567104422 and parameters: {'n_estimators': 400, 'learning_rate': 0.00967959127941406, 'num_leaves': 172, 'max_depth': 10, 'lambda_l1': 0.012642861022540747, 'lambda_l2': 0.004901202657041507, 'feature_fraction': 0.6616058931725537, 'bagging_fraction': 0.7602431177234523, 'bagging_freq': 3}. Best is trial 5 with value: 0.20925148372165456.\n"]},{"output_type":"stream","name":"stdout","text":["\n","[Optuna 조기 종료] 10번의 trial 동안 최고 점수가 갱신되지 않아 튜닝을 중단합니다.\n","\n","✅ 튜닝 완료!\n","\n","==================================================\n","🔬 최적 하이퍼파라미터 (Best Hyperparameters)\n","==================================================\n","        n_estimators: 500\n","       learning_rate: 0.011918054443761877\n","          num_leaves: 113\n","           max_depth: 10\n","           lambda_l1: 0.0007441469827980438\n","           lambda_l2: 4.252650394325436\n","    feature_fraction: 0.6225137409030421\n","    bagging_fraction: 0.7551596115189563\n","        bagging_freq: 3\n","==================================================\n","\n","🔬 Step 5: 튜닝된 최종 모델 학습 및 평가...\n","✅ 튜닝된 모델 평가 완료.\n","\n","============================================================\n","📊 최종 성능 비교 결과 (Test Set)\n","============================================================\n","              PR AUC  ROC AUC  F1-Score\n","Baseline      0.1819   0.7689    0.0893\n","Optuna Tuned  0.2140   0.7886    0.0647\n","\n","============================================================\n","💾 Step 6: 최종 모델 예측 결과를 원본 CSV에 추가하여 저장\n","============================================================\n","✅ 모든 데이터의 예측 결과가 '/content/drive/MyDrive/review_helpfulness/PADA/results/s2/coursera/BERT_coursera_with_s2_predictions.csv' 파일에 성공적으로 저장되었습니다.\n","\n","============================================================\n","🧹 Step 7: 사용된 변수들을 메모리에서 정리\n","============================================================\n","✅ 메모리 정리가 완료되었습니다.\n","\n","🎉 모든 과정이 완료되었습니다!\n"]}]},{"cell_type":"markdown","source":["## SentenceBERT"],"metadata":{"id":"03RxKjLEusWc"}},{"cell_type":"code","source":["# === 2. 환경설정 클래스 ===\n","class Config:\n","    \"\"\"실행에 필요한 모든 설정값을 중앙에서 관리합니다.\"\"\"\n","    # 🌟 1. 입력 파일 경로 설정\n","    CSV_FILE_PATH = \"/content/drive/MyDrive/review_helpfulness/PADA/data/coursera/coursera.csv\"\n","    EMBEDDING_PATH = \"/content/drive/MyDrive/review_helpfulness/PADA/embedding/coursera_SentenceBERT.npy\"\n","\n","    # 🌟 2. 최종 결과 CSV 파일 저장 경로 설정\n","    OUTPUT_CSV_PATH = \"/content/drive/MyDrive/review_helpfulness/PADA/results/s2/coursera/SentenceBERT_coursera_with_s2_predictions.csv\"\n","\n","    # --- 데이터 정보 ---\n","    TARGET_COLUMN = 'binary_helpfulness'\n","\n","    # --- 데이터 분할 ---\n","    TEST_SPLIT_RATIO = 0.2\n","    RANDOM_STATE = 42\n","\n","    # --- Optuna 튜닝 설정 ---\n","    N_TRIALS = 50\n","    TUNING_METRIC = 'pr_auc'\n","    EARLY_STOPPING_ROUNDS = 10 # 🌟 Optuna 조기 종료 횟수\n","\n","# === 3. Optuna 조기 종료 콜백 ===\n","class EarlyStoppingCallback:\n","    \"\"\"Optuna 스터디의 조기 종료를 위한 콜백 클래스\"\"\"\n","    def __init__(self, early_stopping_rounds: int):\n","        self._early_stopping_rounds = early_stopping_rounds\n","        self._best_value = -float(\"inf\")\n","        self._counter = 0\n","\n","    def __call__(self, study: optuna.study.Study, trial: optuna.trial.Trial):\n","        current_best_value = study.best_value\n","        if current_best_value is not None and current_best_value > self._best_value:\n","            self._best_value = current_best_value\n","            self._counter = 0\n","        else:\n","            self._counter += 1\n","\n","        if self._counter >= self._early_stopping_rounds:\n","            print(f\"\\n[Optuna 조기 종료] {self._early_stopping_rounds}번의 trial 동안 최고 점수가 갱신되지 않아 튜닝을 중단합니다.\")\n","            study.stop()\n","\n","# === 4. Optuna Objective 함수 ===\n","def objective(trial, X, y):\n","    \"\"\"Optuna가 최적의 하이퍼파라미터를 찾기 위해 반복 호출하는 함수\"\"\"\n","    X_train, X_val, y_train, y_val = train_test_split(\n","        X, y, test_size=0.25, random_state=Config.RANDOM_STATE, stratify=y\n","    )\n","\n","    params = {\n","        'objective': 'binary', 'metric': 'logloss', 'verbosity': -1,\n","        'boosting_type': 'gbdt', 'random_state': Config.RANDOM_STATE,\n","        'device': 'gpu',  # 🌟 Optuna Trial 내부에서도 GPU 사용\n","        'n_estimators': trial.suggest_int('n_estimators', 100, 2000, step=100),\n","        'learning_rate': trial.suggest_float('learning_rate', 1e-3, 0.3, log=True),\n","        'num_leaves': trial.suggest_int('num_leaves', 20, 300),\n","        'max_depth': trial.suggest_int('max_depth', 3, 12),\n","        'lambda_l1': trial.suggest_float('lambda_l1', 1e-8, 10.0, log=True),\n","        'lambda_l2': trial.suggest_float('lambda_l2', 1e-8, 10.0, log=True),\n","        'feature_fraction': trial.suggest_float('feature_fraction', 0.6, 1.0),\n","        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.6, 1.0),\n","        'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\n","    }\n","\n","    model = lgb.LGBMClassifier(**params)\n","    model.fit(X_train, y_train,\n","              eval_set=[(X_val, y_val)],\n","              eval_metric='logloss',\n","              callbacks=[lgb.early_stopping(100, verbose=False)])\n","\n","    y_pred_proba = model.predict_proba(X_val)[:, 1]\n","    score = average_precision_score(y_val, y_pred_proba)\n","    return score\n","\n","# === 5. 메인 실행 블록 ===\n","if __name__ == '__main__':\n","    config = Config()\n","\n","    # ... (Step 1 ~ 2: 데이터 로드, 분할, 베이스라인 측정) ...\n","    print(\"Step 1: 데이터 로드 및 분할 중...\")\n","    try:\n","        df = pd.read_csv(config.CSV_FILE_PATH)\n","        labels = df[config.TARGET_COLUMN].values\n","        embeddings = np.load(config.EMBEDDING_PATH)\n","        assert len(df) == len(embeddings)\n","    except Exception as e:\n","        print(f\"🔥 파일 로드 실패: {e}\"); exit()\n","\n","    indices = np.arange(len(df))\n","    train_indices, test_indices = train_test_split(\n","        indices, test_size=config.TEST_SPLIT_RATIO, random_state=config.RANDOM_STATE, stratify=labels\n","    )\n","    X_train, X_test = embeddings[train_indices], embeddings[test_indices]\n","    y_train, y_test = labels[train_indices], labels[test_indices]\n","    print(f\"✅ 완료 (학습용: {len(y_train)}건, 테스트용: {len(y_test)}건)\")\n","\n","    print(\"\\n\" + \"=\"*50)\n","    print(\"📊 Step 2: 베이스라인 모델 성능 측정 (GPU 사용)\")\n","    print(\"=\"*50)\n","\n","    baseline_model = lgb.LGBMClassifier(device='gpu', random_state=config.RANDOM_STATE)\n","    baseline_model.fit(X_train, y_train)\n","\n","    y_pred_proba_base = baseline_model.predict_proba(X_test)[:, 1]\n","    y_pred_class_base = (y_pred_proba_base > 0.5).astype(int)\n","\n","    final_results = {}\n","    final_results['Baseline'] = {\n","        \"PR AUC\": average_precision_score(y_test, y_pred_proba_base),\n","        \"ROC AUC\": roc_auc_score(y_test, y_pred_proba_base),\n","        \"F1-Score\": f1_score(y_test, y_pred_class_base),\n","    }\n","    print(\"✅ 베이스라인 모델 평가 완료.\")\n","\n","    # --- Step 3: Optuna 튜닝 수행 (조기 종료 포함) ---\n","    print(\"\\n\" + \"=\"*50)\n","    print(f\"🔬 Step 3: Optuna 하이퍼파라미터 튜닝 시작 (GPU 사용)...\")\n","    print(f\"(최대 {config.N_TRIALS}번 시도, {config.EARLY_STOPPING_ROUNDS}번 개선 없으면 조기 종료)\")\n","    print(\"=\"*50)\n","\n","    early_stopping_callback = EarlyStoppingCallback(early_stopping_rounds=config.EARLY_STOPPING_ROUNDS)\n","    study = optuna.create_study(direction='maximize')\n","    pbar = tqdm(total=config.N_TRIALS, desc=\"Optuna 튜닝 진행률\")\n","\n","    try:\n","        study.optimize(lambda trial: objective(trial, X_train, y_train),\n","                       n_trials=config.N_TRIALS,\n","                       callbacks=[lambda study, trial: pbar.update(1), early_stopping_callback])\n","    except optuna.exceptions.OptunaError:\n","        # 조기 종료 시 발생하는 예외를 정상 처리\n","        pass\n","    pbar.close()\n","\n","    # ... (Step 4 ~ 6: 결과 출력, 저장, 메모리 정리) ...\n","    print(f\"\\n✅ 튜닝 완료!\")\n","    print(\"\\n\" + \"=\"*50)\n","    print(\"🔬 최적 하이퍼파라미터 (Best Hyperparameters)\")\n","    print(\"=\"*50)\n","    best_params = study.best_params\n","    for key, value in best_params.items():\n","        print(f\"{key:>20s}: {value}\")\n","    print(\"=\"*50)\n","\n","    print(f\"\\n🔬 Step 5: 튜닝된 최종 모델 학습 및 평가...\")\n","    final_model = lgb.LGBMClassifier(device='gpu', objective='binary', verbosity=-1, random_state=config.RANDOM_STATE, **best_params)\n","    final_model.fit(X_train, y_train)\n","\n","    y_pred_proba_tuned = final_model.predict_proba(X_test)[:, 1]\n","    y_pred_class_tuned = (y_pred_proba_tuned > 0.5).astype(int)\n","\n","    final_results['Optuna Tuned'] = {\n","        \"PR AUC\": average_precision_score(y_test, y_pred_proba_tuned),\n","        \"ROC AUC\": roc_auc_score(y_test, y_pred_proba_tuned),\n","        \"F1-Score\": f1_score(y_test, y_pred_class_tuned),\n","    }\n","    print(\"✅ 튜닝된 모델 평가 완료.\")\n","\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"📊 최종 성능 비교 결과 (Test Set)\")\n","    print(\"=\"*60)\n","    results_df = pd.DataFrame(final_results).T\n","    print(results_df.round(4))\n","\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"💾 Step 6: 최종 모델 예측 결과를 원본 CSV에 추가하여 저장\")\n","    print(\"=\"*60)\n","\n","    train_pred_proba = final_model.predict_proba(X_train)[:, 1]\n","    train_pred_class = (train_pred_proba > 0.5).astype(int)\n","\n","    df['s2_pred_proba'] = np.nan\n","    df['s2_pred_class'] = np.nan\n","\n","    df.loc[train_indices, 's2_pred_proba'] = train_pred_proba\n","    df.loc[train_indices, 's2_pred_class'] = train_pred_class\n","\n","    df.loc[test_indices, 's2_pred_proba'] = y_pred_proba_tuned\n","    df.loc[test_indices, 's2_pred_class'] = y_pred_class_tuned\n","\n","    # 🌟 Config에 설정된 경로로 최종 파일 저장\n","    df.to_csv(config.OUTPUT_CSV_PATH, index=False, encoding='utf-8-sig')\n","\n","    print(f\"✅ 모든 데이터의 예측 결과가 '{config.OUTPUT_CSV_PATH}' 파일에 성공적으로 저장되었습니다.\")\n","\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"🧹 Step 7: 사용된 변수들을 메모리에서 정리\")\n","    print(\"=\"*60)\n","\n","    vars_to_delete = [\n","        'df', 'labels', 'embeddings', 'indices', 'X_train', 'X_test',\n","        'y_train', 'y_test', 'train_indices', 'test_indices',\n","        'baseline_model', 'final_model', 'study',\n","    ]\n","    for var_name in vars_to_delete:\n","        if var_name in locals() or var_name in globals():\n","            if var_name in globals(): del globals()[var_name]\n","\n","    gc.collect()\n","    print(\"✅ 메모리 정리가 완료되었습니다.\")\n","\n","    print(\"\\n🎉 모든 과정이 완료되었습니다!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","referenced_widgets":["76023f06b3004399a2189b351959b427","3af8e5ba049a4ba5b75c018295867f05","fb406027a268485ba6234e26b25c8c35","220b4847fd0d4e4693a6dc22a858439d","c274c6a261a14defaffd431cfc7345b8","3364d3f8b6d54503ab6efb4054d3d4d1","1dd48e13b4a24cefb2dbc221f0dd31b0","507567a0ba2c42f0b1c40e7a4c4a85a2","07999052b7e74e1c9ef381b242de0ca0","83027739c00f4a0895fe1ea9b89ff695","a51c9bb214da40d39ac425ba26c69993"]},"id":"1JQS2y4cwHxM","executionInfo":{"status":"ok","timestamp":1760215529869,"user_tz":-540,"elapsed":509437,"user":{"displayName":"KW-data-analytics","userId":"09651493752354345908"}},"outputId":"43557ab6-00f5-4af7-8f9d-70639e2d5c6d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Step 1: 데이터 로드 및 분할 중...\n","✅ 완료 (학습용: 97108건, 테스트용: 24278건)\n","\n","==================================================\n","📊 Step 2: 베이스라인 모델 성능 측정 (GPU 사용)\n","==================================================\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-10-11 20:37:14,777] A new study created in memory with name: no-name-f274ba56-50f1-47c0-8e1a-cd366b8dc6b3\n"]},{"output_type":"stream","name":"stdout","text":["✅ 베이스라인 모델 평가 완료.\n","\n","==================================================\n","🔬 Step 3: Optuna 하이퍼파라미터 튜닝 시작 (GPU 사용)...\n","(최대 50번 시도, 10번 개선 없으면 조기 종료)\n","==================================================\n"]},{"output_type":"display_data","data":{"text/plain":["Optuna 튜닝 진행률:   0%|          | 0/50 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"76023f06b3004399a2189b351959b427"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2025-10-11 20:37:44,011] Trial 0 finished with value: 0.20022188125795112 and parameters: {'n_estimators': 1300, 'learning_rate': 0.002276460191144249, 'num_leaves': 249, 'max_depth': 6, 'lambda_l1': 7.941848998960709e-08, 'lambda_l2': 1.0250116917434139e-05, 'feature_fraction': 0.7708413003197726, 'bagging_fraction': 0.826954036942413, 'bagging_freq': 7}. Best is trial 0 with value: 0.20022188125795112.\n","[I 2025-10-11 20:38:11,653] Trial 1 finished with value: 0.1976726415702342 and parameters: {'n_estimators': 1400, 'learning_rate': 0.016343904041966062, 'num_leaves': 196, 'max_depth': 12, 'lambda_l1': 0.00023624182131236414, 'lambda_l2': 0.0014459001102957738, 'feature_fraction': 0.8471742731822693, 'bagging_fraction': 0.8984822288045906, 'bagging_freq': 2}. Best is trial 0 with value: 0.20022188125795112.\n","[I 2025-10-11 20:38:28,994] Trial 2 finished with value: 0.18586545548066655 and parameters: {'n_estimators': 1800, 'learning_rate': 0.001404353208653213, 'num_leaves': 197, 'max_depth': 4, 'lambda_l1': 0.11984726545874616, 'lambda_l2': 1.3470872942820635, 'feature_fraction': 0.8973257899418154, 'bagging_fraction': 0.9899624123438115, 'bagging_freq': 6}. Best is trial 0 with value: 0.20022188125795112.\n","[I 2025-10-11 20:38:39,081] Trial 3 finished with value: 0.16898050479265173 and parameters: {'n_estimators': 1600, 'learning_rate': 0.09600157479690505, 'num_leaves': 267, 'max_depth': 8, 'lambda_l1': 4.765835096843445e-05, 'lambda_l2': 9.597999737518217e-07, 'feature_fraction': 0.9444564692708827, 'bagging_fraction': 0.964954646417818, 'bagging_freq': 7}. Best is trial 0 with value: 0.20022188125795112.\n","[I 2025-10-11 20:38:55,660] Trial 4 finished with value: 0.20225235254865115 and parameters: {'n_estimators': 1200, 'learning_rate': 0.009412968135517525, 'num_leaves': 20, 'max_depth': 11, 'lambda_l1': 0.05003455692427976, 'lambda_l2': 8.666552101858038e-06, 'feature_fraction': 0.6580130570052699, 'bagging_fraction': 0.8807178452713362, 'bagging_freq': 3}. Best is trial 4 with value: 0.20225235254865115.\n","[I 2025-10-11 20:38:59,715] Trial 5 finished with value: 0.17650561446906382 and parameters: {'n_estimators': 500, 'learning_rate': 0.17830515513886389, 'num_leaves': 27, 'max_depth': 3, 'lambda_l1': 1.6252441951219893e-08, 'lambda_l2': 0.0003138046449689182, 'feature_fraction': 0.7670560000118111, 'bagging_fraction': 0.7799053723541169, 'bagging_freq': 1}. Best is trial 4 with value: 0.20225235254865115.\n","[I 2025-10-11 20:39:06,829] Trial 6 finished with value: 0.19034019293275253 and parameters: {'n_estimators': 500, 'learning_rate': 0.003956349715811577, 'num_leaves': 140, 'max_depth': 4, 'lambda_l1': 0.6441563351214461, 'lambda_l2': 1.3700788626060635e-08, 'feature_fraction': 0.7451430401034205, 'bagging_fraction': 0.7798726153572294, 'bagging_freq': 3}. Best is trial 4 with value: 0.20225235254865115.\n","[I 2025-10-11 20:39:10,887] Trial 7 finished with value: 0.1904033352593964 and parameters: {'n_estimators': 100, 'learning_rate': 0.12117342709537875, 'num_leaves': 44, 'max_depth': 4, 'lambda_l1': 0.000513338900303083, 'lambda_l2': 4.868815314857273, 'feature_fraction': 0.6528465824708902, 'bagging_fraction': 0.9332160303139866, 'bagging_freq': 3}. Best is trial 4 with value: 0.20225235254865115.\n","[I 2025-10-11 20:40:43,566] Trial 8 finished with value: 0.2014954259307727 and parameters: {'n_estimators': 1100, 'learning_rate': 0.0018258063138784533, 'num_leaves': 277, 'max_depth': 9, 'lambda_l1': 5.405711538039602e-07, 'lambda_l2': 1.2243568677022046e-08, 'feature_fraction': 0.9223445986942536, 'bagging_fraction': 0.751256422205356, 'bagging_freq': 6}. Best is trial 4 with value: 0.20225235254865115.\n","[I 2025-10-11 20:41:12,459] Trial 9 finished with value: 0.20848146382099428 and parameters: {'n_estimators': 2000, 'learning_rate': 0.00411758295662484, 'num_leaves': 137, 'max_depth': 5, 'lambda_l1': 0.0002660818959315374, 'lambda_l2': 1.2115732946146658, 'feature_fraction': 0.9300570317392396, 'bagging_fraction': 0.6379945563339555, 'bagging_freq': 4}. Best is trial 9 with value: 0.20848146382099428.\n","[I 2025-10-11 20:41:20,411] Trial 10 finished with value: 0.189936951348042 and parameters: {'n_estimators': 2000, 'learning_rate': 0.04550947333135702, 'num_leaves': 105, 'max_depth': 6, 'lambda_l1': 7.5437460498136556e-06, 'lambda_l2': 0.08568767547713543, 'feature_fraction': 0.9907883681082564, 'bagging_fraction': 0.6291356706356559, 'bagging_freq': 5}. Best is trial 9 with value: 0.20848146382099428.\n","[I 2025-10-11 20:41:45,613] Trial 11 finished with value: 0.20414770857621145 and parameters: {'n_estimators': 900, 'learning_rate': 0.008935125712975101, 'num_leaves': 85, 'max_depth': 12, 'lambda_l1': 0.011234296948081434, 'lambda_l2': 0.0037207389593317984, 'feature_fraction': 0.6322123990441902, 'bagging_fraction': 0.6065673399976966, 'bagging_freq': 4}. Best is trial 9 with value: 0.20848146382099428.\n","[I 2025-10-11 20:42:16,591] Trial 12 finished with value: 0.2079814376071435 and parameters: {'n_estimators': 700, 'learning_rate': 0.006200063140432887, 'num_leaves': 96, 'max_depth': 10, 'lambda_l1': 0.004984004086559135, 'lambda_l2': 0.0606433469832595, 'feature_fraction': 0.6103507721265004, 'bagging_fraction': 0.6139803409769243, 'bagging_freq': 4}. Best is trial 9 with value: 0.20848146382099428.\n","[I 2025-10-11 20:42:33,565] Trial 13 finished with value: 0.2035440209762517 and parameters: {'n_estimators': 700, 'learning_rate': 0.0044476094833510735, 'num_leaves': 131, 'max_depth': 6, 'lambda_l1': 0.0024392626332723345, 'lambda_l2': 0.09333839058663473, 'feature_fraction': 0.7081290182689792, 'bagging_fraction': 0.6728789988744469, 'bagging_freq': 4}. Best is trial 9 with value: 0.20848146382099428.\n","[I 2025-10-11 20:42:44,304] Trial 14 finished with value: 0.19578958712090694 and parameters: {'n_estimators': 200, 'learning_rate': 0.040534822524342554, 'num_leaves': 77, 'max_depth': 10, 'lambda_l1': 1.9261942724058543, 'lambda_l2': 0.1143685604051871, 'feature_fraction': 0.8366041323144502, 'bagging_fraction': 0.6980474976303176, 'bagging_freq': 5}. Best is trial 9 with value: 0.20848146382099428.\n","[I 2025-10-11 20:43:25,641] Trial 15 finished with value: 0.20532080099816155 and parameters: {'n_estimators': 800, 'learning_rate': 0.005591166124128078, 'num_leaves': 180, 'max_depth': 8, 'lambda_l1': 6.9977744783767206e-06, 'lambda_l2': 0.86050752530004, 'feature_fraction': 0.8473430055418958, 'bagging_fraction': 0.6860375503030159, 'bagging_freq': 5}. Best is trial 9 with value: 0.20848146382099428.\n","[I 2025-10-11 20:43:42,287] Trial 16 finished with value: 0.20449579163203585 and parameters: {'n_estimators': 1600, 'learning_rate': 0.022806658216899815, 'num_leaves': 147, 'max_depth': 10, 'lambda_l1': 0.007756739737418122, 'lambda_l2': 0.0057095631821598705, 'feature_fraction': 0.6058310985356675, 'bagging_fraction': 0.645827527410592, 'bagging_freq': 2}. Best is trial 9 with value: 0.20848146382099428.\n","[I 2025-10-11 20:44:00,539] Trial 17 finished with value: 0.18699127121420817 and parameters: {'n_estimators': 400, 'learning_rate': 0.0027129563102578067, 'num_leaves': 103, 'max_depth': 7, 'lambda_l1': 0.0005409752558910637, 'lambda_l2': 8.959370257093294, 'feature_fraction': 0.9945198620333551, 'bagging_fraction': 0.7264597539413324, 'bagging_freq': 4}. Best is trial 9 with value: 0.20848146382099428.\n","[I 2025-10-11 20:44:19,682] Trial 18 finished with value: 0.20664389575996728 and parameters: {'n_estimators': 2000, 'learning_rate': 0.00815508803576135, 'num_leaves': 222, 'max_depth': 5, 'lambda_l1': 7.022458328711364, 'lambda_l2': 0.03262300081292203, 'feature_fraction': 0.6974871318847149, 'bagging_fraction': 0.6079107731249843, 'bagging_freq': 2}. Best is trial 9 with value: 0.20848146382099428.\n","[I 2025-10-11 20:44:52,561] Trial 19 finished with value: 0.19358951171211022 and parameters: {'n_estimators': 1000, 'learning_rate': 0.0011206134412579908, 'num_leaves': 61, 'max_depth': 9, 'lambda_l1': 4.062914405847736e-05, 'lambda_l2': 0.00017481695230902347, 'feature_fraction': 0.8073797858844936, 'bagging_fraction': 0.8387639934353266, 'bagging_freq': 6}. Best is trial 9 with value: 0.20848146382099428.\n"]},{"output_type":"stream","name":"stdout","text":["\n","[Optuna 조기 종료] 10번의 trial 동안 최고 점수가 갱신되지 않아 튜닝을 중단합니다.\n","\n","✅ 튜닝 완료!\n","\n","==================================================\n","🔬 최적 하이퍼파라미터 (Best Hyperparameters)\n","==================================================\n","        n_estimators: 2000\n","       learning_rate: 0.00411758295662484\n","          num_leaves: 137\n","           max_depth: 5\n","           lambda_l1: 0.0002660818959315374\n","           lambda_l2: 1.2115732946146658\n","    feature_fraction: 0.9300570317392396\n","    bagging_fraction: 0.6379945563339555\n","        bagging_freq: 4\n","==================================================\n","\n","🔬 Step 5: 튜닝된 최종 모델 학습 및 평가...\n","✅ 튜닝된 모델 평가 완료.\n","\n","============================================================\n","📊 최종 성능 비교 결과 (Test Set)\n","============================================================\n","              PR AUC  ROC AUC  F1-Score\n","Baseline      0.1885   0.7751    0.0811\n","Optuna Tuned  0.2139   0.7872    0.0515\n","\n","============================================================\n","💾 Step 6: 최종 모델 예측 결과를 원본 CSV에 추가하여 저장\n","============================================================\n","✅ 모든 데이터의 예측 결과가 '/content/drive/MyDrive/review_helpfulness/PADA/results/s2/coursera/SentenceBERT_coursera_with_s2_predictions.csv' 파일에 성공적으로 저장되었습니다.\n","\n","============================================================\n","🧹 Step 7: 사용된 변수들을 메모리에서 정리\n","============================================================\n","✅ 메모리 정리가 완료되었습니다.\n","\n","🎉 모든 과정이 완료되었습니다!\n"]}]},{"cell_type":"markdown","source":["## RoBERTa"],"metadata":{"id":"e6cAaLwmusj5"}},{"cell_type":"code","source":["# === 2. 환경설정 클래스 ===\n","class Config:\n","    \"\"\"실행에 필요한 모든 설정값을 중앙에서 관리합니다.\"\"\"\n","    # 🌟 1. 입력 파일 경로 설정\n","    CSV_FILE_PATH = \"/content/drive/MyDrive/review_helpfulness/PADA/data/coursera/coursera.csv\"\n","    EMBEDDING_PATH = \"/content/drive/MyDrive/review_helpfulness/PADA/embedding/coursera_RoBERTa.npy\"\n","\n","    # 🌟 2. 최종 결과 CSV 파일 저장 경로 설정\n","    OUTPUT_CSV_PATH = \"/content/drive/MyDrive/review_helpfulness/PADA/results/s2/coursera/RoBERTa_coursera_with_s2_predictions.csv\"\n","\n","    # --- 데이터 정보 ---\n","    TARGET_COLUMN = 'binary_helpfulness'\n","\n","    # --- 데이터 분할 ---\n","    TEST_SPLIT_RATIO = 0.2\n","    RANDOM_STATE = 42\n","\n","    # --- Optuna 튜닝 설정 ---\n","    N_TRIALS = 50\n","    TUNING_METRIC = 'pr_auc'\n","    EARLY_STOPPING_ROUNDS = 10 # 🌟 Optuna 조기 종료 횟수\n","\n","# === 3. Optuna 조기 종료 콜백 ===\n","class EarlyStoppingCallback:\n","    \"\"\"Optuna 스터디의 조기 종료를 위한 콜백 클래스\"\"\"\n","    def __init__(self, early_stopping_rounds: int):\n","        self._early_stopping_rounds = early_stopping_rounds\n","        self._best_value = -float(\"inf\")\n","        self._counter = 0\n","\n","    def __call__(self, study: optuna.study.Study, trial: optuna.trial.Trial):\n","        current_best_value = study.best_value\n","        if current_best_value is not None and current_best_value > self._best_value:\n","            self._best_value = current_best_value\n","            self._counter = 0\n","        else:\n","            self._counter += 1\n","\n","        if self._counter >= self._early_stopping_rounds:\n","            print(f\"\\n[Optuna 조기 종료] {self._early_stopping_rounds}번의 trial 동안 최고 점수가 갱신되지 않아 튜닝을 중단합니다.\")\n","            study.stop()\n","\n","# === 4. Optuna Objective 함수 ===\n","def objective(trial, X, y):\n","    \"\"\"Optuna가 최적의 하이퍼파라미터를 찾기 위해 반복 호출하는 함수\"\"\"\n","    X_train, X_val, y_train, y_val = train_test_split(\n","        X, y, test_size=0.25, random_state=Config.RANDOM_STATE, stratify=y\n","    )\n","\n","    params = {\n","        'objective': 'binary', 'metric': 'logloss', 'verbosity': -1,\n","        'boosting_type': 'gbdt', 'random_state': Config.RANDOM_STATE,\n","        'device': 'gpu',  # 🌟 Optuna Trial 내부에서도 GPU 사용\n","        'n_estimators': trial.suggest_int('n_estimators', 100, 2000, step=100),\n","        'learning_rate': trial.suggest_float('learning_rate', 1e-3, 0.3, log=True),\n","        'num_leaves': trial.suggest_int('num_leaves', 20, 300),\n","        'max_depth': trial.suggest_int('max_depth', 3, 12),\n","        'lambda_l1': trial.suggest_float('lambda_l1', 1e-8, 10.0, log=True),\n","        'lambda_l2': trial.suggest_float('lambda_l2', 1e-8, 10.0, log=True),\n","        'feature_fraction': trial.suggest_float('feature_fraction', 0.6, 1.0),\n","        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.6, 1.0),\n","        'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\n","    }\n","\n","    model = lgb.LGBMClassifier(**params)\n","    model.fit(X_train, y_train,\n","              eval_set=[(X_val, y_val)],\n","              eval_metric='logloss',\n","              callbacks=[lgb.early_stopping(100, verbose=False)])\n","\n","    y_pred_proba = model.predict_proba(X_val)[:, 1]\n","    score = average_precision_score(y_val, y_pred_proba)\n","    return score\n","\n","# === 5. 메인 실행 블록 ===\n","if __name__ == '__main__':\n","    config = Config()\n","\n","    # ... (Step 1 ~ 2: 데이터 로드, 분할, 베이스라인 측정) ...\n","    print(\"Step 1: 데이터 로드 및 분할 중...\")\n","    try:\n","        df = pd.read_csv(config.CSV_FILE_PATH)\n","        labels = df[config.TARGET_COLUMN].values\n","        embeddings = np.load(config.EMBEDDING_PATH)\n","        assert len(df) == len(embeddings)\n","    except Exception as e:\n","        print(f\"🔥 파일 로드 실패: {e}\"); exit()\n","\n","    indices = np.arange(len(df))\n","    train_indices, test_indices = train_test_split(\n","        indices, test_size=config.TEST_SPLIT_RATIO, random_state=config.RANDOM_STATE, stratify=labels\n","    )\n","    X_train, X_test = embeddings[train_indices], embeddings[test_indices]\n","    y_train, y_test = labels[train_indices], labels[test_indices]\n","    print(f\"✅ 완료 (학습용: {len(y_train)}건, 테스트용: {len(y_test)}건)\")\n","\n","    print(\"\\n\" + \"=\"*50)\n","    print(\"📊 Step 2: 베이스라인 모델 성능 측정 (GPU 사용)\")\n","    print(\"=\"*50)\n","\n","    baseline_model = lgb.LGBMClassifier(device='gpu', random_state=config.RANDOM_STATE)\n","    baseline_model.fit(X_train, y_train)\n","\n","    y_pred_proba_base = baseline_model.predict_proba(X_test)[:, 1]\n","    y_pred_class_base = (y_pred_proba_base > 0.5).astype(int)\n","\n","    final_results = {}\n","    final_results['Baseline'] = {\n","        \"PR AUC\": average_precision_score(y_test, y_pred_proba_base),\n","        \"ROC AUC\": roc_auc_score(y_test, y_pred_proba_base),\n","        \"F1-Score\": f1_score(y_test, y_pred_class_base),\n","    }\n","    print(\"✅ 베이스라인 모델 평가 완료.\")\n","\n","    # --- Step 3: Optuna 튜닝 수행 (조기 종료 포함) ---\n","    print(\"\\n\" + \"=\"*50)\n","    print(f\"🔬 Step 3: Optuna 하이퍼파라미터 튜닝 시작 (GPU 사용)...\")\n","    print(f\"(최대 {config.N_TRIALS}번 시도, {config.EARLY_STOPPING_ROUNDS}번 개선 없으면 조기 종료)\")\n","    print(\"=\"*50)\n","\n","    early_stopping_callback = EarlyStoppingCallback(early_stopping_rounds=config.EARLY_STOPPING_ROUNDS)\n","    study = optuna.create_study(direction='maximize')\n","    pbar = tqdm(total=config.N_TRIALS, desc=\"Optuna 튜닝 진행률\")\n","\n","    try:\n","        study.optimize(lambda trial: objective(trial, X_train, y_train),\n","                       n_trials=config.N_TRIALS,\n","                       callbacks=[lambda study, trial: pbar.update(1), early_stopping_callback])\n","    except optuna.exceptions.OptunaError:\n","        # 조기 종료 시 발생하는 예외를 정상 처리\n","        pass\n","    pbar.close()\n","\n","    # ... (Step 4 ~ 6: 결과 출력, 저장, 메모리 정리) ...\n","    print(f\"\\n✅ 튜닝 완료!\")\n","    print(\"\\n\" + \"=\"*50)\n","    print(\"🔬 최적 하이퍼파라미터 (Best Hyperparameters)\")\n","    print(\"=\"*50)\n","    best_params = study.best_params\n","    for key, value in best_params.items():\n","        print(f\"{key:>20s}: {value}\")\n","    print(\"=\"*50)\n","\n","    print(f\"\\n🔬 Step 5: 튜닝된 최종 모델 학습 및 평가...\")\n","    final_model = lgb.LGBMClassifier(device='gpu', objective='binary', verbosity=-1, random_state=config.RANDOM_STATE, **best_params)\n","    final_model.fit(X_train, y_train)\n","\n","    y_pred_proba_tuned = final_model.predict_proba(X_test)[:, 1]\n","    y_pred_class_tuned = (y_pred_proba_tuned > 0.5).astype(int)\n","\n","    final_results['Optuna Tuned'] = {\n","        \"PR AUC\": average_precision_score(y_test, y_pred_proba_tuned),\n","        \"ROC AUC\": roc_auc_score(y_test, y_pred_proba_tuned),\n","        \"F1-Score\": f1_score(y_test, y_pred_class_tuned),\n","    }\n","    print(\"✅ 튜닝된 모델 평가 완료.\")\n","\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"📊 최종 성능 비교 결과 (Test Set)\")\n","    print(\"=\"*60)\n","    results_df = pd.DataFrame(final_results).T\n","    print(results_df.round(4))\n","\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"💾 Step 6: 최종 모델 예측 결과를 원본 CSV에 추가하여 저장\")\n","    print(\"=\"*60)\n","\n","    train_pred_proba = final_model.predict_proba(X_train)[:, 1]\n","    train_pred_class = (train_pred_proba > 0.5).astype(int)\n","\n","    df['s2_pred_proba'] = np.nan\n","    df['s2_pred_class'] = np.nan\n","\n","    df.loc[train_indices, 's2_pred_proba'] = train_pred_proba\n","    df.loc[train_indices, 's2_pred_class'] = train_pred_class\n","\n","    df.loc[test_indices, 's2_pred_proba'] = y_pred_proba_tuned\n","    df.loc[test_indices, 's2_pred_class'] = y_pred_class_tuned\n","\n","    # 🌟 Config에 설정된 경로로 최종 파일 저장\n","    df.to_csv(config.OUTPUT_CSV_PATH, index=False, encoding='utf-8-sig')\n","\n","    print(f\"✅ 모든 데이터의 예측 결과가 '{config.OUTPUT_CSV_PATH}' 파일에 성공적으로 저장되었습니다.\")\n","\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"🧹 Step 7: 사용된 변수들을 메모리에서 정리\")\n","    print(\"=\"*60)\n","\n","    vars_to_delete = [\n","        'df', 'labels', 'embeddings', 'indices', 'X_train', 'X_test',\n","        'y_train', 'y_test', 'train_indices', 'test_indices',\n","        'baseline_model', 'final_model', 'study',\n","    ]\n","    for var_name in vars_to_delete:\n","        if var_name in locals() or var_name in globals():\n","            if var_name in globals(): del globals()[var_name]\n","\n","    gc.collect()\n","    print(\"✅ 메모리 정리가 완료되었습니다.\")\n","\n","    print(\"\\n🎉 모든 과정이 완료되었습니다!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","referenced_widgets":["74fcba6c467148a29b8cf9a476d1b958","82cd9f3482ef4b7b8cbe4576202ae9df","549b1bf7ba864bffaa39695ea9e94d7e","89b58c39934749c59f068e868768f682","917e0d5525524088a9fa5bb95fd5049c","6eb8d61c10324c959668444243a988f4","4390cf5f5ef74e178018784297742a83","58c5d1002af74996842ad0ff9b4169a8","3a896fb195cf45178ef19837a8ac3ebf","dc7724b0a0604821b8cfd3a19b409115","5573d8cdd67d4f7c869ce3de9476169f"]},"id":"dAtvxHR5wSaq","executionInfo":{"status":"ok","timestamp":1760216579248,"user_tz":-540,"elapsed":1049376,"user":{"displayName":"KW-data-analytics","userId":"09651493752354345908"}},"outputId":"07b8f203-3365-43c1-87c0-a3939428d991"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Step 1: 데이터 로드 및 분할 중...\n","✅ 완료 (학습용: 97108건, 테스트용: 24278건)\n","\n","==================================================\n","📊 Step 2: 베이스라인 모델 성능 측정 (GPU 사용)\n","==================================================\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-10-11 20:45:44,523] A new study created in memory with name: no-name-d6c8b90d-1760-48ec-ad57-a7ad6f60352a\n"]},{"output_type":"stream","name":"stdout","text":["✅ 베이스라인 모델 평가 완료.\n","\n","==================================================\n","🔬 Step 3: Optuna 하이퍼파라미터 튜닝 시작 (GPU 사용)...\n","(최대 50번 시도, 10번 개선 없으면 조기 종료)\n","==================================================\n"]},{"output_type":"display_data","data":{"text/plain":["Optuna 튜닝 진행률:   0%|          | 0/50 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"74fcba6c467148a29b8cf9a476d1b958"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2025-10-11 20:45:52,090] Trial 0 finished with value: 0.17019138373960713 and parameters: {'n_estimators': 700, 'learning_rate': 0.17584144746091818, 'num_leaves': 82, 'max_depth': 4, 'lambda_l1': 4.339008005892517, 'lambda_l2': 0.02079242601796223, 'feature_fraction': 0.7943961375137776, 'bagging_fraction': 0.63106581538639, 'bagging_freq': 7}. Best is trial 0 with value: 0.17019138373960713.\n","[I 2025-10-11 20:46:36,817] Trial 1 finished with value: 0.18541249803635354 and parameters: {'n_estimators': 400, 'learning_rate': 0.004841601222991729, 'num_leaves': 138, 'max_depth': 8, 'lambda_l1': 5.331940591085429e-08, 'lambda_l2': 9.384495553569026e-05, 'feature_fraction': 0.9364816937541144, 'bagging_fraction': 0.9657035929252764, 'bagging_freq': 5}. Best is trial 1 with value: 0.18541249803635354.\n","[I 2025-10-11 20:47:13,731] Trial 2 finished with value: 0.17026062436177236 and parameters: {'n_estimators': 200, 'learning_rate': 0.0022623264563756784, 'num_leaves': 210, 'max_depth': 10, 'lambda_l1': 0.0004853199199930181, 'lambda_l2': 0.0002220466986439796, 'feature_fraction': 0.9926134221058672, 'bagging_fraction': 0.9978886967367183, 'bagging_freq': 7}. Best is trial 1 with value: 0.18541249803635354.\n","[I 2025-10-11 20:47:38,904] Trial 3 finished with value: 0.17723161334267687 and parameters: {'n_estimators': 1600, 'learning_rate': 0.03941553882213901, 'num_leaves': 282, 'max_depth': 9, 'lambda_l1': 5.407201952430337e-06, 'lambda_l2': 0.016339850638244696, 'feature_fraction': 0.780375447043976, 'bagging_fraction': 0.7247154185433944, 'bagging_freq': 1}. Best is trial 1 with value: 0.18541249803635354.\n","[I 2025-10-11 20:48:17,140] Trial 4 finished with value: 0.19003584203174803 and parameters: {'n_estimators': 1900, 'learning_rate': 0.010405457699055376, 'num_leaves': 294, 'max_depth': 7, 'lambda_l1': 0.022170109070175515, 'lambda_l2': 0.9953611595611578, 'feature_fraction': 0.8154578344009357, 'bagging_fraction': 0.8497312803540058, 'bagging_freq': 5}. Best is trial 4 with value: 0.19003584203174803.\n","[I 2025-10-11 20:48:35,745] Trial 5 finished with value: 0.18836700127760353 and parameters: {'n_estimators': 700, 'learning_rate': 0.022408484994206133, 'num_leaves': 132, 'max_depth': 5, 'lambda_l1': 1.783174470438896e-06, 'lambda_l2': 0.05588378166753714, 'feature_fraction': 0.9589881540815957, 'bagging_fraction': 0.89774495392334, 'bagging_freq': 2}. Best is trial 4 with value: 0.19003584203174803.\n","[I 2025-10-11 20:49:33,571] Trial 6 finished with value: 0.19347053018555208 and parameters: {'n_estimators': 1700, 'learning_rate': 0.005026443575275517, 'num_leaves': 252, 'max_depth': 7, 'lambda_l1': 6.168976827346322e-05, 'lambda_l2': 0.6667358043234803, 'feature_fraction': 0.6133458571743926, 'bagging_fraction': 0.8893760466350575, 'bagging_freq': 3}. Best is trial 6 with value: 0.19347053018555208.\n","[I 2025-10-11 20:49:45,532] Trial 7 finished with value: 0.18411527158665342 and parameters: {'n_estimators': 200, 'learning_rate': 0.005104666341286413, 'num_leaves': 34, 'max_depth': 7, 'lambda_l1': 1.8858831787648125e-08, 'lambda_l2': 0.00019496860962847865, 'feature_fraction': 0.8900365844449558, 'bagging_fraction': 0.605976251879764, 'bagging_freq': 7}. Best is trial 6 with value: 0.19347053018555208.\n","[I 2025-10-11 20:50:22,133] Trial 8 finished with value: 0.1941350030701183 and parameters: {'n_estimators': 1100, 'learning_rate': 0.006779603795429032, 'num_leaves': 52, 'max_depth': 6, 'lambda_l1': 2.8207955901961875e-07, 'lambda_l2': 3.409536925408435e-05, 'feature_fraction': 0.6410790156319814, 'bagging_fraction': 0.6307110263146831, 'bagging_freq': 7}. Best is trial 8 with value: 0.1941350030701183.\n","[I 2025-10-11 20:50:41,631] Trial 9 finished with value: 0.18908690678737253 and parameters: {'n_estimators': 1500, 'learning_rate': 0.015570413980772392, 'num_leaves': 127, 'max_depth': 5, 'lambda_l1': 1.0285953410329916e-06, 'lambda_l2': 0.033264742053900585, 'feature_fraction': 0.8540490819637684, 'bagging_fraction': 0.883545496515044, 'bagging_freq': 2}. Best is trial 8 with value: 0.1941350030701183.\n","[I 2025-10-11 20:51:09,896] Trial 10 finished with value: 0.18037369459365413 and parameters: {'n_estimators': 1200, 'learning_rate': 0.00131430254682652, 'num_leaves': 21, 'max_depth': 12, 'lambda_l1': 0.004255991774384735, 'lambda_l2': 2.0030197907024822e-07, 'feature_fraction': 0.6162618411054138, 'bagging_fraction': 0.7180389804394862, 'bagging_freq': 5}. Best is trial 8 with value: 0.1941350030701183.\n","[I 2025-10-11 20:51:23,421] Trial 11 finished with value: 0.18219384593739607 and parameters: {'n_estimators': 1300, 'learning_rate': 0.00462207664676522, 'num_leaves': 223, 'max_depth': 3, 'lambda_l1': 3.6755740204696795e-05, 'lambda_l2': 8.546140991636422e-07, 'feature_fraction': 0.602930565595068, 'bagging_fraction': 0.7804624579369048, 'bagging_freq': 3}. Best is trial 8 with value: 0.1941350030701183.\n","[I 2025-10-11 20:51:35,982] Trial 12 finished with value: 0.18056667450412742 and parameters: {'n_estimators': 2000, 'learning_rate': 0.05512300294218239, 'num_leaves': 231, 'max_depth': 6, 'lambda_l1': 0.00042808576886376067, 'lambda_l2': 3.1968252076086077e-06, 'feature_fraction': 0.6954550900375619, 'bagging_fraction': 0.8159878652994824, 'bagging_freq': 4}. Best is trial 8 with value: 0.1941350030701183.\n","[I 2025-10-11 20:52:38,974] Trial 13 finished with value: 0.19342498051291146 and parameters: {'n_estimators': 1000, 'learning_rate': 0.008674527731555966, 'num_leaves': 186, 'max_depth': 9, 'lambda_l1': 2.2202018063283747e-07, 'lambda_l2': 2.6130103884177016, 'feature_fraction': 0.7066859564793133, 'bagging_fraction': 0.6772942795528539, 'bagging_freq': 4}. Best is trial 8 with value: 0.1941350030701183.\n","[I 2025-10-11 20:53:39,579] Trial 14 finished with value: 0.1900802746573328 and parameters: {'n_estimators': 1700, 'learning_rate': 0.0021757851807373287, 'num_leaves': 254, 'max_depth': 6, 'lambda_l1': 2.2948060070549766e-05, 'lambda_l2': 7.556147114105286e-06, 'feature_fraction': 0.6711143490767854, 'bagging_fraction': 0.9218340276257749, 'bagging_freq': 6}. Best is trial 8 with value: 0.1941350030701183.\n","[I 2025-10-11 20:54:34,156] Trial 15 finished with value: 0.17294248774489135 and parameters: {'n_estimators': 900, 'learning_rate': 0.0010824081470475805, 'num_leaves': 83, 'max_depth': 11, 'lambda_l1': 8.763275959941673, 'lambda_l2': 1.5803440580385606e-08, 'feature_fraction': 0.7440619094241508, 'bagging_fraction': 0.7768559241460589, 'bagging_freq': 3}. Best is trial 8 with value: 0.1941350030701183.\n","[I 2025-10-11 20:56:21,751] Trial 16 finished with value: 0.1921591966842936 and parameters: {'n_estimators': 1400, 'learning_rate': 0.002818557175035352, 'num_leaves': 173, 'max_depth': 8, 'lambda_l1': 0.024354548302480523, 'lambda_l2': 0.002308697431619686, 'feature_fraction': 0.6518572042038088, 'bagging_fraction': 0.8212889199992737, 'bagging_freq': 3}. Best is trial 8 with value: 0.1941350030701183.\n","[I 2025-10-11 20:56:33,568] Trial 17 finished with value: 0.1780348830216154 and parameters: {'n_estimators': 1700, 'learning_rate': 0.07498753864377336, 'num_leaves': 76, 'max_depth': 6, 'lambda_l1': 3.6527190523141315e-05, 'lambda_l2': 1.823458191752955e-05, 'feature_fraction': 0.6415911946176366, 'bagging_fraction': 0.6707146456087273, 'bagging_freq': 6}. Best is trial 8 with value: 0.1941350030701183.\n","[I 2025-10-11 20:56:43,452] Trial 18 finished with value: 0.19481388119142284 and parameters: {'n_estimators': 600, 'learning_rate': 0.025933748232062823, 'num_leaves': 55, 'max_depth': 3, 'lambda_l1': 2.4019425588937767e-07, 'lambda_l2': 7.619855396452355, 'feature_fraction': 0.7361497063513817, 'bagging_fraction': 0.738985797049742, 'bagging_freq': 1}. Best is trial 18 with value: 0.19481388119142284.\n","[I 2025-10-11 20:56:50,719] Trial 19 finished with value: 0.17162905109784304 and parameters: {'n_estimators': 600, 'learning_rate': 0.17894979365459274, 'num_leaves': 54, 'max_depth': 3, 'lambda_l1': 2.5340727890939587e-07, 'lambda_l2': 0.001948393625154772, 'feature_fraction': 0.7226219098282803, 'bagging_fraction': 0.7155841713250353, 'bagging_freq': 1}. Best is trial 18 with value: 0.19481388119142284.\n","[I 2025-10-11 20:57:04,507] Trial 20 finished with value: 0.1960825737666584 and parameters: {'n_estimators': 900, 'learning_rate': 0.02726046563962758, 'num_leaves': 109, 'max_depth': 4, 'lambda_l1': 1.7457741091368028e-08, 'lambda_l2': 6.401542119349747, 'feature_fraction': 0.7590252584358613, 'bagging_fraction': 0.6550209719786978, 'bagging_freq': 2}. Best is trial 20 with value: 0.1960825737666584.\n","[I 2025-10-11 20:57:17,586] Trial 21 finished with value: 0.19720521841231664 and parameters: {'n_estimators': 900, 'learning_rate': 0.027754185254594412, 'num_leaves': 58, 'max_depth': 4, 'lambda_l1': 2.535131488804478e-08, 'lambda_l2': 8.262344343216366, 'feature_fraction': 0.7548663258557451, 'bagging_fraction': 0.6541451172704997, 'bagging_freq': 2}. Best is trial 21 with value: 0.19720521841231664.\n","[I 2025-10-11 20:57:33,417] Trial 22 finished with value: 0.19479893570949447 and parameters: {'n_estimators': 900, 'learning_rate': 0.026522159731987384, 'num_leaves': 107, 'max_depth': 4, 'lambda_l1': 1.471456709600593e-08, 'lambda_l2': 7.56491048521543, 'feature_fraction': 0.7538221445138806, 'bagging_fraction': 0.6747851292218198, 'bagging_freq': 2}. Best is trial 21 with value: 0.19720521841231664.\n","[I 2025-10-11 20:57:41,461] Trial 23 finished with value: 0.18173402869587374 and parameters: {'n_estimators': 500, 'learning_rate': 0.10135810816565384, 'num_leaves': 104, 'max_depth': 4, 'lambda_l1': 5.065218162145082e-08, 'lambda_l2': 0.2441120312932713, 'feature_fraction': 0.8256535427713076, 'bagging_fraction': 0.7475983768277986, 'bagging_freq': 1}. Best is trial 21 with value: 0.19720521841231664.\n","[I 2025-10-11 20:57:52,604] Trial 24 finished with value: 0.19597934735133254 and parameters: {'n_estimators': 800, 'learning_rate': 0.03679183635496584, 'num_leaves': 55, 'max_depth': 3, 'lambda_l1': 1.3981944208857329e-08, 'lambda_l2': 7.035106846935785, 'feature_fraction': 0.7578083734849246, 'bagging_fraction': 0.6498406875820355, 'bagging_freq': 2}. Best is trial 21 with value: 0.19720521841231664.\n","[I 2025-10-11 20:58:04,750] Trial 25 finished with value: 0.18694489924742952 and parameters: {'n_estimators': 800, 'learning_rate': 0.04448190548848926, 'num_leaves': 106, 'max_depth': 5, 'lambda_l1': 1.709910477698744e-08, 'lambda_l2': 0.20944627581878578, 'feature_fraction': 0.7712835857182482, 'bagging_fraction': 0.6416084968517843, 'bagging_freq': 2}. Best is trial 21 with value: 0.19720521841231664.\n","[I 2025-10-11 20:58:23,452] Trial 26 finished with value: 0.19652651272665278 and parameters: {'n_estimators': 1100, 'learning_rate': 0.01359701653436081, 'num_leaves': 67, 'max_depth': 4, 'lambda_l1': 7.166210463531582e-08, 'lambda_l2': 1.778386873422589, 'feature_fraction': 0.8526895112763924, 'bagging_fraction': 0.6018486556322102, 'bagging_freq': 2}. Best is trial 21 with value: 0.19720521841231664.\n","[I 2025-10-11 20:58:40,612] Trial 27 finished with value: 0.19332521622439225 and parameters: {'n_estimators': 1100, 'learning_rate': 0.01237295625802047, 'num_leaves': 151, 'max_depth': 4, 'lambda_l1': 2.541297530649172e-06, 'lambda_l2': 0.8046832756493313, 'feature_fraction': 0.8584935756419421, 'bagging_fraction': 0.6084247337235362, 'bagging_freq': 3}. Best is trial 21 with value: 0.19720521841231664.\n","[I 2025-10-11 20:59:00,487] Trial 28 finished with value: 0.19454790338934108 and parameters: {'n_estimators': 1300, 'learning_rate': 0.01912126976760384, 'num_leaves': 89, 'max_depth': 5, 'lambda_l1': 1.0016124429099599e-07, 'lambda_l2': 0.15308854391076804, 'feature_fraction': 0.8941536354289947, 'bagging_fraction': 0.6922105194514854, 'bagging_freq': 2}. Best is trial 21 with value: 0.19720521841231664.\n","[I 2025-10-11 20:59:08,413] Trial 29 finished with value: 0.1713038692724389 and parameters: {'n_estimators': 400, 'learning_rate': 0.11216167360299374, 'num_leaves': 81, 'max_depth': 4, 'lambda_l1': 0.4317151275533026, 'lambda_l2': 0.008963305483231815, 'feature_fraction': 0.7981023118000731, 'bagging_fraction': 0.6241953071627603, 'bagging_freq': 1}. Best is trial 21 with value: 0.19720521841231664.\n","[I 2025-10-11 20:59:16,295] Trial 30 finished with value: 0.16563130743496057 and parameters: {'n_estimators': 1000, 'learning_rate': 0.29508215552008477, 'num_leaves': 34, 'max_depth': 4, 'lambda_l1': 7.488959894961555e-07, 'lambda_l2': 1.6349619483685027, 'feature_fraction': 0.831307139733505, 'bagging_fraction': 0.6460492077463798, 'bagging_freq': 4}. Best is trial 21 with value: 0.19720521841231664.\n","[I 2025-10-11 20:59:26,056] Trial 31 finished with value: 0.19774961378378014 and parameters: {'n_estimators': 800, 'learning_rate': 0.04491713933013319, 'num_leaves': 64, 'max_depth': 3, 'lambda_l1': 5.046608656123682e-08, 'lambda_l2': 5.90361203462853, 'feature_fraction': 0.7677137700830172, 'bagging_fraction': 0.656918951624284, 'bagging_freq': 2}. Best is trial 31 with value: 0.19774961378378014.\n","[I 2025-10-11 20:59:35,004] Trial 32 finished with value: 0.19361255393356547 and parameters: {'n_estimators': 800, 'learning_rate': 0.06565950091355459, 'num_leaves': 70, 'max_depth': 3, 'lambda_l1': 9.274732632805943e-08, 'lambda_l2': 2.4717384739752086, 'feature_fraction': 0.7806909210818099, 'bagging_fraction': 0.6955360776306392, 'bagging_freq': 2}. Best is trial 31 with value: 0.19774961378378014.\n","[I 2025-10-11 20:59:49,025] Trial 33 finished with value: 0.19058268561843747 and parameters: {'n_estimators': 900, 'learning_rate': 0.03037340987843532, 'num_leaves': 118, 'max_depth': 5, 'lambda_l1': 7.771535020652307e-06, 'lambda_l2': 0.3306329248191261, 'feature_fraction': 0.8572544501124136, 'bagging_fraction': 0.6022251678719225, 'bagging_freq': 3}. Best is trial 31 with value: 0.19774961378378014.\n","[I 2025-10-11 21:00:02,766] Trial 34 finished with value: 0.19332804806111853 and parameters: {'n_estimators': 1200, 'learning_rate': 0.015119091882550341, 'num_leaves': 94, 'max_depth': 3, 'lambda_l1': 5.644620045777775e-08, 'lambda_l2': 2.6193786439674835, 'feature_fraction': 0.8016707917553485, 'bagging_fraction': 0.6593800762657023, 'bagging_freq': 1}. Best is trial 31 with value: 0.19774961378378014.\n","[I 2025-10-11 21:00:15,680] Trial 35 finished with value: 0.19589485622149916 and parameters: {'n_estimators': 700, 'learning_rate': 0.03818353129754732, 'num_leaves': 66, 'max_depth': 4, 'lambda_l1': 3.998315474874303e-08, 'lambda_l2': 9.527196606786875, 'feature_fraction': 0.8940815644964677, 'bagging_fraction': 0.6943148738227013, 'bagging_freq': 2}. Best is trial 31 with value: 0.19774961378378014.\n","[I 2025-10-11 21:00:22,970] Trial 36 finished with value: 0.1764960058429659 and parameters: {'n_estimators': 100, 'learning_rate': 0.01780108264651253, 'num_leaves': 33, 'max_depth': 4, 'lambda_l1': 8.177771325999531e-07, 'lambda_l2': 0.08051071646884721, 'feature_fraction': 0.7142886049727082, 'bagging_fraction': 0.6259159549401576, 'bagging_freq': 3}. Best is trial 31 with value: 0.19774961378378014.\n","[I 2025-10-11 21:00:32,300] Trial 37 finished with value: 0.17999481003460605 and parameters: {'n_estimators': 600, 'learning_rate': 0.08982839914347898, 'num_leaves': 148, 'max_depth': 5, 'lambda_l1': 8.598101932853473e-06, 'lambda_l2': 0.6371399346689718, 'feature_fraction': 0.6844537519793754, 'bagging_fraction': 0.7585705445865671, 'bagging_freq': 2}. Best is trial 31 with value: 0.19774961378378014.\n","[I 2025-10-11 21:00:41,469] Trial 38 finished with value: 0.1887150586755789 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05276545244821766, 'num_leaves': 118, 'max_depth': 3, 'lambda_l1': 1.1018234916798023e-08, 'lambda_l2': 0.005380086173936154, 'feature_fraction': 0.7767343045987468, 'bagging_fraction': 0.6606937394599715, 'bagging_freq': 1}. Best is trial 31 with value: 0.19774961378378014.\n","[I 2025-10-11 21:01:16,695] Trial 39 finished with value: 0.19648587876582918 and parameters: {'n_estimators': 1200, 'learning_rate': 0.009552943906871291, 'num_leaves': 21, 'max_depth': 8, 'lambda_l1': 1.1008387630329056e-07, 'lambda_l2': 2.8280406992505687, 'feature_fraction': 0.9435482320460715, 'bagging_fraction': 0.6211782121087408, 'bagging_freq': 4}. Best is trial 31 with value: 0.19774961378378014.\n","[I 2025-10-11 21:01:59,250] Trial 40 finished with value: 0.19376841347685192 and parameters: {'n_estimators': 1400, 'learning_rate': 0.008063325247209532, 'num_leaves': 44, 'max_depth': 8, 'lambda_l1': 3.5613417476592767e-06, 'lambda_l2': 0.06965449737070065, 'feature_fraction': 0.9269775691626897, 'bagging_fraction': 0.6201776706681323, 'bagging_freq': 5}. Best is trial 31 with value: 0.19774961378378014.\n","[I 2025-10-11 21:02:42,793] Trial 41 finished with value: 0.19456652720760398 and parameters: {'n_estimators': 1200, 'learning_rate': 0.011043856175360195, 'num_leaves': 27, 'max_depth': 9, 'lambda_l1': 1.2887695514188953e-07, 'lambda_l2': 2.6560312706660403, 'feature_fraction': 0.9689801750898553, 'bagging_fraction': 0.6384934529086336, 'bagging_freq': 4}. Best is trial 31 with value: 0.19774961378378014.\n"]},{"output_type":"stream","name":"stdout","text":["\n","[Optuna 조기 종료] 10번의 trial 동안 최고 점수가 갱신되지 않아 튜닝을 중단합니다.\n","\n","✅ 튜닝 완료!\n","\n","==================================================\n","🔬 최적 하이퍼파라미터 (Best Hyperparameters)\n","==================================================\n","        n_estimators: 800\n","       learning_rate: 0.04491713933013319\n","          num_leaves: 64\n","           max_depth: 3\n","           lambda_l1: 5.046608656123682e-08\n","           lambda_l2: 5.90361203462853\n","    feature_fraction: 0.7677137700830172\n","    bagging_fraction: 0.656918951624284\n","        bagging_freq: 2\n","==================================================\n","\n","🔬 Step 5: 튜닝된 최종 모델 학습 및 평가...\n","✅ 튜닝된 모델 평가 완료.\n","\n","============================================================\n","📊 최종 성능 비교 결과 (Test Set)\n","============================================================\n","              PR AUC  ROC AUC  F1-Score\n","Baseline      0.1784   0.7533    0.0818\n","Optuna Tuned  0.2066   0.7668    0.0821\n","\n","============================================================\n","💾 Step 6: 최종 모델 예측 결과를 원본 CSV에 추가하여 저장\n","============================================================\n","✅ 모든 데이터의 예측 결과가 '/content/drive/MyDrive/review_helpfulness/PADA/results/s2/coursera/RoBERTa_coursera_with_s2_predictions.csv' 파일에 성공적으로 저장되었습니다.\n","\n","============================================================\n","🧹 Step 7: 사용된 변수들을 메모리에서 정리\n","============================================================\n","✅ 메모리 정리가 완료되었습니다.\n","\n","🎉 모든 과정이 완료되었습니다!\n"]}]},{"cell_type":"markdown","source":["## DistilBERT"],"metadata":{"id":"9M6uFjgeuta8"}},{"cell_type":"code","source":["# === 2. 환경설정 클래스 ===\n","class Config:\n","    \"\"\"실행에 필요한 모든 설정값을 중앙에서 관리합니다.\"\"\"\n","    # 🌟 1. 입력 파일 경로 설정\n","    CSV_FILE_PATH = \"/content/drive/MyDrive/review_helpfulness/PADA/data/coursera/coursera.csv\"\n","    EMBEDDING_PATH = \"/content/drive/MyDrive/review_helpfulness/PADA/embedding/coursera_DistilBERT.npy\"\n","\n","    # 🌟 2. 최종 결과 CSV 파일 저장 경로 설정\n","    OUTPUT_CSV_PATH = \"/content/drive/MyDrive/review_helpfulness/PADA/results/s2/coursera/DistilBERT_coursera_with_s2_predictions.csv\"\n","\n","    # --- 데이터 정보 ---\n","    TARGET_COLUMN = 'binary_helpfulness'\n","\n","    # --- 데이터 분할 ---\n","    TEST_SPLIT_RATIO = 0.2\n","    RANDOM_STATE = 42\n","\n","    # --- Optuna 튜닝 설정 ---\n","    N_TRIALS = 50\n","    TUNING_METRIC = 'pr_auc'\n","    EARLY_STOPPING_ROUNDS = 10 # 🌟 Optuna 조기 종료 횟수\n","\n","# === 3. Optuna 조기 종료 콜백 ===\n","class EarlyStoppingCallback:\n","    \"\"\"Optuna 스터디의 조기 종료를 위한 콜백 클래스\"\"\"\n","    def __init__(self, early_stopping_rounds: int):\n","        self._early_stopping_rounds = early_stopping_rounds\n","        self._best_value = -float(\"inf\")\n","        self._counter = 0\n","\n","    def __call__(self, study: optuna.study.Study, trial: optuna.trial.Trial):\n","        current_best_value = study.best_value\n","        if current_best_value is not None and current_best_value > self._best_value:\n","            self._best_value = current_best_value\n","            self._counter = 0\n","        else:\n","            self._counter += 1\n","\n","        if self._counter >= self._early_stopping_rounds:\n","            print(f\"\\n[Optuna 조기 종료] {self._early_stopping_rounds}번의 trial 동안 최고 점수가 갱신되지 않아 튜닝을 중단합니다.\")\n","            study.stop()\n","\n","# === 4. Optuna Objective 함수 ===\n","def objective(trial, X, y):\n","    \"\"\"Optuna가 최적의 하이퍼파라미터를 찾기 위해 반복 호출하는 함수\"\"\"\n","    X_train, X_val, y_train, y_val = train_test_split(\n","        X, y, test_size=0.25, random_state=Config.RANDOM_STATE, stratify=y\n","    )\n","\n","    params = {\n","        'objective': 'binary', 'metric': 'logloss', 'verbosity': -1,\n","        'boosting_type': 'gbdt', 'random_state': Config.RANDOM_STATE,\n","        'device': 'gpu',  # 🌟 Optuna Trial 내부에서도 GPU 사용\n","        'n_estimators': trial.suggest_int('n_estimators', 100, 2000, step=100),\n","        'learning_rate': trial.suggest_float('learning_rate', 1e-3, 0.3, log=True),\n","        'num_leaves': trial.suggest_int('num_leaves', 20, 300),\n","        'max_depth': trial.suggest_int('max_depth', 3, 12),\n","        'lambda_l1': trial.suggest_float('lambda_l1', 1e-8, 10.0, log=True),\n","        'lambda_l2': trial.suggest_float('lambda_l2', 1e-8, 10.0, log=True),\n","        'feature_fraction': trial.suggest_float('feature_fraction', 0.6, 1.0),\n","        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.6, 1.0),\n","        'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\n","    }\n","\n","    model = lgb.LGBMClassifier(**params)\n","    model.fit(X_train, y_train,\n","              eval_set=[(X_val, y_val)],\n","              eval_metric='logloss',\n","              callbacks=[lgb.early_stopping(100, verbose=False)])\n","\n","    y_pred_proba = model.predict_proba(X_val)[:, 1]\n","    score = average_precision_score(y_val, y_pred_proba)\n","    return score\n","\n","# === 5. 메인 실행 블록 ===\n","if __name__ == '__main__':\n","    config = Config()\n","\n","    # ... (Step 1 ~ 2: 데이터 로드, 분할, 베이스라인 측정) ...\n","    print(\"Step 1: 데이터 로드 및 분할 중...\")\n","    try:\n","        df = pd.read_csv(config.CSV_FILE_PATH)\n","        labels = df[config.TARGET_COLUMN].values\n","        embeddings = np.load(config.EMBEDDING_PATH)\n","        assert len(df) == len(embeddings)\n","    except Exception as e:\n","        print(f\"🔥 파일 로드 실패: {e}\"); exit()\n","\n","    indices = np.arange(len(df))\n","    train_indices, test_indices = train_test_split(\n","        indices, test_size=config.TEST_SPLIT_RATIO, random_state=config.RANDOM_STATE, stratify=labels\n","    )\n","    X_train, X_test = embeddings[train_indices], embeddings[test_indices]\n","    y_train, y_test = labels[train_indices], labels[test_indices]\n","    print(f\"✅ 완료 (학습용: {len(y_train)}건, 테스트용: {len(y_test)}건)\")\n","\n","    print(\"\\n\" + \"=\"*50)\n","    print(\"📊 Step 2: 베이스라인 모델 성능 측정 (GPU 사용)\")\n","    print(\"=\"*50)\n","\n","    baseline_model = lgb.LGBMClassifier(device='gpu', random_state=config.RANDOM_STATE)\n","    baseline_model.fit(X_train, y_train)\n","\n","    y_pred_proba_base = baseline_model.predict_proba(X_test)[:, 1]\n","    y_pred_class_base = (y_pred_proba_base > 0.5).astype(int)\n","\n","    final_results = {}\n","    final_results['Baseline'] = {\n","        \"PR AUC\": average_precision_score(y_test, y_pred_proba_base),\n","        \"ROC AUC\": roc_auc_score(y_test, y_pred_proba_base),\n","        \"F1-Score\": f1_score(y_test, y_pred_class_base),\n","    }\n","    print(\"✅ 베이스라인 모델 평가 완료.\")\n","\n","    # --- Step 3: Optuna 튜닝 수행 (조기 종료 포함) ---\n","    print(\"\\n\" + \"=\"*50)\n","    print(f\"🔬 Step 3: Optuna 하이퍼파라미터 튜닝 시작 (GPU 사용)...\")\n","    print(f\"(최대 {config.N_TRIALS}번 시도, {config.EARLY_STOPPING_ROUNDS}번 개선 없으면 조기 종료)\")\n","    print(\"=\"*50)\n","\n","    early_stopping_callback = EarlyStoppingCallback(early_stopping_rounds=config.EARLY_STOPPING_ROUNDS)\n","    study = optuna.create_study(direction='maximize')\n","    pbar = tqdm(total=config.N_TRIALS, desc=\"Optuna 튜닝 진행률\")\n","\n","    try:\n","        study.optimize(lambda trial: objective(trial, X_train, y_train),\n","                       n_trials=config.N_TRIALS,\n","                       callbacks=[lambda study, trial: pbar.update(1), early_stopping_callback])\n","    except optuna.exceptions.OptunaError:\n","        # 조기 종료 시 발생하는 예외를 정상 처리\n","        pass\n","    pbar.close()\n","\n","    # ... (Step 4 ~ 6: 결과 출력, 저장, 메모리 정리) ...\n","    print(f\"\\n✅ 튜닝 완료!\")\n","    print(\"\\n\" + \"=\"*50)\n","    print(\"🔬 최적 하이퍼파라미터 (Best Hyperparameters)\")\n","    print(\"=\"*50)\n","    best_params = study.best_params\n","    for key, value in best_params.items():\n","        print(f\"{key:>20s}: {value}\")\n","    print(\"=\"*50)\n","\n","    print(f\"\\n🔬 Step 5: 튜닝된 최종 모델 학습 및 평가...\")\n","    final_model = lgb.LGBMClassifier(device='gpu', objective='binary', verbosity=-1, random_state=config.RANDOM_STATE, **best_params)\n","    final_model.fit(X_train, y_train)\n","\n","    y_pred_proba_tuned = final_model.predict_proba(X_test)[:, 1]\n","    y_pred_class_tuned = (y_pred_proba_tuned > 0.5).astype(int)\n","\n","    final_results['Optuna Tuned'] = {\n","        \"PR AUC\": average_precision_score(y_test, y_pred_proba_tuned),\n","        \"ROC AUC\": roc_auc_score(y_test, y_pred_proba_tuned),\n","        \"F1-Score\": f1_score(y_test, y_pred_class_tuned),\n","    }\n","    print(\"✅ 튜닝된 모델 평가 완료.\")\n","\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"📊 최종 성능 비교 결과 (Test Set)\")\n","    print(\"=\"*60)\n","    results_df = pd.DataFrame(final_results).T\n","    print(results_df.round(4))\n","\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"💾 Step 6: 최종 모델 예측 결과를 원본 CSV에 추가하여 저장\")\n","    print(\"=\"*60)\n","\n","    train_pred_proba = final_model.predict_proba(X_train)[:, 1]\n","    train_pred_class = (train_pred_proba > 0.5).astype(int)\n","\n","    df['s2_pred_proba'] = np.nan\n","    df['s2_pred_class'] = np.nan\n","\n","    df.loc[train_indices, 's2_pred_proba'] = train_pred_proba\n","    df.loc[train_indices, 's2_pred_class'] = train_pred_class\n","\n","    df.loc[test_indices, 's2_pred_proba'] = y_pred_proba_tuned\n","    df.loc[test_indices, 's2_pred_class'] = y_pred_class_tuned\n","\n","    # 🌟 Config에 설정된 경로로 최종 파일 저장\n","    df.to_csv(config.OUTPUT_CSV_PATH, index=False, encoding='utf-8-sig')\n","\n","    print(f\"✅ 모든 데이터의 예측 결과가 '{config.OUTPUT_CSV_PATH}' 파일에 성공적으로 저장되었습니다.\")\n","\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"🧹 Step 7: 사용된 변수들을 메모리에서 정리\")\n","    print(\"=\"*60)\n","\n","    vars_to_delete = [\n","        'df', 'labels', 'embeddings', 'indices', 'X_train', 'X_test',\n","        'y_train', 'y_test', 'train_indices', 'test_indices',\n","        'baseline_model', 'final_model', 'study',\n","    ]\n","    for var_name in vars_to_delete:\n","        if var_name in locals() or var_name in globals():\n","            if var_name in globals(): del globals()[var_name]\n","\n","    gc.collect()\n","    print(\"✅ 메모리 정리가 완료되었습니다.\")\n","\n","    print(\"\\n🎉 모든 과정이 완료되었습니다!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","referenced_widgets":["1ba6332055034a898979671c01173c80","584f2bf9a37a4a959175e97445c73515","ddc3685b62f241a5b3389e221dc15878","70e8c8104c484e19b3ab4c8e8f77870e","e130719f081e44a28d3eabe8291b557b","88b59307584f435382706ad81977d82a","ad10d090317c4eda94189fd556878536","e68f3ad8ee2d4fd3a6394154f30fc561","ec8ae113779c4fcda4b58ae4ed6eaaed","b300ba8300644c97ae9a5ad6ae60171e","ce2df40505284f598ea8efa487980fd4"]},"id":"Kh06ly19wx5a","executionInfo":{"status":"ok","timestamp":1760216949717,"user_tz":-540,"elapsed":370455,"user":{"displayName":"KW-data-analytics","userId":"09651493752354345908"}},"outputId":"a7f54686-04d5-45fb-82f0-8a1b0576e83f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Step 1: 데이터 로드 및 분할 중...\n","✅ 완료 (학습용: 97108건, 테스트용: 24278건)\n","\n","==================================================\n","📊 Step 2: 베이스라인 모델 성능 측정 (GPU 사용)\n","==================================================\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-10-11 21:03:15,449] A new study created in memory with name: no-name-747389dd-ac48-4b46-b797-bfd2b661380f\n"]},{"output_type":"stream","name":"stdout","text":["✅ 베이스라인 모델 평가 완료.\n","\n","==================================================\n","🔬 Step 3: Optuna 하이퍼파라미터 튜닝 시작 (GPU 사용)...\n","(최대 50번 시도, 10번 개선 없으면 조기 종료)\n","==================================================\n"]},{"output_type":"display_data","data":{"text/plain":["Optuna 튜닝 진행률:   0%|          | 0/50 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1ba6332055034a898979671c01173c80"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2025-10-11 21:03:39,472] Trial 0 finished with value: 0.18111642941895523 and parameters: {'n_estimators': 500, 'learning_rate': 0.058094245451650074, 'num_leaves': 285, 'max_depth': 9, 'lambda_l1': 0.001310261415545032, 'lambda_l2': 0.01040080217542489, 'feature_fraction': 0.9463124922493077, 'bagging_fraction': 0.7031642813235403, 'bagging_freq': 6}. Best is trial 0 with value: 0.18111642941895523.\n","[I 2025-10-11 21:04:05,603] Trial 1 finished with value: 0.1998090152976513 and parameters: {'n_estimators': 700, 'learning_rate': 0.0036518647659001197, 'num_leaves': 27, 'max_depth': 10, 'lambda_l1': 2.283171361851737e-08, 'lambda_l2': 6.151903428525071e-08, 'feature_fraction': 0.9859484792615983, 'bagging_fraction': 0.7756480402219587, 'bagging_freq': 4}. Best is trial 1 with value: 0.1998090152976513.\n","[I 2025-10-11 21:04:23,647] Trial 2 finished with value: 0.2078844121121917 and parameters: {'n_estimators': 1100, 'learning_rate': 0.054114441477715575, 'num_leaves': 300, 'max_depth': 7, 'lambda_l1': 8.681406465477098, 'lambda_l2': 2.4854725646545834e-06, 'feature_fraction': 0.9461824632394943, 'bagging_fraction': 0.7161866797991427, 'bagging_freq': 7}. Best is trial 2 with value: 0.2078844121121917.\n","[I 2025-10-11 21:04:38,686] Trial 3 finished with value: 0.13436122813422044 and parameters: {'n_estimators': 1700, 'learning_rate': 0.15725138415139828, 'num_leaves': 118, 'max_depth': 10, 'lambda_l1': 0.00010925275773395085, 'lambda_l2': 4.6725887295458067e-07, 'feature_fraction': 0.7259726204934084, 'bagging_fraction': 0.6434420441856233, 'bagging_freq': 5}. Best is trial 2 with value: 0.2078844121121917.\n","[I 2025-10-11 21:05:24,490] Trial 4 finished with value: 0.1927508013928039 and parameters: {'n_estimators': 200, 'learning_rate': 0.01421743229712561, 'num_leaves': 266, 'max_depth': 11, 'lambda_l1': 3.682706947762843e-06, 'lambda_l2': 1.171526343890115e-06, 'feature_fraction': 0.9292086188893035, 'bagging_fraction': 0.6321889617722836, 'bagging_freq': 3}. Best is trial 2 with value: 0.2078844121121917.\n","[I 2025-10-11 21:05:33,241] Trial 5 finished with value: 0.19659926877648437 and parameters: {'n_estimators': 1000, 'learning_rate': 0.07582154249545991, 'num_leaves': 279, 'max_depth': 5, 'lambda_l1': 0.0077212103443277166, 'lambda_l2': 0.00042942447003765797, 'feature_fraction': 0.7760386460043168, 'bagging_fraction': 0.7161607128954612, 'bagging_freq': 1}. Best is trial 2 with value: 0.2078844121121917.\n","[I 2025-10-11 21:05:57,584] Trial 6 finished with value: 0.20307819261655466 and parameters: {'n_estimators': 500, 'learning_rate': 0.016120890899474796, 'num_leaves': 46, 'max_depth': 7, 'lambda_l1': 0.006716676938319566, 'lambda_l2': 1.7421487776875293e-08, 'feature_fraction': 0.891159373425872, 'bagging_fraction': 0.6737678619550099, 'bagging_freq': 2}. Best is trial 2 with value: 0.2078844121121917.\n","[I 2025-10-11 21:06:21,161] Trial 7 finished with value: 0.19635545622452755 and parameters: {'n_estimators': 200, 'learning_rate': 0.0014615554759603146, 'num_leaves': 230, 'max_depth': 8, 'lambda_l1': 2.2547423825495718e-05, 'lambda_l2': 1.2170887767419178, 'feature_fraction': 0.7945822036698023, 'bagging_fraction': 0.6745327353225187, 'bagging_freq': 1}. Best is trial 2 with value: 0.2078844121121917.\n","[I 2025-10-11 21:07:09,223] Trial 8 finished with value: 0.200811834203578 and parameters: {'n_estimators': 1600, 'learning_rate': 0.012705991151198573, 'num_leaves': 290, 'max_depth': 9, 'lambda_l1': 6.154643759463549e-06, 'lambda_l2': 0.18108153566713278, 'feature_fraction': 0.8800712523998758, 'bagging_fraction': 0.9773360019844489, 'bagging_freq': 4}. Best is trial 2 with value: 0.2078844121121917.\n","[I 2025-10-11 21:07:26,071] Trial 9 finished with value: 0.19577754238820166 and parameters: {'n_estimators': 1800, 'learning_rate': 0.0024168982715852875, 'num_leaves': 71, 'max_depth': 3, 'lambda_l1': 5.405204818375286e-07, 'lambda_l2': 0.7167017867823823, 'feature_fraction': 0.6915324297445733, 'bagging_fraction': 0.6413372514558348, 'bagging_freq': 6}. Best is trial 2 with value: 0.2078844121121917.\n","[I 2025-10-11 21:07:35,504] Trial 10 finished with value: 0.16865894287716351 and parameters: {'n_estimators': 1300, 'learning_rate': 0.23169439355459565, 'num_leaves': 193, 'max_depth': 6, 'lambda_l1': 3.7219589772509143, 'lambda_l2': 1.687202455973053e-05, 'feature_fraction': 0.6238197747410462, 'bagging_fraction': 0.8857210622776587, 'bagging_freq': 7}. Best is trial 2 with value: 0.2078844121121917.\n","[I 2025-10-11 21:07:48,699] Trial 11 finished with value: 0.19793806599189234 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05880534433897147, 'num_leaves': 143, 'max_depth': 6, 'lambda_l1': 6.210231076100056, 'lambda_l2': 1.5384969972984177e-08, 'feature_fraction': 0.8754922887391775, 'bagging_fraction': 0.7710699714690293, 'bagging_freq': 2}. Best is trial 2 with value: 0.2078844121121917.\n","[I 2025-10-11 21:08:08,864] Trial 12 finished with value: 0.19323284320520565 and parameters: {'n_estimators': 700, 'learning_rate': 0.027118455045143822, 'num_leaves': 94, 'max_depth': 7, 'lambda_l1': 0.09632522400811687, 'lambda_l2': 1.2633983701564635e-05, 'feature_fraction': 0.8723684138539645, 'bagging_fraction': 0.8426620741374765, 'bagging_freq': 3}. Best is trial 2 with value: 0.2078844121121917.\n"]},{"output_type":"stream","name":"stdout","text":["\n","[Optuna 조기 종료] 10번의 trial 동안 최고 점수가 갱신되지 않아 튜닝을 중단합니다.\n","\n","✅ 튜닝 완료!\n","\n","==================================================\n","🔬 최적 하이퍼파라미터 (Best Hyperparameters)\n","==================================================\n","        n_estimators: 1100\n","       learning_rate: 0.054114441477715575\n","          num_leaves: 300\n","           max_depth: 7\n","           lambda_l1: 8.681406465477098\n","           lambda_l2: 2.4854725646545834e-06\n","    feature_fraction: 0.9461824632394943\n","    bagging_fraction: 0.7161866797991427\n","        bagging_freq: 7\n","==================================================\n","\n","🔬 Step 5: 튜닝된 최종 모델 학습 및 평가...\n","✅ 튜닝된 모델 평가 완료.\n","\n","============================================================\n","📊 최종 성능 비교 결과 (Test Set)\n","============================================================\n","              PR AUC  ROC AUC  F1-Score\n","Baseline      0.1846   0.7771    0.0701\n","Optuna Tuned  0.1944   0.7709    0.0788\n","\n","============================================================\n","💾 Step 6: 최종 모델 예측 결과를 원본 CSV에 추가하여 저장\n","============================================================\n","✅ 모든 데이터의 예측 결과가 '/content/drive/MyDrive/review_helpfulness/PADA/results/s2/coursera/DistilBERT_coursera_with_s2_predictions.csv' 파일에 성공적으로 저장되었습니다.\n","\n","============================================================\n","🧹 Step 7: 사용된 변수들을 메모리에서 정리\n","============================================================\n","✅ 메모리 정리가 완료되었습니다.\n","\n","🎉 모든 과정이 완료되었습니다!\n"]}]},{"cell_type":"markdown","source":["# Audible"],"metadata":{"id":"5dG09xq9vAGI"}},{"cell_type":"markdown","source":["## T5"],"metadata":{"id":"x3s9_sz3vDgh"}},{"cell_type":"code","source":["# === 2. 환경설정 클래스 ===\n","class Config:\n","    \"\"\"실행에 필요한 모든 설정값을 중앙에서 관리합니다.\"\"\"\n","    # 🌟 1. 입력 파일 경로 설정\n","    CSV_FILE_PATH = \"/content/drive/MyDrive/review_helpfulness/PADA/data/audible/audible.csv\"\n","    EMBEDDING_PATH = \"/content/drive/MyDrive/review_helpfulness/PADA/embedding/audible_T5.npy\"\n","\n","    # 🌟 2. 최종 결과 CSV 파일 저장 경로 설정\n","    OUTPUT_CSV_PATH = \"/content/drive/MyDrive/review_helpfulness/PADA/results/s2/audible/T5_audible_with_s2_predictions.csv\"\n","\n","    # --- 데이터 정보 ---\n","    TARGET_COLUMN = 'binary_helpfulness'\n","\n","    # --- 데이터 분할 ---\n","    TEST_SPLIT_RATIO = 0.2\n","    RANDOM_STATE = 42\n","\n","    # --- Optuna 튜닝 설정 ---\n","    N_TRIALS = 50\n","    TUNING_METRIC = 'pr_auc'\n","    EARLY_STOPPING_ROUNDS = 10 # 🌟 Optuna 조기 종료 횟수\n","\n","# === 3. Optuna 조기 종료 콜백 ===\n","class EarlyStoppingCallback:\n","    \"\"\"Optuna 스터디의 조기 종료를 위한 콜백 클래스\"\"\"\n","    def __init__(self, early_stopping_rounds: int):\n","        self._early_stopping_rounds = early_stopping_rounds\n","        self._best_value = -float(\"inf\")\n","        self._counter = 0\n","\n","    def __call__(self, study: optuna.study.Study, trial: optuna.trial.Trial):\n","        current_best_value = study.best_value\n","        if current_best_value is not None and current_best_value > self._best_value:\n","            self._best_value = current_best_value\n","            self._counter = 0\n","        else:\n","            self._counter += 1\n","\n","        if self._counter >= self._early_stopping_rounds:\n","            print(f\"\\n[Optuna 조기 종료] {self._early_stopping_rounds}번의 trial 동안 최고 점수가 갱신되지 않아 튜닝을 중단합니다.\")\n","            study.stop()\n","\n","# === 4. Optuna Objective 함수 ===\n","def objective(trial, X, y):\n","    \"\"\"Optuna가 최적의 하이퍼파라미터를 찾기 위해 반복 호출하는 함수\"\"\"\n","    X_train, X_val, y_train, y_val = train_test_split(\n","        X, y, test_size=0.25, random_state=Config.RANDOM_STATE, stratify=y\n","    )\n","\n","    params = {\n","        'objective': 'binary', 'metric': 'logloss', 'verbosity': -1,\n","        'boosting_type': 'gbdt', 'random_state': Config.RANDOM_STATE,\n","        'device': 'gpu',  # 🌟 Optuna Trial 내부에서도 GPU 사용\n","        'n_estimators': trial.suggest_int('n_estimators', 100, 2000, step=100),\n","        'learning_rate': trial.suggest_float('learning_rate', 1e-3, 0.3, log=True),\n","        'num_leaves': trial.suggest_int('num_leaves', 20, 300),\n","        'max_depth': trial.suggest_int('max_depth', 3, 12),\n","        'lambda_l1': trial.suggest_float('lambda_l1', 1e-8, 10.0, log=True),\n","        'lambda_l2': trial.suggest_float('lambda_l2', 1e-8, 10.0, log=True),\n","        'feature_fraction': trial.suggest_float('feature_fraction', 0.6, 1.0),\n","        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.6, 1.0),\n","        'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\n","    }\n","\n","    model = lgb.LGBMClassifier(**params)\n","    model.fit(X_train, y_train,\n","              eval_set=[(X_val, y_val)],\n","              eval_metric='logloss',\n","              callbacks=[lgb.early_stopping(100, verbose=False)])\n","\n","    y_pred_proba = model.predict_proba(X_val)[:, 1]\n","    score = average_precision_score(y_val, y_pred_proba)\n","    return score\n","\n","# === 5. 메인 실행 블록 ===\n","if __name__ == '__main__':\n","    config = Config()\n","\n","    # ... (Step 1 ~ 2: 데이터 로드, 분할, 베이스라인 측정) ...\n","    print(\"Step 1: 데이터 로드 및 분할 중...\")\n","    try:\n","        df = pd.read_csv(config.CSV_FILE_PATH)\n","        labels = df[config.TARGET_COLUMN].values\n","        embeddings = np.load(config.EMBEDDING_PATH)\n","        assert len(df) == len(embeddings)\n","    except Exception as e:\n","        print(f\"🔥 파일 로드 실패: {e}\"); exit()\n","\n","    indices = np.arange(len(df))\n","    train_indices, test_indices = train_test_split(\n","        indices, test_size=config.TEST_SPLIT_RATIO, random_state=config.RANDOM_STATE, stratify=labels\n","    )\n","    X_train, X_test = embeddings[train_indices], embeddings[test_indices]\n","    y_train, y_test = labels[train_indices], labels[test_indices]\n","    print(f\"✅ 완료 (학습용: {len(y_train)}건, 테스트용: {len(y_test)}건)\")\n","\n","    print(\"\\n\" + \"=\"*50)\n","    print(\"📊 Step 2: 베이스라인 모델 성능 측정 (GPU 사용)\")\n","    print(\"=\"*50)\n","\n","    baseline_model = lgb.LGBMClassifier(device='gpu', random_state=config.RANDOM_STATE)\n","    baseline_model.fit(X_train, y_train)\n","\n","    y_pred_proba_base = baseline_model.predict_proba(X_test)[:, 1]\n","    y_pred_class_base = (y_pred_proba_base > 0.5).astype(int)\n","\n","    final_results = {}\n","    final_results['Baseline'] = {\n","        \"PR AUC\": average_precision_score(y_test, y_pred_proba_base),\n","        \"ROC AUC\": roc_auc_score(y_test, y_pred_proba_base),\n","        \"F1-Score\": f1_score(y_test, y_pred_class_base),\n","    }\n","    print(\"✅ 베이스라인 모델 평가 완료.\")\n","\n","    # --- Step 3: Optuna 튜닝 수행 (조기 종료 포함) ---\n","    print(\"\\n\" + \"=\"*50)\n","    print(f\"🔬 Step 3: Optuna 하이퍼파라미터 튜닝 시작 (GPU 사용)...\")\n","    print(f\"(최대 {config.N_TRIALS}번 시도, {config.EARLY_STOPPING_ROUNDS}번 개선 없으면 조기 종료)\")\n","    print(\"=\"*50)\n","\n","    early_stopping_callback = EarlyStoppingCallback(early_stopping_rounds=config.EARLY_STOPPING_ROUNDS)\n","    study = optuna.create_study(direction='maximize')\n","    pbar = tqdm(total=config.N_TRIALS, desc=\"Optuna 튜닝 진행률\")\n","\n","    try:\n","        study.optimize(lambda trial: objective(trial, X_train, y_train),\n","                       n_trials=config.N_TRIALS,\n","                       callbacks=[lambda study, trial: pbar.update(1), early_stopping_callback])\n","    except optuna.exceptions.OptunaError:\n","        # 조기 종료 시 발생하는 예외를 정상 처리\n","        pass\n","    pbar.close()\n","\n","    # ... (Step 4 ~ 6: 결과 출력, 저장, 메모리 정리) ...\n","    print(f\"\\n✅ 튜닝 완료!\")\n","    print(\"\\n\" + \"=\"*50)\n","    print(\"🔬 최적 하이퍼파라미터 (Best Hyperparameters)\")\n","    print(\"=\"*50)\n","    best_params = study.best_params\n","    for key, value in best_params.items():\n","        print(f\"{key:>20s}: {value}\")\n","    print(\"=\"*50)\n","\n","    print(f\"\\n🔬 Step 5: 튜닝된 최종 모델 학습 및 평가...\")\n","    final_model = lgb.LGBMClassifier(device='gpu', objective='binary', verbosity=-1, random_state=config.RANDOM_STATE, **best_params)\n","    final_model.fit(X_train, y_train)\n","\n","    y_pred_proba_tuned = final_model.predict_proba(X_test)[:, 1]\n","    y_pred_class_tuned = (y_pred_proba_tuned > 0.5).astype(int)\n","\n","    final_results['Optuna Tuned'] = {\n","        \"PR AUC\": average_precision_score(y_test, y_pred_proba_tuned),\n","        \"ROC AUC\": roc_auc_score(y_test, y_pred_proba_tuned),\n","        \"F1-Score\": f1_score(y_test, y_pred_class_tuned),\n","    }\n","    print(\"✅ 튜닝된 모델 평가 완료.\")\n","\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"📊 최종 성능 비교 결과 (Test Set)\")\n","    print(\"=\"*60)\n","    results_df = pd.DataFrame(final_results).T\n","    print(results_df.round(4))\n","\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"💾 Step 6: 최종 모델 예측 결과를 원본 CSV에 추가하여 저장\")\n","    print(\"=\"*60)\n","\n","    train_pred_proba = final_model.predict_proba(X_train)[:, 1]\n","    train_pred_class = (train_pred_proba > 0.5).astype(int)\n","\n","    df['s2_pred_proba'] = np.nan\n","    df['s2_pred_class'] = np.nan\n","\n","    df.loc[train_indices, 's2_pred_proba'] = train_pred_proba\n","    df.loc[train_indices, 's2_pred_class'] = train_pred_class\n","\n","    df.loc[test_indices, 's2_pred_proba'] = y_pred_proba_tuned\n","    df.loc[test_indices, 's2_pred_class'] = y_pred_class_tuned\n","\n","    # 🌟 Config에 설정된 경로로 최종 파일 저장\n","    df.to_csv(config.OUTPUT_CSV_PATH, index=False, encoding='utf-8-sig')\n","\n","    print(f\"✅ 모든 데이터의 예측 결과가 '{config.OUTPUT_CSV_PATH}' 파일에 성공적으로 저장되었습니다.\")\n","\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"🧹 Step 7: 사용된 변수들을 메모리에서 정리\")\n","    print(\"=\"*60)\n","\n","    vars_to_delete = [\n","        'df', 'labels', 'embeddings', 'indices', 'X_train', 'X_test',\n","        'y_train', 'y_test', 'train_indices', 'test_indices',\n","        'baseline_model', 'final_model', 'study',\n","    ]\n","    for var_name in vars_to_delete:\n","        if var_name in locals() or var_name in globals():\n","            if var_name in globals(): del globals()[var_name]\n","\n","    gc.collect()\n","    print(\"✅ 메모리 정리가 완료되었습니다.\")\n","\n","    print(\"\\n🎉 모든 과정이 완료되었습니다!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","referenced_widgets":["5568e6dca5cf4f339cd9f5bb695b8cf1","09ecd53c609749018ff803f9e0a6af2b","4f5676b2afaf43dc9db4567329d60e0d","91a6d51816b34a7299c0f74fa4220b08","d03e63daf9b340d4a264ae2bc34c1686","3b01489a7283419191d9788ba1e0a3f1","6e9566eac5864e51bda16254a6ca67c0","b80221133e224e7391c8d2f7c2192279","ae56566814d743ac874512137f415328","8965258d3a5a4322a4374058c4aa0a58","01a726b70a6e4d48af9fc12bb076f912"]},"id":"NIHVJi0fw6JL","executionInfo":{"status":"ok","timestamp":1760217581004,"user_tz":-540,"elapsed":631285,"user":{"displayName":"KW-data-analytics","userId":"09651493752354345908"}},"outputId":"693b3acd-9d5f-46d2-c0f3-608b40dc2289"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Step 1: 데이터 로드 및 분할 중...\n","✅ 완료 (학습용: 74391건, 테스트용: 18598건)\n","\n","==================================================\n","📊 Step 2: 베이스라인 모델 성능 측정 (GPU 사용)\n","==================================================\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-10-11 21:09:24,924] A new study created in memory with name: no-name-8d095473-fe9b-4213-8d93-05404b4f623b\n"]},{"output_type":"stream","name":"stdout","text":["✅ 베이스라인 모델 평가 완료.\n","\n","==================================================\n","🔬 Step 3: Optuna 하이퍼파라미터 튜닝 시작 (GPU 사용)...\n","(최대 50번 시도, 10번 개선 없으면 조기 종료)\n","==================================================\n"]},{"output_type":"display_data","data":{"text/plain":["Optuna 튜닝 진행률:   0%|          | 0/50 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5568e6dca5cf4f339cd9f5bb695b8cf1"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2025-10-11 21:10:56,660] Trial 0 finished with value: 0.1615461098561281 and parameters: {'n_estimators': 1900, 'learning_rate': 0.0018579444209650842, 'num_leaves': 46, 'max_depth': 11, 'lambda_l1': 2.3721396579494408e-05, 'lambda_l2': 5.656955078244137, 'feature_fraction': 0.7956508263749972, 'bagging_fraction': 0.7010694270666304, 'bagging_freq': 6}. Best is trial 0 with value: 0.1615461098561281.\n","[I 2025-10-11 21:11:04,457] Trial 1 finished with value: 0.1528516809693229 and parameters: {'n_estimators': 600, 'learning_rate': 0.03332928760418356, 'num_leaves': 205, 'max_depth': 3, 'lambda_l1': 9.047077665292781e-06, 'lambda_l2': 0.12909842284352258, 'feature_fraction': 0.9730000601078201, 'bagging_fraction': 0.7628127238052675, 'bagging_freq': 1}. Best is trial 0 with value: 0.1615461098561281.\n","[I 2025-10-11 21:11:12,531] Trial 2 finished with value: 0.15353316899212915 and parameters: {'n_estimators': 1500, 'learning_rate': 0.057215948070315055, 'num_leaves': 131, 'max_depth': 5, 'lambda_l1': 1.3360627906360456, 'lambda_l2': 0.27235833698416284, 'feature_fraction': 0.9786558788189205, 'bagging_fraction': 0.868346098381916, 'bagging_freq': 2}. Best is trial 0 with value: 0.1615461098561281.\n","[I 2025-10-11 21:11:54,096] Trial 3 finished with value: 0.15764224715369957 and parameters: {'n_estimators': 1300, 'learning_rate': 0.0010871715363238578, 'num_leaves': 88, 'max_depth': 6, 'lambda_l1': 1.4868167310265435e-08, 'lambda_l2': 2.612469765209332e-05, 'feature_fraction': 0.6526783526008374, 'bagging_fraction': 0.6947193232799487, 'bagging_freq': 2}. Best is trial 0 with value: 0.1615461098561281.\n","[I 2025-10-11 21:13:01,350] Trial 4 finished with value: 0.16330603145757366 and parameters: {'n_estimators': 1000, 'learning_rate': 0.004451578538008239, 'num_leaves': 74, 'max_depth': 9, 'lambda_l1': 0.48131928307825345, 'lambda_l2': 0.025837136669473012, 'feature_fraction': 0.863991217155609, 'bagging_fraction': 0.9372161621462469, 'bagging_freq': 7}. Best is trial 4 with value: 0.16330603145757366.\n","[I 2025-10-11 21:13:11,480] Trial 5 finished with value: 0.14497070803233011 and parameters: {'n_estimators': 1900, 'learning_rate': 0.0947734948673194, 'num_leaves': 44, 'max_depth': 11, 'lambda_l1': 1.2246051880373563e-08, 'lambda_l2': 5.8077424606785755, 'feature_fraction': 0.8884054359685551, 'bagging_fraction': 0.7065440533769375, 'bagging_freq': 6}. Best is trial 4 with value: 0.16330603145757366.\n","[I 2025-10-11 21:13:18,929] Trial 6 finished with value: 0.12891184260310656 and parameters: {'n_estimators': 1000, 'learning_rate': 0.1902849448230646, 'num_leaves': 288, 'max_depth': 6, 'lambda_l1': 2.249514741262388e-06, 'lambda_l2': 9.71450101834524e-06, 'feature_fraction': 0.7759800018650901, 'bagging_fraction': 0.8713787287545912, 'bagging_freq': 1}. Best is trial 4 with value: 0.16330603145757366.\n","[I 2025-10-11 21:13:24,224] Trial 7 finished with value: 0.1524014979773715 and parameters: {'n_estimators': 800, 'learning_rate': 0.13734673806308942, 'num_leaves': 148, 'max_depth': 3, 'lambda_l1': 0.07288506487879824, 'lambda_l2': 2.245463481749996, 'feature_fraction': 0.6684724315511402, 'bagging_fraction': 0.6892506937842828, 'bagging_freq': 3}. Best is trial 4 with value: 0.16330603145757366.\n","[I 2025-10-11 21:13:32,056] Trial 8 finished with value: 0.1515877653495546 and parameters: {'n_estimators': 300, 'learning_rate': 0.007479972135671346, 'num_leaves': 288, 'max_depth': 4, 'lambda_l1': 2.822884111441931e-05, 'lambda_l2': 0.08314013951859653, 'feature_fraction': 0.8053975590973463, 'bagging_fraction': 0.9668737734478126, 'bagging_freq': 1}. Best is trial 4 with value: 0.16330603145757366.\n","[I 2025-10-11 21:13:42,951] Trial 9 finished with value: 0.15278531354768873 and parameters: {'n_estimators': 1100, 'learning_rate': 0.003990121716035367, 'num_leaves': 133, 'max_depth': 3, 'lambda_l1': 1.5766263077693007e-05, 'lambda_l2': 8.865044635127063e-05, 'feature_fraction': 0.6851455969160566, 'bagging_fraction': 0.7900950565748626, 'bagging_freq': 1}. Best is trial 4 with value: 0.16330603145757366.\n","[I 2025-10-11 21:14:14,778] Trial 10 finished with value: 0.15588312285030187 and parameters: {'n_estimators': 200, 'learning_rate': 0.01277224225438955, 'num_leaves': 205, 'max_depth': 9, 'lambda_l1': 0.010063429367238455, 'lambda_l2': 2.0193540696230805e-08, 'feature_fraction': 0.8853359884622329, 'bagging_fraction': 0.9935056138451409, 'bagging_freq': 7}. Best is trial 4 with value: 0.16330603145757366.\n","[I 2025-10-11 21:15:03,088] Trial 11 finished with value: 0.15871763953433465 and parameters: {'n_estimators': 2000, 'learning_rate': 0.001794836798743251, 'num_leaves': 24, 'max_depth': 12, 'lambda_l1': 0.0020549434781514594, 'lambda_l2': 0.004558810077357563, 'feature_fraction': 0.7858472075263069, 'bagging_fraction': 0.6010661917515102, 'bagging_freq': 5}. Best is trial 4 with value: 0.16330603145757366.\n","[I 2025-10-11 21:16:43,598] Trial 12 finished with value: 0.16252412133757244 and parameters: {'n_estimators': 1600, 'learning_rate': 0.003604944923258078, 'num_leaves': 79, 'max_depth': 9, 'lambda_l1': 7.258668779223952, 'lambda_l2': 0.003791723190343649, 'feature_fraction': 0.8608358326657027, 'bagging_fraction': 0.904224523684423, 'bagging_freq': 7}. Best is trial 4 with value: 0.16330603145757366.\n","[I 2025-10-11 21:17:58,726] Trial 13 finished with value: 0.16027776191490467 and parameters: {'n_estimators': 1500, 'learning_rate': 0.004687953844508598, 'num_leaves': 88, 'max_depth': 9, 'lambda_l1': 6.469965528902224, 'lambda_l2': 0.002217193580476454, 'feature_fraction': 0.8841427830657571, 'bagging_fraction': 0.9135926421120273, 'bagging_freq': 7}. Best is trial 4 with value: 0.16330603145757366.\n","[I 2025-10-11 21:18:25,737] Trial 14 finished with value: 0.1587577071168597 and parameters: {'n_estimators': 1600, 'learning_rate': 0.01203170934478712, 'num_leaves': 81, 'max_depth': 8, 'lambda_l1': 0.4378383064563237, 'lambda_l2': 0.002305012100092566, 'feature_fraction': 0.8575651350964849, 'bagging_fraction': 0.9248063117505144, 'bagging_freq': 5}. Best is trial 4 with value: 0.16330603145757366.\n"]},{"output_type":"stream","name":"stdout","text":["\n","[Optuna 조기 종료] 10번의 trial 동안 최고 점수가 갱신되지 않아 튜닝을 중단합니다.\n","\n","✅ 튜닝 완료!\n","\n","==================================================\n","🔬 최적 하이퍼파라미터 (Best Hyperparameters)\n","==================================================\n","        n_estimators: 1000\n","       learning_rate: 0.004451578538008239\n","          num_leaves: 74\n","           max_depth: 9\n","           lambda_l1: 0.48131928307825345\n","           lambda_l2: 0.025837136669473012\n","    feature_fraction: 0.863991217155609\n","    bagging_fraction: 0.9372161621462469\n","        bagging_freq: 7\n","==================================================\n","\n","🔬 Step 5: 튜닝된 최종 모델 학습 및 평가...\n","✅ 튜닝된 모델 평가 완료.\n","\n","============================================================\n","📊 최종 성능 비교 결과 (Test Set)\n","============================================================\n","              PR AUC  ROC AUC  F1-Score\n","Baseline      0.1575   0.6698    0.0087\n","Optuna Tuned  0.1716   0.6845    0.0000\n","\n","============================================================\n","💾 Step 6: 최종 모델 예측 결과를 원본 CSV에 추가하여 저장\n","============================================================\n","✅ 모든 데이터의 예측 결과가 '/content/drive/MyDrive/review_helpfulness/PADA/results/s2/audible/T5_audible_with_s2_predictions.csv' 파일에 성공적으로 저장되었습니다.\n","\n","============================================================\n","🧹 Step 7: 사용된 변수들을 메모리에서 정리\n","============================================================\n","✅ 메모리 정리가 완료되었습니다.\n","\n","🎉 모든 과정이 완료되었습니다!\n"]}]},{"cell_type":"markdown","source":["## BERT"],"metadata":{"id":"ty6_-AJIvDxN"}},{"cell_type":"code","source":["# === 2. 환경설정 클래스 ===\n","class Config:\n","    \"\"\"실행에 필요한 모든 설정값을 중앙에서 관리합니다.\"\"\"\n","    # 🌟 1. 입력 파일 경로 설정\n","    CSV_FILE_PATH = \"/content/drive/MyDrive/review_helpfulness/PADA/data/audible/audible.csv\"\n","    EMBEDDING_PATH = \"/content/drive/MyDrive/review_helpfulness/PADA/embedding/audible_BERT.npy\"\n","\n","    # 🌟 2. 최종 결과 CSV 파일 저장 경로 설정\n","    OUTPUT_CSV_PATH = \"/content/drive/MyDrive/review_helpfulness/PADA/results/s2/audible/BERT_audible_with_s2_predictions.csv\"\n","\n","    # --- 데이터 정보 ---\n","    TARGET_COLUMN = 'binary_helpfulness'\n","\n","    # --- 데이터 분할 ---\n","    TEST_SPLIT_RATIO = 0.2\n","    RANDOM_STATE = 42\n","\n","    # --- Optuna 튜닝 설정 ---\n","    N_TRIALS = 50\n","    TUNING_METRIC = 'pr_auc'\n","    EARLY_STOPPING_ROUNDS = 10 # 🌟 Optuna 조기 종료 횟수\n","\n","# === 3. Optuna 조기 종료 콜백 ===\n","class EarlyStoppingCallback:\n","    \"\"\"Optuna 스터디의 조기 종료를 위한 콜백 클래스\"\"\"\n","    def __init__(self, early_stopping_rounds: int):\n","        self._early_stopping_rounds = early_stopping_rounds\n","        self._best_value = -float(\"inf\")\n","        self._counter = 0\n","\n","    def __call__(self, study: optuna.study.Study, trial: optuna.trial.Trial):\n","        current_best_value = study.best_value\n","        if current_best_value is not None and current_best_value > self._best_value:\n","            self._best_value = current_best_value\n","            self._counter = 0\n","        else:\n","            self._counter += 1\n","\n","        if self._counter >= self._early_stopping_rounds:\n","            print(f\"\\n[Optuna 조기 종료] {self._early_stopping_rounds}번의 trial 동안 최고 점수가 갱신되지 않아 튜닝을 중단합니다.\")\n","            study.stop()\n","\n","# === 4. Optuna Objective 함수 ===\n","def objective(trial, X, y):\n","    \"\"\"Optuna가 최적의 하이퍼파라미터를 찾기 위해 반복 호출하는 함수\"\"\"\n","    X_train, X_val, y_train, y_val = train_test_split(\n","        X, y, test_size=0.25, random_state=Config.RANDOM_STATE, stratify=y\n","    )\n","\n","    params = {\n","        'objective': 'binary', 'metric': 'logloss', 'verbosity': -1,\n","        'boosting_type': 'gbdt', 'random_state': Config.RANDOM_STATE,\n","        'device': 'gpu',  # 🌟 Optuna Trial 내부에서도 GPU 사용\n","        'n_estimators': trial.suggest_int('n_estimators', 100, 2000, step=100),\n","        'learning_rate': trial.suggest_float('learning_rate', 1e-3, 0.3, log=True),\n","        'num_leaves': trial.suggest_int('num_leaves', 20, 300),\n","        'max_depth': trial.suggest_int('max_depth', 3, 12),\n","        'lambda_l1': trial.suggest_float('lambda_l1', 1e-8, 10.0, log=True),\n","        'lambda_l2': trial.suggest_float('lambda_l2', 1e-8, 10.0, log=True),\n","        'feature_fraction': trial.suggest_float('feature_fraction', 0.6, 1.0),\n","        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.6, 1.0),\n","        'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\n","    }\n","\n","    model = lgb.LGBMClassifier(**params)\n","    model.fit(X_train, y_train,\n","              eval_set=[(X_val, y_val)],\n","              eval_metric='logloss',\n","              callbacks=[lgb.early_stopping(100, verbose=False)])\n","\n","    y_pred_proba = model.predict_proba(X_val)[:, 1]\n","    score = average_precision_score(y_val, y_pred_proba)\n","    return score\n","\n","# === 5. 메인 실행 블록 ===\n","if __name__ == '__main__':\n","    config = Config()\n","\n","    # ... (Step 1 ~ 2: 데이터 로드, 분할, 베이스라인 측정) ...\n","    print(\"Step 1: 데이터 로드 및 분할 중...\")\n","    try:\n","        df = pd.read_csv(config.CSV_FILE_PATH)\n","        labels = df[config.TARGET_COLUMN].values\n","        embeddings = np.load(config.EMBEDDING_PATH)\n","        assert len(df) == len(embeddings)\n","    except Exception as e:\n","        print(f\"🔥 파일 로드 실패: {e}\"); exit()\n","\n","    indices = np.arange(len(df))\n","    train_indices, test_indices = train_test_split(\n","        indices, test_size=config.TEST_SPLIT_RATIO, random_state=config.RANDOM_STATE, stratify=labels\n","    )\n","    X_train, X_test = embeddings[train_indices], embeddings[test_indices]\n","    y_train, y_test = labels[train_indices], labels[test_indices]\n","    print(f\"✅ 완료 (학습용: {len(y_train)}건, 테스트용: {len(y_test)}건)\")\n","\n","    print(\"\\n\" + \"=\"*50)\n","    print(\"📊 Step 2: 베이스라인 모델 성능 측정 (GPU 사용)\")\n","    print(\"=\"*50)\n","\n","    baseline_model = lgb.LGBMClassifier(device='gpu', random_state=config.RANDOM_STATE)\n","    baseline_model.fit(X_train, y_train)\n","\n","    y_pred_proba_base = baseline_model.predict_proba(X_test)[:, 1]\n","    y_pred_class_base = (y_pred_proba_base > 0.5).astype(int)\n","\n","    final_results = {}\n","    final_results['Baseline'] = {\n","        \"PR AUC\": average_precision_score(y_test, y_pred_proba_base),\n","        \"ROC AUC\": roc_auc_score(y_test, y_pred_proba_base),\n","        \"F1-Score\": f1_score(y_test, y_pred_class_base),\n","    }\n","    print(\"✅ 베이스라인 모델 평가 완료.\")\n","\n","    # --- Step 3: Optuna 튜닝 수행 (조기 종료 포함) ---\n","    print(\"\\n\" + \"=\"*50)\n","    print(f\"🔬 Step 3: Optuna 하이퍼파라미터 튜닝 시작 (GPU 사용)...\")\n","    print(f\"(최대 {config.N_TRIALS}번 시도, {config.EARLY_STOPPING_ROUNDS}번 개선 없으면 조기 종료)\")\n","    print(\"=\"*50)\n","\n","    early_stopping_callback = EarlyStoppingCallback(early_stopping_rounds=config.EARLY_STOPPING_ROUNDS)\n","    study = optuna.create_study(direction='maximize')\n","    pbar = tqdm(total=config.N_TRIALS, desc=\"Optuna 튜닝 진행률\")\n","\n","    try:\n","        study.optimize(lambda trial: objective(trial, X_train, y_train),\n","                       n_trials=config.N_TRIALS,\n","                       callbacks=[lambda study, trial: pbar.update(1), early_stopping_callback])\n","    except optuna.exceptions.OptunaError:\n","        # 조기 종료 시 발생하는 예외를 정상 처리\n","        pass\n","    pbar.close()\n","\n","    # ... (Step 4 ~ 6: 결과 출력, 저장, 메모리 정리) ...\n","    print(f\"\\n✅ 튜닝 완료!\")\n","    print(\"\\n\" + \"=\"*50)\n","    print(\"🔬 최적 하이퍼파라미터 (Best Hyperparameters)\")\n","    print(\"=\"*50)\n","    best_params = study.best_params\n","    for key, value in best_params.items():\n","        print(f\"{key:>20s}: {value}\")\n","    print(\"=\"*50)\n","\n","    print(f\"\\n🔬 Step 5: 튜닝된 최종 모델 학습 및 평가...\")\n","    final_model = lgb.LGBMClassifier(device='gpu', objective='binary', verbosity=-1, random_state=config.RANDOM_STATE, **best_params)\n","    final_model.fit(X_train, y_train)\n","\n","    y_pred_proba_tuned = final_model.predict_proba(X_test)[:, 1]\n","    y_pred_class_tuned = (y_pred_proba_tuned > 0.5).astype(int)\n","\n","    final_results['Optuna Tuned'] = {\n","        \"PR AUC\": average_precision_score(y_test, y_pred_proba_tuned),\n","        \"ROC AUC\": roc_auc_score(y_test, y_pred_proba_tuned),\n","        \"F1-Score\": f1_score(y_test, y_pred_class_tuned),\n","    }\n","    print(\"✅ 튜닝된 모델 평가 완료.\")\n","\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"📊 최종 성능 비교 결과 (Test Set)\")\n","    print(\"=\"*60)\n","    results_df = pd.DataFrame(final_results).T\n","    print(results_df.round(4))\n","\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"💾 Step 6: 최종 모델 예측 결과를 원본 CSV에 추가하여 저장\")\n","    print(\"=\"*60)\n","\n","    train_pred_proba = final_model.predict_proba(X_train)[:, 1]\n","    train_pred_class = (train_pred_proba > 0.5).astype(int)\n","\n","    df['s2_pred_proba'] = np.nan\n","    df['s2_pred_class'] = np.nan\n","\n","    df.loc[train_indices, 's2_pred_proba'] = train_pred_proba\n","    df.loc[train_indices, 's2_pred_class'] = train_pred_class\n","\n","    df.loc[test_indices, 's2_pred_proba'] = y_pred_proba_tuned\n","    df.loc[test_indices, 's2_pred_class'] = y_pred_class_tuned\n","\n","    # 🌟 Config에 설정된 경로로 최종 파일 저장\n","    df.to_csv(config.OUTPUT_CSV_PATH, index=False, encoding='utf-8-sig')\n","\n","    print(f\"✅ 모든 데이터의 예측 결과가 '{config.OUTPUT_CSV_PATH}' 파일에 성공적으로 저장되었습니다.\")\n","\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"🧹 Step 7: 사용된 변수들을 메모리에서 정리\")\n","    print(\"=\"*60)\n","\n","    vars_to_delete = [\n","        'df', 'labels', 'embeddings', 'indices', 'X_train', 'X_test',\n","        'y_train', 'y_test', 'train_indices', 'test_indices',\n","        'baseline_model', 'final_model', 'study',\n","    ]\n","    for var_name in vars_to_delete:\n","        if var_name in locals() or var_name in globals():\n","            if var_name in globals(): del globals()[var_name]\n","\n","    gc.collect()\n","    print(\"✅ 메모리 정리가 완료되었습니다.\")\n","\n","    print(\"\\n🎉 모든 과정이 완료되었습니다!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","referenced_widgets":["10860ddc842942509f9f48fa823d1137","2eb84d70cb63405d89a8eb545d1b2357","fbeda94d79ca4101a79a90f32742c9de","6e6a9ebcea58414d9bd7c51a31a7048c","fce18f20ff504908977255f76c7eedf0","fc6381417db140bb8a98b5586ff53ede","a35b1595c5b9412ba7687bba3d495681","f94fd1fcbd164ad8ab0d5f8961ecb6e1","b3ec152d7bc3492a9da18953f5eff250","7cd9d89cdc5243cf8d56c2686a296071","2b581eb3ff934fb3b8b47c5782df5663"]},"id":"Tx_nHJ-fxRSJ","executionInfo":{"status":"ok","timestamp":1760218132567,"user_tz":-540,"elapsed":551559,"user":{"displayName":"KW-data-analytics","userId":"09651493752354345908"}},"outputId":"c8235f81-c31b-46ff-8295-aa908aec71a6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Step 1: 데이터 로드 및 분할 중...\n","✅ 완료 (학습용: 74391건, 테스트용: 18598건)\n","\n","==================================================\n","📊 Step 2: 베이스라인 모델 성능 측정 (GPU 사용)\n","==================================================\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-10-11 21:19:53,414] A new study created in memory with name: no-name-dc33f4cb-91d2-49e2-8852-9775545cf8dd\n"]},{"output_type":"stream","name":"stdout","text":["✅ 베이스라인 모델 평가 완료.\n","\n","==================================================\n","🔬 Step 3: Optuna 하이퍼파라미터 튜닝 시작 (GPU 사용)...\n","(최대 50번 시도, 10번 개선 없으면 조기 종료)\n","==================================================\n"]},{"output_type":"display_data","data":{"text/plain":["Optuna 튜닝 진행률:   0%|          | 0/50 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"10860ddc842942509f9f48fa823d1137"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2025-10-11 21:20:05,602] Trial 0 finished with value: 0.141489347632069 and parameters: {'n_estimators': 2000, 'learning_rate': 0.054895265457821786, 'num_leaves': 107, 'max_depth': 7, 'lambda_l1': 0.004888051041968124, 'lambda_l2': 1.0519181140301666e-07, 'feature_fraction': 0.9077283755222015, 'bagging_fraction': 0.8228296331058187, 'bagging_freq': 2}. Best is trial 0 with value: 0.141489347632069.\n","[I 2025-10-11 21:20:18,506] Trial 1 finished with value: 0.1298104509563271 and parameters: {'n_estimators': 300, 'learning_rate': 0.09550865772153064, 'num_leaves': 93, 'max_depth': 8, 'lambda_l1': 0.0034754729926163947, 'lambda_l2': 3.207493039666788e-08, 'feature_fraction': 0.9110144518733756, 'bagging_fraction': 0.9266395446871918, 'bagging_freq': 5}. Best is trial 0 with value: 0.141489347632069.\n","[I 2025-10-11 21:21:20,618] Trial 2 finished with value: 0.1423933619722336 and parameters: {'n_estimators': 1200, 'learning_rate': 0.008036989670498467, 'num_leaves': 221, 'max_depth': 12, 'lambda_l1': 0.0018064020706019058, 'lambda_l2': 1.3557583770428637e-08, 'feature_fraction': 0.8552874960396686, 'bagging_fraction': 0.7484492256032538, 'bagging_freq': 4}. Best is trial 2 with value: 0.1423933619722336.\n","[I 2025-10-11 21:21:33,253] Trial 3 finished with value: 0.12064865680751051 and parameters: {'n_estimators': 1200, 'learning_rate': 0.08389341264307007, 'num_leaves': 136, 'max_depth': 9, 'lambda_l1': 3.297795326319156e-08, 'lambda_l2': 2.0190346751557318e-08, 'feature_fraction': 0.6161931011749259, 'bagging_fraction': 0.7004383633779975, 'bagging_freq': 1}. Best is trial 2 with value: 0.1423933619722336.\n","[I 2025-10-11 21:21:46,564] Trial 4 finished with value: 0.14579109379028163 and parameters: {'n_estimators': 900, 'learning_rate': 0.019876993646764436, 'num_leaves': 160, 'max_depth': 5, 'lambda_l1': 0.009777396744624578, 'lambda_l2': 8.288743947055266e-05, 'feature_fraction': 0.9584664399175973, 'bagging_fraction': 0.9388400063085297, 'bagging_freq': 7}. Best is trial 4 with value: 0.14579109379028163.\n","[I 2025-10-11 21:21:51,709] Trial 5 finished with value: 0.13403818859085018 and parameters: {'n_estimators': 100, 'learning_rate': 0.01135428318548622, 'num_leaves': 223, 'max_depth': 3, 'lambda_l1': 0.049614761120907784, 'lambda_l2': 0.8749770073329687, 'feature_fraction': 0.9328668026160344, 'bagging_fraction': 0.7475255387154842, 'bagging_freq': 3}. Best is trial 4 with value: 0.14579109379028163.\n","[I 2025-10-11 21:21:59,860] Trial 6 finished with value: 0.14101303493423137 and parameters: {'n_estimators': 1100, 'learning_rate': 0.10515494287410158, 'num_leaves': 272, 'max_depth': 5, 'lambda_l1': 0.0582621564658254, 'lambda_l2': 4.662125446745887, 'feature_fraction': 0.9353683946360651, 'bagging_fraction': 0.6108691384379911, 'bagging_freq': 2}. Best is trial 4 with value: 0.14579109379028163.\n","[I 2025-10-11 21:22:14,327] Trial 7 finished with value: 0.10220505661828279 and parameters: {'n_estimators': 1700, 'learning_rate': 0.1732026759388837, 'num_leaves': 195, 'max_depth': 9, 'lambda_l1': 0.1525078178612488, 'lambda_l2': 4.936533940475884e-07, 'feature_fraction': 0.6856321461636847, 'bagging_fraction': 0.7386992302402496, 'bagging_freq': 6}. Best is trial 4 with value: 0.14579109379028163.\n","[I 2025-10-11 21:23:22,857] Trial 8 finished with value: 0.14409400783130072 and parameters: {'n_estimators': 1400, 'learning_rate': 0.0018989509352783395, 'num_leaves': 105, 'max_depth': 7, 'lambda_l1': 0.00039542845614154134, 'lambda_l2': 0.0983407718552821, 'feature_fraction': 0.6135088660933862, 'bagging_fraction': 0.7448747904603457, 'bagging_freq': 4}. Best is trial 4 with value: 0.14579109379028163.\n","[I 2025-10-11 21:23:41,990] Trial 9 finished with value: 0.13053404040781172 and parameters: {'n_estimators': 200, 'learning_rate': 0.03814190304595668, 'num_leaves': 196, 'max_depth': 9, 'lambda_l1': 0.00011276022744836091, 'lambda_l2': 4.0534723952916065e-07, 'feature_fraction': 0.6840641224938638, 'bagging_fraction': 0.9209021827587802, 'bagging_freq': 5}. Best is trial 4 with value: 0.14579109379028163.\n","[I 2025-10-11 21:23:51,123] Trial 10 finished with value: 0.1419157721970264 and parameters: {'n_estimators': 700, 'learning_rate': 0.0039588193387343155, 'num_leaves': 46, 'max_depth': 3, 'lambda_l1': 1.5869935501044645e-05, 'lambda_l2': 0.0001719150255118725, 'feature_fraction': 0.9876117755243645, 'bagging_fraction': 0.9852511761662366, 'bagging_freq': 7}. Best is trial 4 with value: 0.14579109379028163.\n","[I 2025-10-11 21:24:16,753] Trial 11 finished with value: 0.13889452368913938 and parameters: {'n_estimators': 700, 'learning_rate': 0.0011002896737123769, 'num_leaves': 44, 'max_depth': 6, 'lambda_l1': 3.2801226649612733e-06, 'lambda_l2': 0.010739768579237132, 'feature_fraction': 0.7759249837501059, 'bagging_fraction': 0.8372697889659402, 'bagging_freq': 7}. Best is trial 4 with value: 0.14579109379028163.\n","[I 2025-10-11 21:24:54,279] Trial 12 finished with value: 0.14470421203697714 and parameters: {'n_estimators': 1600, 'learning_rate': 0.001919680534985917, 'num_leaves': 155, 'max_depth': 5, 'lambda_l1': 0.8877599758262286, 'lambda_l2': 0.00011398097666963258, 'feature_fraction': 0.7862507178579927, 'bagging_fraction': 0.8852669333996092, 'bagging_freq': 4}. Best is trial 4 with value: 0.14579109379028163.\n","[I 2025-10-11 21:25:14,633] Trial 13 finished with value: 0.14852776124552525 and parameters: {'n_estimators': 800, 'learning_rate': 0.005240875296109549, 'num_leaves': 151, 'max_depth': 5, 'lambda_l1': 5.1983918933043665, 'lambda_l2': 7.281634579884682e-05, 'feature_fraction': 0.7934535366974442, 'bagging_fraction': 0.8975792466173078, 'bagging_freq': 5}. Best is trial 13 with value: 0.14852776124552525.\n","[I 2025-10-11 21:25:27,093] Trial 14 finished with value: 0.15180412242380362 and parameters: {'n_estimators': 700, 'learning_rate': 0.024167532604579968, 'num_leaves': 291, 'max_depth': 4, 'lambda_l1': 9.915177774108065, 'lambda_l2': 9.576513124393539e-06, 'feature_fraction': 0.8492264398759357, 'bagging_fraction': 0.9935626253634324, 'bagging_freq': 6}. Best is trial 14 with value: 0.15180412242380362.\n","[I 2025-10-11 21:25:37,481] Trial 15 finished with value: 0.15142239867566926 and parameters: {'n_estimators': 500, 'learning_rate': 0.02391381843365669, 'num_leaves': 299, 'max_depth': 4, 'lambda_l1': 9.702902860917122, 'lambda_l2': 5.288743129535531e-06, 'feature_fraction': 0.8472882280447704, 'bagging_fraction': 0.9912782331408507, 'bagging_freq': 6}. Best is trial 14 with value: 0.15180412242380362.\n","[I 2025-10-11 21:25:45,559] Trial 16 finished with value: 0.15055345381353008 and parameters: {'n_estimators': 500, 'learning_rate': 0.024539285297014372, 'num_leaves': 296, 'max_depth': 3, 'lambda_l1': 2.9360496661778095, 'lambda_l2': 4.6716353763441655e-06, 'feature_fraction': 0.8301634725495597, 'bagging_fraction': 0.9989531880080534, 'bagging_freq': 6}. Best is trial 14 with value: 0.15180412242380362.\n","[I 2025-10-11 21:25:55,081] Trial 17 finished with value: 0.1522280422408131 and parameters: {'n_estimators': 500, 'learning_rate': 0.030044984363995508, 'num_leaves': 262, 'max_depth': 4, 'lambda_l1': 9.077806269171756, 'lambda_l2': 6.3250682477191635e-06, 'feature_fraction': 0.7366381892130716, 'bagging_fraction': 0.9611284347056361, 'bagging_freq': 6}. Best is trial 17 with value: 0.1522280422408131.\n","[I 2025-10-11 21:26:16,063] Trial 18 finished with value: 0.09372907499377627 and parameters: {'n_estimators': 400, 'learning_rate': 0.21196074718873903, 'num_leaves': 258, 'max_depth': 11, 'lambda_l1': 0.3752177290472127, 'lambda_l2': 0.0012419129262883596, 'feature_fraction': 0.7213201484883871, 'bagging_fraction': 0.9578850954966013, 'bagging_freq': 6}. Best is trial 17 with value: 0.1522280422408131.\n","[I 2025-10-11 21:26:28,263] Trial 19 finished with value: 0.14547614729426384 and parameters: {'n_estimators': 900, 'learning_rate': 0.011677990077747898, 'num_leaves': 253, 'max_depth': 4, 'lambda_l1': 1.7984875838005337e-07, 'lambda_l2': 4.06591507300334e-06, 'feature_fraction': 0.7438147282473846, 'bagging_fraction': 0.8589168484319215, 'bagging_freq': 5}. Best is trial 17 with value: 0.1522280422408131.\n","[I 2025-10-11 21:26:38,815] Trial 20 finished with value: 0.1402923930319301 and parameters: {'n_estimators': 600, 'learning_rate': 0.04050386036794374, 'num_leaves': 242, 'max_depth': 6, 'lambda_l1': 0.8865780151258779, 'lambda_l2': 0.0018641953935872929, 'feature_fraction': 0.8657436400980449, 'bagging_fraction': 0.7985776399407569, 'bagging_freq': 7}. Best is trial 17 with value: 0.1522280422408131.\n","[I 2025-10-11 21:26:48,962] Trial 21 finished with value: 0.15222795020952595 and parameters: {'n_estimators': 500, 'learning_rate': 0.025147103007795147, 'num_leaves': 294, 'max_depth': 4, 'lambda_l1': 7.767493928633089, 'lambda_l2': 8.508958780007792e-06, 'feature_fraction': 0.8541307759281672, 'bagging_fraction': 0.9691225229949292, 'bagging_freq': 6}. Best is trial 17 with value: 0.1522280422408131.\n","[I 2025-10-11 21:26:56,688] Trial 22 finished with value: 0.15334993777794687 and parameters: {'n_estimators': 300, 'learning_rate': 0.03592280632071865, 'num_leaves': 285, 'max_depth': 4, 'lambda_l1': 6.868642672596015, 'lambda_l2': 1.1929083069353505e-05, 'feature_fraction': 0.8209357514611245, 'bagging_fraction': 0.9601977186143064, 'bagging_freq': 6}. Best is trial 22 with value: 0.15334993777794687.\n","[I 2025-10-11 21:27:02,667] Trial 23 finished with value: 0.14652075225686714 and parameters: {'n_estimators': 100, 'learning_rate': 0.054569927620435374, 'num_leaves': 272, 'max_depth': 4, 'lambda_l1': 1.1742138737076286, 'lambda_l2': 9.383090991459793e-07, 'feature_fraction': 0.752818111969133, 'bagging_fraction': 0.9567134200466192, 'bagging_freq': 5}. Best is trial 22 with value: 0.15334993777794687.\n","[I 2025-10-11 21:27:19,638] Trial 24 finished with value: 0.1451494333167023 and parameters: {'n_estimators': 400, 'learning_rate': 0.01363252391775751, 'num_leaves': 227, 'max_depth': 6, 'lambda_l1': 0.0390149728944729, 'lambda_l2': 2.3751643039970694e-05, 'feature_fraction': 0.8075694518222757, 'bagging_fraction': 0.8928538912523559, 'bagging_freq': 6}. Best is trial 22 with value: 0.15334993777794687.\n","[I 2025-10-11 21:27:26,070] Trial 25 finished with value: 0.1474340198527384 and parameters: {'n_estimators': 300, 'learning_rate': 0.038708457056173366, 'num_leaves': 277, 'max_depth': 3, 'lambda_l1': 0.27228329871313045, 'lambda_l2': 0.0014607067592994692, 'feature_fraction': 0.8888330455476166, 'bagging_fraction': 0.9522461363383515, 'bagging_freq': 7}. Best is trial 22 with value: 0.15334993777794687.\n","[I 2025-10-11 21:27:35,475] Trial 26 finished with value: 0.14688187368020234 and parameters: {'n_estimators': 500, 'learning_rate': 0.007164770944977195, 'num_leaves': 188, 'max_depth': 4, 'lambda_l1': 9.864824611575258, 'lambda_l2': 1.0505719354714758e-06, 'feature_fraction': 0.6807054448125963, 'bagging_fraction': 0.907274484980566, 'bagging_freq': 3}. Best is trial 22 with value: 0.15334993777794687.\n","[I 2025-10-11 21:27:46,177] Trial 27 finished with value: 0.14227703817700676 and parameters: {'n_estimators': 300, 'learning_rate': 0.06341159284785113, 'num_leaves': 244, 'max_depth': 6, 'lambda_l1': 1.5717677651626392, 'lambda_l2': 2.378937391195131e-05, 'feature_fraction': 0.8238135258716707, 'bagging_fraction': 0.8710343610797773, 'bagging_freq': 5}. Best is trial 22 with value: 0.15334993777794687.\n","[I 2025-10-11 21:27:53,036] Trial 28 finished with value: 0.13644297889181262 and parameters: {'n_estimators': 900, 'learning_rate': 0.15094100582415423, 'num_leaves': 266, 'max_depth': 5, 'lambda_l1': 0.19298154743743046, 'lambda_l2': 9.16775705060407e-08, 'feature_fraction': 0.7201117775328599, 'bagging_fraction': 0.9674473603408327, 'bagging_freq': 6}. Best is trial 22 with value: 0.15334993777794687.\n","[I 2025-10-11 21:28:03,288] Trial 29 finished with value: 0.14137820989040145 and parameters: {'n_estimators': 100, 'learning_rate': 0.0161725617277237, 'num_leaves': 284, 'max_depth': 7, 'lambda_l1': 0.022651288423405136, 'lambda_l2': 1.379299764793093e-07, 'feature_fraction': 0.8757600040388229, 'bagging_fraction': 0.8094431621219041, 'bagging_freq': 3}. Best is trial 22 with value: 0.15334993777794687.\n","[I 2025-10-11 21:28:22,213] Trial 30 finished with value: 0.14158743565243662 and parameters: {'n_estimators': 600, 'learning_rate': 0.03338492012054152, 'num_leaves': 209, 'max_depth': 8, 'lambda_l1': 0.0009408136247927257, 'lambda_l2': 0.010825912939855227, 'feature_fraction': 0.7540404897059769, 'bagging_fraction': 0.8408379290441701, 'bagging_freq': 7}. Best is trial 22 with value: 0.15334993777794687.\n","[I 2025-10-11 21:28:32,007] Trial 31 finished with value: 0.15292725353655054 and parameters: {'n_estimators': 700, 'learning_rate': 0.027317709859561792, 'num_leaves': 300, 'max_depth': 4, 'lambda_l1': 2.893739833041112, 'lambda_l2': 2.1106527887952458e-05, 'feature_fraction': 0.8294311180235457, 'bagging_fraction': 0.9701932502895858, 'bagging_freq': 6}. Best is trial 22 with value: 0.15334993777794687.\n","[I 2025-10-11 21:28:39,405] Trial 32 finished with value: 0.15021720889573228 and parameters: {'n_estimators': 400, 'learning_rate': 0.05730467326851869, 'num_leaves': 299, 'max_depth': 4, 'lambda_l1': 2.7067888638751247, 'lambda_l2': 0.0005495408117855385, 'feature_fraction': 0.90119900678931, 'bagging_fraction': 0.9302295276606037, 'bagging_freq': 6}. Best is trial 22 with value: 0.15334993777794687.\n"]},{"output_type":"stream","name":"stdout","text":["\n","[Optuna 조기 종료] 10번의 trial 동안 최고 점수가 갱신되지 않아 튜닝을 중단합니다.\n","\n","✅ 튜닝 완료!\n","\n","==================================================\n","🔬 최적 하이퍼파라미터 (Best Hyperparameters)\n","==================================================\n","        n_estimators: 300\n","       learning_rate: 0.03592280632071865\n","          num_leaves: 285\n","           max_depth: 4\n","           lambda_l1: 6.868642672596015\n","           lambda_l2: 1.1929083069353505e-05\n","    feature_fraction: 0.8209357514611245\n","    bagging_fraction: 0.9601977186143064\n","        bagging_freq: 6\n","==================================================\n","\n","🔬 Step 5: 튜닝된 최종 모델 학습 및 평가...\n","✅ 튜닝된 모델 평가 완료.\n","\n","============================================================\n","📊 최종 성능 비교 결과 (Test Set)\n","============================================================\n","              PR AUC  ROC AUC  F1-Score\n","Baseline       0.135   0.6420    0.0086\n","Optuna Tuned   0.152   0.6594    0.0000\n","\n","============================================================\n","💾 Step 6: 최종 모델 예측 결과를 원본 CSV에 추가하여 저장\n","============================================================\n","✅ 모든 데이터의 예측 결과가 '/content/drive/MyDrive/review_helpfulness/PADA/results/s2/audible/BERT_audible_with_s2_predictions.csv' 파일에 성공적으로 저장되었습니다.\n","\n","============================================================\n","🧹 Step 7: 사용된 변수들을 메모리에서 정리\n","============================================================\n","✅ 메모리 정리가 완료되었습니다.\n","\n","🎉 모든 과정이 완료되었습니다!\n"]}]},{"cell_type":"markdown","source":["## SentenceBERT"],"metadata":{"id":"3WZFezxAvEEc"}},{"cell_type":"code","source":["# === 2. 환경설정 클래스 ===\n","class Config:\n","    \"\"\"실행에 필요한 모든 설정값을 중앙에서 관리합니다.\"\"\"\n","    # 🌟 1. 입력 파일 경로 설정\n","    CSV_FILE_PATH = \"/content/drive/MyDrive/review_helpfulness/PADA/data/audible/audible.csv\"\n","    EMBEDDING_PATH = \"/content/drive/MyDrive/review_helpfulness/PADA/embedding/audible_SentenceBERT.npy\"\n","\n","    # 🌟 2. 최종 결과 CSV 파일 저장 경로 설정\n","    OUTPUT_CSV_PATH = \"/content/drive/MyDrive/review_helpfulness/PADA/results/s2/audible/SentenceBERT_audible_with_s2_predictions.csv\"\n","\n","    # --- 데이터 정보 ---\n","    TARGET_COLUMN = 'binary_helpfulness'\n","\n","    # --- 데이터 분할 ---\n","    TEST_SPLIT_RATIO = 0.2\n","    RANDOM_STATE = 42\n","\n","    # --- Optuna 튜닝 설정 ---\n","    N_TRIALS = 50\n","    TUNING_METRIC = 'pr_auc'\n","    EARLY_STOPPING_ROUNDS = 10 # 🌟 Optuna 조기 종료 횟수\n","\n","# === 3. Optuna 조기 종료 콜백 ===\n","class EarlyStoppingCallback:\n","    \"\"\"Optuna 스터디의 조기 종료를 위한 콜백 클래스\"\"\"\n","    def __init__(self, early_stopping_rounds: int):\n","        self._early_stopping_rounds = early_stopping_rounds\n","        self._best_value = -float(\"inf\")\n","        self._counter = 0\n","\n","    def __call__(self, study: optuna.study.Study, trial: optuna.trial.Trial):\n","        current_best_value = study.best_value\n","        if current_best_value is not None and current_best_value > self._best_value:\n","            self._best_value = current_best_value\n","            self._counter = 0\n","        else:\n","            self._counter += 1\n","\n","        if self._counter >= self._early_stopping_rounds:\n","            print(f\"\\n[Optuna 조기 종료] {self._early_stopping_rounds}번의 trial 동안 최고 점수가 갱신되지 않아 튜닝을 중단합니다.\")\n","            study.stop()\n","\n","# === 4. Optuna Objective 함수 ===\n","def objective(trial, X, y):\n","    \"\"\"Optuna가 최적의 하이퍼파라미터를 찾기 위해 반복 호출하는 함수\"\"\"\n","    X_train, X_val, y_train, y_val = train_test_split(\n","        X, y, test_size=0.25, random_state=Config.RANDOM_STATE, stratify=y\n","    )\n","\n","    params = {\n","        'objective': 'binary', 'metric': 'logloss', 'verbosity': -1,\n","        'boosting_type': 'gbdt', 'random_state': Config.RANDOM_STATE,\n","        'device': 'gpu',  # 🌟 Optuna Trial 내부에서도 GPU 사용\n","        'n_estimators': trial.suggest_int('n_estimators', 100, 2000, step=100),\n","        'learning_rate': trial.suggest_float('learning_rate', 1e-3, 0.3, log=True),\n","        'num_leaves': trial.suggest_int('num_leaves', 20, 300),\n","        'max_depth': trial.suggest_int('max_depth', 3, 12),\n","        'lambda_l1': trial.suggest_float('lambda_l1', 1e-8, 10.0, log=True),\n","        'lambda_l2': trial.suggest_float('lambda_l2', 1e-8, 10.0, log=True),\n","        'feature_fraction': trial.suggest_float('feature_fraction', 0.6, 1.0),\n","        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.6, 1.0),\n","        'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\n","    }\n","\n","    model = lgb.LGBMClassifier(**params)\n","    model.fit(X_train, y_train,\n","              eval_set=[(X_val, y_val)],\n","              eval_metric='logloss',\n","              callbacks=[lgb.early_stopping(100, verbose=False)])\n","\n","    y_pred_proba = model.predict_proba(X_val)[:, 1]\n","    score = average_precision_score(y_val, y_pred_proba)\n","    return score\n","\n","# === 5. 메인 실행 블록 ===\n","if __name__ == '__main__':\n","    config = Config()\n","\n","    # ... (Step 1 ~ 2: 데이터 로드, 분할, 베이스라인 측정) ...\n","    print(\"Step 1: 데이터 로드 및 분할 중...\")\n","    try:\n","        df = pd.read_csv(config.CSV_FILE_PATH)\n","        labels = df[config.TARGET_COLUMN].values\n","        embeddings = np.load(config.EMBEDDING_PATH)\n","        assert len(df) == len(embeddings)\n","    except Exception as e:\n","        print(f\"🔥 파일 로드 실패: {e}\"); exit()\n","\n","    indices = np.arange(len(df))\n","    train_indices, test_indices = train_test_split(\n","        indices, test_size=config.TEST_SPLIT_RATIO, random_state=config.RANDOM_STATE, stratify=labels\n","    )\n","    X_train, X_test = embeddings[train_indices], embeddings[test_indices]\n","    y_train, y_test = labels[train_indices], labels[test_indices]\n","    print(f\"✅ 완료 (학습용: {len(y_train)}건, 테스트용: {len(y_test)}건)\")\n","\n","    print(\"\\n\" + \"=\"*50)\n","    print(\"📊 Step 2: 베이스라인 모델 성능 측정 (GPU 사용)\")\n","    print(\"=\"*50)\n","\n","    baseline_model = lgb.LGBMClassifier(device='gpu', random_state=config.RANDOM_STATE)\n","    baseline_model.fit(X_train, y_train)\n","\n","    y_pred_proba_base = baseline_model.predict_proba(X_test)[:, 1]\n","    y_pred_class_base = (y_pred_proba_base > 0.5).astype(int)\n","\n","    final_results = {}\n","    final_results['Baseline'] = {\n","        \"PR AUC\": average_precision_score(y_test, y_pred_proba_base),\n","        \"ROC AUC\": roc_auc_score(y_test, y_pred_proba_base),\n","        \"F1-Score\": f1_score(y_test, y_pred_class_base),\n","    }\n","    print(\"✅ 베이스라인 모델 평가 완료.\")\n","\n","    # --- Step 3: Optuna 튜닝 수행 (조기 종료 포함) ---\n","    print(\"\\n\" + \"=\"*50)\n","    print(f\"🔬 Step 3: Optuna 하이퍼파라미터 튜닝 시작 (GPU 사용)...\")\n","    print(f\"(최대 {config.N_TRIALS}번 시도, {config.EARLY_STOPPING_ROUNDS}번 개선 없으면 조기 종료)\")\n","    print(\"=\"*50)\n","\n","    early_stopping_callback = EarlyStoppingCallback(early_stopping_rounds=config.EARLY_STOPPING_ROUNDS)\n","    study = optuna.create_study(direction='maximize')\n","    pbar = tqdm(total=config.N_TRIALS, desc=\"Optuna 튜닝 진행률\")\n","\n","    try:\n","        study.optimize(lambda trial: objective(trial, X_train, y_train),\n","                       n_trials=config.N_TRIALS,\n","                       callbacks=[lambda study, trial: pbar.update(1), early_stopping_callback])\n","    except optuna.exceptions.OptunaError:\n","        # 조기 종료 시 발생하는 예외를 정상 처리\n","        pass\n","    pbar.close()\n","\n","    # ... (Step 4 ~ 6: 결과 출력, 저장, 메모리 정리) ...\n","    print(f\"\\n✅ 튜닝 완료!\")\n","    print(\"\\n\" + \"=\"*50)\n","    print(\"🔬 최적 하이퍼파라미터 (Best Hyperparameters)\")\n","    print(\"=\"*50)\n","    best_params = study.best_params\n","    for key, value in best_params.items():\n","        print(f\"{key:>20s}: {value}\")\n","    print(\"=\"*50)\n","\n","    print(f\"\\n🔬 Step 5: 튜닝된 최종 모델 학습 및 평가...\")\n","    final_model = lgb.LGBMClassifier(device='gpu', objective='binary', verbosity=-1, random_state=config.RANDOM_STATE, **best_params)\n","    final_model.fit(X_train, y_train)\n","\n","    y_pred_proba_tuned = final_model.predict_proba(X_test)[:, 1]\n","    y_pred_class_tuned = (y_pred_proba_tuned > 0.5).astype(int)\n","\n","    final_results['Optuna Tuned'] = {\n","        \"PR AUC\": average_precision_score(y_test, y_pred_proba_tuned),\n","        \"ROC AUC\": roc_auc_score(y_test, y_pred_proba_tuned),\n","        \"F1-Score\": f1_score(y_test, y_pred_class_tuned),\n","    }\n","    print(\"✅ 튜닝된 모델 평가 완료.\")\n","\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"📊 최종 성능 비교 결과 (Test Set)\")\n","    print(\"=\"*60)\n","    results_df = pd.DataFrame(final_results).T\n","    print(results_df.round(4))\n","\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"💾 Step 6: 최종 모델 예측 결과를 원본 CSV에 추가하여 저장\")\n","    print(\"=\"*60)\n","\n","    train_pred_proba = final_model.predict_proba(X_train)[:, 1]\n","    train_pred_class = (train_pred_proba > 0.5).astype(int)\n","\n","    df['s2_pred_proba'] = np.nan\n","    df['s2_pred_class'] = np.nan\n","\n","    df.loc[train_indices, 's2_pred_proba'] = train_pred_proba\n","    df.loc[train_indices, 's2_pred_class'] = train_pred_class\n","\n","    df.loc[test_indices, 's2_pred_proba'] = y_pred_proba_tuned\n","    df.loc[test_indices, 's2_pred_class'] = y_pred_class_tuned\n","\n","    # 🌟 Config에 설정된 경로로 최종 파일 저장\n","    df.to_csv(config.OUTPUT_CSV_PATH, index=False, encoding='utf-8-sig')\n","\n","    print(f\"✅ 모든 데이터의 예측 결과가 '{config.OUTPUT_CSV_PATH}' 파일에 성공적으로 저장되었습니다.\")\n","\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"🧹 Step 7: 사용된 변수들을 메모리에서 정리\")\n","    print(\"=\"*60)\n","\n","    vars_to_delete = [\n","        'df', 'labels', 'embeddings', 'indices', 'X_train', 'X_test',\n","        'y_train', 'y_test', 'train_indices', 'test_indices',\n","        'baseline_model', 'final_model', 'study',\n","    ]\n","    for var_name in vars_to_delete:\n","        if var_name in locals() or var_name in globals():\n","            if var_name in globals(): del globals()[var_name]\n","\n","    gc.collect()\n","    print(\"✅ 메모리 정리가 완료되었습니다.\")\n","\n","    print(\"\\n🎉 모든 과정이 완료되었습니다!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","referenced_widgets":["999c30a9016a4288892a25f072f129e9","8639cf0fa79047738f0a8aae0aa9bf7e","46cddae85d1a4f2d81001955c6db0856","47a4dfe31a984f12a53d16b9868ea75b","b2cb4990e58e4607b9973e39c53bcaf4","23071aa7fe0e4ce58a015adeb2b67114","77208d37845f4da29483a1e56cc15d87","ca5b06a231dd4d62b3eb216c8592fa61","7299eb505d5f42b29f9dee53ad4dd841","07c07998533542209f83e4270659d873","2e41445600524e2b91e8538593c2714f"]},"id":"NUXPmON5xWgM","executionInfo":{"status":"ok","timestamp":1760218580611,"user_tz":-540,"elapsed":448042,"user":{"displayName":"KW-data-analytics","userId":"09651493752354345908"}},"outputId":"c58c04b6-e759-4960-dad1-3c6933b78881"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Step 1: 데이터 로드 및 분할 중...\n","✅ 완료 (학습용: 74391건, 테스트용: 18598건)\n","\n","==================================================\n","📊 Step 2: 베이스라인 모델 성능 측정 (GPU 사용)\n","==================================================\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-10-11 21:29:04,206] A new study created in memory with name: no-name-59fb69a6-297b-43d4-8896-1f6758a646b6\n"]},{"output_type":"stream","name":"stdout","text":["✅ 베이스라인 모델 평가 완료.\n","\n","==================================================\n","🔬 Step 3: Optuna 하이퍼파라미터 튜닝 시작 (GPU 사용)...\n","(최대 50번 시도, 10번 개선 없으면 조기 종료)\n","==================================================\n"]},{"output_type":"display_data","data":{"text/plain":["Optuna 튜닝 진행률:   0%|          | 0/50 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"999c30a9016a4288892a25f072f129e9"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2025-10-11 21:30:43,470] Trial 0 finished with value: 0.14553675282946257 and parameters: {'n_estimators': 1900, 'learning_rate': 0.0013714659998085848, 'num_leaves': 125, 'max_depth': 9, 'lambda_l1': 0.8996622270722991, 'lambda_l2': 4.640650486289767e-05, 'feature_fraction': 0.7888079403803553, 'bagging_fraction': 0.69469079489932, 'bagging_freq': 3}. Best is trial 0 with value: 0.14553675282946257.\n","[I 2025-10-11 21:32:39,406] Trial 1 finished with value: 0.14227756526976792 and parameters: {'n_estimators': 1800, 'learning_rate': 0.0017375230342082273, 'num_leaves': 169, 'max_depth': 11, 'lambda_l1': 2.1522814846585543e-05, 'lambda_l2': 1.0076576546200888e-07, 'feature_fraction': 0.7709798732527592, 'bagging_fraction': 0.9247425966141084, 'bagging_freq': 7}. Best is trial 0 with value: 0.14553675282946257.\n","[I 2025-10-11 21:33:04,388] Trial 2 finished with value: 0.1448184325139152 and parameters: {'n_estimators': 1400, 'learning_rate': 0.01305626539643458, 'num_leaves': 284, 'max_depth': 9, 'lambda_l1': 5.6919740366679275, 'lambda_l2': 0.004830221219353837, 'feature_fraction': 0.6177833974516834, 'bagging_fraction': 0.8697387581791547, 'bagging_freq': 2}. Best is trial 0 with value: 0.14553675282946257.\n","[I 2025-10-11 21:33:15,325] Trial 3 finished with value: 0.13701338875270513 and parameters: {'n_estimators': 200, 'learning_rate': 0.02711222500594123, 'num_leaves': 218, 'max_depth': 8, 'lambda_l1': 1.7323787229557753e-05, 'lambda_l2': 8.24102719343012e-07, 'feature_fraction': 0.7867508053862089, 'bagging_fraction': 0.8087100240708809, 'bagging_freq': 6}. Best is trial 0 with value: 0.14553675282946257.\n","[I 2025-10-11 21:33:19,278] Trial 4 finished with value: 0.1378846047997132 and parameters: {'n_estimators': 2000, 'learning_rate': 0.0667976104854891, 'num_leaves': 104, 'max_depth': 4, 'lambda_l1': 0.007640360065710862, 'lambda_l2': 9.05020544195951e-08, 'feature_fraction': 0.9255803688412324, 'bagging_fraction': 0.7238676003219667, 'bagging_freq': 5}. Best is trial 0 with value: 0.14553675282946257.\n","[I 2025-10-11 21:33:36,563] Trial 5 finished with value: 0.14132841359581455 and parameters: {'n_estimators': 500, 'learning_rate': 0.020622036599937808, 'num_leaves': 198, 'max_depth': 8, 'lambda_l1': 0.5749941524218869, 'lambda_l2': 3.6405795105345, 'feature_fraction': 0.7634323382251416, 'bagging_fraction': 0.8795774086978214, 'bagging_freq': 3}. Best is trial 0 with value: 0.14553675282946257.\n","[I 2025-10-11 21:33:49,456] Trial 6 finished with value: 0.14236557260662136 and parameters: {'n_estimators': 900, 'learning_rate': 0.027018112247380204, 'num_leaves': 110, 'max_depth': 10, 'lambda_l1': 0.00017492269023477975, 'lambda_l2': 0.0006799279795467898, 'feature_fraction': 0.692595841889778, 'bagging_fraction': 0.7330689996502359, 'bagging_freq': 2}. Best is trial 0 with value: 0.14553675282946257.\n","[I 2025-10-11 21:33:59,548] Trial 7 finished with value: 0.10801306253528595 and parameters: {'n_estimators': 800, 'learning_rate': 0.249948510956339, 'num_leaves': 196, 'max_depth': 10, 'lambda_l1': 0.5046591900149066, 'lambda_l2': 8.207656010894082, 'feature_fraction': 0.7395728648955828, 'bagging_fraction': 0.7374449378867498, 'bagging_freq': 6}. Best is trial 0 with value: 0.14553675282946257.\n","[I 2025-10-11 21:34:08,664] Trial 8 finished with value: 0.10786799159300584 and parameters: {'n_estimators': 600, 'learning_rate': 0.1132058084878167, 'num_leaves': 148, 'max_depth': 10, 'lambda_l1': 0.006357718361045667, 'lambda_l2': 5.15477910097951e-05, 'feature_fraction': 0.8432907354810362, 'bagging_fraction': 0.6292126511165969, 'bagging_freq': 6}. Best is trial 0 with value: 0.14553675282946257.\n","[I 2025-10-11 21:34:13,346] Trial 9 finished with value: 0.11248215967458218 and parameters: {'n_estimators': 100, 'learning_rate': 0.19864394655600046, 'num_leaves': 290, 'max_depth': 6, 'lambda_l1': 4.60242572251627e-07, 'lambda_l2': 0.09293338104155255, 'feature_fraction': 0.825703011132793, 'bagging_fraction': 0.759380597205536, 'bagging_freq': 5}. Best is trial 0 with value: 0.14553675282946257.\n","[I 2025-10-11 21:34:31,293] Trial 10 finished with value: 0.13584748107885497 and parameters: {'n_estimators': 1300, 'learning_rate': 0.0010231316142531005, 'num_leaves': 20, 'max_depth': 12, 'lambda_l1': 1.1755820794151794e-08, 'lambda_l2': 1.2426720857942546e-05, 'feature_fraction': 0.9746855452748343, 'bagging_fraction': 0.6000098804796361, 'bagging_freq': 1}. Best is trial 0 with value: 0.14553675282946257.\n"]},{"output_type":"stream","name":"stdout","text":["\n","[Optuna 조기 종료] 10번의 trial 동안 최고 점수가 갱신되지 않아 튜닝을 중단합니다.\n","\n","✅ 튜닝 완료!\n","\n","==================================================\n","🔬 최적 하이퍼파라미터 (Best Hyperparameters)\n","==================================================\n","        n_estimators: 1900\n","       learning_rate: 0.0013714659998085848\n","          num_leaves: 125\n","           max_depth: 9\n","           lambda_l1: 0.8996622270722991\n","           lambda_l2: 4.640650486289767e-05\n","    feature_fraction: 0.7888079403803553\n","    bagging_fraction: 0.69469079489932\n","        bagging_freq: 3\n","==================================================\n","\n","🔬 Step 5: 튜닝된 최종 모델 학습 및 평가...\n","✅ 튜닝된 모델 평가 완료.\n","\n","============================================================\n","📊 최종 성능 비교 결과 (Test Set)\n","============================================================\n","              PR AUC  ROC AUC  F1-Score\n","Baseline      0.1353   0.6506    0.0015\n","Optuna Tuned  0.1600   0.6729    0.0000\n","\n","============================================================\n","💾 Step 6: 최종 모델 예측 결과를 원본 CSV에 추가하여 저장\n","============================================================\n","✅ 모든 데이터의 예측 결과가 '/content/drive/MyDrive/review_helpfulness/PADA/results/s2/audible/SentenceBERT_audible_with_s2_predictions.csv' 파일에 성공적으로 저장되었습니다.\n","\n","============================================================\n","🧹 Step 7: 사용된 변수들을 메모리에서 정리\n","============================================================\n","✅ 메모리 정리가 완료되었습니다.\n","\n","🎉 모든 과정이 완료되었습니다!\n"]}]},{"cell_type":"markdown","source":["## RoBERTa"],"metadata":{"id":"8cCLOe9jvEQE"}},{"cell_type":"code","source":["# === 2. 환경설정 클래스 ===\n","class Config:\n","    \"\"\"실행에 필요한 모든 설정값을 중앙에서 관리합니다.\"\"\"\n","    # 🌟 1. 입력 파일 경로 설정\n","    CSV_FILE_PATH = \"/content/drive/MyDrive/review_helpfulness/PADA/data/audible/audible.csv\"\n","    EMBEDDING_PATH = \"/content/drive/MyDrive/review_helpfulness/PADA/embedding/audible_RoBERTa.npy\"\n","\n","    # 🌟 2. 최종 결과 CSV 파일 저장 경로 설정\n","    OUTPUT_CSV_PATH = \"/content/drive/MyDrive/review_helpfulness/PADA/results/s2/audible/RoBERTa_audible_with_s2_predictions.csv\"\n","\n","    # --- 데이터 정보 ---\n","    TARGET_COLUMN = 'binary_helpfulness'\n","\n","    # --- 데이터 분할 ---\n","    TEST_SPLIT_RATIO = 0.2\n","    RANDOM_STATE = 42\n","\n","    # --- Optuna 튜닝 설정 ---\n","    N_TRIALS = 50\n","    TUNING_METRIC = 'pr_auc'\n","    EARLY_STOPPING_ROUNDS = 10 # 🌟 Optuna 조기 종료 횟수\n","\n","# === 3. Optuna 조기 종료 콜백 ===\n","class EarlyStoppingCallback:\n","    \"\"\"Optuna 스터디의 조기 종료를 위한 콜백 클래스\"\"\"\n","    def __init__(self, early_stopping_rounds: int):\n","        self._early_stopping_rounds = early_stopping_rounds\n","        self._best_value = -float(\"inf\")\n","        self._counter = 0\n","\n","    def __call__(self, study: optuna.study.Study, trial: optuna.trial.Trial):\n","        current_best_value = study.best_value\n","        if current_best_value is not None and current_best_value > self._best_value:\n","            self._best_value = current_best_value\n","            self._counter = 0\n","        else:\n","            self._counter += 1\n","\n","        if self._counter >= self._early_stopping_rounds:\n","            print(f\"\\n[Optuna 조기 종료] {self._early_stopping_rounds}번의 trial 동안 최고 점수가 갱신되지 않아 튜닝을 중단합니다.\")\n","            study.stop()\n","\n","# === 4. Optuna Objective 함수 ===\n","def objective(trial, X, y):\n","    \"\"\"Optuna가 최적의 하이퍼파라미터를 찾기 위해 반복 호출하는 함수\"\"\"\n","    X_train, X_val, y_train, y_val = train_test_split(\n","        X, y, test_size=0.25, random_state=Config.RANDOM_STATE, stratify=y\n","    )\n","\n","    params = {\n","        'objective': 'binary', 'metric': 'logloss', 'verbosity': -1,\n","        'boosting_type': 'gbdt', 'random_state': Config.RANDOM_STATE,\n","        'device': 'gpu',  # 🌟 Optuna Trial 내부에서도 GPU 사용\n","        'n_estimators': trial.suggest_int('n_estimators', 100, 2000, step=100),\n","        'learning_rate': trial.suggest_float('learning_rate', 1e-3, 0.3, log=True),\n","        'num_leaves': trial.suggest_int('num_leaves', 20, 300),\n","        'max_depth': trial.suggest_int('max_depth', 3, 12),\n","        'lambda_l1': trial.suggest_float('lambda_l1', 1e-8, 10.0, log=True),\n","        'lambda_l2': trial.suggest_float('lambda_l2', 1e-8, 10.0, log=True),\n","        'feature_fraction': trial.suggest_float('feature_fraction', 0.6, 1.0),\n","        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.6, 1.0),\n","        'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\n","    }\n","\n","    model = lgb.LGBMClassifier(**params)\n","    model.fit(X_train, y_train,\n","              eval_set=[(X_val, y_val)],\n","              eval_metric='logloss',\n","              callbacks=[lgb.early_stopping(100, verbose=False)])\n","\n","    y_pred_proba = model.predict_proba(X_val)[:, 1]\n","    score = average_precision_score(y_val, y_pred_proba)\n","    return score\n","\n","# === 5. 메인 실행 블록 ===\n","if __name__ == '__main__':\n","    config = Config()\n","\n","    # ... (Step 1 ~ 2: 데이터 로드, 분할, 베이스라인 측정) ...\n","    print(\"Step 1: 데이터 로드 및 분할 중...\")\n","    try:\n","        df = pd.read_csv(config.CSV_FILE_PATH)\n","        labels = df[config.TARGET_COLUMN].values\n","        embeddings = np.load(config.EMBEDDING_PATH)\n","        assert len(df) == len(embeddings)\n","    except Exception as e:\n","        print(f\"🔥 파일 로드 실패: {e}\"); exit()\n","\n","    indices = np.arange(len(df))\n","    train_indices, test_indices = train_test_split(\n","        indices, test_size=config.TEST_SPLIT_RATIO, random_state=config.RANDOM_STATE, stratify=labels\n","    )\n","    X_train, X_test = embeddings[train_indices], embeddings[test_indices]\n","    y_train, y_test = labels[train_indices], labels[test_indices]\n","    print(f\"✅ 완료 (학습용: {len(y_train)}건, 테스트용: {len(y_test)}건)\")\n","\n","    print(\"\\n\" + \"=\"*50)\n","    print(\"📊 Step 2: 베이스라인 모델 성능 측정 (GPU 사용)\")\n","    print(\"=\"*50)\n","\n","    baseline_model = lgb.LGBMClassifier(device='gpu', random_state=config.RANDOM_STATE)\n","    baseline_model.fit(X_train, y_train)\n","\n","    y_pred_proba_base = baseline_model.predict_proba(X_test)[:, 1]\n","    y_pred_class_base = (y_pred_proba_base > 0.5).astype(int)\n","\n","    final_results = {}\n","    final_results['Baseline'] = {\n","        \"PR AUC\": average_precision_score(y_test, y_pred_proba_base),\n","        \"ROC AUC\": roc_auc_score(y_test, y_pred_proba_base),\n","        \"F1-Score\": f1_score(y_test, y_pred_class_base),\n","    }\n","    print(\"✅ 베이스라인 모델 평가 완료.\")\n","\n","    # --- Step 3: Optuna 튜닝 수행 (조기 종료 포함) ---\n","    print(\"\\n\" + \"=\"*50)\n","    print(f\"🔬 Step 3: Optuna 하이퍼파라미터 튜닝 시작 (GPU 사용)...\")\n","    print(f\"(최대 {config.N_TRIALS}번 시도, {config.EARLY_STOPPING_ROUNDS}번 개선 없으면 조기 종료)\")\n","    print(\"=\"*50)\n","\n","    early_stopping_callback = EarlyStoppingCallback(early_stopping_rounds=config.EARLY_STOPPING_ROUNDS)\n","    study = optuna.create_study(direction='maximize')\n","    pbar = tqdm(total=config.N_TRIALS, desc=\"Optuna 튜닝 진행률\")\n","\n","    try:\n","        study.optimize(lambda trial: objective(trial, X_train, y_train),\n","                       n_trials=config.N_TRIALS,\n","                       callbacks=[lambda study, trial: pbar.update(1), early_stopping_callback])\n","    except optuna.exceptions.OptunaError:\n","        # 조기 종료 시 발생하는 예외를 정상 처리\n","        pass\n","    pbar.close()\n","\n","    # ... (Step 4 ~ 6: 결과 출력, 저장, 메모리 정리) ...\n","    print(f\"\\n✅ 튜닝 완료!\")\n","    print(\"\\n\" + \"=\"*50)\n","    print(\"🔬 최적 하이퍼파라미터 (Best Hyperparameters)\")\n","    print(\"=\"*50)\n","    best_params = study.best_params\n","    for key, value in best_params.items():\n","        print(f\"{key:>20s}: {value}\")\n","    print(\"=\"*50)\n","\n","    print(f\"\\n🔬 Step 5: 튜닝된 최종 모델 학습 및 평가...\")\n","    final_model = lgb.LGBMClassifier(device='gpu', objective='binary', verbosity=-1, random_state=config.RANDOM_STATE, **best_params)\n","    final_model.fit(X_train, y_train)\n","\n","    y_pred_proba_tuned = final_model.predict_proba(X_test)[:, 1]\n","    y_pred_class_tuned = (y_pred_proba_tuned > 0.5).astype(int)\n","\n","    final_results['Optuna Tuned'] = {\n","        \"PR AUC\": average_precision_score(y_test, y_pred_proba_tuned),\n","        \"ROC AUC\": roc_auc_score(y_test, y_pred_proba_tuned),\n","        \"F1-Score\": f1_score(y_test, y_pred_class_tuned),\n","    }\n","    print(\"✅ 튜닝된 모델 평가 완료.\")\n","\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"📊 최종 성능 비교 결과 (Test Set)\")\n","    print(\"=\"*60)\n","    results_df = pd.DataFrame(final_results).T\n","    print(results_df.round(4))\n","\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"💾 Step 6: 최종 모델 예측 결과를 원본 CSV에 추가하여 저장\")\n","    print(\"=\"*60)\n","\n","    train_pred_proba = final_model.predict_proba(X_train)[:, 1]\n","    train_pred_class = (train_pred_proba > 0.5).astype(int)\n","\n","    df['s2_pred_proba'] = np.nan\n","    df['s2_pred_class'] = np.nan\n","\n","    df.loc[train_indices, 's2_pred_proba'] = train_pred_proba\n","    df.loc[train_indices, 's2_pred_class'] = train_pred_class\n","\n","    df.loc[test_indices, 's2_pred_proba'] = y_pred_proba_tuned\n","    df.loc[test_indices, 's2_pred_class'] = y_pred_class_tuned\n","\n","    # 🌟 Config에 설정된 경로로 최종 파일 저장\n","    df.to_csv(config.OUTPUT_CSV_PATH, index=False, encoding='utf-8-sig')\n","\n","    print(f\"✅ 모든 데이터의 예측 결과가 '{config.OUTPUT_CSV_PATH}' 파일에 성공적으로 저장되었습니다.\")\n","\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"🧹 Step 7: 사용된 변수들을 메모리에서 정리\")\n","    print(\"=\"*60)\n","\n","    vars_to_delete = [\n","        'df', 'labels', 'embeddings', 'indices', 'X_train', 'X_test',\n","        'y_train', 'y_test', 'train_indices', 'test_indices',\n","        'baseline_model', 'final_model', 'study',\n","    ]\n","    for var_name in vars_to_delete:\n","        if var_name in locals() or var_name in globals():\n","            if var_name in globals(): del globals()[var_name]\n","\n","    gc.collect()\n","    print(\"✅ 메모리 정리가 완료되었습니다.\")\n","\n","    print(\"\\n🎉 모든 과정이 완료되었습니다!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","referenced_widgets":["7d6717639ac74cd3851140bdc413630c","0d29969b30cd4eed9f2146771232a9bd","d531aeaad2964638b6fe542b7a1356c3","c3c486bc71324d43b2b4ec2956e61b26","86d20758499946e88ec8f182a16da1f5","ae76cc972f0a43eb98020608b975bed4","cfb71c7b25854c4b8b7e9ce0a2d7e111","be2746843d654fdab758b464546e8d14","388760b9cf66474489d5a83605a240ac","ce7bad216f48446e946efdbcfcb8970c","6c6f521942a64289b8a9b880581bdd8c"]},"id":"GB4cF59QxcM0","executionInfo":{"status":"ok","timestamp":1760220048892,"user_tz":-540,"elapsed":1468278,"user":{"displayName":"KW-data-analytics","userId":"09651493752354345908"}},"outputId":"13a8903f-e02f-43e2-c21a-c5114c1e22bd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Step 1: 데이터 로드 및 분할 중...\n","✅ 완료 (학습용: 74391건, 테스트용: 18598건)\n","\n","==================================================\n","📊 Step 2: 베이스라인 모델 성능 측정 (GPU 사용)\n","==================================================\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-10-11 21:36:33,685] A new study created in memory with name: no-name-e2d1dcd3-2271-4e79-b1cf-0eaabef7efd4\n"]},{"output_type":"stream","name":"stdout","text":["✅ 베이스라인 모델 평가 완료.\n","\n","==================================================\n","🔬 Step 3: Optuna 하이퍼파라미터 튜닝 시작 (GPU 사용)...\n","(최대 50번 시도, 10번 개선 없으면 조기 종료)\n","==================================================\n"]},{"output_type":"display_data","data":{"text/plain":["Optuna 튜닝 진행률:   0%|          | 0/50 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7d6717639ac74cd3851140bdc413630c"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2025-10-11 21:36:40,640] Trial 0 finished with value: 0.1415243894266757 and parameters: {'n_estimators': 400, 'learning_rate': 0.02135444366250037, 'num_leaves': 20, 'max_depth': 3, 'lambda_l1': 1.3616801391692733e-06, 'lambda_l2': 0.09194350421130441, 'feature_fraction': 0.9403636574647329, 'bagging_fraction': 0.6980357963491699, 'bagging_freq': 5}. Best is trial 0 with value: 0.1415243894266757.\n","[I 2025-10-11 21:36:48,741] Trial 1 finished with value: 0.1351579884352608 and parameters: {'n_estimators': 900, 'learning_rate': 0.0721751286437755, 'num_leaves': 20, 'max_depth': 11, 'lambda_l1': 0.032751189551571386, 'lambda_l2': 4.2292213123740994e-05, 'feature_fraction': 0.9297496418709909, 'bagging_fraction': 0.9686517532180405, 'bagging_freq': 1}. Best is trial 0 with value: 0.1415243894266757.\n","[I 2025-10-11 21:37:11,458] Trial 2 finished with value: 0.14843502787557472 and parameters: {'n_estimators': 1100, 'learning_rate': 0.011816379893566027, 'num_leaves': 146, 'max_depth': 6, 'lambda_l1': 0.938239095882179, 'lambda_l2': 4.957897351013009e-05, 'feature_fraction': 0.8364377609734217, 'bagging_fraction': 0.6470106991213845, 'bagging_freq': 1}. Best is trial 2 with value: 0.14843502787557472.\n","[I 2025-10-11 21:37:45,430] Trial 3 finished with value: 0.127051956674739 and parameters: {'n_estimators': 1000, 'learning_rate': 0.0344268271472135, 'num_leaves': 258, 'max_depth': 11, 'lambda_l1': 0.0003192136362486503, 'lambda_l2': 9.154527806313841e-06, 'feature_fraction': 0.9736193294747736, 'bagging_fraction': 0.7788030474453513, 'bagging_freq': 2}. Best is trial 2 with value: 0.14843502787557472.\n","[I 2025-10-11 21:38:14,649] Trial 4 finished with value: 0.14144670251610267 and parameters: {'n_estimators': 800, 'learning_rate': 0.004662872791052475, 'num_leaves': 208, 'max_depth': 6, 'lambda_l1': 0.0020819810810123796, 'lambda_l2': 0.0008224872127163968, 'feature_fraction': 0.6959758105089593, 'bagging_fraction': 0.9564457747698906, 'bagging_freq': 6}. Best is trial 2 with value: 0.14843502787557472.\n","[I 2025-10-11 21:38:39,759] Trial 5 finished with value: 0.14305023218625945 and parameters: {'n_estimators': 1400, 'learning_rate': 0.016707256845951507, 'num_leaves': 90, 'max_depth': 8, 'lambda_l1': 0.0009036649215690604, 'lambda_l2': 2.3763928079527975e-07, 'feature_fraction': 0.9244135446896184, 'bagging_fraction': 0.7417107625960329, 'bagging_freq': 2}. Best is trial 2 with value: 0.14843502787557472.\n","[I 2025-10-11 21:38:53,448] Trial 6 finished with value: 0.13970029102006232 and parameters: {'n_estimators': 1200, 'learning_rate': 0.04064465815117335, 'num_leaves': 57, 'max_depth': 12, 'lambda_l1': 2.358660322358701e-08, 'lambda_l2': 0.016191987178845676, 'feature_fraction': 0.7228002310265497, 'bagging_fraction': 0.9939263189958942, 'bagging_freq': 2}. Best is trial 2 with value: 0.14843502787557472.\n","[I 2025-10-11 21:39:17,251] Trial 7 finished with value: 0.1374194136698073 and parameters: {'n_estimators': 1000, 'learning_rate': 0.043853669055175445, 'num_leaves': 209, 'max_depth': 10, 'lambda_l1': 1.0421366566325305, 'lambda_l2': 0.0692392428387586, 'feature_fraction': 0.6881267116694703, 'bagging_fraction': 0.9814298418621394, 'bagging_freq': 2}. Best is trial 2 with value: 0.14843502787557472.\n","[I 2025-10-11 21:39:31,849] Trial 8 finished with value: 0.12451185009033541 and parameters: {'n_estimators': 1700, 'learning_rate': 0.1080502145464574, 'num_leaves': 274, 'max_depth': 8, 'lambda_l1': 4.431946321812099e-08, 'lambda_l2': 1.7280347089111938, 'feature_fraction': 0.978392574039423, 'bagging_fraction': 0.6805753865482579, 'bagging_freq': 3}. Best is trial 2 with value: 0.14843502787557472.\n","[I 2025-10-11 21:41:40,313] Trial 9 finished with value: 0.14934978550990463 and parameters: {'n_estimators': 1900, 'learning_rate': 0.0028733770989325396, 'num_leaves': 233, 'max_depth': 8, 'lambda_l1': 2.676398588758774, 'lambda_l2': 3.108967281335458e-08, 'feature_fraction': 0.9011824094036464, 'bagging_fraction': 0.7848285706257181, 'bagging_freq': 1}. Best is trial 9 with value: 0.14934978550990463.\n","[I 2025-10-11 21:41:57,287] Trial 10 finished with value: 0.13447498060695554 and parameters: {'n_estimators': 2000, 'learning_rate': 0.001114409851833312, 'num_leaves': 155, 'max_depth': 3, 'lambda_l1': 8.199101803887888, 'lambda_l2': 2.0787488503335505e-08, 'feature_fraction': 0.8272577084664148, 'bagging_fraction': 0.8627067870101293, 'bagging_freq': 7}. Best is trial 9 with value: 0.14934978550990463.\n","[I 2025-10-11 21:42:15,440] Trial 11 finished with value: 0.1388410918550968 and parameters: {'n_estimators': 400, 'learning_rate': 0.005065049550176607, 'num_leaves': 146, 'max_depth': 6, 'lambda_l1': 0.13655268036461066, 'lambda_l2': 8.7475261298853e-07, 'feature_fraction': 0.8366137552052316, 'bagging_fraction': 0.6188377804522618, 'bagging_freq': 4}. Best is trial 9 with value: 0.14934978550990463.\n","[I 2025-10-11 21:42:58,428] Trial 12 finished with value: 0.15069935499786105 and parameters: {'n_estimators': 2000, 'learning_rate': 0.005185293338245441, 'num_leaves': 214, 'max_depth': 6, 'lambda_l1': 3.919289977566827, 'lambda_l2': 1.789839423079064e-08, 'feature_fraction': 0.6051744202250284, 'bagging_fraction': 0.8549848112256139, 'bagging_freq': 1}. Best is trial 12 with value: 0.15069935499786105.\n","[I 2025-10-11 21:43:35,757] Trial 13 finished with value: 0.14096886443464646 and parameters: {'n_estimators': 2000, 'learning_rate': 0.0012608564441856137, 'num_leaves': 217, 'max_depth': 5, 'lambda_l1': 8.331074710878516e-06, 'lambda_l2': 1.1100430410927074e-07, 'feature_fraction': 0.6102044474186591, 'bagging_fraction': 0.8582125144114341, 'bagging_freq': 4}. Best is trial 12 with value: 0.15069935499786105.\n","[I 2025-10-11 21:45:11,387] Trial 14 finished with value: 0.1430697131887926 and parameters: {'n_estimators': 1600, 'learning_rate': 0.0033908652162699254, 'num_leaves': 295, 'max_depth': 9, 'lambda_l1': 0.012315174369298002, 'lambda_l2': 3.0286975392826975e-08, 'feature_fraction': 0.6158347945841434, 'bagging_fraction': 0.8519420637775155, 'bagging_freq': 1}. Best is trial 12 with value: 0.15069935499786105.\n","[I 2025-10-11 21:45:21,077] Trial 15 finished with value: 0.10739720651746061 and parameters: {'n_estimators': 1700, 'learning_rate': 0.26808475754205435, 'num_leaves': 230, 'max_depth': 7, 'lambda_l1': 0.7117497459440068, 'lambda_l2': 1.3469675639043694e-06, 'feature_fraction': 0.7532472506848469, 'bagging_fraction': 0.9120793492326454, 'bagging_freq': 3}. Best is trial 12 with value: 0.15069935499786105.\n","[I 2025-10-11 21:45:48,840] Trial 16 finished with value: 0.14561488789548843 and parameters: {'n_estimators': 2000, 'learning_rate': 0.002419378989087379, 'num_leaves': 184, 'max_depth': 4, 'lambda_l1': 5.755511582108629, 'lambda_l2': 1.3514667408596594e-08, 'feature_fraction': 0.8833083766333261, 'bagging_fraction': 0.7990318708040769, 'bagging_freq': 3}. Best is trial 12 with value: 0.15069935499786105.\n","[I 2025-10-11 21:46:38,636] Trial 17 finished with value: 0.14025632293484971 and parameters: {'n_estimators': 1500, 'learning_rate': 0.00890808177632904, 'num_leaves': 253, 'max_depth': 9, 'lambda_l1': 9.758293989913552e-06, 'lambda_l2': 0.0008274038000602389, 'feature_fraction': 0.7878840042514661, 'bagging_fraction': 0.7430285021690856, 'bagging_freq': 1}. Best is trial 12 with value: 0.15069935499786105.\n","[I 2025-10-11 21:48:30,363] Trial 18 finished with value: 0.14323693064270865 and parameters: {'n_estimators': 1800, 'learning_rate': 0.00197363242234161, 'num_leaves': 112, 'max_depth': 7, 'lambda_l1': 0.0738899566797999, 'lambda_l2': 2.099189417305261e-06, 'feature_fraction': 0.8781264976622936, 'bagging_fraction': 0.829203605056465, 'bagging_freq': 5}. Best is trial 12 with value: 0.15069935499786105.\n","[I 2025-10-11 21:48:57,490] Trial 19 finished with value: 0.1508758786725353 and parameters: {'n_estimators': 1300, 'learning_rate': 0.005716766923120814, 'num_leaves': 177, 'max_depth': 5, 'lambda_l1': 8.75366731270645, 'lambda_l2': 1.8552803793433824e-07, 'feature_fraction': 0.6661730809457997, 'bagging_fraction': 0.7618729032943952, 'bagging_freq': 3}. Best is trial 19 with value: 0.1508758786725353.\n","[I 2025-10-11 21:49:03,715] Trial 20 finished with value: 0.1315663585051587 and parameters: {'n_estimators': 100, 'learning_rate': 0.007735495601711264, 'num_leaves': 118, 'max_depth': 5, 'lambda_l1': 0.18092579704400588, 'lambda_l2': 1.7904867406315008e-07, 'feature_fraction': 0.6488882619014503, 'bagging_fraction': 0.9065702048590517, 'bagging_freq': 3}. Best is trial 19 with value: 0.1508758786725353.\n","[I 2025-10-11 21:49:30,677] Trial 21 finished with value: 0.150737268161643 and parameters: {'n_estimators': 1300, 'learning_rate': 0.006007563994275516, 'num_leaves': 189, 'max_depth': 5, 'lambda_l1': 5.744473253038918, 'lambda_l2': 1.208991568563836e-08, 'feature_fraction': 0.6597877539668964, 'bagging_fraction': 0.7442945250883486, 'bagging_freq': 2}. Best is trial 19 with value: 0.1508758786725353.\n","[I 2025-10-11 21:49:57,411] Trial 22 finished with value: 0.1514538413718406 and parameters: {'n_estimators': 1300, 'learning_rate': 0.00615219513355989, 'num_leaves': 184, 'max_depth': 5, 'lambda_l1': 8.412840495986007, 'lambda_l2': 1.0005887414088563e-08, 'feature_fraction': 0.6537250527230731, 'bagging_fraction': 0.7403704598579095, 'bagging_freq': 2}. Best is trial 22 with value: 0.1514538413718406.\n","[I 2025-10-11 21:50:13,765] Trial 23 finished with value: 0.14706122477980782 and parameters: {'n_estimators': 1400, 'learning_rate': 0.009559175007825292, 'num_leaves': 180, 'max_depth': 4, 'lambda_l1': 0.005804647955761532, 'lambda_l2': 3.347903801293895e-07, 'feature_fraction': 0.6590424061763175, 'bagging_fraction': 0.7325346177188599, 'bagging_freq': 2}. Best is trial 22 with value: 0.1514538413718406.\n","[I 2025-10-11 21:50:23,831] Trial 24 finished with value: 0.1478781536590593 and parameters: {'n_estimators': 1300, 'learning_rate': 0.02065800556954904, 'num_leaves': 180, 'max_depth': 4, 'lambda_l1': 0.37197088829054464, 'lambda_l2': 7.114584828727467e-06, 'feature_fraction': 0.6531630976895174, 'bagging_fraction': 0.7083561477720716, 'bagging_freq': 4}. Best is trial 22 with value: 0.1514538413718406.\n","[I 2025-10-11 21:50:41,552] Trial 25 finished with value: 0.1482205653973892 and parameters: {'n_estimators': 700, 'learning_rate': 0.0060298610003856196, 'num_leaves': 188, 'max_depth': 5, 'lambda_l1': 7.379255540886876, 'lambda_l2': 8.03371251989822e-08, 'feature_fraction': 0.7563241618260461, 'bagging_fraction': 0.7630955537929945, 'bagging_freq': 3}. Best is trial 22 with value: 0.1514538413718406.\n","[I 2025-10-11 21:51:08,531] Trial 26 finished with value: 0.13995858570652256 and parameters: {'n_estimators': 1200, 'learning_rate': 0.0016139611745471438, 'num_leaves': 113, 'max_depth': 5, 'lambda_l1': 0.02944371177330299, 'lambda_l2': 6.176620715572034e-06, 'feature_fraction': 0.7173986993938871, 'bagging_fraction': 0.6618180073207258, 'bagging_freq': 2}. Best is trial 22 with value: 0.1514538413718406.\n","[I 2025-10-11 21:51:23,567] Trial 27 finished with value: 0.15025548886395773 and parameters: {'n_estimators': 1500, 'learning_rate': 0.015649909468147354, 'num_leaves': 168, 'max_depth': 4, 'lambda_l1': 1.3347199473350473, 'lambda_l2': 1.1568747761465626e-08, 'feature_fraction': 0.6820621826949546, 'bagging_fraction': 0.7160748534703844, 'bagging_freq': 3}. Best is trial 22 with value: 0.1514538413718406.\n","[I 2025-10-11 21:51:34,697] Trial 28 finished with value: 0.14185586011191614 and parameters: {'n_estimators': 1200, 'learning_rate': 0.004220539729492135, 'num_leaves': 139, 'max_depth': 3, 'lambda_l1': 3.506158935511544e-05, 'lambda_l2': 5.918595681670073e-07, 'feature_fraction': 0.6377923687969265, 'bagging_fraction': 0.8191769781247633, 'bagging_freq': 5}. Best is trial 22 with value: 0.1514538413718406.\n","[I 2025-10-11 21:51:42,950] Trial 29 finished with value: 0.1442760743921976 and parameters: {'n_estimators': 600, 'learning_rate': 0.012490921916491848, 'num_leaves': 195, 'max_depth': 3, 'lambda_l1': 0.33256211881108927, 'lambda_l2': 4.7545933528163165, 'feature_fraction': 0.7347381803884663, 'bagging_fraction': 0.6788459534000066, 'bagging_freq': 4}. Best is trial 22 with value: 0.1514538413718406.\n","[I 2025-10-11 21:52:58,068] Trial 30 finished with value: 0.1442028225626742 and parameters: {'n_estimators': 1400, 'learning_rate': 0.0031112006666970033, 'num_leaves': 131, 'max_depth': 7, 'lambda_l1': 5.368783498826591e-07, 'lambda_l2': 9.827586732686522e-08, 'feature_fraction': 0.7840172036168097, 'bagging_fraction': 0.7582783140152229, 'bagging_freq': 2}. Best is trial 22 with value: 0.1514538413718406.\n","[I 2025-10-11 21:53:36,312] Trial 31 finished with value: 0.15125446160914746 and parameters: {'n_estimators': 1600, 'learning_rate': 0.006477918716515425, 'num_leaves': 164, 'max_depth': 6, 'lambda_l1': 3.041843143849963, 'lambda_l2': 1.1489868932977812e-08, 'feature_fraction': 0.6044865914525758, 'bagging_fraction': 0.822962341555521, 'bagging_freq': 1}. Best is trial 22 with value: 0.1514538413718406.\n","[I 2025-10-11 21:54:07,327] Trial 32 finished with value: 0.15164472424756098 and parameters: {'n_estimators': 1600, 'learning_rate': 0.0073225519424753175, 'num_leaves': 168, 'max_depth': 5, 'lambda_l1': 8.499825408574972, 'lambda_l2': 5.968419966588605e-08, 'feature_fraction': 0.6675978590053072, 'bagging_fraction': 0.8124284314376489, 'bagging_freq': 2}. Best is trial 32 with value: 0.15164472424756098.\n","[I 2025-10-11 21:54:22,112] Trial 33 finished with value: 0.1461198476699317 and parameters: {'n_estimators': 1600, 'learning_rate': 0.02634376792042678, 'num_leaves': 163, 'max_depth': 6, 'lambda_l1': 1.7382989125756245, 'lambda_l2': 3.9854602290570026e-05, 'feature_fraction': 0.6261292628615952, 'bagging_fraction': 0.8095523559896206, 'bagging_freq': 1}. Best is trial 32 with value: 0.15164472424756098.\n","[I 2025-10-11 21:54:54,280] Trial 34 finished with value: 0.1482566949260523 and parameters: {'n_estimators': 1800, 'learning_rate': 0.008535549749298979, 'num_leaves': 84, 'max_depth': 6, 'lambda_l1': 0.05432616686895775, 'lambda_l2': 5.674526996173189e-08, 'feature_fraction': 0.6748083875254437, 'bagging_fraction': 0.8928195638495642, 'bagging_freq': 1}. Best is trial 32 with value: 0.15164472424756098.\n","[I 2025-10-11 21:55:09,961] Trial 35 finished with value: 0.14977301499231788 and parameters: {'n_estimators': 1100, 'learning_rate': 0.013156672011119256, 'num_leaves': 162, 'max_depth': 4, 'lambda_l1': 0.5115580104762393, 'lambda_l2': 3.198977534577411e-07, 'feature_fraction': 0.7028238180356031, 'bagging_fraction': 0.7815529837483217, 'bagging_freq': 2}. Best is trial 32 with value: 0.15164472424756098.\n","[I 2025-10-11 21:55:30,105] Trial 36 finished with value: 0.14978210894453775 and parameters: {'n_estimators': 900, 'learning_rate': 0.006943531088091786, 'num_leaves': 171, 'max_depth': 5, 'lambda_l1': 1.6281525972377136, 'lambda_l2': 9.174607218401168e-05, 'feature_fraction': 0.6360629710434285, 'bagging_fraction': 0.804258127587147, 'bagging_freq': 3}. Best is trial 32 with value: 0.15164472424756098.\n","[I 2025-10-11 21:56:41,687] Trial 37 finished with value: 0.15158560582757033 and parameters: {'n_estimators': 1600, 'learning_rate': 0.004337396973689864, 'num_leaves': 133, 'max_depth': 7, 'lambda_l1': 8.577976363867647, 'lambda_l2': 7.708347361506597e-08, 'feature_fraction': 0.6041486850865548, 'bagging_fraction': 0.9390770122378386, 'bagging_freq': 2}. Best is trial 32 with value: 0.15164472424756098.\n","[I 2025-10-11 21:57:41,759] Trial 38 finished with value: 0.146834821986956 and parameters: {'n_estimators': 1600, 'learning_rate': 0.0039266833178113955, 'num_leaves': 95, 'max_depth': 7, 'lambda_l1': 0.00010513395750395511, 'lambda_l2': 2.6169863533588168e-06, 'feature_fraction': 0.6298489633145404, 'bagging_fraction': 0.9468895537804972, 'bagging_freq': 1}. Best is trial 32 with value: 0.15164472424756098.\n","[I 2025-10-11 21:58:19,189] Trial 39 finished with value: 0.14361540636656306 and parameters: {'n_estimators': 1800, 'learning_rate': 0.0020335486113238644, 'num_leaves': 23, 'max_depth': 7, 'lambda_l1': 0.160251953970068, 'lambda_l2': 0.0014608827033495378, 'feature_fraction': 0.600114334912058, 'bagging_fraction': 0.9242777505373518, 'bagging_freq': 2}. Best is trial 32 with value: 0.15164472424756098.\n","[I 2025-10-11 21:59:00,043] Trial 40 finished with value: 0.14449574778897745 and parameters: {'n_estimators': 1500, 'learning_rate': 0.010184173644196522, 'num_leaves': 131, 'max_depth': 9, 'lambda_l1': 0.002668445099554684, 'lambda_l2': 1.8755471869647772e-05, 'feature_fraction': 0.6979692554340472, 'bagging_fraction': 0.8828812006183354, 'bagging_freq': 1}. Best is trial 32 with value: 0.15164472424756098.\n","[I 2025-10-11 21:59:34,448] Trial 41 finished with value: 0.15002152686104547 and parameters: {'n_estimators': 1300, 'learning_rate': 0.006779967268982968, 'num_leaves': 150, 'max_depth': 6, 'lambda_l1': 2.692356230704305, 'lambda_l2': 5.273787925288657e-08, 'feature_fraction': 0.6630838466497113, 'bagging_fraction': 0.7689419158012916, 'bagging_freq': 2}. Best is trial 32 with value: 0.15164472424756098.\n","[I 2025-10-11 22:00:08,569] Trial 42 finished with value: 0.15009864392093336 and parameters: {'n_estimators': 1700, 'learning_rate': 0.0038946251824569984, 'num_leaves': 199, 'max_depth': 5, 'lambda_l1': 9.356882654901838, 'lambda_l2': 1.676060873730358e-07, 'feature_fraction': 0.6754495342986524, 'bagging_fraction': 0.8287492906430776, 'bagging_freq': 3}. Best is trial 32 with value: 0.15164472424756098.\n"]},{"output_type":"stream","name":"stdout","text":["\n","[Optuna 조기 종료] 10번의 trial 동안 최고 점수가 갱신되지 않아 튜닝을 중단합니다.\n","\n","✅ 튜닝 완료!\n","\n","==================================================\n","🔬 최적 하이퍼파라미터 (Best Hyperparameters)\n","==================================================\n","        n_estimators: 1600\n","       learning_rate: 0.0073225519424753175\n","          num_leaves: 168\n","           max_depth: 5\n","           lambda_l1: 8.499825408574972\n","           lambda_l2: 5.968419966588605e-08\n","    feature_fraction: 0.6675978590053072\n","    bagging_fraction: 0.8124284314376489\n","        bagging_freq: 2\n","==================================================\n","\n","🔬 Step 5: 튜닝된 최종 모델 학습 및 평가...\n","✅ 튜닝된 모델 평가 완료.\n","\n","============================================================\n","📊 최종 성능 비교 결과 (Test Set)\n","============================================================\n","              PR AUC  ROC AUC  F1-Score\n","Baseline      0.1395   0.6480    0.0101\n","Optuna Tuned  0.1546   0.6666    0.0015\n","\n","============================================================\n","💾 Step 6: 최종 모델 예측 결과를 원본 CSV에 추가하여 저장\n","============================================================\n","✅ 모든 데이터의 예측 결과가 '/content/drive/MyDrive/review_helpfulness/PADA/results/s2/audible/RoBERTa_audible_with_s2_predictions.csv' 파일에 성공적으로 저장되었습니다.\n","\n","============================================================\n","🧹 Step 7: 사용된 변수들을 메모리에서 정리\n","============================================================\n","✅ 메모리 정리가 완료되었습니다.\n","\n","🎉 모든 과정이 완료되었습니다!\n"]}]},{"cell_type":"markdown","source":["## DistilBERT"],"metadata":{"id":"kFbIc6WZvEh1"}},{"cell_type":"code","source":["# === 2. 환경설정 클래스 ===\n","class Config:\n","    \"\"\"실행에 필요한 모든 설정값을 중앙에서 관리합니다.\"\"\"\n","    # 🌟 1. 입력 파일 경로 설정\n","    CSV_FILE_PATH = \"/content/drive/MyDrive/review_helpfulness/PADA/data/audible/audible.csv\"\n","    EMBEDDING_PATH = \"/content/drive/MyDrive/review_helpfulness/PADA/embedding/audible_DistilBERT.npy\"\n","\n","    # 🌟 2. 최종 결과 CSV 파일 저장 경로 설정\n","    OUTPUT_CSV_PATH = \"/content/drive/MyDrive/review_helpfulness/PADA/results/s2/audible/DistilBERT_audible_with_s2_predictions.csv\"\n","\n","    # --- 데이터 정보 ---\n","    TARGET_COLUMN = 'binary_helpfulness'\n","\n","    # --- 데이터 분할 ---\n","    TEST_SPLIT_RATIO = 0.2\n","    RANDOM_STATE = 42\n","\n","    # --- Optuna 튜닝 설정 ---\n","    N_TRIALS = 50\n","    TUNING_METRIC = 'pr_auc'\n","    EARLY_STOPPING_ROUNDS = 10 # 🌟 Optuna 조기 종료 횟수\n","\n","# === 3. Optuna 조기 종료 콜백 ===\n","class EarlyStoppingCallback:\n","    \"\"\"Optuna 스터디의 조기 종료를 위한 콜백 클래스\"\"\"\n","    def __init__(self, early_stopping_rounds: int):\n","        self._early_stopping_rounds = early_stopping_rounds\n","        self._best_value = -float(\"inf\")\n","        self._counter = 0\n","\n","    def __call__(self, study: optuna.study.Study, trial: optuna.trial.Trial):\n","        current_best_value = study.best_value\n","        if current_best_value is not None and current_best_value > self._best_value:\n","            self._best_value = current_best_value\n","            self._counter = 0\n","        else:\n","            self._counter += 1\n","\n","        if self._counter >= self._early_stopping_rounds:\n","            print(f\"\\n[Optuna 조기 종료] {self._early_stopping_rounds}번의 trial 동안 최고 점수가 갱신되지 않아 튜닝을 중단합니다.\")\n","            study.stop()\n","\n","# === 4. Optuna Objective 함수 ===\n","def objective(trial, X, y):\n","    \"\"\"Optuna가 최적의 하이퍼파라미터를 찾기 위해 반복 호출하는 함수\"\"\"\n","    X_train, X_val, y_train, y_val = train_test_split(\n","        X, y, test_size=0.25, random_state=Config.RANDOM_STATE, stratify=y\n","    )\n","\n","    params = {\n","        'objective': 'binary', 'metric': 'logloss', 'verbosity': -1,\n","        'boosting_type': 'gbdt', 'random_state': Config.RANDOM_STATE,\n","        'device': 'gpu',  # 🌟 Optuna Trial 내부에서도 GPU 사용\n","        'n_estimators': trial.suggest_int('n_estimators', 100, 2000, step=100),\n","        'learning_rate': trial.suggest_float('learning_rate', 1e-3, 0.3, log=True),\n","        'num_leaves': trial.suggest_int('num_leaves', 20, 300),\n","        'max_depth': trial.suggest_int('max_depth', 3, 12),\n","        'lambda_l1': trial.suggest_float('lambda_l1', 1e-8, 10.0, log=True),\n","        'lambda_l2': trial.suggest_float('lambda_l2', 1e-8, 10.0, log=True),\n","        'feature_fraction': trial.suggest_float('feature_fraction', 0.6, 1.0),\n","        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.6, 1.0),\n","        'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\n","    }\n","\n","    model = lgb.LGBMClassifier(**params)\n","    model.fit(X_train, y_train,\n","              eval_set=[(X_val, y_val)],\n","              eval_metric='logloss',\n","              callbacks=[lgb.early_stopping(100, verbose=False)])\n","\n","    y_pred_proba = model.predict_proba(X_val)[:, 1]\n","    score = average_precision_score(y_val, y_pred_proba)\n","    return score\n","\n","# === 5. 메인 실행 블록 ===\n","if __name__ == '__main__':\n","    config = Config()\n","\n","    # ... (Step 1 ~ 2: 데이터 로드, 분할, 베이스라인 측정) ...\n","    print(\"Step 1: 데이터 로드 및 분할 중...\")\n","    try:\n","        df = pd.read_csv(config.CSV_FILE_PATH)\n","        labels = df[config.TARGET_COLUMN].values\n","        embeddings = np.load(config.EMBEDDING_PATH)\n","        assert len(df) == len(embeddings)\n","    except Exception as e:\n","        print(f\"🔥 파일 로드 실패: {e}\"); exit()\n","\n","    indices = np.arange(len(df))\n","    train_indices, test_indices = train_test_split(\n","        indices, test_size=config.TEST_SPLIT_RATIO, random_state=config.RANDOM_STATE, stratify=labels\n","    )\n","    X_train, X_test = embeddings[train_indices], embeddings[test_indices]\n","    y_train, y_test = labels[train_indices], labels[test_indices]\n","    print(f\"✅ 완료 (학습용: {len(y_train)}건, 테스트용: {len(y_test)}건)\")\n","\n","    print(\"\\n\" + \"=\"*50)\n","    print(\"📊 Step 2: 베이스라인 모델 성능 측정 (GPU 사용)\")\n","    print(\"=\"*50)\n","\n","    baseline_model = lgb.LGBMClassifier(device='gpu', random_state=config.RANDOM_STATE)\n","    baseline_model.fit(X_train, y_train)\n","\n","    y_pred_proba_base = baseline_model.predict_proba(X_test)[:, 1]\n","    y_pred_class_base = (y_pred_proba_base > 0.5).astype(int)\n","\n","    final_results = {}\n","    final_results['Baseline'] = {\n","        \"PR AUC\": average_precision_score(y_test, y_pred_proba_base),\n","        \"ROC AUC\": roc_auc_score(y_test, y_pred_proba_base),\n","        \"F1-Score\": f1_score(y_test, y_pred_class_base),\n","    }\n","    print(\"✅ 베이스라인 모델 평가 완료.\")\n","\n","    # --- Step 3: Optuna 튜닝 수행 (조기 종료 포함) ---\n","    print(\"\\n\" + \"=\"*50)\n","    print(f\"🔬 Step 3: Optuna 하이퍼파라미터 튜닝 시작 (GPU 사용)...\")\n","    print(f\"(최대 {config.N_TRIALS}번 시도, {config.EARLY_STOPPING_ROUNDS}번 개선 없으면 조기 종료)\")\n","    print(\"=\"*50)\n","\n","    early_stopping_callback = EarlyStoppingCallback(early_stopping_rounds=config.EARLY_STOPPING_ROUNDS)\n","    study = optuna.create_study(direction='maximize')\n","    pbar = tqdm(total=config.N_TRIALS, desc=\"Optuna 튜닝 진행률\")\n","\n","    try:\n","        study.optimize(lambda trial: objective(trial, X_train, y_train),\n","                       n_trials=config.N_TRIALS,\n","                       callbacks=[lambda study, trial: pbar.update(1), early_stopping_callback])\n","    except optuna.exceptions.OptunaError:\n","        # 조기 종료 시 발생하는 예외를 정상 처리\n","        pass\n","    pbar.close()\n","\n","    # ... (Step 4 ~ 6: 결과 출력, 저장, 메모리 정리) ...\n","    print(f\"\\n✅ 튜닝 완료!\")\n","    print(\"\\n\" + \"=\"*50)\n","    print(\"🔬 최적 하이퍼파라미터 (Best Hyperparameters)\")\n","    print(\"=\"*50)\n","    best_params = study.best_params\n","    for key, value in best_params.items():\n","        print(f\"{key:>20s}: {value}\")\n","    print(\"=\"*50)\n","\n","    print(f\"\\n🔬 Step 5: 튜닝된 최종 모델 학습 및 평가...\")\n","    final_model = lgb.LGBMClassifier(device='gpu', objective='binary', verbosity=-1, random_state=config.RANDOM_STATE, **best_params)\n","    final_model.fit(X_train, y_train)\n","\n","    y_pred_proba_tuned = final_model.predict_proba(X_test)[:, 1]\n","    y_pred_class_tuned = (y_pred_proba_tuned > 0.5).astype(int)\n","\n","    final_results['Optuna Tuned'] = {\n","        \"PR AUC\": average_precision_score(y_test, y_pred_proba_tuned),\n","        \"ROC AUC\": roc_auc_score(y_test, y_pred_proba_tuned),\n","        \"F1-Score\": f1_score(y_test, y_pred_class_tuned),\n","    }\n","    print(\"✅ 튜닝된 모델 평가 완료.\")\n","\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"📊 최종 성능 비교 결과 (Test Set)\")\n","    print(\"=\"*60)\n","    results_df = pd.DataFrame(final_results).T\n","    print(results_df.round(4))\n","\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"💾 Step 6: 최종 모델 예측 결과를 원본 CSV에 추가하여 저장\")\n","    print(\"=\"*60)\n","\n","    train_pred_proba = final_model.predict_proba(X_train)[:, 1]\n","    train_pred_class = (train_pred_proba > 0.5).astype(int)\n","\n","    df['s2_pred_proba'] = np.nan\n","    df['s2_pred_class'] = np.nan\n","\n","    df.loc[train_indices, 's2_pred_proba'] = train_pred_proba\n","    df.loc[train_indices, 's2_pred_class'] = train_pred_class\n","\n","    df.loc[test_indices, 's2_pred_proba'] = y_pred_proba_tuned\n","    df.loc[test_indices, 's2_pred_class'] = y_pred_class_tuned\n","\n","    # 🌟 Config에 설정된 경로로 최종 파일 저장\n","    df.to_csv(config.OUTPUT_CSV_PATH, index=False, encoding='utf-8-sig')\n","\n","    print(f\"✅ 모든 데이터의 예측 결과가 '{config.OUTPUT_CSV_PATH}' 파일에 성공적으로 저장되었습니다.\")\n","\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"🧹 Step 7: 사용된 변수들을 메모리에서 정리\")\n","    print(\"=\"*60)\n","\n","    vars_to_delete = [\n","        'df', 'labels', 'embeddings', 'indices', 'X_train', 'X_test',\n","        'y_train', 'y_test', 'train_indices', 'test_indices',\n","        'baseline_model', 'final_model', 'study',\n","    ]\n","    for var_name in vars_to_delete:\n","        if var_name in locals() or var_name in globals():\n","            if var_name in globals(): del globals()[var_name]\n","\n","    gc.collect()\n","    print(\"✅ 메모리 정리가 완료되었습니다.\")\n","\n","    print(\"\\n🎉 모든 과정이 완료되었습니다!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","referenced_widgets":["b10ca073771c421ba5f39826c93e722d","acc2dded66ef4994840658817f2f5df8","82342606e2fc428496499192dcffd4dc","b9dd5d12a46d49cd95c3c96759635f50","08035371cce34a4b8b81f6788441f9c2","91329570636e43af8e334c4aaaf72d71","e215865e537a4009b933dd1ad9e4787b","773a1d321a7346a19fe88acf37c61513","c9b74b27f1db4c3987a79c281d282d17","7811c1e6d80a41539afdefea9f655a53","6cc738bf88de40bd83d949d78ab801a6"]},"id":"0gvaJHeDxhk7","executionInfo":{"status":"ok","timestamp":1760220451720,"user_tz":-540,"elapsed":402829,"user":{"displayName":"KW-data-analytics","userId":"09651493752354345908"}},"outputId":"29656683-206c-43a8-9715-89bdc029266a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Step 1: 데이터 로드 및 분할 중...\n","✅ 완료 (학습용: 74391건, 테스트용: 18598건)\n","\n","==================================================\n","📊 Step 2: 베이스라인 모델 성능 측정 (GPU 사용)\n","==================================================\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-10-11 22:01:01,129] A new study created in memory with name: no-name-a15d3f70-6f56-4ad3-be3a-41a13427900b\n"]},{"output_type":"stream","name":"stdout","text":["✅ 베이스라인 모델 평가 완료.\n","\n","==================================================\n","🔬 Step 3: Optuna 하이퍼파라미터 튜닝 시작 (GPU 사용)...\n","(최대 50번 시도, 10번 개선 없으면 조기 종료)\n","==================================================\n"]},{"output_type":"display_data","data":{"text/plain":["Optuna 튜닝 진행률:   0%|          | 0/50 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b10ca073771c421ba5f39826c93e722d"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2025-10-11 22:01:12,329] Trial 0 finished with value: 0.14688707822727604 and parameters: {'n_estimators': 2000, 'learning_rate': 0.021727139532555003, 'num_leaves': 88, 'max_depth': 5, 'lambda_l1': 6.798930373100897e-05, 'lambda_l2': 7.487895916827592, 'feature_fraction': 0.8393529020860595, 'bagging_fraction': 0.7975251112943258, 'bagging_freq': 5}. Best is trial 0 with value: 0.14688707822727604.\n","[I 2025-10-11 22:02:08,532] Trial 1 finished with value: 0.14198449611236572 and parameters: {'n_estimators': 1700, 'learning_rate': 0.0014311790934840038, 'num_leaves': 31, 'max_depth': 11, 'lambda_l1': 0.01141525217302734, 'lambda_l2': 0.00018458535407303583, 'feature_fraction': 0.8329413573837661, 'bagging_fraction': 0.9881747852137114, 'bagging_freq': 4}. Best is trial 0 with value: 0.14688707822727604.\n","[I 2025-10-11 22:04:27,628] Trial 2 finished with value: 0.14663525715032577 and parameters: {'n_estimators': 1900, 'learning_rate': 0.0020766899003741334, 'num_leaves': 199, 'max_depth': 8, 'lambda_l1': 1.8455965925156559, 'lambda_l2': 6.772471691167783e-07, 'feature_fraction': 0.748578452453394, 'bagging_fraction': 0.8236174743864572, 'bagging_freq': 4}. Best is trial 0 with value: 0.14688707822727604.\n","[I 2025-10-11 22:04:42,787] Trial 3 finished with value: 0.0989276776868813 and parameters: {'n_estimators': 300, 'learning_rate': 0.29444702082483004, 'num_leaves': 138, 'max_depth': 11, 'lambda_l1': 1.694368484071718e-06, 'lambda_l2': 0.0024040363962800288, 'feature_fraction': 0.7354693142086799, 'bagging_fraction': 0.7374845762899794, 'bagging_freq': 5}. Best is trial 0 with value: 0.14688707822727604.\n","[I 2025-10-11 22:04:55,469] Trial 4 finished with value: 0.10852602846936148 and parameters: {'n_estimators': 1100, 'learning_rate': 0.16577168151273738, 'num_leaves': 126, 'max_depth': 9, 'lambda_l1': 1.492920711986629e-05, 'lambda_l2': 3.515728561065889e-08, 'feature_fraction': 0.6991676395703108, 'bagging_fraction': 0.7468666429236916, 'bagging_freq': 6}. Best is trial 0 with value: 0.14688707822727604.\n","[I 2025-10-11 22:05:08,890] Trial 5 finished with value: 0.14244274162226753 and parameters: {'n_estimators': 1100, 'learning_rate': 0.012425378723787902, 'num_leaves': 226, 'max_depth': 5, 'lambda_l1': 1.0117014654569687e-06, 'lambda_l2': 0.027547822192918958, 'feature_fraction': 0.6462103642450115, 'bagging_fraction': 0.6382608074814561, 'bagging_freq': 3}. Best is trial 0 with value: 0.14688707822727604.\n","[I 2025-10-11 22:05:41,400] Trial 6 finished with value: 0.13967544850301508 and parameters: {'n_estimators': 1800, 'learning_rate': 0.017407905570256583, 'num_leaves': 156, 'max_depth': 12, 'lambda_l1': 0.9265990853531212, 'lambda_l2': 9.062896106994266e-05, 'feature_fraction': 0.6738552710161256, 'bagging_fraction': 0.7247614756255252, 'bagging_freq': 5}. Best is trial 0 with value: 0.14688707822727604.\n","[I 2025-10-11 22:05:55,530] Trial 7 finished with value: 0.14348951150804756 and parameters: {'n_estimators': 1700, 'learning_rate': 0.004183095146947304, 'num_leaves': 294, 'max_depth': 3, 'lambda_l1': 0.00023571415866178256, 'lambda_l2': 9.028655708049947e-07, 'feature_fraction': 0.7239614011398207, 'bagging_fraction': 0.8205840283683146, 'bagging_freq': 7}. Best is trial 0 with value: 0.14688707822727604.\n","[I 2025-10-11 22:06:01,309] Trial 8 finished with value: 0.14010943603911802 and parameters: {'n_estimators': 200, 'learning_rate': 0.028488861032734934, 'num_leaves': 207, 'max_depth': 3, 'lambda_l1': 5.0962139581516346e-08, 'lambda_l2': 1.6677310833789876e-08, 'feature_fraction': 0.8799696547328535, 'bagging_fraction': 0.9787728328674794, 'bagging_freq': 6}. Best is trial 0 with value: 0.14688707822727604.\n","[I 2025-10-11 22:06:28,707] Trial 9 finished with value: 0.14145822208693648 and parameters: {'n_estimators': 1100, 'learning_rate': 0.013556585697464518, 'num_leaves': 235, 'max_depth': 8, 'lambda_l1': 2.6621151533894554e-05, 'lambda_l2': 1.4051839060650391e-05, 'feature_fraction': 0.6773650170687397, 'bagging_fraction': 0.929235209151843, 'bagging_freq': 1}. Best is trial 0 with value: 0.14688707822727604.\n","[I 2025-10-11 22:06:39,396] Trial 10 finished with value: 0.13939225490236606 and parameters: {'n_estimators': 600, 'learning_rate': 0.059772955723859586, 'num_leaves': 60, 'max_depth': 6, 'lambda_l1': 0.0031264787678336736, 'lambda_l2': 9.36375112523181, 'feature_fraction': 0.9982619728500755, 'bagging_fraction': 0.882954913083491, 'bagging_freq': 2}. Best is trial 0 with value: 0.14688707822727604.\n"]},{"output_type":"stream","name":"stdout","text":["\n","[Optuna 조기 종료] 10번의 trial 동안 최고 점수가 갱신되지 않아 튜닝을 중단합니다.\n","\n","✅ 튜닝 완료!\n","\n","==================================================\n","🔬 최적 하이퍼파라미터 (Best Hyperparameters)\n","==================================================\n","        n_estimators: 2000\n","       learning_rate: 0.021727139532555003\n","          num_leaves: 88\n","           max_depth: 5\n","           lambda_l1: 6.798930373100897e-05\n","           lambda_l2: 7.487895916827592\n","    feature_fraction: 0.8393529020860595\n","    bagging_fraction: 0.7975251112943258\n","        bagging_freq: 5\n","==================================================\n","\n","🔬 Step 5: 튜닝된 최종 모델 학습 및 평가...\n","✅ 튜닝된 모델 평가 완료.\n","\n","============================================================\n","📊 최종 성능 비교 결과 (Test Set)\n","============================================================\n","              PR AUC  ROC AUC  F1-Score\n","Baseline      0.1443   0.6546    0.0044\n","Optuna Tuned  0.1586   0.6582    0.0044\n","\n","============================================================\n","💾 Step 6: 최종 모델 예측 결과를 원본 CSV에 추가하여 저장\n","============================================================\n","✅ 모든 데이터의 예측 결과가 '/content/drive/MyDrive/review_helpfulness/PADA/results/s2/audible/DistilBERT_audible_with_s2_predictions.csv' 파일에 성공적으로 저장되었습니다.\n","\n","============================================================\n","🧹 Step 7: 사용된 변수들을 메모리에서 정리\n","============================================================\n","✅ 메모리 정리가 완료되었습니다.\n","\n","🎉 모든 과정이 완료되었습니다!\n"]}]},{"cell_type":"markdown","source":["# Hotel"],"metadata":{"id":"DLrkVcZ3vLmm"}},{"cell_type":"markdown","source":["## T5"],"metadata":{"id":"f39dc6bWvO22"}},{"cell_type":"code","source":["# === 2. 환경설정 클래스 ===\n","class Config:\n","    \"\"\"실행에 필요한 모든 설정값을 중앙에서 관리합니다.\"\"\"\n","    # 🌟 1. 입력 파일 경로 설정\n","    CSV_FILE_PATH = \"/content/drive/MyDrive/review_helpfulness/PADA/data/hotel/hotel.csv\"\n","    EMBEDDING_PATH = \"/content/drive/MyDrive/review_helpfulness/PADA/embedding/hotel_T5.npy\"\n","\n","    # 🌟 2. 최종 결과 CSV 파일 저장 경로 설정\n","    OUTPUT_CSV_PATH = \"/content/drive/MyDrive/review_helpfulness/PADA/results/s2/hotel/T5_hotel_with_s2_predictions.csv\"\n","\n","    # --- 데이터 정보 ---\n","    TARGET_COLUMN = 'binary_helpfulness'\n","\n","    # --- 데이터 분할 ---\n","    TEST_SPLIT_RATIO = 0.2\n","    RANDOM_STATE = 42\n","\n","    # --- Optuna 튜닝 설정 ---\n","    N_TRIALS = 50\n","    TUNING_METRIC = 'pr_auc'\n","    EARLY_STOPPING_ROUNDS = 10 # 🌟 Optuna 조기 종료 횟수\n","\n","# === 3. Optuna 조기 종료 콜백 ===\n","class EarlyStoppingCallback:\n","    \"\"\"Optuna 스터디의 조기 종료를 위한 콜백 클래스\"\"\"\n","    def __init__(self, early_stopping_rounds: int):\n","        self._early_stopping_rounds = early_stopping_rounds\n","        self._best_value = -float(\"inf\")\n","        self._counter = 0\n","\n","    def __call__(self, study: optuna.study.Study, trial: optuna.trial.Trial):\n","        current_best_value = study.best_value\n","        if current_best_value is not None and current_best_value > self._best_value:\n","            self._best_value = current_best_value\n","            self._counter = 0\n","        else:\n","            self._counter += 1\n","\n","        if self._counter >= self._early_stopping_rounds:\n","            print(f\"\\n[Optuna 조기 종료] {self._early_stopping_rounds}번의 trial 동안 최고 점수가 갱신되지 않아 튜닝을 중단합니다.\")\n","            study.stop()\n","\n","# === 4. Optuna Objective 함수 ===\n","def objective(trial, X, y):\n","    \"\"\"Optuna가 최적의 하이퍼파라미터를 찾기 위해 반복 호출하는 함수\"\"\"\n","    X_train, X_val, y_train, y_val = train_test_split(\n","        X, y, test_size=0.25, random_state=Config.RANDOM_STATE, stratify=y\n","    )\n","\n","    params = {\n","        'objective': 'binary', 'metric': 'logloss', 'verbosity': -1,\n","        'boosting_type': 'gbdt', 'random_state': Config.RANDOM_STATE,\n","        'device': 'gpu',  # 🌟 Optuna Trial 내부에서도 GPU 사용\n","        'n_estimators': trial.suggest_int('n_estimators', 100, 2000, step=100),\n","        'learning_rate': trial.suggest_float('learning_rate', 1e-3, 0.3, log=True),\n","        'num_leaves': trial.suggest_int('num_leaves', 20, 300),\n","        'max_depth': trial.suggest_int('max_depth', 3, 12),\n","        'lambda_l1': trial.suggest_float('lambda_l1', 1e-8, 10.0, log=True),\n","        'lambda_l2': trial.suggest_float('lambda_l2', 1e-8, 10.0, log=True),\n","        'feature_fraction': trial.suggest_float('feature_fraction', 0.6, 1.0),\n","        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.6, 1.0),\n","        'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\n","    }\n","\n","    model = lgb.LGBMClassifier(**params)\n","    model.fit(X_train, y_train,\n","              eval_set=[(X_val, y_val)],\n","              eval_metric='logloss',\n","              callbacks=[lgb.early_stopping(100, verbose=False)])\n","\n","    y_pred_proba = model.predict_proba(X_val)[:, 1]\n","    score = average_precision_score(y_val, y_pred_proba)\n","    return score\n","\n","# === 5. 메인 실행 블록 ===\n","if __name__ == '__main__':\n","    config = Config()\n","\n","    # ... (Step 1 ~ 2: 데이터 로드, 분할, 베이스라인 측정) ...\n","    print(\"Step 1: 데이터 로드 및 분할 중...\")\n","    try:\n","        df = pd.read_csv(config.CSV_FILE_PATH)\n","        labels = df[config.TARGET_COLUMN].values\n","        embeddings = np.load(config.EMBEDDING_PATH)\n","        assert len(df) == len(embeddings)\n","    except Exception as e:\n","        print(f\"🔥 파일 로드 실패: {e}\"); exit()\n","\n","    indices = np.arange(len(df))\n","    train_indices, test_indices = train_test_split(\n","        indices, test_size=config.TEST_SPLIT_RATIO, random_state=config.RANDOM_STATE, stratify=labels\n","    )\n","    X_train, X_test = embeddings[train_indices], embeddings[test_indices]\n","    y_train, y_test = labels[train_indices], labels[test_indices]\n","    print(f\"✅ 완료 (학습용: {len(y_train)}건, 테스트용: {len(y_test)}건)\")\n","\n","    print(\"\\n\" + \"=\"*50)\n","    print(\"📊 Step 2: 베이스라인 모델 성능 측정 (GPU 사용)\")\n","    print(\"=\"*50)\n","\n","    baseline_model = lgb.LGBMClassifier(device='gpu', random_state=config.RANDOM_STATE)\n","    baseline_model.fit(X_train, y_train)\n","\n","    y_pred_proba_base = baseline_model.predict_proba(X_test)[:, 1]\n","    y_pred_class_base = (y_pred_proba_base > 0.5).astype(int)\n","\n","    final_results = {}\n","    final_results['Baseline'] = {\n","        \"PR AUC\": average_precision_score(y_test, y_pred_proba_base),\n","        \"ROC AUC\": roc_auc_score(y_test, y_pred_proba_base),\n","        \"F1-Score\": f1_score(y_test, y_pred_class_base),\n","    }\n","    print(\"✅ 베이스라인 모델 평가 완료.\")\n","\n","    # --- Step 3: Optuna 튜닝 수행 (조기 종료 포함) ---\n","    print(\"\\n\" + \"=\"*50)\n","    print(f\"🔬 Step 3: Optuna 하이퍼파라미터 튜닝 시작 (GPU 사용)...\")\n","    print(f\"(최대 {config.N_TRIALS}번 시도, {config.EARLY_STOPPING_ROUNDS}번 개선 없으면 조기 종료)\")\n","    print(\"=\"*50)\n","\n","    early_stopping_callback = EarlyStoppingCallback(early_stopping_rounds=config.EARLY_STOPPING_ROUNDS)\n","    study = optuna.create_study(direction='maximize')\n","    pbar = tqdm(total=config.N_TRIALS, desc=\"Optuna 튜닝 진행률\")\n","\n","    try:\n","        study.optimize(lambda trial: objective(trial, X_train, y_train),\n","                       n_trials=config.N_TRIALS,\n","                       callbacks=[lambda study, trial: pbar.update(1), early_stopping_callback])\n","    except optuna.exceptions.OptunaError:\n","        # 조기 종료 시 발생하는 예외를 정상 처리\n","        pass\n","    pbar.close()\n","\n","    # ... (Step 4 ~ 6: 결과 출력, 저장, 메모리 정리) ...\n","    print(f\"\\n✅ 튜닝 완료!\")\n","    print(\"\\n\" + \"=\"*50)\n","    print(\"🔬 최적 하이퍼파라미터 (Best Hyperparameters)\")\n","    print(\"=\"*50)\n","    best_params = study.best_params\n","    for key, value in best_params.items():\n","        print(f\"{key:>20s}: {value}\")\n","    print(\"=\"*50)\n","\n","    print(f\"\\n🔬 Step 5: 튜닝된 최종 모델 학습 및 평가...\")\n","    final_model = lgb.LGBMClassifier(device='gpu', objective='binary', verbosity=-1, random_state=config.RANDOM_STATE, **best_params)\n","    final_model.fit(X_train, y_train)\n","\n","    y_pred_proba_tuned = final_model.predict_proba(X_test)[:, 1]\n","    y_pred_class_tuned = (y_pred_proba_tuned > 0.5).astype(int)\n","\n","    final_results['Optuna Tuned'] = {\n","        \"PR AUC\": average_precision_score(y_test, y_pred_proba_tuned),\n","        \"ROC AUC\": roc_auc_score(y_test, y_pred_proba_tuned),\n","        \"F1-Score\": f1_score(y_test, y_pred_class_tuned),\n","    }\n","    print(\"✅ 튜닝된 모델 평가 완료.\")\n","\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"📊 최종 성능 비교 결과 (Test Set)\")\n","    print(\"=\"*60)\n","    results_df = pd.DataFrame(final_results).T\n","    print(results_df.round(4))\n","\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"💾 Step 6: 최종 모델 예측 결과를 원본 CSV에 추가하여 저장\")\n","    print(\"=\"*60)\n","\n","    train_pred_proba = final_model.predict_proba(X_train)[:, 1]\n","    train_pred_class = (train_pred_proba > 0.5).astype(int)\n","\n","    df['s2_pred_proba'] = np.nan\n","    df['s2_pred_class'] = np.nan\n","\n","    df.loc[train_indices, 's2_pred_proba'] = train_pred_proba\n","    df.loc[train_indices, 's2_pred_class'] = train_pred_class\n","\n","    df.loc[test_indices, 's2_pred_proba'] = y_pred_proba_tuned\n","    df.loc[test_indices, 's2_pred_class'] = y_pred_class_tuned\n","\n","    # 🌟 Config에 설정된 경로로 최종 파일 저장\n","    df.to_csv(config.OUTPUT_CSV_PATH, index=False, encoding='utf-8-sig')\n","\n","    print(f\"✅ 모든 데이터의 예측 결과가 '{config.OUTPUT_CSV_PATH}' 파일에 성공적으로 저장되었습니다.\")\n","\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"🧹 Step 7: 사용된 변수들을 메모리에서 정리\")\n","    print(\"=\"*60)\n","\n","    vars_to_delete = [\n","        'df', 'labels', 'embeddings', 'indices', 'X_train', 'X_test',\n","        'y_train', 'y_test', 'train_indices', 'test_indices',\n","        'baseline_model', 'final_model', 'study',\n","    ]\n","    for var_name in vars_to_delete:\n","        if var_name in locals() or var_name in globals():\n","            if var_name in globals(): del globals()[var_name]\n","\n","    gc.collect()\n","    print(\"✅ 메모리 정리가 완료되었습니다.\")\n","\n","    print(\"\\n🎉 모든 과정이 완료되었습니다!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["3e22913477b0463799f4d75fab3f7c1d","333470c373f44f18bd2dba276ee78c3b","01c29d961d7f40808965e434f5e29b7f","803cb2aacae04d08b8dbdcfcd62dd74f","c4734536b2d147e49aecae71bb12641d","934d9dcd6a9543f1a0d726398853639f","4b9096b1ce3c43e481f648d030722caa","d5ba3e3857c749f5a057ec1179f628f6","a14c8b58d6134ee28a8fb226c7b953c9","1bc52f6825024966b52c0465f7321244","db381bdb115744318b935c5920492088"]},"id":"vuEOOHAWxlkh","executionInfo":{"status":"ok","timestamp":1760251015440,"user_tz":-540,"elapsed":642579,"user":{"displayName":"KW-data-analytics","userId":"09651493752354345908"}},"outputId":"6e6f3612-f246-4098-e4ba-573ffa55964c"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Step 1: 데이터 로드 및 분할 중...\n","✅ 완료 (학습용: 71604건, 테스트용: 17901건)\n","\n","==================================================\n","📊 Step 2: 베이스라인 모델 성능 측정 (GPU 사용)\n","==================================================\n","[LightGBM] [Info] Number of positive: 6586, number of negative: 65018\n","[LightGBM] [Info] This is the GPU trainer!!\n","[LightGBM] [Info] Total Bins 195840\n","[LightGBM] [Info] Number of data points in the train set: 71604, number of used features: 768\n","[LightGBM] [Info] Using GPU Device: NVIDIA A100-SXM4-80GB, Vendor: NVIDIA Corporation\n","[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n","[LightGBM] [Info] GPU programs have been built\n","[LightGBM] [Info] Size of histogram bin entry: 8\n","[LightGBM] [Info] 768 dense feature groups (52.44 MB) transferred to GPU in 0.019890 secs. 0 sparse feature groups\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.091978 -> initscore=-2.289718\n","[LightGBM] [Info] Start training from score -2.289718\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-10-12 06:26:35,031] A new study created in memory with name: no-name-7340e22d-8b6d-4ec2-9e20-2a50f926cf95\n"]},{"output_type":"stream","name":"stdout","text":["✅ 베이스라인 모델 평가 완료.\n","\n","==================================================\n","🔬 Step 3: Optuna 하이퍼파라미터 튜닝 시작 (GPU 사용)...\n","(최대 50번 시도, 10번 개선 없으면 조기 종료)\n","==================================================\n"]},{"output_type":"display_data","data":{"text/plain":["Optuna 튜닝 진행률:   0%|          | 0/50 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3e22913477b0463799f4d75fab3f7c1d"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2025-10-12 06:26:45,198] Trial 0 finished with value: 0.15213446515927667 and parameters: {'n_estimators': 1200, 'learning_rate': 0.020417841187667107, 'num_leaves': 39, 'max_depth': 5, 'lambda_l1': 0.4792098310469275, 'lambda_l2': 1.078154277561877, 'feature_fraction': 0.7916919694550321, 'bagging_fraction': 0.7800569871647935, 'bagging_freq': 6}. Best is trial 0 with value: 0.15213446515927667.\n","[I 2025-10-12 06:27:05,358] Trial 1 finished with value: 0.14432457209665023 and parameters: {'n_estimators': 500, 'learning_rate': 0.028070308628647355, 'num_leaves': 155, 'max_depth': 11, 'lambda_l1': 0.00032401533379208006, 'lambda_l2': 1.9981262241385757e-06, 'feature_fraction': 0.7258776302053424, 'bagging_fraction': 0.6821596666513379, 'bagging_freq': 4}. Best is trial 0 with value: 0.15213446515927667.\n","[I 2025-10-12 06:27:18,210] Trial 2 finished with value: 0.120059808064244 and parameters: {'n_estimators': 1900, 'learning_rate': 0.22668538456619708, 'num_leaves': 236, 'max_depth': 9, 'lambda_l1': 1.5803940033301724e-08, 'lambda_l2': 0.03409859072690598, 'feature_fraction': 0.6466392096266765, 'bagging_fraction': 0.9122191617914341, 'bagging_freq': 7}. Best is trial 0 with value: 0.15213446515927667.\n","[I 2025-10-12 06:28:50,787] Trial 3 finished with value: 0.15412802484205737 and parameters: {'n_estimators': 1800, 'learning_rate': 0.002481033466505058, 'num_leaves': 273, 'max_depth': 8, 'lambda_l1': 1.3420600252507857, 'lambda_l2': 0.00845504228759606, 'feature_fraction': 0.6288263588306325, 'bagging_fraction': 0.9424137919143921, 'bagging_freq': 5}. Best is trial 3 with value: 0.15412802484205737.\n","[I 2025-10-12 06:29:02,823] Trial 4 finished with value: 0.14931585323277832 and parameters: {'n_estimators': 1600, 'learning_rate': 0.06164706804815589, 'num_leaves': 140, 'max_depth': 7, 'lambda_l1': 8.719043315485738, 'lambda_l2': 1.3671978658074886e-05, 'feature_fraction': 0.7775414693829186, 'bagging_fraction': 0.9507425916564508, 'bagging_freq': 2}. Best is trial 3 with value: 0.15412802484205737.\n","[I 2025-10-12 06:29:07,802] Trial 5 finished with value: 0.14300071025494812 and parameters: {'n_estimators': 100, 'learning_rate': 0.003688456086479783, 'num_leaves': 156, 'max_depth': 3, 'lambda_l1': 1.1052612978958443e-05, 'lambda_l2': 0.001417216304571968, 'feature_fraction': 0.9452238094096165, 'bagging_fraction': 0.7660817907681741, 'bagging_freq': 5}. Best is trial 3 with value: 0.15412802484205737.\n","[I 2025-10-12 06:29:17,362] Trial 6 finished with value: 0.15001737217304825 and parameters: {'n_estimators': 1500, 'learning_rate': 0.021787245794258094, 'num_leaves': 69, 'max_depth': 5, 'lambda_l1': 0.019113731238886815, 'lambda_l2': 0.0032299033398635315, 'feature_fraction': 0.8924659015326057, 'bagging_fraction': 0.9251197520560298, 'bagging_freq': 6}. Best is trial 3 with value: 0.15412802484205737.\n","[I 2025-10-12 06:29:33,077] Trial 7 finished with value: 0.15192539755027398 and parameters: {'n_estimators': 600, 'learning_rate': 0.001247378353397946, 'num_leaves': 128, 'max_depth': 5, 'lambda_l1': 0.00036458471716657297, 'lambda_l2': 0.905164366422769, 'feature_fraction': 0.7466331264786668, 'bagging_fraction': 0.6984362851471919, 'bagging_freq': 6}. Best is trial 3 with value: 0.15412802484205737.\n","[I 2025-10-12 06:29:59,020] Trial 8 finished with value: 0.15238862086479832 and parameters: {'n_estimators': 500, 'learning_rate': 0.0010893586578876358, 'num_leaves': 62, 'max_depth': 8, 'lambda_l1': 4.043721327887701e-07, 'lambda_l2': 1.6837217120226242, 'feature_fraction': 0.6157071175906722, 'bagging_fraction': 0.8846719675842882, 'bagging_freq': 6}. Best is trial 3 with value: 0.15412802484205737.\n","[I 2025-10-12 06:30:18,576] Trial 9 finished with value: 0.1483740163632175 and parameters: {'n_estimators': 100, 'learning_rate': 0.0021121290672872425, 'num_leaves': 266, 'max_depth': 10, 'lambda_l1': 0.20777724210622248, 'lambda_l2': 1.7397562281829326, 'feature_fraction': 0.7016199343007267, 'bagging_fraction': 0.818381509860231, 'bagging_freq': 4}. Best is trial 3 with value: 0.15412802484205737.\n","[I 2025-10-12 06:31:54,077] Trial 10 finished with value: 0.14932301551281607 and parameters: {'n_estimators': 2000, 'learning_rate': 0.005549021786283846, 'num_leaves': 298, 'max_depth': 12, 'lambda_l1': 0.008294139294144331, 'lambda_l2': 1.4838445839565926e-08, 'feature_fraction': 0.8597538413729362, 'bagging_fraction': 0.9988150373098418, 'bagging_freq': 1}. Best is trial 3 with value: 0.15412802484205737.\n","[I 2025-10-12 06:33:02,510] Trial 11 finished with value: 0.15388629687825606 and parameters: {'n_estimators': 900, 'learning_rate': 0.0010457218005583372, 'num_leaves': 215, 'max_depth': 8, 'lambda_l1': 2.9462790420069853e-07, 'lambda_l2': 0.04689031686269585, 'feature_fraction': 0.6206844586358866, 'bagging_fraction': 0.8613461304283897, 'bagging_freq': 5}. Best is trial 3 with value: 0.15412802484205737.\n","[I 2025-10-12 06:33:39,000] Trial 12 finished with value: 0.15331934039379538 and parameters: {'n_estimators': 900, 'learning_rate': 0.006279870879264988, 'num_leaves': 214, 'max_depth': 8, 'lambda_l1': 6.2490505626903675e-06, 'lambda_l2': 0.04393209035442475, 'feature_fraction': 0.656180797219622, 'bagging_fraction': 0.8509692256185751, 'bagging_freq': 3}. Best is trial 3 with value: 0.15412802484205737.\n","[I 2025-10-12 06:34:23,509] Trial 13 finished with value: 0.1534659069807755 and parameters: {'n_estimators': 1100, 'learning_rate': 0.002320127182826474, 'num_leaves': 208, 'max_depth': 7, 'lambda_l1': 1.1855979863677289e-08, 'lambda_l2': 1.67032499814536e-05, 'feature_fraction': 0.6063044003917009, 'bagging_fraction': 0.6099957102080087, 'bagging_freq': 4}. Best is trial 3 with value: 0.15412802484205737.\n"]},{"output_type":"stream","name":"stdout","text":["\n","[Optuna 조기 종료] 10번의 trial 동안 최고 점수가 갱신되지 않아 튜닝을 중단합니다.\n","\n","✅ 튜닝 완료!\n","\n","==================================================\n","🔬 최적 하이퍼파라미터 (Best Hyperparameters)\n","==================================================\n","        n_estimators: 1800\n","       learning_rate: 0.002481033466505058\n","          num_leaves: 273\n","           max_depth: 8\n","           lambda_l1: 1.3420600252507857\n","           lambda_l2: 0.00845504228759606\n","    feature_fraction: 0.6288263588306325\n","    bagging_fraction: 0.9424137919143921\n","        bagging_freq: 5\n","==================================================\n","\n","🔬 Step 5: 튜닝된 최종 모델 학습 및 평가...\n","✅ 튜닝된 모델 평가 완료.\n","\n","============================================================\n","📊 최종 성능 비교 결과 (Test Set)\n","============================================================\n","              PR AUC  ROC AUC  F1-Score\n","Baseline      0.1390   0.6099       0.0\n","Optuna Tuned  0.1648   0.6356       0.0\n","\n","============================================================\n","💾 Step 6: 최종 모델 예측 결과를 원본 CSV에 추가하여 저장\n","============================================================\n","✅ 모든 데이터의 예측 결과가 '/content/drive/MyDrive/review_helpfulness/PADA/results/s2/hotel/T5_hotel_with_s2_predictions.csv' 파일에 성공적으로 저장되었습니다.\n","\n","============================================================\n","🧹 Step 7: 사용된 변수들을 메모리에서 정리\n","============================================================\n","✅ 메모리 정리가 완료되었습니다.\n","\n","🎉 모든 과정이 완료되었습니다!\n"]}]},{"cell_type":"markdown","source":["## BERT"],"metadata":{"id":"KVbY_3OjvPFY"}},{"cell_type":"code","source":["# === 2. 환경설정 클래스 ===\n","class Config:\n","    \"\"\"실행에 필요한 모든 설정값을 중앙에서 관리합니다.\"\"\"\n","    # 🌟 1. 입력 파일 경로 설정\n","    CSV_FILE_PATH = \"/content/drive/MyDrive/review_helpfulness/PADA/data/hotel/hotel.csv\"\n","    EMBEDDING_PATH = \"/content/drive/MyDrive/review_helpfulness/PADA/embedding/hotel_BERT.npy\"\n","\n","    # 🌟 2. 최종 결과 CSV 파일 저장 경로 설정\n","    OUTPUT_CSV_PATH = \"/content/drive/MyDrive/review_helpfulness/PADA/results/s2/hotel/BERT_hotel_with_s2_predictions.csv\"\n","\n","    # --- 데이터 정보 ---\n","    TARGET_COLUMN = 'binary_helpfulness'\n","\n","    # --- 데이터 분할 ---\n","    TEST_SPLIT_RATIO = 0.2\n","    RANDOM_STATE = 42\n","\n","    # --- Optuna 튜닝 설정 ---\n","    N_TRIALS = 50\n","    TUNING_METRIC = 'pr_auc'\n","    EARLY_STOPPING_ROUNDS = 10 # 🌟 Optuna 조기 종료 횟수\n","\n","# === 3. Optuna 조기 종료 콜백 ===\n","class EarlyStoppingCallback:\n","    \"\"\"Optuna 스터디의 조기 종료를 위한 콜백 클래스\"\"\"\n","    def __init__(self, early_stopping_rounds: int):\n","        self._early_stopping_rounds = early_stopping_rounds\n","        self._best_value = -float(\"inf\")\n","        self._counter = 0\n","\n","    def __call__(self, study: optuna.study.Study, trial: optuna.trial.Trial):\n","        current_best_value = study.best_value\n","        if current_best_value is not None and current_best_value > self._best_value:\n","            self._best_value = current_best_value\n","            self._counter = 0\n","        else:\n","            self._counter += 1\n","\n","        if self._counter >= self._early_stopping_rounds:\n","            print(f\"\\n[Optuna 조기 종료] {self._early_stopping_rounds}번의 trial 동안 최고 점수가 갱신되지 않아 튜닝을 중단합니다.\")\n","            study.stop()\n","\n","# === 4. Optuna Objective 함수 ===\n","def objective(trial, X, y):\n","    \"\"\"Optuna가 최적의 하이퍼파라미터를 찾기 위해 반복 호출하는 함수\"\"\"\n","    X_train, X_val, y_train, y_val = train_test_split(\n","        X, y, test_size=0.25, random_state=Config.RANDOM_STATE, stratify=y\n","    )\n","\n","    params = {\n","        'objective': 'binary', 'metric': 'logloss', 'verbosity': -1,\n","        'boosting_type': 'gbdt', 'random_state': Config.RANDOM_STATE,\n","        'device': 'gpu',  # 🌟 Optuna Trial 내부에서도 GPU 사용\n","        'n_estimators': trial.suggest_int('n_estimators', 100, 2000, step=100),\n","        'learning_rate': trial.suggest_float('learning_rate', 1e-3, 0.3, log=True),\n","        'num_leaves': trial.suggest_int('num_leaves', 20, 300),\n","        'max_depth': trial.suggest_int('max_depth', 3, 12),\n","        'lambda_l1': trial.suggest_float('lambda_l1', 1e-8, 10.0, log=True),\n","        'lambda_l2': trial.suggest_float('lambda_l2', 1e-8, 10.0, log=True),\n","        'feature_fraction': trial.suggest_float('feature_fraction', 0.6, 1.0),\n","        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.6, 1.0),\n","        'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\n","    }\n","\n","    model = lgb.LGBMClassifier(**params)\n","    model.fit(X_train, y_train,\n","              eval_set=[(X_val, y_val)],\n","              eval_metric='logloss',\n","              callbacks=[lgb.early_stopping(100, verbose=False)])\n","\n","    y_pred_proba = model.predict_proba(X_val)[:, 1]\n","    score = average_precision_score(y_val, y_pred_proba)\n","    return score\n","\n","# === 5. 메인 실행 블록 ===\n","if __name__ == '__main__':\n","    config = Config()\n","\n","    # ... (Step 1 ~ 2: 데이터 로드, 분할, 베이스라인 측정) ...\n","    print(\"Step 1: 데이터 로드 및 분할 중...\")\n","    try:\n","        df = pd.read_csv(config.CSV_FILE_PATH)\n","        labels = df[config.TARGET_COLUMN].values\n","        embeddings = np.load(config.EMBEDDING_PATH)\n","        assert len(df) == len(embeddings)\n","    except Exception as e:\n","        print(f\"🔥 파일 로드 실패: {e}\"); exit()\n","\n","    indices = np.arange(len(df))\n","    train_indices, test_indices = train_test_split(\n","        indices, test_size=config.TEST_SPLIT_RATIO, random_state=config.RANDOM_STATE, stratify=labels\n","    )\n","    X_train, X_test = embeddings[train_indices], embeddings[test_indices]\n","    y_train, y_test = labels[train_indices], labels[test_indices]\n","    print(f\"✅ 완료 (학습용: {len(y_train)}건, 테스트용: {len(y_test)}건)\")\n","\n","    print(\"\\n\" + \"=\"*50)\n","    print(\"📊 Step 2: 베이스라인 모델 성능 측정 (GPU 사용)\")\n","    print(\"=\"*50)\n","\n","    baseline_model = lgb.LGBMClassifier(device='gpu', random_state=config.RANDOM_STATE)\n","    baseline_model.fit(X_train, y_train)\n","\n","    y_pred_proba_base = baseline_model.predict_proba(X_test)[:, 1]\n","    y_pred_class_base = (y_pred_proba_base > 0.5).astype(int)\n","\n","    final_results = {}\n","    final_results['Baseline'] = {\n","        \"PR AUC\": average_precision_score(y_test, y_pred_proba_base),\n","        \"ROC AUC\": roc_auc_score(y_test, y_pred_proba_base),\n","        \"F1-Score\": f1_score(y_test, y_pred_class_base),\n","    }\n","    print(\"✅ 베이스라인 모델 평가 완료.\")\n","\n","    # --- Step 3: Optuna 튜닝 수행 (조기 종료 포함) ---\n","    print(\"\\n\" + \"=\"*50)\n","    print(f\"🔬 Step 3: Optuna 하이퍼파라미터 튜닝 시작 (GPU 사용)...\")\n","    print(f\"(최대 {config.N_TRIALS}번 시도, {config.EARLY_STOPPING_ROUNDS}번 개선 없으면 조기 종료)\")\n","    print(\"=\"*50)\n","\n","    early_stopping_callback = EarlyStoppingCallback(early_stopping_rounds=config.EARLY_STOPPING_ROUNDS)\n","    study = optuna.create_study(direction='maximize')\n","    pbar = tqdm(total=config.N_TRIALS, desc=\"Optuna 튜닝 진행률\")\n","\n","    try:\n","        study.optimize(lambda trial: objective(trial, X_train, y_train),\n","                       n_trials=config.N_TRIALS,\n","                       callbacks=[lambda study, trial: pbar.update(1), early_stopping_callback])\n","    except optuna.exceptions.OptunaError:\n","        # 조기 종료 시 발생하는 예외를 정상 처리\n","        pass\n","    pbar.close()\n","\n","    # ... (Step 4 ~ 6: 결과 출력, 저장, 메모리 정리) ...\n","    print(f\"\\n✅ 튜닝 완료!\")\n","    print(\"\\n\" + \"=\"*50)\n","    print(\"🔬 최적 하이퍼파라미터 (Best Hyperparameters)\")\n","    print(\"=\"*50)\n","    best_params = study.best_params\n","    for key, value in best_params.items():\n","        print(f\"{key:>20s}: {value}\")\n","    print(\"=\"*50)\n","\n","    print(f\"\\n🔬 Step 5: 튜닝된 최종 모델 학습 및 평가...\")\n","    final_model = lgb.LGBMClassifier(device='gpu', objective='binary', verbosity=-1, random_state=config.RANDOM_STATE, **best_params)\n","    final_model.fit(X_train, y_train)\n","\n","    y_pred_proba_tuned = final_model.predict_proba(X_test)[:, 1]\n","    y_pred_class_tuned = (y_pred_proba_tuned > 0.5).astype(int)\n","\n","    final_results['Optuna Tuned'] = {\n","        \"PR AUC\": average_precision_score(y_test, y_pred_proba_tuned),\n","        \"ROC AUC\": roc_auc_score(y_test, y_pred_proba_tuned),\n","        \"F1-Score\": f1_score(y_test, y_pred_class_tuned),\n","    }\n","    print(\"✅ 튜닝된 모델 평가 완료.\")\n","\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"📊 최종 성능 비교 결과 (Test Set)\")\n","    print(\"=\"*60)\n","    results_df = pd.DataFrame(final_results).T\n","    print(results_df.round(4))\n","\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"💾 Step 6: 최종 모델 예측 결과를 원본 CSV에 추가하여 저장\")\n","    print(\"=\"*60)\n","\n","    train_pred_proba = final_model.predict_proba(X_train)[:, 1]\n","    train_pred_class = (train_pred_proba > 0.5).astype(int)\n","\n","    df['s2_pred_proba'] = np.nan\n","    df['s2_pred_class'] = np.nan\n","\n","    df.loc[train_indices, 's2_pred_proba'] = train_pred_proba\n","    df.loc[train_indices, 's2_pred_class'] = train_pred_class\n","\n","    df.loc[test_indices, 's2_pred_proba'] = y_pred_proba_tuned\n","    df.loc[test_indices, 's2_pred_class'] = y_pred_class_tuned\n","\n","    # 🌟 Config에 설정된 경로로 최종 파일 저장\n","    df.to_csv(config.OUTPUT_CSV_PATH, index=False, encoding='utf-8-sig')\n","\n","    print(f\"✅ 모든 데이터의 예측 결과가 '{config.OUTPUT_CSV_PATH}' 파일에 성공적으로 저장되었습니다.\")\n","\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"🧹 Step 7: 사용된 변수들을 메모리에서 정리\")\n","    print(\"=\"*60)\n","\n","    vars_to_delete = [\n","        'df', 'labels', 'embeddings', 'indices', 'X_train', 'X_test',\n","        'y_train', 'y_test', 'train_indices', 'test_indices',\n","        'baseline_model', 'final_model', 'study',\n","    ]\n","    for var_name in vars_to_delete:\n","        if var_name in locals() or var_name in globals():\n","            if var_name in globals(): del globals()[var_name]\n","\n","    gc.collect()\n","    print(\"✅ 메모리 정리가 완료되었습니다.\")\n","\n","    print(\"\\n🎉 모든 과정이 완료되었습니다!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["b90b17b1fd354057ba8001d2d2d66e83","7e771fd7b5954adaacb9703695ac6f68","d42dfac5c61e4ab0ad37013b60ec22b6","bbdb07f8108846388066370eb9d67f4e","2b882e2ab1f9412d9cd8efdd70aaa464","2b612e5016eb4fe99542c7a73a0e4298","b3d79089d1b64f5bab6d6ed412f89082","8f54965aefec4a35b1e7c7ece6ee7bc0","b8c615610d1e41dc98c126b936e53e7c","6c39ff3484b4435f972f0fea0fbd77c2","df37faa390f54d55b99b8901fdf7df17"]},"id":"YT8trNmzyBND","executionInfo":{"status":"ok","timestamp":1760251661420,"user_tz":-540,"elapsed":645966,"user":{"displayName":"KW-data-analytics","userId":"09651493752354345908"}},"outputId":"47c32f58-9720-43f5-e64a-f3f06e310236"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Step 1: 데이터 로드 및 분할 중...\n","✅ 완료 (학습용: 71604건, 테스트용: 17901건)\n","\n","==================================================\n","📊 Step 2: 베이스라인 모델 성능 측정 (GPU 사용)\n","==================================================\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-10-12 06:37:07,949] A new study created in memory with name: no-name-ff8f9b83-1323-4efc-abf9-6482afa7b345\n"]},{"output_type":"stream","name":"stdout","text":["✅ 베이스라인 모델 평가 완료.\n","\n","==================================================\n","🔬 Step 3: Optuna 하이퍼파라미터 튜닝 시작 (GPU 사용)...\n","(최대 50번 시도, 10번 개선 없으면 조기 종료)\n","==================================================\n"]},{"output_type":"display_data","data":{"text/plain":["Optuna 튜닝 진행률:   0%|          | 0/50 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b90b17b1fd354057ba8001d2d2d66e83"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2025-10-12 06:37:16,230] Trial 0 finished with value: 0.1261756742383485 and parameters: {'n_estimators': 2000, 'learning_rate': 0.28616219469207493, 'num_leaves': 62, 'max_depth': 9, 'lambda_l1': 8.863677188401592e-08, 'lambda_l2': 1.2632018974413965e-08, 'feature_fraction': 0.7124478477033773, 'bagging_fraction': 0.6716822014072272, 'bagging_freq': 7}. Best is trial 0 with value: 0.1261756742383485.\n","[I 2025-10-12 06:37:21,972] Trial 1 finished with value: 0.15003664805482397 and parameters: {'n_estimators': 800, 'learning_rate': 0.16895044706987095, 'num_leaves': 171, 'max_depth': 4, 'lambda_l1': 0.0026519164972713754, 'lambda_l2': 0.5692871528067157, 'feature_fraction': 0.7215793033500075, 'bagging_fraction': 0.9521355676770022, 'bagging_freq': 6}. Best is trial 1 with value: 0.15003664805482397.\n","[I 2025-10-12 06:38:04,758] Trial 2 finished with value: 0.1511834151167769 and parameters: {'n_estimators': 600, 'learning_rate': 0.0010879785020850672, 'num_leaves': 72, 'max_depth': 10, 'lambda_l1': 0.017109598503000218, 'lambda_l2': 6.470818624820068e-07, 'feature_fraction': 0.9981453007239436, 'bagging_fraction': 0.9737481679929816, 'bagging_freq': 7}. Best is trial 2 with value: 0.1511834151167769.\n","[I 2025-10-12 06:38:09,526] Trial 3 finished with value: 0.15143832250334344 and parameters: {'n_estimators': 1900, 'learning_rate': 0.210324904385441, 'num_leaves': 83, 'max_depth': 3, 'lambda_l1': 7.976800903393617, 'lambda_l2': 5.4766162689536485e-06, 'feature_fraction': 0.7573233440432453, 'bagging_fraction': 0.9560873414003472, 'bagging_freq': 2}. Best is trial 3 with value: 0.15143832250334344.\n","[I 2025-10-12 06:38:34,321] Trial 4 finished with value: 0.1538181509911733 and parameters: {'n_estimators': 1200, 'learning_rate': 0.015524605510960788, 'num_leaves': 116, 'max_depth': 11, 'lambda_l1': 0.8963915558034223, 'lambda_l2': 0.0009061223822411036, 'feature_fraction': 0.7839175224533701, 'bagging_fraction': 0.895792869204711, 'bagging_freq': 5}. Best is trial 4 with value: 0.1538181509911733.\n","[I 2025-10-12 06:38:45,506] Trial 5 finished with value: 0.15459027166302514 and parameters: {'n_estimators': 100, 'learning_rate': 0.02893157730635046, 'num_leaves': 255, 'max_depth': 8, 'lambda_l1': 9.84699129077602, 'lambda_l2': 1.825732347285616e-05, 'feature_fraction': 0.7617788510206287, 'bagging_fraction': 0.9247673921608743, 'bagging_freq': 1}. Best is trial 5 with value: 0.15459027166302514.\n","[I 2025-10-12 06:38:51,640] Trial 6 finished with value: 0.1541199656830619 and parameters: {'n_estimators': 500, 'learning_rate': 0.02847286230734637, 'num_leaves': 298, 'max_depth': 3, 'lambda_l1': 1.2668765298397175, 'lambda_l2': 0.10112544605028591, 'feature_fraction': 0.8980046696377457, 'bagging_fraction': 0.9709432946698084, 'bagging_freq': 3}. Best is trial 5 with value: 0.15459027166302514.\n","[I 2025-10-12 06:39:07,294] Trial 7 finished with value: 0.12661877376130762 and parameters: {'n_estimators': 1400, 'learning_rate': 0.2023519069945204, 'num_leaves': 202, 'max_depth': 9, 'lambda_l1': 0.0008153446047372529, 'lambda_l2': 1.877414009733372e-07, 'feature_fraction': 0.9010122710309252, 'bagging_fraction': 0.8322957467393434, 'bagging_freq': 6}. Best is trial 5 with value: 0.15459027166302514.\n","[I 2025-10-12 06:39:23,422] Trial 8 finished with value: 0.15428362844627147 and parameters: {'n_estimators': 1700, 'learning_rate': 0.019029997526654966, 'num_leaves': 300, 'max_depth': 7, 'lambda_l1': 1.969395658754589e-06, 'lambda_l2': 1.3518307382151498e-08, 'feature_fraction': 0.8792290036389174, 'bagging_fraction': 0.9563019282024727, 'bagging_freq': 7}. Best is trial 5 with value: 0.15459027166302514.\n","[I 2025-10-12 06:39:35,941] Trial 9 finished with value: 0.15597376041458416 and parameters: {'n_estimators': 1100, 'learning_rate': 0.013145762899460262, 'num_leaves': 254, 'max_depth': 5, 'lambda_l1': 0.11256737133366358, 'lambda_l2': 0.025957772528628215, 'feature_fraction': 0.8030355757326181, 'bagging_fraction': 0.8713856808988826, 'bagging_freq': 3}. Best is trial 9 with value: 0.15597376041458416.\n","[I 2025-10-12 06:39:59,939] Trial 10 finished with value: 0.1542654819243417 and parameters: {'n_estimators': 1000, 'learning_rate': 0.005381836279991293, 'num_leaves': 221, 'max_depth': 6, 'lambda_l1': 9.982304510691233e-06, 'lambda_l2': 0.00964432151785659, 'feature_fraction': 0.6042581510833305, 'bagging_fraction': 0.7428859338004594, 'bagging_freq': 4}. Best is trial 9 with value: 0.15597376041458416.\n","[I 2025-10-12 06:40:07,007] Trial 11 finished with value: 0.14877708971027231 and parameters: {'n_estimators': 100, 'learning_rate': 0.048497317538218225, 'num_leaves': 248, 'max_depth': 6, 'lambda_l1': 0.08823429033337922, 'lambda_l2': 6.102899894753696e-05, 'feature_fraction': 0.8306462872413136, 'bagging_fraction': 0.8461060784659802, 'bagging_freq': 1}. Best is trial 9 with value: 0.15597376041458416.\n","[I 2025-10-12 06:40:12,931] Trial 12 finished with value: 0.15204308820877147 and parameters: {'n_estimators': 100, 'learning_rate': 0.00591537981925073, 'num_leaves': 244, 'max_depth': 5, 'lambda_l1': 9.969486600894765, 'lambda_l2': 5.1039496818519945, 'feature_fraction': 0.663347070117355, 'bagging_fraction': 0.7676027351028417, 'bagging_freq': 1}. Best is trial 9 with value: 0.15597376041458416.\n","[I 2025-10-12 06:40:54,055] Trial 13 finished with value: 0.1531747308459362 and parameters: {'n_estimators': 1300, 'learning_rate': 0.00741302673221242, 'num_leaves': 151, 'max_depth': 8, 'lambda_l1': 0.11704594318494455, 'lambda_l2': 0.0003609684612422434, 'feature_fraction': 0.8399766356024965, 'bagging_fraction': 0.8861220099963053, 'bagging_freq': 3}. Best is trial 9 with value: 0.15597376041458416.\n","[I 2025-10-12 06:41:22,367] Trial 14 finished with value: 0.1329860989184285 and parameters: {'n_estimators': 400, 'learning_rate': 0.06940530975091762, 'num_leaves': 262, 'max_depth': 12, 'lambda_l1': 0.000108008417490716, 'lambda_l2': 0.029778817905266836, 'feature_fraction': 0.9694728146401975, 'bagging_fraction': 0.8983316098679458, 'bagging_freq': 2}. Best is trial 9 with value: 0.15597376041458416.\n","[I 2025-10-12 06:42:14,220] Trial 15 finished with value: 0.15542884711453106 and parameters: {'n_estimators': 900, 'learning_rate': 0.001560393662619211, 'num_leaves': 186, 'max_depth': 7, 'lambda_l1': 0.016193083616586532, 'lambda_l2': 1.7618857650118892e-05, 'feature_fraction': 0.7450168258046221, 'bagging_fraction': 0.8051087721239316, 'bagging_freq': 2}. Best is trial 9 with value: 0.15597376041458416.\n","[I 2025-10-12 06:42:35,495] Trial 16 finished with value: 0.15578367210276356 and parameters: {'n_estimators': 1000, 'learning_rate': 0.0010612246665263555, 'num_leaves': 179, 'max_depth': 5, 'lambda_l1': 0.010330216262138979, 'lambda_l2': 0.0061935554783882985, 'feature_fraction': 0.6630512770956041, 'bagging_fraction': 0.7202762311148747, 'bagging_freq': 3}. Best is trial 9 with value: 0.15597376041458416.\n","[I 2025-10-12 06:42:59,301] Trial 17 finished with value: 0.15663984078742163 and parameters: {'n_estimators': 1500, 'learning_rate': 0.002830668835820194, 'num_leaves': 26, 'max_depth': 5, 'lambda_l1': 9.231545233803382e-05, 'lambda_l2': 0.002879832751125398, 'feature_fraction': 0.6501494595468753, 'bagging_fraction': 0.6050573502906857, 'bagging_freq': 4}. Best is trial 17 with value: 0.15663984078742163.\n","[I 2025-10-12 06:43:25,008] Trial 18 finished with value: 0.15606070262001098 and parameters: {'n_estimators': 1600, 'learning_rate': 0.0028256611313437416, 'num_leaves': 128, 'max_depth': 5, 'lambda_l1': 8.385294662200754e-05, 'lambda_l2': 0.4370306668521054, 'feature_fraction': 0.6054616593082759, 'bagging_fraction': 0.6039241180686017, 'bagging_freq': 4}. Best is trial 17 with value: 0.15663984078742163.\n","[I 2025-10-12 06:43:43,671] Trial 19 finished with value: 0.15533239830600812 and parameters: {'n_estimators': 1600, 'learning_rate': 0.0027968375984306643, 'num_leaves': 34, 'max_depth': 4, 'lambda_l1': 4.7134803268097064e-05, 'lambda_l2': 4.506771160711044, 'feature_fraction': 0.6025303304488587, 'bagging_fraction': 0.6079927755051041, 'bagging_freq': 5}. Best is trial 17 with value: 0.15663984078742163.\n","[I 2025-10-12 06:44:24,933] Trial 20 finished with value: 0.1560377749695442 and parameters: {'n_estimators': 1500, 'learning_rate': 0.0027319822130860215, 'num_leaves': 137, 'max_depth': 6, 'lambda_l1': 5.398373056164629e-07, 'lambda_l2': 0.8111461382188982, 'feature_fraction': 0.6544803190589217, 'bagging_fraction': 0.611392001360179, 'bagging_freq': 4}. Best is trial 17 with value: 0.15663984078742163.\n","[I 2025-10-12 06:45:04,386] Trial 21 finished with value: 0.1550927622358645 and parameters: {'n_estimators': 1500, 'learning_rate': 0.002678164877355659, 'num_leaves': 128, 'max_depth': 6, 'lambda_l1': 3.768830297984062e-07, 'lambda_l2': 0.2590504320094707, 'feature_fraction': 0.6544101754225513, 'bagging_fraction': 0.602411651495223, 'bagging_freq': 4}. Best is trial 17 with value: 0.15663984078742163.\n","[I 2025-10-12 06:45:24,676] Trial 22 finished with value: 0.15584495118427094 and parameters: {'n_estimators': 1800, 'learning_rate': 0.002736919343427477, 'num_leaves': 118, 'max_depth': 4, 'lambda_l1': 1.1165700726710295e-08, 'lambda_l2': 1.1044025465951466, 'feature_fraction': 0.6383235350895006, 'bagging_fraction': 0.6380614556117223, 'bagging_freq': 5}. Best is trial 17 with value: 0.15663984078742163.\n","[I 2025-10-12 06:45:56,339] Trial 23 finished with value: 0.15573559004427584 and parameters: {'n_estimators': 1500, 'learning_rate': 0.002072164566559572, 'num_leaves': 28, 'max_depth': 6, 'lambda_l1': 2.7266985853744234e-05, 'lambda_l2': 0.0019114451947971822, 'feature_fraction': 0.6878899670200248, 'bagging_fraction': 0.6728338214704539, 'bagging_freq': 4}. Best is trial 17 with value: 0.15663984078742163.\n","[I 2025-10-12 06:46:13,157] Trial 24 finished with value: 0.15492998187225362 and parameters: {'n_estimators': 1700, 'learning_rate': 0.004542248876160508, 'num_leaves': 144, 'max_depth': 5, 'lambda_l1': 3.8902300853361715e-06, 'lambda_l2': 0.06031551170082039, 'feature_fraction': 0.6256423753910141, 'bagging_fraction': 0.6610426147272571, 'bagging_freq': 5}. Best is trial 17 with value: 0.15663984078742163.\n","[I 2025-10-12 06:46:35,928] Trial 25 finished with value: 0.15277826750895435 and parameters: {'n_estimators': 1300, 'learning_rate': 0.009096612927175894, 'num_leaves': 89, 'max_depth': 7, 'lambda_l1': 0.0003065335399386532, 'lambda_l2': 1.1419892719870708, 'feature_fraction': 0.6962182616037038, 'bagging_fraction': 0.7006348983375335, 'bagging_freq': 4}. Best is trial 17 with value: 0.15663984078742163.\n","[I 2025-10-12 06:46:54,380] Trial 26 finished with value: 0.1554035789306908 and parameters: {'n_estimators': 1600, 'learning_rate': 0.0039201305831287345, 'num_leaves': 110, 'max_depth': 4, 'lambda_l1': 6.223294000372579e-07, 'lambda_l2': 0.21899437803055163, 'feature_fraction': 0.6812136981540657, 'bagging_fraction': 0.6373371623388135, 'bagging_freq': 6}. Best is trial 17 with value: 0.15663984078742163.\n","[I 2025-10-12 06:47:08,920] Trial 27 finished with value: 0.1545100484369846 and parameters: {'n_estimators': 2000, 'learning_rate': 0.001827468558522887, 'num_leaves': 55, 'max_depth': 3, 'lambda_l1': 4.956973098901469e-08, 'lambda_l2': 6.951529530631278, 'feature_fraction': 0.6263709535388999, 'bagging_fraction': 0.6292099866266875, 'bagging_freq': 4}. Best is trial 17 with value: 0.15663984078742163.\n"]},{"output_type":"stream","name":"stdout","text":["\n","[Optuna 조기 종료] 10번의 trial 동안 최고 점수가 갱신되지 않아 튜닝을 중단합니다.\n","\n","✅ 튜닝 완료!\n","\n","==================================================\n","🔬 최적 하이퍼파라미터 (Best Hyperparameters)\n","==================================================\n","        n_estimators: 1500\n","       learning_rate: 0.002830668835820194\n","          num_leaves: 26\n","           max_depth: 5\n","           lambda_l1: 9.231545233803382e-05\n","           lambda_l2: 0.002879832751125398\n","    feature_fraction: 0.6501494595468753\n","    bagging_fraction: 0.6050573502906857\n","        bagging_freq: 4\n","==================================================\n","\n","🔬 Step 5: 튜닝된 최종 모델 학습 및 평가...\n","✅ 튜닝된 모델 평가 완료.\n","\n","============================================================\n","📊 최종 성능 비교 결과 (Test Set)\n","============================================================\n","              PR AUC  ROC AUC  F1-Score\n","Baseline      0.1463   0.6203    0.0024\n","Optuna Tuned  0.1600   0.6294    0.0000\n","\n","============================================================\n","💾 Step 6: 최종 모델 예측 결과를 원본 CSV에 추가하여 저장\n","============================================================\n","✅ 모든 데이터의 예측 결과가 '/content/drive/MyDrive/review_helpfulness/PADA/results/s2/hotel/BERT_hotel_with_s2_predictions.csv' 파일에 성공적으로 저장되었습니다.\n","\n","============================================================\n","🧹 Step 7: 사용된 변수들을 메모리에서 정리\n","============================================================\n","✅ 메모리 정리가 완료되었습니다.\n","\n","🎉 모든 과정이 완료되었습니다!\n"]}]},{"cell_type":"markdown","source":["## SentenceBERT"],"metadata":{"id":"570R1n6evPqE"}},{"cell_type":"code","source":["# === 2. 환경설정 클래스 ===\n","class Config:\n","    \"\"\"실행에 필요한 모든 설정값을 중앙에서 관리합니다.\"\"\"\n","    # 🌟 1. 입력 파일 경로 설정\n","    CSV_FILE_PATH = \"/content/drive/MyDrive/review_helpfulness/PADA/data/hotel/hotel.csv\"\n","    EMBEDDING_PATH = \"/content/drive/MyDrive/review_helpfulness/PADA/embedding/hotel_SentenceBERT.npy\"\n","\n","    # 🌟 2. 최종 결과 CSV 파일 저장 경로 설정\n","    OUTPUT_CSV_PATH = \"/content/drive/MyDrive/review_helpfulness/PADA/results/s2/hotel/SentenceBERT_hotel_with_s2_predictions.csv\"\n","\n","    # --- 데이터 정보 ---\n","    TARGET_COLUMN = 'binary_helpfulness'\n","\n","    # --- 데이터 분할 ---\n","    TEST_SPLIT_RATIO = 0.2\n","    RANDOM_STATE = 42\n","\n","    # --- Optuna 튜닝 설정 ---\n","    N_TRIALS = 50\n","    TUNING_METRIC = 'pr_auc'\n","    EARLY_STOPPING_ROUNDS = 10 # 🌟 Optuna 조기 종료 횟수\n","\n","# === 3. Optuna 조기 종료 콜백 ===\n","class EarlyStoppingCallback:\n","    \"\"\"Optuna 스터디의 조기 종료를 위한 콜백 클래스\"\"\"\n","    def __init__(self, early_stopping_rounds: int):\n","        self._early_stopping_rounds = early_stopping_rounds\n","        self._best_value = -float(\"inf\")\n","        self._counter = 0\n","\n","    def __call__(self, study: optuna.study.Study, trial: optuna.trial.Trial):\n","        current_best_value = study.best_value\n","        if current_best_value is not None and current_best_value > self._best_value:\n","            self._best_value = current_best_value\n","            self._counter = 0\n","        else:\n","            self._counter += 1\n","\n","        if self._counter >= self._early_stopping_rounds:\n","            print(f\"\\n[Optuna 조기 종료] {self._early_stopping_rounds}번의 trial 동안 최고 점수가 갱신되지 않아 튜닝을 중단합니다.\")\n","            study.stop()\n","\n","# === 4. Optuna Objective 함수 ===\n","def objective(trial, X, y):\n","    \"\"\"Optuna가 최적의 하이퍼파라미터를 찾기 위해 반복 호출하는 함수\"\"\"\n","    X_train, X_val, y_train, y_val = train_test_split(\n","        X, y, test_size=0.25, random_state=Config.RANDOM_STATE, stratify=y\n","    )\n","\n","    params = {\n","        'objective': 'binary', 'metric': 'logloss', 'verbosity': -1,\n","        'boosting_type': 'gbdt', 'random_state': Config.RANDOM_STATE,\n","        'device': 'gpu',  # 🌟 Optuna Trial 내부에서도 GPU 사용\n","        'n_estimators': trial.suggest_int('n_estimators', 100, 2000, step=100),\n","        'learning_rate': trial.suggest_float('learning_rate', 1e-3, 0.3, log=True),\n","        'num_leaves': trial.suggest_int('num_leaves', 20, 300),\n","        'max_depth': trial.suggest_int('max_depth', 3, 12),\n","        'lambda_l1': trial.suggest_float('lambda_l1', 1e-8, 10.0, log=True),\n","        'lambda_l2': trial.suggest_float('lambda_l2', 1e-8, 10.0, log=True),\n","        'feature_fraction': trial.suggest_float('feature_fraction', 0.6, 1.0),\n","        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.6, 1.0),\n","        'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\n","    }\n","\n","    model = lgb.LGBMClassifier(**params)\n","    model.fit(X_train, y_train,\n","              eval_set=[(X_val, y_val)],\n","              eval_metric='logloss',\n","              callbacks=[lgb.early_stopping(100, verbose=False)])\n","\n","    y_pred_proba = model.predict_proba(X_val)[:, 1]\n","    score = average_precision_score(y_val, y_pred_proba)\n","    return score\n","\n","# === 5. 메인 실행 블록 ===\n","if __name__ == '__main__':\n","    config = Config()\n","\n","    # ... (Step 1 ~ 2: 데이터 로드, 분할, 베이스라인 측정) ...\n","    print(\"Step 1: 데이터 로드 및 분할 중...\")\n","    try:\n","        df = pd.read_csv(config.CSV_FILE_PATH)\n","        labels = df[config.TARGET_COLUMN].values\n","        embeddings = np.load(config.EMBEDDING_PATH)\n","        assert len(df) == len(embeddings)\n","    except Exception as e:\n","        print(f\"🔥 파일 로드 실패: {e}\"); exit()\n","\n","    indices = np.arange(len(df))\n","    train_indices, test_indices = train_test_split(\n","        indices, test_size=config.TEST_SPLIT_RATIO, random_state=config.RANDOM_STATE, stratify=labels\n","    )\n","    X_train, X_test = embeddings[train_indices], embeddings[test_indices]\n","    y_train, y_test = labels[train_indices], labels[test_indices]\n","    print(f\"✅ 완료 (학습용: {len(y_train)}건, 테스트용: {len(y_test)}건)\")\n","\n","    print(\"\\n\" + \"=\"*50)\n","    print(\"📊 Step 2: 베이스라인 모델 성능 측정 (GPU 사용)\")\n","    print(\"=\"*50)\n","\n","    baseline_model = lgb.LGBMClassifier(device='gpu', random_state=config.RANDOM_STATE)\n","    baseline_model.fit(X_train, y_train)\n","\n","    y_pred_proba_base = baseline_model.predict_proba(X_test)[:, 1]\n","    y_pred_class_base = (y_pred_proba_base > 0.5).astype(int)\n","\n","    final_results = {}\n","    final_results['Baseline'] = {\n","        \"PR AUC\": average_precision_score(y_test, y_pred_proba_base),\n","        \"ROC AUC\": roc_auc_score(y_test, y_pred_proba_base),\n","        \"F1-Score\": f1_score(y_test, y_pred_class_base),\n","    }\n","    print(\"✅ 베이스라인 모델 평가 완료.\")\n","\n","    # --- Step 3: Optuna 튜닝 수행 (조기 종료 포함) ---\n","    print(\"\\n\" + \"=\"*50)\n","    print(f\"🔬 Step 3: Optuna 하이퍼파라미터 튜닝 시작 (GPU 사용)...\")\n","    print(f\"(최대 {config.N_TRIALS}번 시도, {config.EARLY_STOPPING_ROUNDS}번 개선 없으면 조기 종료)\")\n","    print(\"=\"*50)\n","\n","    early_stopping_callback = EarlyStoppingCallback(early_stopping_rounds=config.EARLY_STOPPING_ROUNDS)\n","    study = optuna.create_study(direction='maximize')\n","    pbar = tqdm(total=config.N_TRIALS, desc=\"Optuna 튜닝 진행률\")\n","\n","    try:\n","        study.optimize(lambda trial: objective(trial, X_train, y_train),\n","                       n_trials=config.N_TRIALS,\n","                       callbacks=[lambda study, trial: pbar.update(1), early_stopping_callback])\n","    except optuna.exceptions.OptunaError:\n","        # 조기 종료 시 발생하는 예외를 정상 처리\n","        pass\n","    pbar.close()\n","\n","    # ... (Step 4 ~ 6: 결과 출력, 저장, 메모리 정리) ...\n","    print(f\"\\n✅ 튜닝 완료!\")\n","    print(\"\\n\" + \"=\"*50)\n","    print(\"🔬 최적 하이퍼파라미터 (Best Hyperparameters)\")\n","    print(\"=\"*50)\n","    best_params = study.best_params\n","    for key, value in best_params.items():\n","        print(f\"{key:>20s}: {value}\")\n","    print(\"=\"*50)\n","\n","    print(f\"\\n🔬 Step 5: 튜닝된 최종 모델 학습 및 평가...\")\n","    final_model = lgb.LGBMClassifier(device='gpu', objective='binary', verbosity=-1, random_state=config.RANDOM_STATE, **best_params)\n","    final_model.fit(X_train, y_train)\n","\n","    y_pred_proba_tuned = final_model.predict_proba(X_test)[:, 1]\n","    y_pred_class_tuned = (y_pred_proba_tuned > 0.5).astype(int)\n","\n","    final_results['Optuna Tuned'] = {\n","        \"PR AUC\": average_precision_score(y_test, y_pred_proba_tuned),\n","        \"ROC AUC\": roc_auc_score(y_test, y_pred_proba_tuned),\n","        \"F1-Score\": f1_score(y_test, y_pred_class_tuned),\n","    }\n","    print(\"✅ 튜닝된 모델 평가 완료.\")\n","\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"📊 최종 성능 비교 결과 (Test Set)\")\n","    print(\"=\"*60)\n","    results_df = pd.DataFrame(final_results).T\n","    print(results_df.round(4))\n","\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"💾 Step 6: 최종 모델 예측 결과를 원본 CSV에 추가하여 저장\")\n","    print(\"=\"*60)\n","\n","    train_pred_proba = final_model.predict_proba(X_train)[:, 1]\n","    train_pred_class = (train_pred_proba > 0.5).astype(int)\n","\n","    df['s2_pred_proba'] = np.nan\n","    df['s2_pred_class'] = np.nan\n","\n","    df.loc[train_indices, 's2_pred_proba'] = train_pred_proba\n","    df.loc[train_indices, 's2_pred_class'] = train_pred_class\n","\n","    df.loc[test_indices, 's2_pred_proba'] = y_pred_proba_tuned\n","    df.loc[test_indices, 's2_pred_class'] = y_pred_class_tuned\n","\n","    # 🌟 Config에 설정된 경로로 최종 파일 저장\n","    df.to_csv(config.OUTPUT_CSV_PATH, index=False, encoding='utf-8-sig')\n","\n","    print(f\"✅ 모든 데이터의 예측 결과가 '{config.OUTPUT_CSV_PATH}' 파일에 성공적으로 저장되었습니다.\")\n","\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"🧹 Step 7: 사용된 변수들을 메모리에서 정리\")\n","    print(\"=\"*60)\n","\n","    vars_to_delete = [\n","        'df', 'labels', 'embeddings', 'indices', 'X_train', 'X_test',\n","        'y_train', 'y_test', 'train_indices', 'test_indices',\n","        'baseline_model', 'final_model', 'study',\n","    ]\n","    for var_name in vars_to_delete:\n","        if var_name in locals() or var_name in globals():\n","            if var_name in globals(): del globals()[var_name]\n","\n","    gc.collect()\n","    print(\"✅ 메모리 정리가 완료되었습니다.\")\n","\n","    print(\"\\n🎉 모든 과정이 완료되었습니다!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["c9897f45fc824f40bc3c63441c6210f5","921be6a91dfd4f7dbdb685f718f04c53","107c227bbd6444e1a9fc7940705c9e1d","492198bc880a449aadcc08cb35044a85","68acb0cc96ae4ecbb2af864a3d672f36","a9ee2db2513a44ed9ee28deb64eece97","ce3c0ac76def4db0910087e346e49880","2dd8f692129e4b8cbd107858c5551e64","eebcac7b67924d6a847d564f304fb070","469766e4152a4f36bd83f593a9ac20a1","0c7c445e4c4e42df879f1643d5b19aed"]},"id":"U4ZkmLQayGc4","executionInfo":{"status":"ok","timestamp":1760251987725,"user_tz":-540,"elapsed":326303,"user":{"displayName":"KW-data-analytics","userId":"09651493752354345908"}},"outputId":"a8c3580b-497e-49a2-a147-5a9c6d85954f"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Step 1: 데이터 로드 및 분할 중...\n","✅ 완료 (학습용: 71604건, 테스트용: 17901건)\n","\n","==================================================\n","📊 Step 2: 베이스라인 모델 성능 측정 (GPU 사용)\n","==================================================\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-10-12 06:47:53,156] A new study created in memory with name: no-name-c743a3a7-dc01-456c-9778-e91dd5d31aac\n"]},{"output_type":"stream","name":"stdout","text":["✅ 베이스라인 모델 평가 완료.\n","\n","==================================================\n","🔬 Step 3: Optuna 하이퍼파라미터 튜닝 시작 (GPU 사용)...\n","(최대 50번 시도, 10번 개선 없으면 조기 종료)\n","==================================================\n"]},{"output_type":"display_data","data":{"text/plain":["Optuna 튜닝 진행률:   0%|          | 0/50 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c9897f45fc824f40bc3c63441c6210f5"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2025-10-12 06:47:56,546] Trial 0 finished with value: 0.13717886619943928 and parameters: {'n_estimators': 500, 'learning_rate': 0.1152319195237506, 'num_leaves': 101, 'max_depth': 5, 'lambda_l1': 7.719021570410522e-06, 'lambda_l2': 1.2163945012053485e-06, 'feature_fraction': 0.8868738973372874, 'bagging_fraction': 0.6801277396230722, 'bagging_freq': 1}. Best is trial 0 with value: 0.13717886619943928.\n","[I 2025-10-12 06:48:07,202] Trial 1 finished with value: 0.14710225707341368 and parameters: {'n_estimators': 700, 'learning_rate': 0.004001936614871667, 'num_leaves': 23, 'max_depth': 9, 'lambda_l1': 0.5682348845098928, 'lambda_l2': 1.5117010187302793e-07, 'feature_fraction': 0.7822946318094723, 'bagging_fraction': 0.789935867639714, 'bagging_freq': 1}. Best is trial 1 with value: 0.14710225707341368.\n","[I 2025-10-12 06:49:28,978] Trial 2 finished with value: 0.14380653328111323 and parameters: {'n_estimators': 800, 'learning_rate': 0.0017815263726160295, 'num_leaves': 297, 'max_depth': 11, 'lambda_l1': 7.731880218117753e-05, 'lambda_l2': 4.0319728814475825e-08, 'feature_fraction': 0.8919401968061591, 'bagging_fraction': 0.7002811418298313, 'bagging_freq': 3}. Best is trial 1 with value: 0.14710225707341368.\n","[I 2025-10-12 06:49:36,973] Trial 3 finished with value: 0.1292899546486286 and parameters: {'n_estimators': 2000, 'learning_rate': 0.11571093197777502, 'num_leaves': 196, 'max_depth': 9, 'lambda_l1': 0.007747625180643865, 'lambda_l2': 5.4904153700099457e-05, 'feature_fraction': 0.9025647421175059, 'bagging_fraction': 0.7436505573241579, 'bagging_freq': 6}. Best is trial 1 with value: 0.14710225707341368.\n","[I 2025-10-12 06:49:54,852] Trial 4 finished with value: 0.14717942263312794 and parameters: {'n_estimators': 1600, 'learning_rate': 0.0013646417760825853, 'num_leaves': 244, 'max_depth': 5, 'lambda_l1': 1.1861511646284831e-05, 'lambda_l2': 3.214692603116354e-05, 'feature_fraction': 0.7829508533762386, 'bagging_fraction': 0.6481887556062559, 'bagging_freq': 2}. Best is trial 4 with value: 0.14717942263312794.\n","[I 2025-10-12 06:50:22,407] Trial 5 finished with value: 0.1460555695965587 and parameters: {'n_estimators': 900, 'learning_rate': 0.007122836829589865, 'num_leaves': 291, 'max_depth': 9, 'lambda_l1': 1.3905581926996608e-07, 'lambda_l2': 0.0020953252382172505, 'feature_fraction': 0.6443822444574615, 'bagging_fraction': 0.7970847395477221, 'bagging_freq': 3}. Best is trial 4 with value: 0.14717942263312794.\n","[I 2025-10-12 06:50:30,043] Trial 6 finished with value: 0.14537031667032538 and parameters: {'n_estimators': 300, 'learning_rate': 0.0021007178462077287, 'num_leaves': 43, 'max_depth': 11, 'lambda_l1': 0.9185386513441036, 'lambda_l2': 8.994049202652926e-05, 'feature_fraction': 0.6575990169236224, 'bagging_fraction': 0.8071042623593354, 'bagging_freq': 5}. Best is trial 4 with value: 0.14717942263312794.\n","[I 2025-10-12 06:50:33,483] Trial 7 finished with value: 0.13705820600701007 and parameters: {'n_estimators': 300, 'learning_rate': 0.17269909233985936, 'num_leaves': 264, 'max_depth': 5, 'lambda_l1': 0.0002276805118096614, 'lambda_l2': 9.11836164365157e-08, 'feature_fraction': 0.9660018853935215, 'bagging_fraction': 0.8663465438062825, 'bagging_freq': 5}. Best is trial 4 with value: 0.14717942263312794.\n","[I 2025-10-12 06:50:53,411] Trial 8 finished with value: 0.1427866009753817 and parameters: {'n_estimators': 200, 'learning_rate': 0.002152899218596584, 'num_leaves': 254, 'max_depth': 10, 'lambda_l1': 4.080046197892327e-07, 'lambda_l2': 0.23010709647613525, 'feature_fraction': 0.8001301302224977, 'bagging_fraction': 0.8973545486095251, 'bagging_freq': 5}. Best is trial 4 with value: 0.14717942263312794.\n","[I 2025-10-12 06:50:58,840] Trial 9 finished with value: 0.14362037904414593 and parameters: {'n_estimators': 900, 'learning_rate': 0.029126017035462925, 'num_leaves': 300, 'max_depth': 6, 'lambda_l1': 8.547161492467605e-06, 'lambda_l2': 0.044471446456661574, 'feature_fraction': 0.7882129648448222, 'bagging_fraction': 0.8178227736512423, 'bagging_freq': 7}. Best is trial 4 with value: 0.14717942263312794.\n","[I 2025-10-12 06:51:03,254] Trial 10 finished with value: 0.148341170478136 and parameters: {'n_estimators': 1500, 'learning_rate': 0.0203186067702649, 'num_leaves': 188, 'max_depth': 3, 'lambda_l1': 0.023824801840336352, 'lambda_l2': 9.713379419470073, 'feature_fraction': 0.721929184161326, 'bagging_fraction': 0.60145511108521, 'bagging_freq': 2}. Best is trial 10 with value: 0.148341170478136.\n","[I 2025-10-12 06:51:07,125] Trial 11 finished with value: 0.14838426657807535 and parameters: {'n_estimators': 1500, 'learning_rate': 0.021109436112837263, 'num_leaves': 189, 'max_depth': 3, 'lambda_l1': 0.014564050795595614, 'lambda_l2': 3.196091550549373, 'feature_fraction': 0.7144378875244477, 'bagging_fraction': 0.6123817002981435, 'bagging_freq': 2}. Best is trial 11 with value: 0.14838426657807535.\n","[I 2025-10-12 06:51:10,807] Trial 12 finished with value: 0.14858905779697132 and parameters: {'n_estimators': 1400, 'learning_rate': 0.030579147770233385, 'num_leaves': 163, 'max_depth': 3, 'lambda_l1': 0.010579031268531878, 'lambda_l2': 6.300841753371043, 'feature_fraction': 0.7077134871885141, 'bagging_fraction': 0.6076362495874321, 'bagging_freq': 3}. Best is trial 12 with value: 0.14858905779697132.\n","[I 2025-10-12 06:51:14,332] Trial 13 finished with value: 0.14845420884119914 and parameters: {'n_estimators': 1300, 'learning_rate': 0.04639250130855173, 'num_leaves': 132, 'max_depth': 3, 'lambda_l1': 0.013036856246465991, 'lambda_l2': 5.694487701032464, 'feature_fraction': 0.6976713765630689, 'bagging_fraction': 0.6069046099699631, 'bagging_freq': 3}. Best is trial 12 with value: 0.14858905779697132.\n","[I 2025-10-12 06:51:17,559] Trial 14 finished with value: 0.14818233559813065 and parameters: {'n_estimators': 1300, 'learning_rate': 0.051028964905976144, 'num_leaves': 124, 'max_depth': 3, 'lambda_l1': 9.108909290579982, 'lambda_l2': 0.19762679583176382, 'feature_fraction': 0.7109163930514537, 'bagging_fraction': 0.9839413349016417, 'bagging_freq': 4}. Best is trial 12 with value: 0.14858905779697132.\n","[I 2025-10-12 06:51:22,595] Trial 15 finished with value: 0.13830770657166408 and parameters: {'n_estimators': 1200, 'learning_rate': 0.05100635521364257, 'num_leaves': 130, 'max_depth': 7, 'lambda_l1': 0.0015931668796255831, 'lambda_l2': 0.017369618629249482, 'feature_fraction': 0.6075810214808637, 'bagging_fraction': 0.7213166275183359, 'bagging_freq': 3}. Best is trial 12 with value: 0.14858905779697132.\n","[I 2025-10-12 06:51:29,169] Trial 16 finished with value: 0.14822541199854306 and parameters: {'n_estimators': 1800, 'learning_rate': 0.007140742026454343, 'num_leaves': 83, 'max_depth': 4, 'lambda_l1': 0.12751621482003803, 'lambda_l2': 1.0556838669340338, 'feature_fraction': 0.6815329002232919, 'bagging_fraction': 0.6480971652879162, 'bagging_freq': 4}. Best is trial 12 with value: 0.14858905779697132.\n","[I 2025-10-12 06:51:34,291] Trial 17 finished with value: 0.1378775823980482 and parameters: {'n_estimators': 1200, 'learning_rate': 0.05208688437915165, 'num_leaves': 155, 'max_depth': 7, 'lambda_l1': 0.001588413975586945, 'lambda_l2': 0.004884025403358884, 'feature_fraction': 0.6055877080167792, 'bagging_fraction': 0.6474091250121957, 'bagging_freq': 4}. Best is trial 12 with value: 0.14858905779697132.\n","[I 2025-10-12 06:51:37,568] Trial 18 finished with value: 0.13629908395803725 and parameters: {'n_estimators': 1700, 'learning_rate': 0.29656864678177913, 'num_leaves': 77, 'max_depth': 4, 'lambda_l1': 0.09873952065776162, 'lambda_l2': 0.4806786389962799, 'feature_fraction': 0.7472070643472509, 'bagging_fraction': 0.7542163233894477, 'bagging_freq': 3}. Best is trial 12 with value: 0.14858905779697132.\n","[I 2025-10-12 06:51:43,391] Trial 19 finished with value: 0.1471267042086663 and parameters: {'n_estimators': 1300, 'learning_rate': 0.01001113372720419, 'num_leaves': 222, 'max_depth': 4, 'lambda_l1': 0.0016688580629728308, 'lambda_l2': 9.414468294984765, 'feature_fraction': 0.8167836340011134, 'bagging_fraction': 0.9988628413260582, 'bagging_freq': 2}. Best is trial 12 with value: 0.14858905779697132.\n","[I 2025-10-12 06:51:48,422] Trial 20 finished with value: 0.1430953348245814 and parameters: {'n_estimators': 2000, 'learning_rate': 0.03409950194876066, 'num_leaves': 160, 'max_depth': 6, 'lambda_l1': 2.2487182384120958e-08, 'lambda_l2': 0.0008112509311244557, 'feature_fraction': 0.8394953915526595, 'bagging_fraction': 0.6848654934221254, 'bagging_freq': 6}. Best is trial 12 with value: 0.14858905779697132.\n","[I 2025-10-12 06:51:52,708] Trial 21 finished with value: 0.14940632273483243 and parameters: {'n_estimators': 1400, 'learning_rate': 0.016870397012923487, 'num_leaves': 179, 'max_depth': 3, 'lambda_l1': 0.010418235143693487, 'lambda_l2': 2.1948382378677365, 'feature_fraction': 0.7305379430644312, 'bagging_fraction': 0.6055332408290104, 'bagging_freq': 2}. Best is trial 21 with value: 0.14940632273483243.\n","[I 2025-10-12 06:51:57,359] Trial 22 finished with value: 0.14812477089673387 and parameters: {'n_estimators': 1100, 'learning_rate': 0.014592797669492398, 'num_leaves': 136, 'max_depth': 3, 'lambda_l1': 0.0051596956876996695, 'lambda_l2': 0.062067677479206454, 'feature_fraction': 0.7460729642529794, 'bagging_fraction': 0.6043542095182877, 'bagging_freq': 1}. Best is trial 21 with value: 0.14940632273483243.\n","[I 2025-10-12 06:52:00,862] Trial 23 finished with value: 0.1437373956045974 and parameters: {'n_estimators': 1400, 'learning_rate': 0.07030619850850978, 'num_leaves': 174, 'max_depth': 4, 'lambda_l1': 0.06947877216981686, 'lambda_l2': 1.6404928871853512, 'feature_fraction': 0.6777849802799272, 'bagging_fraction': 0.6419978696588665, 'bagging_freq': 3}. Best is trial 21 with value: 0.14940632273483243.\n","[I 2025-10-12 06:52:05,389] Trial 24 finished with value: 0.14821174695342562 and parameters: {'n_estimators': 1800, 'learning_rate': 0.013000588790734768, 'num_leaves': 222, 'max_depth': 3, 'lambda_l1': 1.412485419749259, 'lambda_l2': 1.9089704056128896, 'feature_fraction': 0.7427365908893793, 'bagging_fraction': 0.6313697624622364, 'bagging_freq': 2}. Best is trial 21 with value: 0.14940632273483243.\n","[I 2025-10-12 06:52:10,402] Trial 25 finished with value: 0.14786673497180564 and parameters: {'n_estimators': 1000, 'learning_rate': 0.02737270422026421, 'num_leaves': 110, 'max_depth': 6, 'lambda_l1': 0.0003029444110471023, 'lambda_l2': 0.11770307228093305, 'feature_fraction': 0.6870132365972758, 'bagging_fraction': 0.670819220715534, 'bagging_freq': 3}. Best is trial 21 with value: 0.14940632273483243.\n","[I 2025-10-12 06:52:22,949] Trial 26 finished with value: 0.14797611539682437 and parameters: {'n_estimators': 1400, 'learning_rate': 0.0048440744662523886, 'num_leaves': 155, 'max_depth': 5, 'lambda_l1': 0.2616678717762883, 'lambda_l2': 0.013286459326959899, 'feature_fraction': 0.6399665134225976, 'bagging_fraction': 0.715639004978004, 'bagging_freq': 4}. Best is trial 21 with value: 0.14940632273483243.\n","[I 2025-10-12 06:52:26,294] Trial 27 finished with value: 0.14389643113089934 and parameters: {'n_estimators': 1100, 'learning_rate': 0.07718172776657913, 'num_leaves': 213, 'max_depth': 4, 'lambda_l1': 5.2957349802347754e-05, 'lambda_l2': 4.439229080744042e-06, 'feature_fraction': 0.75473659604908, 'bagging_fraction': 0.6212417971732002, 'bagging_freq': 2}. Best is trial 21 with value: 0.14940632273483243.\n","[I 2025-10-12 06:52:39,267] Trial 28 finished with value: 0.1416072365912087 and parameters: {'n_estimators': 1500, 'learning_rate': 0.036090892669025106, 'num_leaves': 144, 'max_depth': 12, 'lambda_l1': 0.026062387387481914, 'lambda_l2': 9.169167896173755, 'feature_fraction': 0.8533414121479675, 'bagging_fraction': 0.6670295155900078, 'bagging_freq': 1}. Best is trial 21 with value: 0.14940632273483243.\n","[I 2025-10-12 06:52:45,424] Trial 29 finished with value: 0.13577425872433904 and parameters: {'n_estimators': 600, 'learning_rate': 0.11456261263596564, 'num_leaves': 101, 'max_depth': 8, 'lambda_l1': 4.3086436001539985, 'lambda_l2': 0.4794499323816591, 'feature_fraction': 0.6977683855319635, 'bagging_fraction': 0.6788798387276191, 'bagging_freq': 1}. Best is trial 21 with value: 0.14940632273483243.\n","[I 2025-10-12 06:52:51,108] Trial 30 finished with value: 0.1470418395234527 and parameters: {'n_estimators': 1700, 'learning_rate': 0.009973792209752969, 'num_leaves': 73, 'max_depth': 4, 'lambda_l1': 0.0027548222858479717, 'lambda_l2': 1.6915571110223444, 'feature_fraction': 0.6662473149300963, 'bagging_fraction': 0.9450286769239195, 'bagging_freq': 4}. Best is trial 21 with value: 0.14940632273483243.\n","[I 2025-10-12 06:52:55,156] Trial 31 finished with value: 0.14898191703376196 and parameters: {'n_estimators': 1500, 'learning_rate': 0.017246973810659726, 'num_leaves': 190, 'max_depth': 3, 'lambda_l1': 0.015222355331475975, 'lambda_l2': 3.539675034020058, 'feature_fraction': 0.7161868782733738, 'bagging_fraction': 0.6022401737187313, 'bagging_freq': 2}. Best is trial 21 with value: 0.14940632273483243.\n"]},{"output_type":"stream","name":"stdout","text":["\n","[Optuna 조기 종료] 10번의 trial 동안 최고 점수가 갱신되지 않아 튜닝을 중단합니다.\n","\n","✅ 튜닝 완료!\n","\n","==================================================\n","🔬 최적 하이퍼파라미터 (Best Hyperparameters)\n","==================================================\n","        n_estimators: 1400\n","       learning_rate: 0.016870397012923487\n","          num_leaves: 179\n","           max_depth: 3\n","           lambda_l1: 0.010418235143693487\n","           lambda_l2: 2.1948382378677365\n","    feature_fraction: 0.7305379430644312\n","    bagging_fraction: 0.6055332408290104\n","        bagging_freq: 2\n","==================================================\n","\n","🔬 Step 5: 튜닝된 최종 모델 학습 및 평가...\n","✅ 튜닝된 모델 평가 완료.\n","\n","============================================================\n","📊 최종 성능 비교 결과 (Test Set)\n","============================================================\n","              PR AUC  ROC AUC  F1-Score\n","Baseline      0.1404   0.6208    0.0024\n","Optuna Tuned  0.1557   0.6235    0.0012\n","\n","============================================================\n","💾 Step 6: 최종 모델 예측 결과를 원본 CSV에 추가하여 저장\n","============================================================\n","✅ 모든 데이터의 예측 결과가 '/content/drive/MyDrive/review_helpfulness/PADA/results/s2/hotel/SentenceBERT_hotel_with_s2_predictions.csv' 파일에 성공적으로 저장되었습니다.\n","\n","============================================================\n","🧹 Step 7: 사용된 변수들을 메모리에서 정리\n","============================================================\n","✅ 메모리 정리가 완료되었습니다.\n","\n","🎉 모든 과정이 완료되었습니다!\n"]}]},{"cell_type":"markdown","source":["## RoBERTa\n"],"metadata":{"id":"3tVSa3Z-vQBA"}},{"cell_type":"code","source":["# === 2. 환경설정 클래스 ===\n","class Config:\n","    \"\"\"실행에 필요한 모든 설정값을 중앙에서 관리합니다.\"\"\"\n","    # 🌟 1. 입력 파일 경로 설정\n","    CSV_FILE_PATH = \"/content/drive/MyDrive/review_helpfulness/PADA/data/hotel/hotel.csv\"\n","    EMBEDDING_PATH = \"/content/drive/MyDrive/review_helpfulness/PADA/embedding/hotel_RoBERTa.npy\"\n","\n","    # 🌟 2. 최종 결과 CSV 파일 저장 경로 설정\n","    OUTPUT_CSV_PATH = \"/content/drive/MyDrive/review_helpfulness/PADA/results/s2/hotel/RoBERTa_hotel_with_s2_predictions.csv\"\n","\n","    # --- 데이터 정보 ---\n","    TARGET_COLUMN = 'binary_helpfulness'\n","\n","    # --- 데이터 분할 ---\n","    TEST_SPLIT_RATIO = 0.2\n","    RANDOM_STATE = 42\n","\n","    # --- Optuna 튜닝 설정 ---\n","    N_TRIALS = 50\n","    TUNING_METRIC = 'pr_auc'\n","    EARLY_STOPPING_ROUNDS = 10 # 🌟 Optuna 조기 종료 횟수\n","\n","# === 3. Optuna 조기 종료 콜백 ===\n","class EarlyStoppingCallback:\n","    \"\"\"Optuna 스터디의 조기 종료를 위한 콜백 클래스\"\"\"\n","    def __init__(self, early_stopping_rounds: int):\n","        self._early_stopping_rounds = early_stopping_rounds\n","        self._best_value = -float(\"inf\")\n","        self._counter = 0\n","\n","    def __call__(self, study: optuna.study.Study, trial: optuna.trial.Trial):\n","        current_best_value = study.best_value\n","        if current_best_value is not None and current_best_value > self._best_value:\n","            self._best_value = current_best_value\n","            self._counter = 0\n","        else:\n","            self._counter += 1\n","\n","        if self._counter >= self._early_stopping_rounds:\n","            print(f\"\\n[Optuna 조기 종료] {self._early_stopping_rounds}번의 trial 동안 최고 점수가 갱신되지 않아 튜닝을 중단합니다.\")\n","            study.stop()\n","\n","# === 4. Optuna Objective 함수 ===\n","def objective(trial, X, y):\n","    \"\"\"Optuna가 최적의 하이퍼파라미터를 찾기 위해 반복 호출하는 함수\"\"\"\n","    X_train, X_val, y_train, y_val = train_test_split(\n","        X, y, test_size=0.25, random_state=Config.RANDOM_STATE, stratify=y\n","    )\n","\n","    params = {\n","        'objective': 'binary', 'metric': 'logloss', 'verbosity': -1,\n","        'boosting_type': 'gbdt', 'random_state': Config.RANDOM_STATE,\n","        'device': 'gpu',  # 🌟 Optuna Trial 내부에서도 GPU 사용\n","        'n_estimators': trial.suggest_int('n_estimators', 100, 2000, step=100),\n","        'learning_rate': trial.suggest_float('learning_rate', 1e-3, 0.3, log=True),\n","        'num_leaves': trial.suggest_int('num_leaves', 20, 300),\n","        'max_depth': trial.suggest_int('max_depth', 3, 12),\n","        'lambda_l1': trial.suggest_float('lambda_l1', 1e-8, 10.0, log=True),\n","        'lambda_l2': trial.suggest_float('lambda_l2', 1e-8, 10.0, log=True),\n","        'feature_fraction': trial.suggest_float('feature_fraction', 0.6, 1.0),\n","        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.6, 1.0),\n","        'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\n","    }\n","\n","    model = lgb.LGBMClassifier(**params)\n","    model.fit(X_train, y_train,\n","              eval_set=[(X_val, y_val)],\n","              eval_metric='logloss',\n","              callbacks=[lgb.early_stopping(100, verbose=False)])\n","\n","    y_pred_proba = model.predict_proba(X_val)[:, 1]\n","    score = average_precision_score(y_val, y_pred_proba)\n","    return score\n","\n","# === 5. 메인 실행 블록 ===\n","if __name__ == '__main__':\n","    config = Config()\n","\n","    # ... (Step 1 ~ 2: 데이터 로드, 분할, 베이스라인 측정) ...\n","    print(\"Step 1: 데이터 로드 및 분할 중...\")\n","    try:\n","        df = pd.read_csv(config.CSV_FILE_PATH)\n","        labels = df[config.TARGET_COLUMN].values\n","        embeddings = np.load(config.EMBEDDING_PATH)\n","        assert len(df) == len(embeddings)\n","    except Exception as e:\n","        print(f\"🔥 파일 로드 실패: {e}\"); exit()\n","\n","    indices = np.arange(len(df))\n","    train_indices, test_indices = train_test_split(\n","        indices, test_size=config.TEST_SPLIT_RATIO, random_state=config.RANDOM_STATE, stratify=labels\n","    )\n","    X_train, X_test = embeddings[train_indices], embeddings[test_indices]\n","    y_train, y_test = labels[train_indices], labels[test_indices]\n","    print(f\"✅ 완료 (학습용: {len(y_train)}건, 테스트용: {len(y_test)}건)\")\n","\n","    print(\"\\n\" + \"=\"*50)\n","    print(\"📊 Step 2: 베이스라인 모델 성능 측정 (GPU 사용)\")\n","    print(\"=\"*50)\n","\n","    baseline_model = lgb.LGBMClassifier(device='gpu', random_state=config.RANDOM_STATE)\n","    baseline_model.fit(X_train, y_train)\n","\n","    y_pred_proba_base = baseline_model.predict_proba(X_test)[:, 1]\n","    y_pred_class_base = (y_pred_proba_base > 0.5).astype(int)\n","\n","    final_results = {}\n","    final_results['Baseline'] = {\n","        \"PR AUC\": average_precision_score(y_test, y_pred_proba_base),\n","        \"ROC AUC\": roc_auc_score(y_test, y_pred_proba_base),\n","        \"F1-Score\": f1_score(y_test, y_pred_class_base),\n","    }\n","    print(\"✅ 베이스라인 모델 평가 완료.\")\n","\n","    # --- Step 3: Optuna 튜닝 수행 (조기 종료 포함) ---\n","    print(\"\\n\" + \"=\"*50)\n","    print(f\"🔬 Step 3: Optuna 하이퍼파라미터 튜닝 시작 (GPU 사용)...\")\n","    print(f\"(최대 {config.N_TRIALS}번 시도, {config.EARLY_STOPPING_ROUNDS}번 개선 없으면 조기 종료)\")\n","    print(\"=\"*50)\n","\n","    early_stopping_callback = EarlyStoppingCallback(early_stopping_rounds=config.EARLY_STOPPING_ROUNDS)\n","    study = optuna.create_study(direction='maximize')\n","    pbar = tqdm(total=config.N_TRIALS, desc=\"Optuna 튜닝 진행률\")\n","\n","    try:\n","        study.optimize(lambda trial: objective(trial, X_train, y_train),\n","                       n_trials=config.N_TRIALS,\n","                       callbacks=[lambda study, trial: pbar.update(1), early_stopping_callback])\n","    except optuna.exceptions.OptunaError:\n","        # 조기 종료 시 발생하는 예외를 정상 처리\n","        pass\n","    pbar.close()\n","\n","    # ... (Step 4 ~ 6: 결과 출력, 저장, 메모리 정리) ...\n","    print(f\"\\n✅ 튜닝 완료!\")\n","    print(\"\\n\" + \"=\"*50)\n","    print(\"🔬 최적 하이퍼파라미터 (Best Hyperparameters)\")\n","    print(\"=\"*50)\n","    best_params = study.best_params\n","    for key, value in best_params.items():\n","        print(f\"{key:>20s}: {value}\")\n","    print(\"=\"*50)\n","\n","    print(f\"\\n🔬 Step 5: 튜닝된 최종 모델 학습 및 평가...\")\n","    final_model = lgb.LGBMClassifier(device='gpu', objective='binary', verbosity=-1, random_state=config.RANDOM_STATE, **best_params)\n","    final_model.fit(X_train, y_train)\n","\n","    y_pred_proba_tuned = final_model.predict_proba(X_test)[:, 1]\n","    y_pred_class_tuned = (y_pred_proba_tuned > 0.5).astype(int)\n","\n","    final_results['Optuna Tuned'] = {\n","        \"PR AUC\": average_precision_score(y_test, y_pred_proba_tuned),\n","        \"ROC AUC\": roc_auc_score(y_test, y_pred_proba_tuned),\n","        \"F1-Score\": f1_score(y_test, y_pred_class_tuned),\n","    }\n","    print(\"✅ 튜닝된 모델 평가 완료.\")\n","\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"📊 최종 성능 비교 결과 (Test Set)\")\n","    print(\"=\"*60)\n","    results_df = pd.DataFrame(final_results).T\n","    print(results_df.round(4))\n","\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"💾 Step 6: 최종 모델 예측 결과를 원본 CSV에 추가하여 저장\")\n","    print(\"=\"*60)\n","\n","    train_pred_proba = final_model.predict_proba(X_train)[:, 1]\n","    train_pred_class = (train_pred_proba > 0.5).astype(int)\n","\n","    df['s2_pred_proba'] = np.nan\n","    df['s2_pred_class'] = np.nan\n","\n","    df.loc[train_indices, 's2_pred_proba'] = train_pred_proba\n","    df.loc[train_indices, 's2_pred_class'] = train_pred_class\n","\n","    df.loc[test_indices, 's2_pred_proba'] = y_pred_proba_tuned\n","    df.loc[test_indices, 's2_pred_class'] = y_pred_class_tuned\n","\n","    # 🌟 Config에 설정된 경로로 최종 파일 저장\n","    df.to_csv(config.OUTPUT_CSV_PATH, index=False, encoding='utf-8-sig')\n","\n","    print(f\"✅ 모든 데이터의 예측 결과가 '{config.OUTPUT_CSV_PATH}' 파일에 성공적으로 저장되었습니다.\")\n","\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"🧹 Step 7: 사용된 변수들을 메모리에서 정리\")\n","    print(\"=\"*60)\n","\n","    vars_to_delete = [\n","        'df', 'labels', 'embeddings', 'indices', 'X_train', 'X_test',\n","        'y_train', 'y_test', 'train_indices', 'test_indices',\n","        'baseline_model', 'final_model', 'study',\n","    ]\n","    for var_name in vars_to_delete:\n","        if var_name in locals() or var_name in globals():\n","            if var_name in globals(): del globals()[var_name]\n","\n","    gc.collect()\n","    print(\"✅ 메모리 정리가 완료되었습니다.\")\n","\n","    print(\"\\n🎉 모든 과정이 완료되었습니다!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["f1aa492dec9e4e5e884483e9da56145c","54977e91f7ec4d5f889d10c0f2c3d76c","e9b6689ab56a4ae0978daee1166ebdc9","007ebcad2b1344d093aff8c030bdb0b7","0655bc417a2c454ba87656444131fa59","191a3a972b604312949d230d983b56d1","7a1380b34e5c4ce3b6b23c292a887e89","17ae79b0219c412d924340657edfd08a","33f21f3aac7c4047bd84dbfb4b16b941","17988837387c4395acecb984f0028d41","4ae3d06358d144b692de01254f03de96"]},"id":"15JdEf6qyMKv","executionInfo":{"status":"ok","timestamp":1760253478272,"user_tz":-540,"elapsed":1490545,"user":{"displayName":"KW-data-analytics","userId":"09651493752354345908"}},"outputId":"cb675234-d4b8-4aae-ca2a-f16e62ff9395"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Step 1: 데이터 로드 및 분할 중...\n","✅ 완료 (학습용: 71604건, 테스트용: 17901건)\n","\n","==================================================\n","📊 Step 2: 베이스라인 모델 성능 측정 (GPU 사용)\n","==================================================\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-10-12 06:53:21,353] A new study created in memory with name: no-name-e5b34902-bb81-486d-bcee-47f51ac32e5d\n"]},{"output_type":"stream","name":"stdout","text":["✅ 베이스라인 모델 평가 완료.\n","\n","==================================================\n","🔬 Step 3: Optuna 하이퍼파라미터 튜닝 시작 (GPU 사용)...\n","(최대 50번 시도, 10번 개선 없으면 조기 종료)\n","==================================================\n"]},{"output_type":"display_data","data":{"text/plain":["Optuna 튜닝 진행률:   0%|          | 0/50 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f1aa492dec9e4e5e884483e9da56145c"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2025-10-12 06:54:01,492] Trial 0 finished with value: 0.1489438350862692 and parameters: {'n_estimators': 700, 'learning_rate': 0.0013217086542025207, 'num_leaves': 85, 'max_depth': 10, 'lambda_l1': 1.0960833422195425e-05, 'lambda_l2': 8.557152478888471e-06, 'feature_fraction': 0.6066949773719481, 'bagging_fraction': 0.8443557724766394, 'bagging_freq': 7}. Best is trial 0 with value: 0.1489438350862692.\n","[I 2025-10-12 06:54:16,320] Trial 1 finished with value: 0.14959917409695517 and parameters: {'n_estimators': 1800, 'learning_rate': 0.009085687386416613, 'num_leaves': 69, 'max_depth': 5, 'lambda_l1': 0.001096276607387823, 'lambda_l2': 0.03898924084167889, 'feature_fraction': 0.644606874095696, 'bagging_fraction': 0.8740672766511774, 'bagging_freq': 3}. Best is trial 1 with value: 0.14959917409695517.\n","[I 2025-10-12 06:54:43,513] Trial 2 finished with value: 0.1495907808976755 and parameters: {'n_estimators': 1400, 'learning_rate': 0.0023740284280010736, 'num_leaves': 267, 'max_depth': 5, 'lambda_l1': 1.0055074292117419e-08, 'lambda_l2': 1.5397688158690655e-06, 'feature_fraction': 0.7246076506632874, 'bagging_fraction': 0.6821391745777815, 'bagging_freq': 4}. Best is trial 1 with value: 0.14959917409695517.\n","[I 2025-10-12 06:54:56,899] Trial 3 finished with value: 0.1240733940860623 and parameters: {'n_estimators': 1100, 'learning_rate': 0.19136055978839317, 'num_leaves': 123, 'max_depth': 9, 'lambda_l1': 5.0159391546600364e-05, 'lambda_l2': 3.58192992396923e-06, 'feature_fraction': 0.8877200905999647, 'bagging_fraction': 0.939702904224889, 'bagging_freq': 2}. Best is trial 1 with value: 0.14959917409695517.\n","[I 2025-10-12 06:55:10,259] Trial 4 finished with value: 0.14509009332890882 and parameters: {'n_estimators': 100, 'learning_rate': 0.007012256519569828, 'num_leaves': 196, 'max_depth': 10, 'lambda_l1': 9.538626292171108, 'lambda_l2': 0.002692850445067302, 'feature_fraction': 0.7754340857073314, 'bagging_fraction': 0.7504632882037967, 'bagging_freq': 4}. Best is trial 1 with value: 0.14959917409695517.\n","[I 2025-10-12 06:55:47,770] Trial 5 finished with value: 0.14628073133398006 and parameters: {'n_estimators': 1500, 'learning_rate': 0.009151338569713905, 'num_leaves': 148, 'max_depth': 9, 'lambda_l1': 3.224434537917865e-07, 'lambda_l2': 0.0937602279810169, 'feature_fraction': 0.7764327530401737, 'bagging_fraction': 0.7565270230747742, 'bagging_freq': 6}. Best is trial 1 with value: 0.14959917409695517.\n","[I 2025-10-12 06:56:07,607] Trial 6 finished with value: 0.14431720588048438 and parameters: {'n_estimators': 1200, 'learning_rate': 0.04667013732121974, 'num_leaves': 125, 'max_depth': 11, 'lambda_l1': 5.924451770952309e-07, 'lambda_l2': 0.5392203354750638, 'feature_fraction': 0.8342938390367404, 'bagging_fraction': 0.9835919099879562, 'bagging_freq': 6}. Best is trial 1 with value: 0.14959917409695517.\n","[I 2025-10-12 06:56:41,204] Trial 7 finished with value: 0.13703676006172516 and parameters: {'n_estimators': 1500, 'learning_rate': 0.03179463282436966, 'num_leaves': 295, 'max_depth': 11, 'lambda_l1': 0.00010692219390202577, 'lambda_l2': 7.028803848103374e-06, 'feature_fraction': 0.9410683445961799, 'bagging_fraction': 0.9667276769723926, 'bagging_freq': 7}. Best is trial 1 with value: 0.14959917409695517.\n","[I 2025-10-12 06:56:46,919] Trial 8 finished with value: 0.1483211015885771 and parameters: {'n_estimators': 500, 'learning_rate': 0.0872335162053181, 'num_leaves': 123, 'max_depth': 4, 'lambda_l1': 0.00018554602991498754, 'lambda_l2': 3.098022699865328, 'feature_fraction': 0.7109898250916117, 'bagging_fraction': 0.8156842235716741, 'bagging_freq': 7}. Best is trial 1 with value: 0.14959917409695517.\n","[I 2025-10-12 06:56:54,122] Trial 9 finished with value: 0.14944300589954884 and parameters: {'n_estimators': 300, 'learning_rate': 0.026192894821674535, 'num_leaves': 190, 'max_depth': 5, 'lambda_l1': 0.00010231606450176035, 'lambda_l2': 3.673538490397203e-07, 'feature_fraction': 0.7578936011514678, 'bagging_fraction': 0.6283667856487084, 'bagging_freq': 5}. Best is trial 1 with value: 0.14959917409695517.\n","[I 2025-10-12 06:57:15,278] Trial 10 finished with value: 0.1493361808602846 and parameters: {'n_estimators': 2000, 'learning_rate': 0.005488359659725846, 'num_leaves': 24, 'max_depth': 7, 'lambda_l1': 0.03955466454621626, 'lambda_l2': 0.00156278615347386, 'feature_fraction': 0.6025185413595363, 'bagging_fraction': 0.8957249270450642, 'bagging_freq': 1}. Best is trial 1 with value: 0.14959917409695517.\n","[I 2025-10-12 06:58:14,401] Trial 11 finished with value: 0.15059655181294102 and parameters: {'n_estimators': 2000, 'learning_rate': 0.0017179725886711885, 'num_leaves': 280, 'max_depth': 6, 'lambda_l1': 0.01143978699015702, 'lambda_l2': 6.242558495287966e-08, 'feature_fraction': 0.6821109848576768, 'bagging_fraction': 0.6447378949214279, 'bagging_freq': 3}. Best is trial 11 with value: 0.15059655181294102.\n","[I 2025-10-12 06:58:56,510] Trial 12 finished with value: 0.15027514324628902 and parameters: {'n_estimators': 2000, 'learning_rate': 0.0010100831125872856, 'num_leaves': 26, 'max_depth': 7, 'lambda_l1': 0.018574463559748424, 'lambda_l2': 1.4669414942147051e-08, 'feature_fraction': 0.6715303613702897, 'bagging_fraction': 0.607369311646174, 'bagging_freq': 3}. Best is trial 11 with value: 0.15059655181294102.\n","[I 2025-10-12 07:00:30,896] Trial 13 finished with value: 0.1509567934515419 and parameters: {'n_estimators': 2000, 'learning_rate': 0.0011808767828013396, 'num_leaves': 234, 'max_depth': 7, 'lambda_l1': 0.04219897390557532, 'lambda_l2': 1.915681795998146e-08, 'feature_fraction': 0.6709316610651762, 'bagging_fraction': 0.6081443595224054, 'bagging_freq': 3}. Best is trial 13 with value: 0.1509567934515419.\n","[I 2025-10-12 07:01:28,900] Trial 14 finished with value: 0.14936503353805852 and parameters: {'n_estimators': 1700, 'learning_rate': 0.003171267615264025, 'num_leaves': 240, 'max_depth': 7, 'lambda_l1': 0.7188024429637137, 'lambda_l2': 1.0149999067724443e-08, 'feature_fraction': 0.6743610413150078, 'bagging_fraction': 0.68299088981567, 'bagging_freq': 2}. Best is trial 13 with value: 0.1509567934515419.\n","[I 2025-10-12 07:01:38,012] Trial 15 finished with value: 0.14840363479416713 and parameters: {'n_estimators': 800, 'learning_rate': 0.0023163508798368605, 'num_leaves': 229, 'max_depth': 3, 'lambda_l1': 0.009013772400722748, 'lambda_l2': 1.3448605945341706e-07, 'feature_fraction': 0.8232602289616956, 'bagging_fraction': 0.6714567209154766, 'bagging_freq': 3}. Best is trial 13 with value: 0.1509567934515419.\n","[I 2025-10-12 07:02:39,683] Trial 16 finished with value: 0.15075636640343998 and parameters: {'n_estimators': 1800, 'learning_rate': 0.0010520672050669665, 'num_leaves': 300, 'max_depth': 6, 'lambda_l1': 0.15056055563417134, 'lambda_l2': 6.440713179188328e-05, 'feature_fraction': 0.7202116527815088, 'bagging_fraction': 0.7488343818510808, 'bagging_freq': 1}. Best is trial 13 with value: 0.1509567934515419.\n","[I 2025-10-12 07:03:57,656] Trial 17 finished with value: 0.14977130388255466 and parameters: {'n_estimators': 1800, 'learning_rate': 0.003746084385301983, 'num_leaves': 240, 'max_depth': 8, 'lambda_l1': 0.271904743396203, 'lambda_l2': 9.3321628512663e-05, 'feature_fraction': 0.9833967764920336, 'bagging_fraction': 0.7635591816297855, 'bagging_freq': 1}. Best is trial 13 with value: 0.1509567934515419.\n","[I 2025-10-12 07:04:56,812] Trial 18 finished with value: 0.15045650970088048 and parameters: {'n_estimators': 1700, 'learning_rate': 0.0010760228666936709, 'num_leaves': 206, 'max_depth': 6, 'lambda_l1': 1.5203557665830654, 'lambda_l2': 0.00011936600188429824, 'feature_fraction': 0.7375963535495538, 'bagging_fraction': 0.7134443806021817, 'bagging_freq': 2}. Best is trial 13 with value: 0.1509567934515419.\n","[I 2025-10-12 07:05:04,252] Trial 19 finished with value: 0.1488697642208377 and parameters: {'n_estimators': 1300, 'learning_rate': 0.016126622249474816, 'num_leaves': 264, 'max_depth': 3, 'lambda_l1': 0.0017788587310685945, 'lambda_l2': 0.0009723170625609928, 'feature_fraction': 0.6384544314365846, 'bagging_fraction': 0.7180119615057152, 'bagging_freq': 1}. Best is trial 13 with value: 0.1509567934515419.\n","[I 2025-10-12 07:06:05,256] Trial 20 finished with value: 0.15134394714801333 and parameters: {'n_estimators': 900, 'learning_rate': 0.004355937374175203, 'num_leaves': 168, 'max_depth': 8, 'lambda_l1': 0.11886169873107448, 'lambda_l2': 2.8546913747580097e-05, 'feature_fraction': 0.8122662773233221, 'bagging_fraction': 0.7786576225929838, 'bagging_freq': 2}. Best is trial 20 with value: 0.15134394714801333.\n","[I 2025-10-12 07:07:15,896] Trial 21 finished with value: 0.15237207364035016 and parameters: {'n_estimators': 900, 'learning_rate': 0.0039196739107984465, 'num_leaves': 167, 'max_depth': 8, 'lambda_l1': 0.13834670343408717, 'lambda_l2': 2.2657808278834583e-05, 'feature_fraction': 0.8629208085647815, 'bagging_fraction': 0.7965134021553388, 'bagging_freq': 2}. Best is trial 21 with value: 0.15237207364035016.\n","[I 2025-10-12 07:08:22,580] Trial 22 finished with value: 0.1504149415995829 and parameters: {'n_estimators': 900, 'learning_rate': 0.004475063669333679, 'num_leaves': 165, 'max_depth': 8, 'lambda_l1': 6.467891673949625, 'lambda_l2': 3.0113580627789183e-05, 'feature_fraction': 0.8718534717385037, 'bagging_fraction': 0.802747438206184, 'bagging_freq': 2}. Best is trial 21 with value: 0.15237207364035016.\n","[I 2025-10-12 07:10:18,099] Trial 23 finished with value: 0.1500804378163921 and parameters: {'n_estimators': 1000, 'learning_rate': 0.0020968901626614625, 'num_leaves': 162, 'max_depth': 9, 'lambda_l1': 0.08304097499311698, 'lambda_l2': 1.170853403176642e-06, 'feature_fraction': 0.8716116162596289, 'bagging_fraction': 0.8341076079632381, 'bagging_freq': 2}. Best is trial 21 with value: 0.15237207364035016.\n","[I 2025-10-12 07:10:43,902] Trial 24 finished with value: 0.14429691404157258 and parameters: {'n_estimators': 600, 'learning_rate': 0.014726908350262012, 'num_leaves': 185, 'max_depth': 8, 'lambda_l1': 0.00256626912226301, 'lambda_l2': 0.0093687344372194, 'feature_fraction': 0.9137321250580317, 'bagging_fraction': 0.9018311410560844, 'bagging_freq': 4}. Best is trial 21 with value: 0.15237207364035016.\n","[I 2025-10-12 07:11:28,994] Trial 25 finished with value: 0.1465848112546643 and parameters: {'n_estimators': 1000, 'learning_rate': 0.010492767671875016, 'num_leaves': 215, 'max_depth': 12, 'lambda_l1': 1.4520086404857233, 'lambda_l2': 0.0004193941065270605, 'feature_fraction': 0.8323184591146129, 'bagging_fraction': 0.777136482524766, 'bagging_freq': 3}. Best is trial 21 with value: 0.15237207364035016.\n","[I 2025-10-12 07:11:58,369] Trial 26 finished with value: 0.14961868817381216 and parameters: {'n_estimators': 400, 'learning_rate': 0.003249656950597796, 'num_leaves': 89, 'max_depth': 8, 'lambda_l1': 0.2964275530940419, 'lambda_l2': 2.2546603394315626e-05, 'feature_fraction': 0.8166142622705088, 'bagging_fraction': 0.8493285732532534, 'bagging_freq': 2}. Best is trial 21 with value: 0.15237207364035016.\n","[I 2025-10-12 07:12:58,325] Trial 27 finished with value: 0.15204768116192724 and parameters: {'n_estimators': 800, 'learning_rate': 0.005431248276326261, 'num_leaves': 172, 'max_depth': 9, 'lambda_l1': 0.04007021429794787, 'lambda_l2': 3.096872411695499e-07, 'feature_fraction': 0.7995813384368397, 'bagging_fraction': 0.7172835216367462, 'bagging_freq': 4}. Best is trial 21 with value: 0.15237207364035016.\n","[I 2025-10-12 07:13:55,876] Trial 28 finished with value: 0.1509586362968398 and parameters: {'n_estimators': 700, 'learning_rate': 0.005718660978961, 'num_leaves': 146, 'max_depth': 10, 'lambda_l1': 0.0036366370318352743, 'lambda_l2': 4.883049374667888e-07, 'feature_fraction': 0.795120106439188, 'bagging_fraction': 0.7221110596841842, 'bagging_freq': 5}. Best is trial 21 with value: 0.15237207364035016.\n","[I 2025-10-12 07:14:56,390] Trial 29 finished with value: 0.14921267591334614 and parameters: {'n_estimators': 800, 'learning_rate': 0.006172058930761757, 'num_leaves': 175, 'max_depth': 10, 'lambda_l1': 5.048746547179053e-06, 'lambda_l2': 9.986996925351921e-06, 'feature_fraction': 0.8652936477504073, 'bagging_fraction': 0.7878360852562608, 'bagging_freq': 5}. Best is trial 21 with value: 0.15237207364035016.\n","[I 2025-10-12 07:15:23,331] Trial 30 finished with value: 0.14937870569706183 and parameters: {'n_estimators': 700, 'learning_rate': 0.012005567027074952, 'num_leaves': 96, 'max_depth': 9, 'lambda_l1': 0.0006269534966824965, 'lambda_l2': 2.5438577680355297e-06, 'feature_fraction': 0.9299974302618228, 'bagging_fraction': 0.8253019200710164, 'bagging_freq': 4}. Best is trial 21 with value: 0.15237207364035016.\n","[I 2025-10-12 07:16:26,216] Trial 31 finished with value: 0.14965208070994077 and parameters: {'n_estimators': 700, 'learning_rate': 0.005011910673652871, 'num_leaves': 146, 'max_depth': 11, 'lambda_l1': 0.005607997900946215, 'lambda_l2': 4.2631961615591844e-07, 'feature_fraction': 0.797429273997862, 'bagging_fraction': 0.7243542400344555, 'bagging_freq': 5}. Best is trial 21 with value: 0.15237207364035016.\n"]},{"output_type":"stream","name":"stdout","text":["\n","[Optuna 조기 종료] 10번의 trial 동안 최고 점수가 갱신되지 않아 튜닝을 중단합니다.\n","\n","✅ 튜닝 완료!\n","\n","==================================================\n","🔬 최적 하이퍼파라미터 (Best Hyperparameters)\n","==================================================\n","        n_estimators: 900\n","       learning_rate: 0.0039196739107984465\n","          num_leaves: 167\n","           max_depth: 8\n","           lambda_l1: 0.13834670343408717\n","           lambda_l2: 2.2657808278834583e-05\n","    feature_fraction: 0.8629208085647815\n","    bagging_fraction: 0.7965134021553388\n","        bagging_freq: 2\n","==================================================\n","\n","🔬 Step 5: 튜닝된 최종 모델 학습 및 평가...\n","✅ 튜닝된 모델 평가 완료.\n","\n","============================================================\n","📊 최종 성능 비교 결과 (Test Set)\n","============================================================\n","              PR AUC  ROC AUC  F1-Score\n","Baseline      0.1425   0.6096     0.006\n","Optuna Tuned  0.1545   0.6229     0.000\n","\n","============================================================\n","💾 Step 6: 최종 모델 예측 결과를 원본 CSV에 추가하여 저장\n","============================================================\n","✅ 모든 데이터의 예측 결과가 '/content/drive/MyDrive/review_helpfulness/PADA/results/s2/hotel/RoBERTa_hotel_with_s2_predictions.csv' 파일에 성공적으로 저장되었습니다.\n","\n","============================================================\n","🧹 Step 7: 사용된 변수들을 메모리에서 정리\n","============================================================\n","✅ 메모리 정리가 완료되었습니다.\n","\n","🎉 모든 과정이 완료되었습니다!\n"]}]},{"cell_type":"markdown","source":["## DistilBERT"],"metadata":{"id":"G7NH-0tcvQZ8"}},{"cell_type":"code","source":["# === 2. 환경설정 클래스 ===\n","class Config:\n","    \"\"\"실행에 필요한 모든 설정값을 중앙에서 관리합니다.\"\"\"\n","    # 🌟 1. 입력 파일 경로 설정\n","    CSV_FILE_PATH = \"/content/drive/MyDrive/review_helpfulness/PADA/data/hotel/hotel.csv\"\n","    EMBEDDING_PATH = \"/content/drive/MyDrive/review_helpfulness/PADA/embedding/hotel_DistilBERT.npy\"\n","\n","    # 🌟 2. 최종 결과 CSV 파일 저장 경로 설정\n","    OUTPUT_CSV_PATH = \"/content/drive/MyDrive/review_helpfulness/PADA/results/s2/hotel/DistilBERT_hotel_with_s2_predictions.csv\"\n","\n","    # --- 데이터 정보 ---\n","    TARGET_COLUMN = 'binary_helpfulness'\n","\n","    # --- 데이터 분할 ---\n","    TEST_SPLIT_RATIO = 0.2\n","    RANDOM_STATE = 42\n","\n","    # --- Optuna 튜닝 설정 ---\n","    N_TRIALS = 50\n","    TUNING_METRIC = 'pr_auc'\n","    EARLY_STOPPING_ROUNDS = 10 # 🌟 Optuna 조기 종료 횟수\n","\n","# === 3. Optuna 조기 종료 콜백 ===\n","class EarlyStoppingCallback:\n","    \"\"\"Optuna 스터디의 조기 종료를 위한 콜백 클래스\"\"\"\n","    def __init__(self, early_stopping_rounds: int):\n","        self._early_stopping_rounds = early_stopping_rounds\n","        self._best_value = -float(\"inf\")\n","        self._counter = 0\n","\n","    def __call__(self, study: optuna.study.Study, trial: optuna.trial.Trial):\n","        current_best_value = study.best_value\n","        if current_best_value is not None and current_best_value > self._best_value:\n","            self._best_value = current_best_value\n","            self._counter = 0\n","        else:\n","            self._counter += 1\n","\n","        if self._counter >= self._early_stopping_rounds:\n","            print(f\"\\n[Optuna 조기 종료] {self._early_stopping_rounds}번의 trial 동안 최고 점수가 갱신되지 않아 튜닝을 중단합니다.\")\n","            study.stop()\n","\n","# === 4. Optuna Objective 함수 ===\n","def objective(trial, X, y):\n","    \"\"\"Optuna가 최적의 하이퍼파라미터를 찾기 위해 반복 호출하는 함수\"\"\"\n","    X_train, X_val, y_train, y_val = train_test_split(\n","        X, y, test_size=0.25, random_state=Config.RANDOM_STATE, stratify=y\n","    )\n","\n","    params = {\n","        'objective': 'binary', 'metric': 'logloss', 'verbosity': -1,\n","        'boosting_type': 'gbdt', 'random_state': Config.RANDOM_STATE,\n","        'device': 'gpu',  # 🌟 Optuna Trial 내부에서도 GPU 사용\n","        'n_estimators': trial.suggest_int('n_estimators', 100, 2000, step=100),\n","        'learning_rate': trial.suggest_float('learning_rate', 1e-3, 0.3, log=True),\n","        'num_leaves': trial.suggest_int('num_leaves', 20, 300),\n","        'max_depth': trial.suggest_int('max_depth', 3, 12),\n","        'lambda_l1': trial.suggest_float('lambda_l1', 1e-8, 10.0, log=True),\n","        'lambda_l2': trial.suggest_float('lambda_l2', 1e-8, 10.0, log=True),\n","        'feature_fraction': trial.suggest_float('feature_fraction', 0.6, 1.0),\n","        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.6, 1.0),\n","        'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\n","    }\n","\n","    model = lgb.LGBMClassifier(**params)\n","    model.fit(X_train, y_train,\n","              eval_set=[(X_val, y_val)],\n","              eval_metric='logloss',\n","              callbacks=[lgb.early_stopping(100, verbose=False)])\n","\n","    y_pred_proba = model.predict_proba(X_val)[:, 1]\n","    score = average_precision_score(y_val, y_pred_proba)\n","    return score\n","\n","# === 5. 메인 실행 블록 ===\n","if __name__ == '__main__':\n","    config = Config()\n","\n","    # ... (Step 1 ~ 2: 데이터 로드, 분할, 베이스라인 측정) ...\n","    print(\"Step 1: 데이터 로드 및 분할 중...\")\n","    try:\n","        df = pd.read_csv(config.CSV_FILE_PATH)\n","        labels = df[config.TARGET_COLUMN].values\n","        embeddings = np.load(config.EMBEDDING_PATH)\n","        assert len(df) == len(embeddings)\n","    except Exception as e:\n","        print(f\"🔥 파일 로드 실패: {e}\"); exit()\n","\n","    indices = np.arange(len(df))\n","    train_indices, test_indices = train_test_split(\n","        indices, test_size=config.TEST_SPLIT_RATIO, random_state=config.RANDOM_STATE, stratify=labels\n","    )\n","    X_train, X_test = embeddings[train_indices], embeddings[test_indices]\n","    y_train, y_test = labels[train_indices], labels[test_indices]\n","    print(f\"✅ 완료 (학습용: {len(y_train)}건, 테스트용: {len(y_test)}건)\")\n","\n","    print(\"\\n\" + \"=\"*50)\n","    print(\"📊 Step 2: 베이스라인 모델 성능 측정 (GPU 사용)\")\n","    print(\"=\"*50)\n","\n","    baseline_model = lgb.LGBMClassifier(device='gpu', random_state=config.RANDOM_STATE)\n","    baseline_model.fit(X_train, y_train)\n","\n","    y_pred_proba_base = baseline_model.predict_proba(X_test)[:, 1]\n","    y_pred_class_base = (y_pred_proba_base > 0.5).astype(int)\n","\n","    final_results = {}\n","    final_results['Baseline'] = {\n","        \"PR AUC\": average_precision_score(y_test, y_pred_proba_base),\n","        \"ROC AUC\": roc_auc_score(y_test, y_pred_proba_base),\n","        \"F1-Score\": f1_score(y_test, y_pred_class_base),\n","    }\n","    print(\"✅ 베이스라인 모델 평가 완료.\")\n","\n","    # --- Step 3: Optuna 튜닝 수행 (조기 종료 포함) ---\n","    print(\"\\n\" + \"=\"*50)\n","    print(f\"🔬 Step 3: Optuna 하이퍼파라미터 튜닝 시작 (GPU 사용)...\")\n","    print(f\"(최대 {config.N_TRIALS}번 시도, {config.EARLY_STOPPING_ROUNDS}번 개선 없으면 조기 종료)\")\n","    print(\"=\"*50)\n","\n","    early_stopping_callback = EarlyStoppingCallback(early_stopping_rounds=config.EARLY_STOPPING_ROUNDS)\n","    study = optuna.create_study(direction='maximize')\n","    pbar = tqdm(total=config.N_TRIALS, desc=\"Optuna 튜닝 진행률\")\n","\n","    try:\n","        study.optimize(lambda trial: objective(trial, X_train, y_train),\n","                       n_trials=config.N_TRIALS,\n","                       callbacks=[lambda study, trial: pbar.update(1), early_stopping_callback])\n","    except optuna.exceptions.OptunaError:\n","        # 조기 종료 시 발생하는 예외를 정상 처리\n","        pass\n","    pbar.close()\n","\n","    # ... (Step 4 ~ 6: 결과 출력, 저장, 메모리 정리) ...\n","    print(f\"\\n✅ 튜닝 완료!\")\n","    print(\"\\n\" + \"=\"*50)\n","    print(\"🔬 최적 하이퍼파라미터 (Best Hyperparameters)\")\n","    print(\"=\"*50)\n","    best_params = study.best_params\n","    for key, value in best_params.items():\n","        print(f\"{key:>20s}: {value}\")\n","    print(\"=\"*50)\n","\n","    print(f\"\\n🔬 Step 5: 튜닝된 최종 모델 학습 및 평가...\")\n","    final_model = lgb.LGBMClassifier(device='gpu', objective='binary', verbosity=-1, random_state=config.RANDOM_STATE, **best_params)\n","    final_model.fit(X_train, y_train)\n","\n","    y_pred_proba_tuned = final_model.predict_proba(X_test)[:, 1]\n","    y_pred_class_tuned = (y_pred_proba_tuned > 0.5).astype(int)\n","\n","    final_results['Optuna Tuned'] = {\n","        \"PR AUC\": average_precision_score(y_test, y_pred_proba_tuned),\n","        \"ROC AUC\": roc_auc_score(y_test, y_pred_proba_tuned),\n","        \"F1-Score\": f1_score(y_test, y_pred_class_tuned),\n","    }\n","    print(\"✅ 튜닝된 모델 평가 완료.\")\n","\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"📊 최종 성능 비교 결과 (Test Set)\")\n","    print(\"=\"*60)\n","    results_df = pd.DataFrame(final_results).T\n","    print(results_df.round(4))\n","\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"💾 Step 6: 최종 모델 예측 결과를 원본 CSV에 추가하여 저장\")\n","    print(\"=\"*60)\n","\n","    train_pred_proba = final_model.predict_proba(X_train)[:, 1]\n","    train_pred_class = (train_pred_proba > 0.5).astype(int)\n","\n","    df['s2_pred_proba'] = np.nan\n","    df['s2_pred_class'] = np.nan\n","\n","    df.loc[train_indices, 's2_pred_proba'] = train_pred_proba\n","    df.loc[train_indices, 's2_pred_class'] = train_pred_class\n","\n","    df.loc[test_indices, 's2_pred_proba'] = y_pred_proba_tuned\n","    df.loc[test_indices, 's2_pred_class'] = y_pred_class_tuned\n","\n","    # 🌟 Config에 설정된 경로로 최종 파일 저장\n","    df.to_csv(config.OUTPUT_CSV_PATH, index=False, encoding='utf-8-sig')\n","\n","    print(f\"✅ 모든 데이터의 예측 결과가 '{config.OUTPUT_CSV_PATH}' 파일에 성공적으로 저장되었습니다.\")\n","\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"🧹 Step 7: 사용된 변수들을 메모리에서 정리\")\n","    print(\"=\"*60)\n","\n","    vars_to_delete = [\n","        'df', 'labels', 'embeddings', 'indices', 'X_train', 'X_test',\n","        'y_train', 'y_test', 'train_indices', 'test_indices',\n","        'baseline_model', 'final_model', 'study',\n","    ]\n","    for var_name in vars_to_delete:\n","        if var_name in locals() or var_name in globals():\n","            if var_name in globals(): del globals()[var_name]\n","\n","    gc.collect()\n","    print(\"✅ 메모리 정리가 완료되었습니다.\")\n","\n","    print(\"\\n🎉 모든 과정이 완료되었습니다!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["774a2007da144d5a95761044ba085343","8ee3067ddf174102af385974aea595ff","662832e895434edfaa746fcbaa63d02c","ff5c630081b047a9ba507b57b6a066f5","06b7c018bf4642f984664a2b7cf499a0","629e7689947647c19b36a5835bd347e9","0e1ad76036894bb783156ee02ab93ee6","f5b02a375ab641a9a7dd7bbf007544fb","14803f7e8a904086a49c46aa96fd6cf0","67cc19e50316462ea13317fa353b98bb","3c4e2e42f0ac4beda5a9c49465e3b9c7"]},"id":"0LGaP64LvWm8","executionInfo":{"status":"ok","timestamp":1760254501966,"user_tz":-540,"elapsed":1023684,"user":{"displayName":"KW-data-analytics","userId":"09651493752354345908"}},"outputId":"6debd270-2f26-4544-ae25-038aacdf9651"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Step 1: 데이터 로드 및 분할 중...\n","✅ 완료 (학습용: 71604건, 테스트용: 17901건)\n","\n","==================================================\n","📊 Step 2: 베이스라인 모델 성능 측정 (GPU 사용)\n","==================================================\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-10-12 07:18:10,135] A new study created in memory with name: no-name-48295338-fd4c-4ab1-af28-fa865339f7a3\n"]},{"output_type":"stream","name":"stdout","text":["✅ 베이스라인 모델 평가 완료.\n","\n","==================================================\n","🔬 Step 3: Optuna 하이퍼파라미터 튜닝 시작 (GPU 사용)...\n","(최대 50번 시도, 10번 개선 없으면 조기 종료)\n","==================================================\n"]},{"output_type":"display_data","data":{"text/plain":["Optuna 튜닝 진행률:   0%|          | 0/50 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"774a2007da144d5a95761044ba085343"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2025-10-12 07:20:17,917] Trial 0 finished with value: 0.1521748529026728 and parameters: {'n_estimators': 1300, 'learning_rate': 0.0024485150348445297, 'num_leaves': 144, 'max_depth': 12, 'lambda_l1': 0.002435764204214115, 'lambda_l2': 3.6763147316705385, 'feature_fraction': 0.6970161692651633, 'bagging_fraction': 0.7533485759403914, 'bagging_freq': 7}. Best is trial 0 with value: 0.1521748529026728.\n","[I 2025-10-12 07:20:46,625] Trial 1 finished with value: 0.14569827235677776 and parameters: {'n_estimators': 1100, 'learning_rate': 0.03531844522788899, 'num_leaves': 189, 'max_depth': 12, 'lambda_l1': 0.08104591707730122, 'lambda_l2': 1.6633126088066197, 'feature_fraction': 0.9178589218049207, 'bagging_fraction': 0.7487415428305433, 'bagging_freq': 3}. Best is trial 0 with value: 0.1521748529026728.\n","[I 2025-10-12 07:20:53,465] Trial 2 finished with value: 0.15004234659446855 and parameters: {'n_estimators': 100, 'learning_rate': 0.07212590610774523, 'num_leaves': 100, 'max_depth': 6, 'lambda_l1': 9.167670837113097e-05, 'lambda_l2': 2.0622995157053063e-06, 'feature_fraction': 0.775815825842051, 'bagging_fraction': 0.8437827319871254, 'bagging_freq': 1}. Best is trial 0 with value: 0.1521748529026728.\n","[I 2025-10-12 07:21:05,835] Trial 3 finished with value: 0.14574699098053528 and parameters: {'n_estimators': 400, 'learning_rate': 0.06310512366764572, 'num_leaves': 84, 'max_depth': 9, 'lambda_l1': 3.3009990248908115e-07, 'lambda_l2': 1.6115625879678865e-05, 'feature_fraction': 0.8000507680938369, 'bagging_fraction': 0.8736718703434003, 'bagging_freq': 4}. Best is trial 0 with value: 0.1521748529026728.\n","[I 2025-10-12 07:21:13,177] Trial 4 finished with value: 0.1483999647322973 and parameters: {'n_estimators': 400, 'learning_rate': 0.0369605519832293, 'num_leaves': 107, 'max_depth': 5, 'lambda_l1': 5.935072063996105e-05, 'lambda_l2': 3.052421109492566e-07, 'feature_fraction': 0.8772692189920681, 'bagging_fraction': 0.7199683676481993, 'bagging_freq': 6}. Best is trial 0 with value: 0.1521748529026728.\n","[I 2025-10-12 07:21:27,804] Trial 5 finished with value: 0.14920366811722285 and parameters: {'n_estimators': 100, 'learning_rate': 0.014460418728651543, 'num_leaves': 168, 'max_depth': 9, 'lambda_l1': 2.2079948197827945e-07, 'lambda_l2': 5.952400791712205e-07, 'feature_fraction': 0.8437209002520197, 'bagging_fraction': 0.6931890204266061, 'bagging_freq': 2}. Best is trial 0 with value: 0.1521748529026728.\n","[I 2025-10-12 07:21:42,241] Trial 6 finished with value: 0.11600669677928083 and parameters: {'n_estimators': 1500, 'learning_rate': 0.2871987364690663, 'num_leaves': 123, 'max_depth': 10, 'lambda_l1': 8.440586824360816e-05, 'lambda_l2': 2.925954263994262e-05, 'feature_fraction': 0.9658893265632946, 'bagging_fraction': 0.652167184858897, 'bagging_freq': 7}. Best is trial 0 with value: 0.1521748529026728.\n","[I 2025-10-12 07:22:26,852] Trial 7 finished with value: 0.1453721829657864 and parameters: {'n_estimators': 700, 'learning_rate': 0.012822525288860229, 'num_leaves': 225, 'max_depth': 11, 'lambda_l1': 5.5112889956815094e-05, 'lambda_l2': 0.054122701902300306, 'feature_fraction': 0.915128643149191, 'bagging_fraction': 0.8671460220673273, 'bagging_freq': 7}. Best is trial 0 with value: 0.1521748529026728.\n","[I 2025-10-12 07:22:43,125] Trial 8 finished with value: 0.14403315950054651 and parameters: {'n_estimators': 700, 'learning_rate': 0.04399013179418077, 'num_leaves': 134, 'max_depth': 9, 'lambda_l1': 0.07252168637216552, 'lambda_l2': 0.000197697287894182, 'feature_fraction': 0.6973196906042485, 'bagging_fraction': 0.7739520794566555, 'bagging_freq': 4}. Best is trial 0 with value: 0.1521748529026728.\n","[I 2025-10-12 07:23:49,867] Trial 9 finished with value: 0.1539220148696564 and parameters: {'n_estimators': 600, 'learning_rate': 0.003479008713147986, 'num_leaves': 146, 'max_depth': 12, 'lambda_l1': 0.06922540741247236, 'lambda_l2': 0.0009527167291907011, 'feature_fraction': 0.7614063818521524, 'bagging_fraction': 0.726514458382889, 'bagging_freq': 7}. Best is trial 9 with value: 0.1539220148696564.\n","[I 2025-10-12 07:24:05,268] Trial 10 finished with value: 0.15055080914080904 and parameters: {'n_estimators': 2000, 'learning_rate': 0.0010792879240622986, 'num_leaves': 22, 'max_depth': 3, 'lambda_l1': 8.800908697754018, 'lambda_l2': 0.019965120336446613, 'feature_fraction': 0.6318307264514273, 'bagging_fraction': 0.9947840261204639, 'bagging_freq': 5}. Best is trial 9 with value: 0.1539220148696564.\n","[I 2025-10-12 07:27:15,047] Trial 11 finished with value: 0.15110775149600858 and parameters: {'n_estimators': 1300, 'learning_rate': 0.0022975467722396265, 'num_leaves': 300, 'max_depth': 12, 'lambda_l1': 0.013133121001384605, 'lambda_l2': 9.84336823258475, 'feature_fraction': 0.7183705887960209, 'bagging_fraction': 0.6208300823113658, 'bagging_freq': 6}. Best is trial 9 with value: 0.1539220148696564.\n","[I 2025-10-12 07:28:48,990] Trial 12 finished with value: 0.15153357491144287 and parameters: {'n_estimators': 1700, 'learning_rate': 0.0036508654315460945, 'num_leaves': 229, 'max_depth': 12, 'lambda_l1': 0.004250880982836873, 'lambda_l2': 0.008759950291523662, 'feature_fraction': 0.6082125422368507, 'bagging_fraction': 0.8103580485171054, 'bagging_freq': 6}. Best is trial 9 with value: 0.1539220148696564.\n","[I 2025-10-12 07:29:22,215] Trial 13 finished with value: 0.15333309283822943 and parameters: {'n_estimators': 800, 'learning_rate': 0.005126765719784573, 'num_leaves': 48, 'max_depth': 10, 'lambda_l1': 2.4831931636182807, 'lambda_l2': 1.1133832636665813e-08, 'feature_fraction': 0.7133881119655905, 'bagging_fraction': 0.6855192792307195, 'bagging_freq': 7}. Best is trial 9 with value: 0.1539220148696564.\n","[I 2025-10-12 07:29:47,735] Trial 14 finished with value: 0.15322746523976155 and parameters: {'n_estimators': 800, 'learning_rate': 0.006311203083608541, 'num_leaves': 33, 'max_depth': 7, 'lambda_l1': 8.888964059718408, 'lambda_l2': 1.4671894042099337e-08, 'feature_fraction': 0.7594939124675739, 'bagging_fraction': 0.6921839729910508, 'bagging_freq': 5}. Best is trial 9 with value: 0.1539220148696564.\n","[I 2025-10-12 07:30:22,304] Trial 15 finished with value: 0.15237742408142846 and parameters: {'n_estimators': 900, 'learning_rate': 0.0071580921479511995, 'num_leaves': 67, 'max_depth': 10, 'lambda_l1': 0.5783464605614375, 'lambda_l2': 0.0019066373738740887, 'feature_fraction': 0.677510714635186, 'bagging_fraction': 0.6159788612454484, 'bagging_freq': 5}. Best is trial 9 with value: 0.1539220148696564.\n","[I 2025-10-12 07:30:47,823] Trial 16 finished with value: 0.152188517046397 and parameters: {'n_estimators': 500, 'learning_rate': 0.0012386747976647372, 'num_leaves': 54, 'max_depth': 10, 'lambda_l1': 0.6424707292475798, 'lambda_l2': 2.638017875190807e-08, 'feature_fraction': 0.8115933954466364, 'bagging_fraction': 0.6668277688437997, 'bagging_freq': 7}. Best is trial 9 with value: 0.1539220148696564.\n","[I 2025-10-12 07:31:31,468] Trial 17 finished with value: 0.15141769788260473 and parameters: {'n_estimators': 1100, 'learning_rate': 0.005663036268689419, 'num_leaves': 201, 'max_depth': 8, 'lambda_l1': 1.0529048850391247, 'lambda_l2': 0.00036281387969605783, 'feature_fraction': 0.7301769852762575, 'bagging_fraction': 0.9586574208846399, 'bagging_freq': 6}. Best is trial 9 with value: 0.1539220148696564.\n","[I 2025-10-12 07:33:05,959] Trial 18 finished with value: 0.15267273118155517 and parameters: {'n_estimators': 500, 'learning_rate': 0.0024473896113177173, 'num_leaves': 288, 'max_depth': 11, 'lambda_l1': 0.04730937005325313, 'lambda_l2': 0.120336056449783, 'feature_fraction': 0.7533408457320859, 'bagging_fraction': 0.8079641402877187, 'bagging_freq': 3}. Best is trial 9 with value: 0.1539220148696564.\n","[I 2025-10-12 07:33:48,270] Trial 19 finished with value: 0.15007147736994803 and parameters: {'n_estimators': 900, 'learning_rate': 0.010843587757356039, 'num_leaves': 254, 'max_depth': 11, 'lambda_l1': 0.0008252210874173645, 'lambda_l2': 1.0866591077399166e-05, 'feature_fraction': 0.6500457871678055, 'bagging_fraction': 0.7292375319636661, 'bagging_freq': 5}. Best is trial 9 with value: 0.1539220148696564.\n"]},{"output_type":"stream","name":"stdout","text":["\n","[Optuna 조기 종료] 10번의 trial 동안 최고 점수가 갱신되지 않아 튜닝을 중단합니다.\n","\n","✅ 튜닝 완료!\n","\n","==================================================\n","🔬 최적 하이퍼파라미터 (Best Hyperparameters)\n","==================================================\n","        n_estimators: 600\n","       learning_rate: 0.003479008713147986\n","          num_leaves: 146\n","           max_depth: 12\n","           lambda_l1: 0.06922540741247236\n","           lambda_l2: 0.0009527167291907011\n","    feature_fraction: 0.7614063818521524\n","    bagging_fraction: 0.726514458382889\n","        bagging_freq: 7\n","==================================================\n","\n","🔬 Step 5: 튜닝된 최종 모델 학습 및 평가...\n","✅ 튜닝된 모델 평가 완료.\n","\n","============================================================\n","📊 최종 성능 비교 결과 (Test Set)\n","============================================================\n","              PR AUC  ROC AUC  F1-Score\n","Baseline      0.1479   0.6201    0.0036\n","Optuna Tuned  0.1585   0.6254    0.0000\n","\n","============================================================\n","💾 Step 6: 최종 모델 예측 결과를 원본 CSV에 추가하여 저장\n","============================================================\n","✅ 모든 데이터의 예측 결과가 '/content/drive/MyDrive/review_helpfulness/PADA/results/s2/hotel/DistilBERT_hotel_with_s2_predictions.csv' 파일에 성공적으로 저장되었습니다.\n","\n","============================================================\n","🧹 Step 7: 사용된 변수들을 메모리에서 정리\n","============================================================\n","✅ 메모리 정리가 완료되었습니다.\n","\n","🎉 모든 과정이 완료되었습니다!\n"]}]}]}