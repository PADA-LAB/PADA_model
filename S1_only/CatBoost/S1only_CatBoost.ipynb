{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mAelB_MH6iJ2"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r7FOCcInJoMf"
      },
      "outputs": [],
      "source": [
        "!pip -q install optuna catboost tqdm ipywidgets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eypT3dG09jOa"
      },
      "outputs": [],
      "source": [
        "# ============================================\n",
        "# CatBoost (GPU 안전 스위치 + 경고 억제 + 견고성 패치)\n",
        "# ============================================\n",
        "import os, json, warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.metrics import (\n",
        "    average_precision_score, roc_auc_score, f1_score, accuracy_score,\n",
        "    precision_recall_curve\n",
        ")\n",
        "import optuna\n",
        "from tqdm.notebook import tqdm\n",
        "from catboost import CatBoostClassifier, Pool\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
        "\n",
        "# --------------------------------\n",
        "# 파일 경로\n",
        "# --------------------------------\n",
        "FILE_PATHS = {\n",
        "    \"Amazon\":  '/content/drive/MyDrive/1014/data/new_amazon.csv',\n",
        "    \"Coursera\":'/content/drive/MyDrive/1014/data/new_coursera.csv',\n",
        "    \"Audible\": '/content/drive/MyDrive/1014/data/new_audible.csv',\n",
        "    \"Hotel\":   '/content/drive/MyDrive/1014/data/new_hotel.csv'\n",
        "}\n",
        "\n",
        "# --------------------------------\n",
        "# S1 피처\n",
        "# --------------------------------\n",
        "S1_FEATURES = {\n",
        "    \"Amazon\":  ['Average_Rating','Rating','Deviation_Of_Star_Ratings','Time_Lapsed','Price','Text_Length','Valence','Arousal','Title_Length','Num_of_Ratings','Is_Photo','Flesch_Reading_Ease','FOG_Index','Sentiment_Score','new_depth','new_breadth'],\n",
        "    \"Coursera\":['Average_Rating','Rating','Deviation_Of_Star_Ratings','Time_Lapsed','Num_of_Reviews','Num_of_Enrolled','Num_of_top_instructor_courses','Num_of_top_instructor_learners','Text_Length','Valence','Arousal','Num_of_Ratings','Flesch_Reading_Ease','FOG_Index','Sentiment_Score','new_depth','new_breadth'],\n",
        "    \"Audible\": ['Average_Rating','Rating','Deviation_Of_Star_Ratings','Time_Lapsed','Text_Length','Valence','Arousal','Title_Length','Num_of_Ratings','Flesch_Reading_Ease','FOG_Index','Sentiment_Score','new_depth','new_breadth'],\n",
        "    \"Hotel\":   ['Average_Rating','Rating','Deviation_Of_Star_Ratings','Time_Lapsed','Text_Length','Valence','Arousal','Title_Length','Num_of_Ratings','Flesch_Reading_Ease','FOG_Index','Sentiment_Score','new_depth','new_breadth','Is_Photo','Hotel_Grade','Employee_Friendliness_Score','Facility_Score','Cleanliness_Score','Comfort_Score','Value_For_Money_Score','Location_Score']\n",
        "}\n",
        "\n",
        "# --------------------------------\n",
        "# Config\n",
        "# --------------------------------\n",
        "TARGET_COLUMN   = 'binary_helpfulness'\n",
        "TEST_SPLIT_RATIO= 0.2\n",
        "RANDOM_STATE    = 42\n",
        "N_TRIALS        = 50\n",
        "\n",
        "# GPU 사용 여부 (코랩이 CPU면 False로)\n",
        "USE_GPU = True\n",
        "STATIC_CTB = {\n",
        "    'task_type': 'GPU' if USE_GPU else 'CPU',\n",
        "    **({'devices':'0'} if USE_GPU else {}),\n",
        "    'logging_level': 'Silent',\n",
        "    'bootstrap_type': 'Bernoulli',\n",
        "    'random_seed': RANDOM_STATE,\n",
        "    'allow_writing_files': False\n",
        "}\n",
        "\n",
        "def _make_numeric_df(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    num = df.apply(pd.to_numeric, errors='coerce')\n",
        "    med = num.median()\n",
        "    return num.fillna(med)\n",
        "\n",
        "def _best_threshold_by_f1(y_true, prob):\n",
        "    precision, recall, thresholds = precision_recall_curve(y_true, prob)\n",
        "    thresholds = np.concatenate([thresholds, [1.0]])\n",
        "    f1s = (2 * precision * recall) / np.clip(precision + recall, 1e-9, None)\n",
        "    idx = int(np.nanargmax(f1s))\n",
        "    return float(thresholds[idx])\n",
        "\n",
        "def run_s1_pipeline(platform, csv_path, features):\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(f\"▶ Platform: {platform}\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Step 1. 데이터 로드\n",
        "    df = pd.read_csv(csv_path)\n",
        "    if TARGET_COLUMN not in df.columns:\n",
        "        raise ValueError(f\"[{platform}] '{TARGET_COLUMN}' 컬럼이 없습니다.\")\n",
        "    labels = df[TARGET_COLUMN].astype(int).values\n",
        "\n",
        "    exists = [c for c in features if c in df.columns]\n",
        "    if not exists:\n",
        "        raise ValueError(f\"[{platform}] 사용 가능한 S1 피처가 없습니다.\")\n",
        "\n",
        "    # 수치화 + Inf/NaN 방어\n",
        "    X_all = (_make_numeric_df(df[exists])\n",
        "             .replace([np.inf, -np.inf], np.nan)\n",
        "             .fillna(0.0)\n",
        "             .to_numpy())\n",
        "\n",
        "    # Stratified split\n",
        "    idx = np.arange(len(df))\n",
        "    tr_idx, te_idx = train_test_split(\n",
        "        idx, test_size=TEST_SPLIT_RATIO, random_state=RANDOM_STATE, stratify=labels\n",
        "    )\n",
        "    X_train, X_test = X_all[tr_idx], X_all[te_idx]\n",
        "    y_train, y_test = labels[tr_idx], labels[te_idx]\n",
        "    print(f\"✅ Train={len(y_train)}, Test={len(y_test)}\")\n",
        "\n",
        "    # ---------- Optuna (CatBoost) ----------\n",
        "    # 내부 메트릭은 GPU에서 경고 없는 'AUC'로, 선택은 외부 PR AUC로\n",
        "    def objective(trial):\n",
        "        tuned = {\n",
        "            'objective': 'Logloss',\n",
        "            'eval_metric': 'AUC',\n",
        "            'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
        "            'iterations': trial.suggest_int('iterations', 100, 2000, step=100),\n",
        "            'learning_rate': trial.suggest_float('learning_rate', 1e-3, 0.3, log=True),\n",
        "            'depth': trial.suggest_int('depth', 3, 12),\n",
        "            'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1e-8, 10.0, log=True)\n",
        "        }\n",
        "        skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=RANDOM_STATE)\n",
        "        pr_aucs = []\n",
        "        for tr, va in skf.split(X_train, y_train):\n",
        "            model = CatBoostClassifier(**STATIC_CTB, **tuned)\n",
        "            model.fit(\n",
        "                Pool(X_train[tr], y_train[tr]),\n",
        "                eval_set=Pool(X_train[va], y_train[va]),\n",
        "                early_stopping_rounds=100,\n",
        "                use_best_model=True\n",
        "            )\n",
        "            prob = model.predict_proba(X_train[va])[:, 1]\n",
        "            pr_aucs.append(average_precision_score(y_train[va], prob))\n",
        "        return float(np.mean(pr_aucs))\n",
        "\n",
        "    study = optuna.create_study(direction=\"maximize\")\n",
        "    with tqdm(total=N_TRIALS, desc=f\"Optuna Tuning [{platform}]\", unit=\"trial\") as pbar:\n",
        "        study.optimize(objective, n_trials=N_TRIALS, callbacks=[lambda s, t: pbar.update(1)])\n",
        "\n",
        "    best_params = study.best_params\n",
        "    print(\"🧪 Best Params:\", best_params)\n",
        "\n",
        "    # Step 3. 최종 학습\n",
        "    clf = CatBoostClassifier(**STATIC_CTB, **best_params)\n",
        "    clf.fit(\n",
        "        Pool(X_train, y_train),\n",
        "        eval_set=Pool(X_test, y_test),\n",
        "        early_stopping_rounds=100,\n",
        "        use_best_model=True\n",
        "    )\n",
        "\n",
        "    # Step 4. 평가 (+ 임계값 F1 기준)\n",
        "    train_prob = clf.predict_proba(X_train)[:, 1]\n",
        "    test_prob  = clf.predict_proba(X_test)[:, 1]\n",
        "    best_th = _best_threshold_by_f1(y_train, train_prob)\n",
        "    test_pred = (test_prob >= best_th).astype(int)\n",
        "\n",
        "    metrics = {\n",
        "        \"Accuracy\": float(accuracy_score(y_test, test_pred)),\n",
        "        \"PR_AUC\":   float(average_precision_score(y_test, test_prob)),\n",
        "        \"ROC_AUC\":  float(roc_auc_score(y_test, test_prob)),\n",
        "        \"F1_score\": float(f1_score(y_test, test_pred)),\n",
        "        \"Best_Threshold\": float(best_th)\n",
        "    }\n",
        "    print(\"=== Test Metrics ===\", metrics)\n",
        "\n",
        "    # Step 5. 저장\n",
        "    save_dir = f\"/content/drive/MyDrive/1014/result_catboost/{platform}\"\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "    pd.DataFrame({\n",
        "        \"index\": te_idx,\n",
        "        \"s1_pred_proba\": test_prob,\n",
        "        \"y_true\": y_test,\n",
        "        \"y_pred_at_best_th\": test_pred\n",
        "    }).to_csv(f\"{save_dir}/s1_pred_proba.csv\", index=False)\n",
        "    with open(f\"{save_dir}/results.json\", \"w\") as f:\n",
        "        json.dump(metrics, f, indent=2)\n",
        "    clf.save_model(f\"{save_dir}/catboost_model.cbm\")\n",
        "\n",
        "# ---- 전체 실행\n",
        "for platform, path in tqdm(FILE_PATHS.items(), desc=\"전체 플랫폼 진행 (CatBoost)\", unit=\"platform\"):\n",
        "    run_s1_pipeline(platform, path, S1_FEATURES[platform])"
      ]
    }
  ]
}
